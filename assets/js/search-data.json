{
  
    
        "post0": {
            "title": "Do it 자연어) 2. 숫자 세계로 떠난 자연어",
            "content": ". &#49472;&#54532; &#50612;&#53584;&#49440; &#46041;&#51089;&#50896;&#47532; . import torch x = torch.tensor([ [1.0, 0.0, 1.0, 0.0], [0.0, 2.0, 0.0, 2.0], [1.0, 1.0, 1.0, 1.0], ]) w_query = torch.tensor([ [1.0, 0.0, 1.0], [1.0, 0.0, 0.0], [0.0, 0.0, 1.0], [0.0, 1.0, 1.0], ]) w_key = torch.tensor([ [0.0, 0.0, 1.0], [1.0, 1.0, 0.0], [0.0, 1.0, 0.0], [1.0, 1.0, 0.0], ]) w_value = torch.tensor([ [0.0, 2.0, 0.0], [0.0, 3.0, 0.0], [1.0, 0.0, 3.0], [1.0, 1.0, 0.0], ]) . 변수를 정의합니다. . keys = torch.matmul(x, w_key) querys = torch.matmul(x, w_query) values = torch.matmul(x, w_value) . 쿼리, 키, 벨류를 만듭니다. . attn_scores = torch.matmul(querys, keys.T) attn_scores . tensor([[ 2., 4., 4.], [ 4., 16., 12.], [ 4., 12., 10.]]) . 어텐션 스코어를 만듭니다. . import numpy as np from torch.nn.functional import softmax key_dim_sqrt = np.sqrt(keys.shape[-1]) attn_probs = softmax(attn_scores / key_dim_sqrt, dim = -1) attn_probs . tensor([[1.3613e-01, 4.3194e-01, 4.3194e-01], [8.9045e-04, 9.0884e-01, 9.0267e-02], [7.4449e-03, 7.5471e-01, 2.3785e-01]]) . 소프트맥스 확률값을 만듭니다. . weighted_values = torch.matmul(attn_probs, values) weighted_values . tensor([[1.8639, 6.3194, 1.7042], [1.9991, 7.8141, 0.2735], [1.9926, 7.4796, 0.7359]]) . 소프트맥스 확률과 밸류를 가중합 하였습니다. 셀프 어텐션에 최종 출력값 입니다. . 셀프 어텐션은 가중치 행렬(w_..) 3개를 학습 대상으로 생각하고 태스크를 잘 수행하는 방향으로 업데이트 됩니다. . &#54588;&#46300;&#54252;&#50892;&#46300; &#45684;&#47092; &#45348;&#53944;&#50892;&#53356; &#44228;&#49328; &#50696;&#49884; . import torch x = torch.tensor([2,1]) w1 = torch.tensor([[3,2,-4],[2,-3,1]]) b1 = 1 w2 = torch.tensor([[-1,1],[1,2],[3,1]]) b2 = -1 . 변수를 입력합니다. . h_preact = torch.matmul(x, w1) + b1 h = torch.nn.functional.relu(h_preact) y = torch.matmul(h, w2) + b2 y . tensor([-8, 12]) . 결과 값 입니다. 여기서 w1, w2, b1, b2가 학습 대상이 됩니다. . 학습 대상은 태스크를 잘 수행하는 방향으로 업데이트 됩니다. . m = torch.nn.Dropout(p = 0.2) input = torch.randn(1,10) output = m(input) print(input) print(output) . tensor([[ 0.3678, 1.6664, 1.6091, 0.1445, 0.9486, 2.0537, 2.4539, 1.4420, 0.9701, -0.2877]]) tensor([[0.0000, 2.0830, 2.0113, 0.1806, 1.1858, 2.5672, 0.0000, 1.8025, 0.0000, -0.0000]]) . 간단한 드롭다웃 예제입니다. p 확률 만큼 뉴련을 0으로 대치해 계산에서 제외합니다. . &#47928;&#51109;&#51012; &#48289;&#53552;&#47196; &#48320;&#54872;&#54616;&#44592; . !pip install ratsnlp . Collecting ratsnlp Downloading ratsnlp-0.0.9999-py3-none-any.whl (53 kB) |████████████████████████████████| 53 kB 1.6 MB/s Requirement already satisfied: flask&gt;=1.1.4 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.1.4) Requirement already satisfied: torch&gt;=1.9.0 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.10.0+cu111) Collecting pytorch-lightning==1.3.4 Downloading pytorch_lightning-1.3.4-py3-none-any.whl (806 kB) |████████████████████████████████| 806 kB 15.9 MB/s Collecting flask-cors&gt;=3.0.10 Downloading Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB) Collecting flask-ngrok&gt;=0.0.25 Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB) Collecting Korpora&gt;=0.2.0 Downloading Korpora-0.2.0-py3-none-any.whl (57 kB) |████████████████████████████████| 57 kB 6.4 MB/s Collecting transformers==4.10.0 Downloading transformers-4.10.0-py3-none-any.whl (2.8 MB) |████████████████████████████████| 2.8 MB 37.5 MB/s Collecting PyYAML&lt;=5.4.1,&gt;=5.1 Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB) |████████████████████████████████| 636 kB 56.2 MB/s Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-&gt;ratsnlp) (21.3) Requirement already satisfied: numpy&gt;=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-&gt;ratsnlp) (1.19.5) Requirement already satisfied: tqdm&gt;=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-&gt;ratsnlp) (4.62.3) Collecting future&gt;=0.17.1 Downloading future-0.18.2.tar.gz (829 kB) |████████████████████████████████| 829 kB 59.2 MB/s Collecting fsspec[http]&gt;=2021.4.0 Downloading fsspec-2021.11.1-py3-none-any.whl (132 kB) |████████████████████████████████| 132 kB 52.0 MB/s Requirement already satisfied: tensorboard!=2.5.0,&gt;=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-&gt;ratsnlp) (2.7.0) Collecting torchmetrics&gt;=0.2.0 Downloading torchmetrics-0.6.2-py3-none-any.whl (332 kB) |████████████████████████████████| 332 kB 64.2 MB/s Collecting pyDeprecate==0.3.0 Downloading pyDeprecate-0.3.0-py3-none-any.whl (10 kB) Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-&gt;ratsnlp) (3.4.0) Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-&gt;ratsnlp) (2019.12.20) Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-&gt;ratsnlp) (4.8.2) Collecting sacremoses Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB) |████████████████████████████████| 895 kB 44.7 MB/s Collecting huggingface-hub&gt;=0.0.12 Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB) |████████████████████████████████| 61 kB 671 kB/s Collecting tokenizers&lt;0.11,&gt;=0.10.1 Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB) |████████████████████████████████| 3.3 MB 48.7 MB/s Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-&gt;ratsnlp) (2.23.0) Requirement already satisfied: click&lt;8.0,&gt;=5.1 in /usr/local/lib/python3.7/dist-packages (from flask&gt;=1.1.4-&gt;ratsnlp) (7.1.2) Requirement already satisfied: Jinja2&lt;3.0,&gt;=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask&gt;=1.1.4-&gt;ratsnlp) (2.11.3) Requirement already satisfied: Werkzeug&lt;2.0,&gt;=0.15 in /usr/local/lib/python3.7/dist-packages (from flask&gt;=1.1.4-&gt;ratsnlp) (1.0.1) Requirement already satisfied: itsdangerous&lt;2.0,&gt;=0.24 in /usr/local/lib/python3.7/dist-packages (from flask&gt;=1.1.4-&gt;ratsnlp) (1.1.0) Requirement already satisfied: Six in /usr/local/lib/python3.7/dist-packages (from flask-cors&gt;=3.0.10-&gt;ratsnlp) (1.15.0) Collecting aiohttp Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB) |████████████████████████████████| 1.1 MB 46.2 MB/s Requirement already satisfied: typing-extensions&gt;=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub&gt;=0.0.12-&gt;transformers==4.10.0-&gt;ratsnlp) (3.10.0.2) Requirement already satisfied: MarkupSafe&gt;=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2&lt;3.0,&gt;=2.10.1-&gt;flask&gt;=1.1.4-&gt;ratsnlp) (2.0.1) Collecting xlrd&gt;=1.2.0 Downloading xlrd-2.0.1-py2.py3-none-any.whl (96 kB) |████████████████████████████████| 96 kB 6.6 MB/s Collecting dataclasses&gt;=0.6 Downloading dataclasses-0.6-py3-none-any.whl (14 kB) Requirement already satisfied: pyparsing!=3.0.5,&gt;=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (3.0.6) Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;transformers==4.10.0-&gt;ratsnlp) (3.0.4) Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;transformers==4.10.0-&gt;ratsnlp) (2021.10.8) Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;transformers==4.10.0-&gt;ratsnlp) (2.10) Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;transformers==4.10.0-&gt;ratsnlp) (1.24.3) Requirement already satisfied: wheel&gt;=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (0.37.0) Requirement already satisfied: absl-py&gt;=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (0.12.0) Requirement already satisfied: tensorboard-data-server&lt;0.7.0,&gt;=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (0.6.1) Requirement already satisfied: setuptools&gt;=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (57.4.0) Requirement already satisfied: tensorboard-plugin-wit&gt;=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (1.8.0) Requirement already satisfied: grpcio&gt;=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (1.42.0) Requirement already satisfied: markdown&gt;=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (3.3.6) Requirement already satisfied: google-auth-oauthlib&lt;0.5,&gt;=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (0.4.6) Requirement already satisfied: protobuf&gt;=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (3.17.3) Requirement already satisfied: google-auth&lt;3,&gt;=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (1.35.0) Requirement already satisfied: cachetools&lt;5.0,&gt;=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (4.2.4) Requirement already satisfied: rsa&lt;5,&gt;=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (4.8) Requirement already satisfied: pyasn1-modules&gt;=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (0.2.8) Requirement already satisfied: requests-oauthlib&gt;=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (1.3.0) Requirement already satisfied: zipp&gt;=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-&gt;transformers==4.10.0-&gt;ratsnlp) (3.6.0) Requirement already satisfied: pyasn1&lt;0.5.0,&gt;=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules&gt;=0.2.1-&gt;google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (0.4.8) Requirement already satisfied: oauthlib&gt;=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib&gt;=0.7.0-&gt;google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (3.1.1) Collecting yarl&lt;2.0,&gt;=1.0 Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB) |████████████████████████████████| 271 kB 69.4 MB/s Collecting multidict&lt;7.0,&gt;=4.5 Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB) |████████████████████████████████| 160 kB 57.9 MB/s Requirement already satisfied: attrs&gt;=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;fsspec[http]&gt;=2021.4.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (21.2.0) Requirement already satisfied: charset-normalizer&lt;3.0,&gt;=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;fsspec[http]&gt;=2021.4.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (2.0.8) Collecting asynctest==0.13.0 Downloading asynctest-0.13.0-py3-none-any.whl (26 kB) Collecting async-timeout&lt;5.0,&gt;=4.0.0a3 Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB) Collecting aiosignal&gt;=1.1.2 Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB) Collecting frozenlist&gt;=1.1.1 Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB) |████████████████████████████████| 192 kB 71.0 MB/s Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses-&gt;transformers==4.10.0-&gt;ratsnlp) (1.1.0) Building wheels for collected packages: future Building wheel for future (setup.py) ... done Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=3cd467807e542363544f5ce4ef26f212f5b2dd8812ec646fa206e9b85b0c7b48 Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0 Successfully built future Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, PyYAML, fsspec, aiohttp, xlrd, torchmetrics, tokenizers, sacremoses, pyDeprecate, huggingface-hub, future, dataclasses, transformers, pytorch-lightning, Korpora, flask-ngrok, flask-cors, ratsnlp Attempting uninstall: PyYAML Found existing installation: PyYAML 3.13 Uninstalling PyYAML-3.13: Successfully uninstalled PyYAML-3.13 Attempting uninstall: xlrd Found existing installation: xlrd 1.1.0 Uninstalling xlrd-1.1.0: Successfully uninstalled xlrd-1.1.0 Attempting uninstall: future Found existing installation: future 0.16.0 Uninstalling future-0.16.0: Successfully uninstalled future-0.16.0 Successfully installed Korpora-0.2.0 PyYAML-5.4.1 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 dataclasses-0.6 flask-cors-3.0.10 flask-ngrok-0.0.25 frozenlist-1.2.0 fsspec-2021.11.1 future-0.18.2 huggingface-hub-0.2.1 multidict-5.2.0 pyDeprecate-0.3.0 pytorch-lightning-1.3.4 ratsnlp-0.0.9999 sacremoses-0.0.46 tokenizers-0.10.3 torchmetrics-0.6.2 transformers-4.10.0 xlrd-2.0.1 yarl-1.7.2 . from transformers import BertTokenizer tokenizer = BertTokenizer.from_pretrained( &#39;beomi/kcbert-base&#39;, do_lower_case = False, ) . BERT(kcbert-base) 모델이 쓰는 토크나이저를 선언합니다. . from transformers import BertConfig, BertModel pretrained_model_config = BertConfig.from_pretrained( &#39;beomi/kcbert-base&#39; ) model = BertModel.from_pretrained( &#39;beomi/kcbert-base&#39;, config = pretrained_model_config, ) . Some weights of the model checkpoint at beomi/kcbert-base were not used when initializing BertModel: [&#39;cls.predictions.transform.LayerNorm.bias&#39;, &#39;cls.seq_relationship.weight&#39;, &#39;cls.predictions.transform.LayerNorm.weight&#39;, &#39;cls.predictions.transform.dense.bias&#39;, &#39;cls.predictions.decoder.weight&#39;, &#39;cls.seq_relationship.bias&#39;, &#39;cls.predictions.bias&#39;, &#39;cls.predictions.decoder.bias&#39;, &#39;cls.predictions.transform.dense.weight&#39;] - This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model). - This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model). . BERT(kcbert-base) 모델을 읽어들입니다. . pretrained_model_config . BertConfig { &#34;_name_or_path&#34;: &#34;beomi/kcbert-base&#34;, &#34;architectures&#34;: [ &#34;BertForMaskedLM&#34; ], &#34;attention_probs_dropout_prob&#34;: 0.1, &#34;classifier_dropout&#34;: null, &#34;directionality&#34;: &#34;bidi&#34;, &#34;gradient_checkpointing&#34;: false, &#34;hidden_act&#34;: &#34;gelu&#34;, &#34;hidden_dropout_prob&#34;: 0.1, &#34;hidden_size&#34;: 768, &#34;initializer_range&#34;: 0.02, &#34;intermediate_size&#34;: 3072, &#34;layer_norm_eps&#34;: 1e-12, &#34;max_position_embeddings&#34;: 300, &#34;model_type&#34;: &#34;bert&#34;, &#34;num_attention_heads&#34;: 12, &#34;num_hidden_layers&#34;: 12, &#34;pad_token_id&#34;: 0, &#34;pooler_fc_size&#34;: 768, &#34;pooler_num_attention_heads&#34;: 12, &#34;pooler_num_fc_layers&#34;: 3, &#34;pooler_size_per_head&#34;: 128, &#34;pooler_type&#34;: &#34;first_token_transform&#34;, &#34;position_embedding_type&#34;: &#34;absolute&#34;, &#34;transformers_version&#34;: &#34;4.10.0&#34;, &#34;type_vocab_size&#34;: 2, &#34;use_cache&#34;: true, &#34;vocab_size&#34;: 30000 } . pretrained_model_config은 BERT 모델을 프리트레인 할때 설정했던 내용이 있습니다. . 블록 수는 12개, 헤드 수는 12개, 어휘 집합 크기는 3만개 입니다. . sentences = [&#39;안녕하세요&#39;, &#39;하이!&#39;] features = tokenizer( sentences, max_length = 10, padding = &#39;max_length&#39;, truncation = True, ) features . {&#39;input_ids&#39;: [[2, 19017, 8482, 3, 0, 0, 0, 0, 0, 0], [2, 15830, 5, 3, 0, 0, 0, 0, 0, 0]], &#39;token_type_ids&#39;: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], &#39;attention_mask&#39;: [[1, 1, 1, 1, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 0, 0, 0, 0, 0, 0]]} . BERT 모델의 입력값을 만듭니다. 앞서 배운 BERT 모델과 같이 3개의 변수가 나옵니다. . features = {k : torch.tensor(v) for k, v in features.items()} . 피처를 파이토치에 넣기 위해선 자료형이 텐서(tensor)이여야 하기 때문에 자료형을 변경했습니다. . outputs = model(**features) outputs . BaseModelOutputWithPoolingAndCrossAttentions([(&#39;last_hidden_state&#39;, tensor([[[-0.6969, -0.8248, 1.7512, ..., -0.3732, 0.7399, 1.1907], [-1.4803, -0.4398, 0.9444, ..., -0.7405, -0.0211, 1.3064], [-1.4299, -0.5033, -0.2069, ..., 0.1285, -0.2611, 1.6057], ..., [-1.4406, 0.3431, 1.4043, ..., -0.0565, 0.8450, -0.2170], [-1.3625, -0.2404, 1.1757, ..., 0.8876, -0.1054, 0.0734], [-1.4244, 0.1518, 1.2920, ..., 0.0245, 0.7572, 0.0080]], [[ 0.9371, -1.4749, 1.7351, ..., -0.3426, 0.8050, 0.4031], [ 1.6095, -1.7269, 2.7936, ..., 0.3100, -0.4787, -1.2491], [ 0.4861, -0.4569, 0.5712, ..., -0.1769, 1.1253, -0.2756], ..., [ 1.2362, -0.6181, 2.0906, ..., 1.3677, 0.8132, -0.2742], [ 0.5409, -0.9652, 1.6237, ..., 1.2395, 0.9185, 0.1782], [ 1.9001, -0.5859, 3.0156, ..., 1.4967, 0.1924, -0.4448]]], grad_fn=&lt;NativeLayerNormBackward0&gt;)), (&#39;pooler_output&#39;, tensor([[-0.1594, 0.0547, 0.1101, ..., 0.2684, 0.1596, -0.9828], [-0.9221, 0.2969, -0.0110, ..., 0.4291, 0.0311, -0.9955]], grad_fn=&lt;TanhBackward0&gt;))]) . BERT 모델에 features를 적용했습니다. 두 개의 출력물 last_hidden_state, pooler_output이 나옵니다. . 전자를 단어수준 임베딩, 후자를 문장수준 임베딩이라고 부릅니다. .",
            "url": "https://ksy1526.github.io/myblog//myblog/2021/12/21/Do_natural_language2.html",
            "relUrl": "/2021/12/21/Do_natural_language2.html",
            "date": " • Dec 21, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Do it 자연어) 1. 문장을 작은 단위로 쪼개기",
            "content": ". &#54056;&#53412;&#51648; &#45796;&#50868;/&#44396;&#44544; &#50672;&#46041; . !pip install ratsnlp . Collecting ratsnlp Downloading ratsnlp-0.0.9999-py3-none-any.whl (53 kB) |████████████████████████████████| 53 kB 1.4 MB/s Collecting flask-ngrok&gt;=0.0.25 Downloading flask_ngrok-0.0.25-py3-none-any.whl (3.1 kB) Collecting transformers==4.10.0 Downloading transformers-4.10.0-py3-none-any.whl (2.8 MB) |████████████████████████████████| 2.8 MB 8.2 MB/s Collecting flask-cors&gt;=3.0.10 Downloading Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB) Requirement already satisfied: torch&gt;=1.9.0 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.10.0+cu111) Collecting pytorch-lightning==1.3.4 Downloading pytorch_lightning-1.3.4-py3-none-any.whl (806 kB) |████████████████████████████████| 806 kB 48.6 MB/s Requirement already satisfied: flask&gt;=1.1.4 in /usr/local/lib/python3.7/dist-packages (from ratsnlp) (1.1.4) Collecting Korpora&gt;=0.2.0 Downloading Korpora-0.2.0-py3-none-any.whl (57 kB) |████████████████████████████████| 57 kB 4.9 MB/s Requirement already satisfied: tensorboard!=2.5.0,&gt;=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-&gt;ratsnlp) (2.7.0) Collecting fsspec[http]&gt;=2021.4.0 Downloading fsspec-2021.11.1-py3-none-any.whl (132 kB) |████████████████████████████████| 132 kB 31.4 MB/s Collecting pyDeprecate==0.3.0 Downloading pyDeprecate-0.3.0-py3-none-any.whl (10 kB) Collecting torchmetrics&gt;=0.2.0 Downloading torchmetrics-0.6.2-py3-none-any.whl (332 kB) |████████████████████████████████| 332 kB 55.5 MB/s Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-&gt;ratsnlp) (21.3) Collecting future&gt;=0.17.1 Downloading future-0.18.2.tar.gz (829 kB) |████████████████████████████████| 829 kB 43.3 MB/s Requirement already satisfied: tqdm&gt;=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-&gt;ratsnlp) (4.62.3) Requirement already satisfied: numpy&gt;=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning==1.3.4-&gt;ratsnlp) (1.19.5) Collecting PyYAML&lt;=5.4.1,&gt;=5.1 Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB) |████████████████████████████████| 636 kB 47.3 MB/s Collecting tokenizers&lt;0.11,&gt;=0.10.1 Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB) |████████████████████████████████| 3.3 MB 13.9 MB/s Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-&gt;ratsnlp) (2019.12.20) Collecting huggingface-hub&gt;=0.0.12 Downloading huggingface_hub-0.2.1-py3-none-any.whl (61 kB) |████████████████████████████████| 61 kB 451 kB/s Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-&gt;ratsnlp) (2.23.0) Collecting sacremoses Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB) |████████████████████████████████| 895 kB 58.6 MB/s Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-&gt;ratsnlp) (3.4.0) Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.10.0-&gt;ratsnlp) (4.8.2) Requirement already satisfied: Werkzeug&lt;2.0,&gt;=0.15 in /usr/local/lib/python3.7/dist-packages (from flask&gt;=1.1.4-&gt;ratsnlp) (1.0.1) Requirement already satisfied: Jinja2&lt;3.0,&gt;=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask&gt;=1.1.4-&gt;ratsnlp) (2.11.3) Requirement already satisfied: click&lt;8.0,&gt;=5.1 in /usr/local/lib/python3.7/dist-packages (from flask&gt;=1.1.4-&gt;ratsnlp) (7.1.2) Requirement already satisfied: itsdangerous&lt;2.0,&gt;=0.24 in /usr/local/lib/python3.7/dist-packages (from flask&gt;=1.1.4-&gt;ratsnlp) (1.1.0) Requirement already satisfied: Six in /usr/local/lib/python3.7/dist-packages (from flask-cors&gt;=3.0.10-&gt;ratsnlp) (1.15.0) Collecting aiohttp Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB) |████████████████████████████████| 1.1 MB 13.2 MB/s Requirement already satisfied: typing-extensions&gt;=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub&gt;=0.0.12-&gt;transformers==4.10.0-&gt;ratsnlp) (3.10.0.2) Requirement already satisfied: MarkupSafe&gt;=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2&lt;3.0,&gt;=2.10.1-&gt;flask&gt;=1.1.4-&gt;ratsnlp) (2.0.1) Collecting xlrd&gt;=1.2.0 Downloading xlrd-2.0.1-py2.py3-none-any.whl (96 kB) |████████████████████████████████| 96 kB 5.1 MB/s Collecting dataclasses&gt;=0.6 Downloading dataclasses-0.6-py3-none-any.whl (14 kB) Requirement already satisfied: pyparsing!=3.0.5,&gt;=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (3.0.6) Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;transformers==4.10.0-&gt;ratsnlp) (2021.10.8) Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;transformers==4.10.0-&gt;ratsnlp) (3.0.4) Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;transformers==4.10.0-&gt;ratsnlp) (2.10) Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;transformers==4.10.0-&gt;ratsnlp) (1.24.3) Requirement already satisfied: absl-py&gt;=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (0.12.0) Requirement already satisfied: tensorboard-plugin-wit&gt;=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (1.8.0) Requirement already satisfied: grpcio&gt;=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (1.42.0) Requirement already satisfied: markdown&gt;=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (3.3.6) Requirement already satisfied: google-auth-oauthlib&lt;0.5,&gt;=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (0.4.6) Requirement already satisfied: setuptools&gt;=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (57.4.0) Requirement already satisfied: protobuf&gt;=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (3.17.3) Requirement already satisfied: tensorboard-data-server&lt;0.7.0,&gt;=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (0.6.1) Requirement already satisfied: google-auth&lt;3,&gt;=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (1.35.0) Requirement already satisfied: wheel&gt;=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (0.37.0) Requirement already satisfied: rsa&lt;5,&gt;=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (4.8) Requirement already satisfied: cachetools&lt;5.0,&gt;=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (4.2.4) Requirement already satisfied: pyasn1-modules&gt;=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (0.2.8) Requirement already satisfied: requests-oauthlib&gt;=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (1.3.0) Requirement already satisfied: zipp&gt;=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-&gt;transformers==4.10.0-&gt;ratsnlp) (3.6.0) Requirement already satisfied: pyasn1&lt;0.5.0,&gt;=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules&gt;=0.2.1-&gt;google-auth&lt;3,&gt;=1.6.3-&gt;tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (0.4.8) Requirement already satisfied: oauthlib&gt;=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib&gt;=0.7.0-&gt;google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard!=2.5.0,&gt;=2.2.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (3.1.1) Collecting yarl&lt;2.0,&gt;=1.0 Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB) |████████████████████████████████| 271 kB 57.5 MB/s Collecting aiosignal&gt;=1.1.2 Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB) Collecting async-timeout&lt;5.0,&gt;=4.0.0a3 Downloading async_timeout-4.0.1-py3-none-any.whl (5.7 kB) Collecting multidict&lt;7.0,&gt;=4.5 Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB) |████████████████████████████████| 160 kB 51.6 MB/s Requirement already satisfied: charset-normalizer&lt;3.0,&gt;=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;fsspec[http]&gt;=2021.4.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (2.0.8) Collecting asynctest==0.13.0 Downloading asynctest-0.13.0-py3-none-any.whl (26 kB) Requirement already satisfied: attrs&gt;=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp-&gt;fsspec[http]&gt;=2021.4.0-&gt;pytorch-lightning==1.3.4-&gt;ratsnlp) (21.2.0) Collecting frozenlist&gt;=1.1.1 Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB) |████████████████████████████████| 192 kB 55.2 MB/s Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses-&gt;transformers==4.10.0-&gt;ratsnlp) (1.1.0) Building wheels for collected packages: future Building wheel for future (setup.py) ... done Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=47a5461d5402fcdc2dcef6ae30181e838b5332b2f517b7570f63edff2f2ce53f Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0 Successfully built future Installing collected packages: multidict, frozenlist, yarl, asynctest, async-timeout, aiosignal, PyYAML, fsspec, aiohttp, xlrd, torchmetrics, tokenizers, sacremoses, pyDeprecate, huggingface-hub, future, dataclasses, transformers, pytorch-lightning, Korpora, flask-ngrok, flask-cors, ratsnlp Attempting uninstall: PyYAML Found existing installation: PyYAML 3.13 Uninstalling PyYAML-3.13: Successfully uninstalled PyYAML-3.13 Attempting uninstall: xlrd Found existing installation: xlrd 1.1.0 Uninstalling xlrd-1.1.0: Successfully uninstalled xlrd-1.1.0 Attempting uninstall: future Found existing installation: future 0.16.0 Uninstalling future-0.16.0: Successfully uninstalled future-0.16.0 Successfully installed Korpora-0.2.0 PyYAML-5.4.1 aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.1 asynctest-0.13.0 dataclasses-0.6 flask-cors-3.0.10 flask-ngrok-0.0.25 frozenlist-1.2.0 fsspec-2021.11.1 future-0.18.2 huggingface-hub-0.2.1 multidict-5.2.0 pyDeprecate-0.3.0 pytorch-lightning-1.3.4 ratsnlp-0.0.9999 sacremoses-0.0.46 tokenizers-0.10.3 torchmetrics-0.6.2 transformers-4.10.0 xlrd-2.0.1 yarl-1.7.2 . from google.colab import drive drive.mount(&#39;/gdrive&#39;, force_remount=True) . Mounted at /gdrive . from Korpora import Korpora nsmc = Korpora.load(&#39;nsmc&#39;, force_download=True) . Korpora 는 다른 분들이 연구 목적으로 공유해주신 말뭉치들을 손쉽게 다운로드, 사용할 수 있는 기능만을 제공합니다. 말뭉치들을 공유해 주신 분들에게 감사드리며, 각 말뭉치 별 설명과 라이센스를 공유 드립니다. 해당 말뭉치에 대해 자세히 알고 싶으신 분은 아래의 description 을 참고, 해당 말뭉치를 연구/상용의 목적으로 이용하실 때에는 아래의 라이센스를 참고해 주시기 바랍니다. # Description Author : e9t@github Repository : https://github.com/e9t/nsmc References : www.lucypark.kr/docs/2015-pyconkr/#39 Naver sentiment movie corpus v1.0 This is a movie review dataset in the Korean language. Reviews were scraped from Naver Movies. The dataset construction is based on the method noted in [Large movie review dataset][^1] from Maas et al., 2011. [^1]: http://ai.stanford.edu/~amaas/data/sentiment/ # License CC0 1.0 Universal (CC0 1.0) Public Domain Dedication Details in https://creativecommons.org/publicdomain/zero/1.0/ . [nsmc] download ratings_train.txt: 14.6MB [00:00, 61.5MB/s] [nsmc] download ratings_test.txt: 4.90MB [00:00, 33.0MB/s] . NSMC는 네이버 영화 리뷰자료 입니다. . import os def write_lines(path, lines): with open(path, &#39;w&#39;, encoding = &#39;utf-8&#39;) as f: for line in lines: f.write(f&#39;{line} n&#39;) write_lines(&#39;/root/train.txt&#39;, nsmc.train.get_all_texts()) write_lines(&#39;/root/test.txt&#39;, nsmc.test.get_all_texts()) . 영화 리뷰들을 순수 텍스트 형태로 저장했습니다. . !head /root/train.txt . 아 더빙.. 진짜 짜증나네요 목소리 흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나 너무재밓었다그래서보는것을추천한다 교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정 사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다 막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움. 원작의 긴장감을 제대로 살려내지못했다. 별 반개도 아깝다 욕나온다 이응경 길용우 연기생활이몇년인지..정말 발로해도 그것보단 낫겟다 납치.감금만반복반복..이드라마는 가족도없다 연기못하는사람만모엿네 액션이 없는데도 재미 있는 몇안되는 영화 왜케 평점이 낮은건데? 꽤 볼만한데.. 헐리우드식 화려함에만 너무 길들여져 있나? . 리뷰 앞 내용입니다. . GPT &#53664;&#53356;&#45208;&#51060;&#51200; &#44396;&#52629; . import os os.makedirs(&#39;/gdrive/My Drive/nlpbook/bbpe&#39;, exist_ok= True) . 저장용 디렉터리를 만들었습니다. . from tokenizers import ByteLevelBPETokenizer bytebpe_tokenizer = ByteLevelBPETokenizer() bytebpe_tokenizer.train( files=[&quot;/root/train.txt&quot;, &quot;/root/test.txt&quot;], # 학습 말뭉치를 리스트 형태로 vocab_size=10000, # 어휘 집합 크기 조절 special_tokens=[&quot;[PAD]&quot;] # 특수 토큰 추가 ) bytebpe_tokenizer.save_model(&quot;/gdrive/My Drive/nlpbook/bbpe&quot;) . [&#39;/gdrive/My Drive/nlpbook/bbpe/vocab.json&#39;, &#39;/gdrive/My Drive/nlpbook/bbpe/merges.txt&#39;] . 코드가 실행되면 vocab.json, merges.txt가 생성됩니다. . 전자는 바이트 수준 BPE 어휘집합, 후자는 바이그램 쌍과 병합우선순위가 있습니다. . !cat /gdrive/My Drive/nlpbook/bbpe/vocab.json . {&#34;[PAD]&#34;:0,&#34;!&#34;:1,&#34; &#34;&#34;:2,&#34;#&#34;:3,&#34;$&#34;:4,&#34;%&#34;:5,&#34;&amp;&#34;:6,&#34;&#39;&#34;:7,&#34;(&#34;:8,&#34;)&#34;:9,&#34;*&#34;:10,&#34;+&#34;:11,&#34;,&#34;:12,&#34;-&#34;:13,&#34;.&#34;:14,&#34;/&#34;:15,&#34;0&#34;:16,&#34;1&#34;:17,&#34;2&#34;:18,&#34;3&#34;:19,&#34;4&#34;:20,&#34;5&#34;:21,&#34;6&#34;:22,&#34;7&#34;:23,&#34;8&#34;:24,&#34;9&#34;:25,&#34;:&#34;:26,&#34;;&#34;:27,&#34;&lt;&#34;:28,&#34;=&#34;:29,&#34;&gt;&#34;:30,&#34;?&#34;:31,&#34;@&#34;:32,&#34;A&#34;:33,&#34;B&#34;:34,&#34;C&#34;:35,&#34;D&#34;:36,&#34;E&#34;:37,&#34;F&#34;:38,&#34;G&#34;:39,&#34;H&#34;:40,&#34;I&#34;:41,&#34;J&#34;:42,&#34;K&#34;:43,&#34;L&#34;:44,&#34;M&#34;:45,&#34;N&#34;:46,&#34;O&#34;:47,&#34;P&#34;:48,&#34;Q&#34;:49,&#34;R&#34;:50,&#34;S&#34;:51,&#34;T&#34;:52,&#34;U&#34;:53,&#34;V&#34;:54,&#34;W&#34;:55,&#34;X&#34;:56,&#34;Y&#34;:57,&#34;Z&#34;:58,&#34;[&#34;:59,&#34; &#34;:60,&#34;]&#34;:61,&#34;^&#34;:62,&#34;_&#34;:63,&#34;`&#34;:64,&#34;a&#34;:65,&#34;b&#34;:66,&#34;c&#34;:67,&#34;d&#34;:68,&#34;e&#34;:69,&#34;f&#34;:70,&#34;g&#34;:71,&#34;h&#34;:72,&#34;i&#34;:73,&#34;j&#34;:74,&#34;k&#34;:75,&#34;l&#34;:76,&#34;m&#34;:77,&#34;n&#34;:78,&#34;o&#34;:79,&#34;p&#34;:80,&#34;q&#34;:81,&#34;r&#34;:82,&#34;s&#34;:83,&#34;t&#34;:84,&#34;u&#34;:85,&#34;v&#34;:86,&#34;w&#34;:87,&#34;x&#34;:88,&#34;y&#34;:89,&#34;z&#34;:90,&#34;{&#34;:91,&#34;|&#34;:92,&#34;}&#34;:93,&#34;~&#34;:94,&#34;¡&#34;:95,&#34;¢&#34;:96,&#34;£&#34;:97,&#34;¤&#34;:98,&#34;¥&#34;:99,&#34;¦&#34;:100,&#34;§&#34;:101,&#34;¨&#34;:102,&#34;©&#34;:103,&#34;ª&#34;:104,&#34;«&#34;:105,&#34;¬&#34;:106,&#34;®&#34;:107,&#34;¯&#34;:108,&#34;°&#34;:109,&#34;±&#34;:110,&#34;²&#34;:111,&#34;³&#34;:112,&#34;´&#34;:113,&#34;µ&#34;:114,&#34;¶&#34;:115,&#34;·&#34;:116,&#34;¸&#34;:117,&#34;¹&#34;:118,&#34;º&#34;:119,&#34;»&#34;:120,&#34;¼&#34;:121,&#34;½&#34;:122,&#34;¾&#34;:123,&#34;¿&#34;:124,&#34;À&#34;:125,&#34;Á&#34;:126,&#34;Â&#34;:127,&#34;Ã&#34;:128,&#34;Ä&#34;:129,&#34;Å&#34;:130,&#34;Æ&#34;:131,&#34;Ç&#34;:132,&#34;È&#34;:133,&#34;É&#34;:134,&#34;Ê&#34;:135,&#34;Ë&#34;:136,&#34;Ì&#34;:137,&#34;Í&#34;:138,&#34;Î&#34;:139,&#34;Ï&#34;:140,&#34;Ð&#34;:141,&#34;Ñ&#34;:142,&#34;Ò&#34;:143,&#34;Ó&#34;:144,&#34;Ô&#34;:145,&#34;Õ&#34;:146,&#34;Ö&#34;:147,&#34;×&#34;:148,&#34;Ø&#34;:149,&#34;Ù&#34;:150,&#34;Ú&#34;:151,&#34;Û&#34;:152,&#34;Ü&#34;:153,&#34;Ý&#34;:154,&#34;Þ&#34;:155,&#34;ß&#34;:156,&#34;à&#34;:157,&#34;á&#34;:158,&#34;â&#34;:159,&#34;ã&#34;:160,&#34;ä&#34;:161,&#34;å&#34;:162,&#34;æ&#34;:163,&#34;ç&#34;:164,&#34;è&#34;:165,&#34;é&#34;:166,&#34;ê&#34;:167,&#34;ë&#34;:168,&#34;ì&#34;:169,&#34;í&#34;:170,&#34;î&#34;:171,&#34;ï&#34;:172,&#34;ð&#34;:173,&#34;ñ&#34;:174,&#34;ò&#34;:175,&#34;ó&#34;:176,&#34;ô&#34;:177,&#34;õ&#34;:178,&#34;ö&#34;:179,&#34;÷&#34;:180,&#34;ø&#34;:181,&#34;ù&#34;:182,&#34;ú&#34;:183,&#34;û&#34;:184,&#34;ü&#34;:185,&#34;ý&#34;:186,&#34;þ&#34;:187,&#34;ÿ&#34;:188,&#34;Ā&#34;:189,&#34;ā&#34;:190,&#34;Ă&#34;:191,&#34;ă&#34;:192,&#34;Ą&#34;:193,&#34;ą&#34;:194,&#34;Ć&#34;:195,&#34;ć&#34;:196,&#34;Ĉ&#34;:197,&#34;ĉ&#34;:198,&#34;Ċ&#34;:199,&#34;ċ&#34;:200,&#34;Č&#34;:201,&#34;č&#34;:202,&#34;Ď&#34;:203,&#34;ď&#34;:204,&#34;Đ&#34;:205,&#34;đ&#34;:206,&#34;Ē&#34;:207,&#34;ē&#34;:208,&#34;Ĕ&#34;:209,&#34;ĕ&#34;:210,&#34;Ė&#34;:211,&#34;ė&#34;:212,&#34;Ę&#34;:213,&#34;ę&#34;:214,&#34;Ě&#34;:215,&#34;ě&#34;:216,&#34;Ĝ&#34;:217,&#34;ĝ&#34;:218,&#34;Ğ&#34;:219,&#34;ğ&#34;:220,&#34;Ġ&#34;:221,&#34;ġ&#34;:222,&#34;Ģ&#34;:223,&#34;ģ&#34;:224,&#34;Ĥ&#34;:225,&#34;ĥ&#34;:226,&#34;Ħ&#34;:227,&#34;ħ&#34;:228,&#34;Ĩ&#34;:229,&#34;ĩ&#34;:230,&#34;Ī&#34;:231,&#34;ī&#34;:232,&#34;Ĭ&#34;:233,&#34;ĭ&#34;:234,&#34;Į&#34;:235,&#34;į&#34;:236,&#34;İ&#34;:237,&#34;ı&#34;:238,&#34;Ĳ&#34;:239,&#34;ĳ&#34;:240,&#34;Ĵ&#34;:241,&#34;ĵ&#34;:242,&#34;Ķ&#34;:243,&#34;ķ&#34;:244,&#34;ĸ&#34;:245,&#34;Ĺ&#34;:246,&#34;ĺ&#34;:247,&#34;Ļ&#34;:248,&#34;ļ&#34;:249,&#34;Ľ&#34;:250,&#34;ľ&#34;:251,&#34;Ŀ&#34;:252,&#34;ŀ&#34;:253,&#34;Ł&#34;:254,&#34;ł&#34;:255,&#34;Ń&#34;:256,&#34;Ġì&#34;:257,&#34;Ġë&#34;:258,&#34;ìĿ&#34;:259,&#34;ëĭ&#34;:260,&#34;íķ&#34;:261,&#34;ê°&#34;:262,&#34;..&#34;:263,&#34;ìĿ´&#34;:264,&#34;ëĭ¤&#34;:265,&#34;ëĬ&#34;:266,&#34;ìĹ&#34;:267,&#34;ê³&#34;:268,&#34;ì§&#34;:269,&#34;ëĬĶ&#34;:270,&#34;ìŀ&#34;:271,&#34;ë§&#34;:272,&#34;íĻ&#34;:273,&#34;ê³ł&#34;:274,&#34;ìł&#34;:275,&#34;íĻĶ&#34;:276,&#34;ĺģ&#34;:277,&#34;Ġê&#34;:278,&#34;ëı&#34;:279,&#34;ìķ&#34;:280,&#34;ãħ&#34;:281,&#34;ĺģíĻĶ&#34;:282,&#34;ìļ&#34;:283,&#34;ì§Ģ&#34;:284,&#34;íķĺ&#34;:285,&#34;ê°Ģ&#34;:286,&#34;ëĤ&#34;:287,&#34;ê²&#34;:288,&#34;ìĦ&#34;:289,&#34;Ġìŀ&#34;:290,&#34;¬ë&#34;:291,&#34;ê¸&#34;:292,&#34;Ġìķ&#34;:293,&#34;ëıĦ&#34;:294,&#34;Ġí&#34;:295,&#34;ëĵ&#34;:296,&#34;ë¦&#34;:297,&#34;ìĹĲ&#34;:298,&#34;ĠìĿ&#34;:299,&#34;íķľ&#34;:300,&#34;ĠìĺģíĻĶ&#34;:301,&#34;Īë&#34;:302,&#34;³´&#34;:303,&#34;ìĭ&#34;:304,&#34;ĸ´&#34;:305,&#34;ìĿĺ&#34;:306,&#34;ê¸°&#34;:307,&#34;ãħĭ&#34;:308,&#34;ĠìĹ&#34;:309,&#34;ìĿĢ&#34;:310,&#34;ë¡&#34;:311,&#34;ëį&#34;:312,&#34;ìĿĦ&#34;:313,&#34;Ŀ¼&#34;:314,&#34;ëĤĺ&#34;:315,&#34;ê²Į&#34;:316,&#34;ĠìĿ´&#34;:317,&#34;ìĦľ&#34;:318,&#34;Ġë§&#34;:319,&#34;ìļĶ&#34;:320,&#34;ìĬ&#34;:321,&#34;ìĸ´&#34;:322,&#34;ë¡ľ&#34;:323,&#34;ĠëĤ&#34;:324,&#34;ë§Į&#34;:325,&#34;ëĿ¼&#34;:326,&#34;ë¦¬&#34;:327,&#34;Ġìł&#34;:328,&#34;·¸&#34;:329,&#34;ëĭĪ&#34;:330,&#34;ëĵ¤&#34;:331,&#34;ë¥&#34;:332,&#34;ê±&#34;:333,&#34;ìķĦ&#34;:334,&#34;ëł&#34;:335,&#34;...&#34;:336,&#34;ë©&#34;:337,&#34;¬´&#34;:338,&#34;ìľ&#34;:339,&#34;Ġê°&#34;:340,&#34;ìĿ¸&#34;:341,&#34;ãħĭãħĭ&#34;:342,&#34;¯¸&#34;:343,&#34;ëį°&#34;:344,&#34;Ġì§&#34;:345,&#34;ëĦ&#34;:346,&#34;ĠìķĦ&#34;:347,&#34;ĮĢ&#34;:348,&#34;ëŁ&#34;:349,&#34;ìĺ&#34;:350,&#34;êµ&#34;:351,&#34;íķ´&#34;:352,&#34;Ġë³´&#34;:353,&#34;ë©´&#34;:354,&#34;ìĥ&#34;:355,&#34;ìĺģíĻĶ&#34;:356,&#34;Ġìĭ&#34;:357,&#34;Ġê·¸&#34;:358,&#34;ê¹&#34;:359,&#34;ë°&#34;:360,&#34;Ġëª&#34;:361,&#34;ìłĲ&#34;:362,&#34;ìĭľ&#34;:363,&#34;Īĺ&#34;:364,&#34;Ġëĭ&#34;:365,&#34;ë³´&#34;:366,&#34;ìĿĮ&#34;:367,&#34;ìĬ¤&#34;:368,&#34;£¼&#34;:369,&#34;ëŀ&#34;:370,&#34;Ġë°&#34;:371,&#34;ìľ¼&#34;:372,&#34;ëĦ¤&#34;:373,&#34;Ġìŀ¬ë&#34;:374,&#34;ë¥¼&#34;:375,&#34;ë§Ĳ&#34;:376,&#34;Ġì¢&#34;:377,&#34;!!&#34;:378,&#34;ë¶&#34;:379,&#34;ì¤&#34;:380,&#34;ĠìĤ&#34;:381,&#34;ê±°&#34;:382,&#34;ìĤ&#34;:383,&#34;ìĻ&#34;:384,&#34;ëĮĢ&#34;:385,&#34;ëĭĪëĭ¤&#34;:386,&#34;Īë¬´&#34;:387,&#34;ìŀĲ&#34;:388,&#34;ëĬĶëį°&#34;:389,&#34;ìĽ&#34;:390,&#34;Ġë³&#34;:391,&#34;ìłķ&#34;:392,&#34;ĠëĦ&#34;:393,&#34;ë§Ī&#34;:394,&#34;ê¹Į&#34;:395,&#34;ì²&#34;:396,&#34;ìĹĨ&#34;:397,&#34;ĠìĹĨ&#34;:398,&#34;ìĹĪ&#34;:399,&#34;ĠëĤĺ&#34;:400,&#34;Ġíķĺ&#34;:401,&#34;ìļ°&#34;:402,&#34;Ġë´&#34;:403,&#34;ì¹&#34;:404,&#34;ìķ¼&#34;:405,&#34;Ġì¢ĭ&#34;:406,&#34;ì£¼&#34;:407,&#34;ì§Ħ&#34;:408,&#34;Ġëĭ¤&#34;:409,&#34;ìĪĺ&#34;:410,&#34;íĸ&#34;:411,&#34;ë³&#34;:412,&#34;ë²&#34;:413,&#34;ìłģ&#34;:414,&#34;µľ&#34;:415,&#34;ìŀ¥&#34;:416,&#34;ìŀĪ&#34;:417,&#34;ìŀĳ&#34;:418,&#34;ìłĦ&#34;:419,&#34;ìĥģ&#34;:420,&#34;ëª&#34;:421,&#34;....&#34;:422,&#34;Ġìĥ&#34;:423,&#34;Ġìłķ&#34;:424,&#34;ì§ľ&#34;:425,&#34;ìĨ&#34;:426,&#34;°Į&#34;:427,&#34;ìľ¼ë¡ľ&#34;:428,&#34;Ġê²&#34;:429,&#34;ĠìŀĪ&#34;:430,&#34;ì§Ģë§Į&#34;:431,&#34;íĺ&#34;:432,&#34;ê°Ħ&#34;:433,&#34;ĠìĹ°&#34;:434,&#34;íķĺê³ł&#34;:435,&#34;ĠìĻ&#34;:436,&#34;¬ëŀ&#34;:437,&#34;ê³¼&#34;:438,&#34;Ĳëı&#34;:439,&#34;ìĺ¤&#34;:440,&#34;ĠìĬ&#34;:441,&#34;Ġëĵ&#34;:442,&#34;ëĤ´&#34;:443,&#34;Ġê¸&#34;:444,&#34;ıī&#34;:445,&#34;ãħł&#34;:446,&#34;ĠëĦĪë¬´&#34;:447,&#34;ëŁ°&#34;:448,&#34;ëħ&#34;:449,&#34;Ġìĸ´&#34;:450,&#34;Ġìĺ&#34;:451,&#34;Ġë§Į&#34;:452,&#34;íĥ&#34;:453,&#34;Ġìŀ¬ë¯¸&#34;:454,&#34;Ġì§Ģ&#34;:455,&#34;¹Ħ&#34;:456,&#34;ëĶ&#34;:457,&#34;ê·¸&#34;:458,&#34;ì°&#34;:459,&#34;íŀ&#34;:460,&#34;ëĥ&#34;:461,&#34;ìĹĲìĦľ&#34;:462,&#34;ĠëĤ´&#34;:463,&#34;ëĦ¤ìļĶ&#34;:464,&#34;ê±´&#34;:465,&#34;Ĳĺ&#34;:466,&#34;Ġíķľ&#34;:467,&#34;ëĵľ&#34;:468,&#34;Ġìĭľ&#34;:469,&#34;íĨ&#34;:470,&#34;Ġë¶&#34;:471,&#34;ìķĺ&#34;:472,&#34;íķł&#34;:473,&#34;ĠìĦ&#34;:474,&#34;ķĮ&#34;:475,&#34;ì¡&#34;:476,&#34;ìŀ¬ë&#34;:477,&#34;ìĹ°&#34;:478,&#34;Ġì§Ħ&#34;:479,&#34;Ġë´¤&#34;:480,&#34;ë£&#34;:481,&#34;Ġê°Ģ&#34;:482,&#34;ìļ´&#34;:483,&#34;ĠìĬ¤&#34;:484,&#34;ê³µ&#34;:485,&#34;Ġìµľ&#34;:486,&#34;ë´&#34;:487,&#34;ìĦ±&#34;:488,&#34;ìĻĢ&#34;:489,&#34;Ġëı&#34;:490,&#34;ë¯¸&#34;:491,&#34;Ġìļ&#34;:492,&#34;ìĹ¬&#34;:493,&#34;ê°ģ&#34;:494,&#34;ìĬµ&#34;:495,&#34;Ġì°&#34;:496,&#34;ê²ĥ&#34;:497,&#34; &#34; &#34;&#34;:498,&#34;íŀĪ&#34;:499,&#34;Ġëį&#34;:500,&#34;ìłľ&#34;:501,&#34;Ġ1&#34;:502,&#34;íĶ&#34;:503,&#34;ì¹ĺ&#34;:504,&#34;ì¶&#34;:505,&#34;ìĸ&#34;:506,&#34;ìļ©&#34;:507,&#34;Ġê¸°&#34;:508,&#34;íķĺëĬĶ&#34;:509,&#34;ĠëĮĢ&#34;:510,&#34;ĠìĨ&#34;:511,&#34;ë¶Ģ&#34;:512,&#34;ëł¤&#34;:513,&#34;ìĿ¼&#34;:514,&#34;ĠìĹ°ê¸°&#34;:515,&#34;íĨł&#34;:516,&#34;ëŀĺ&#34;:517,&#34;Ġê°Ĳëı&#34;:518,&#34;íĸĪ&#34;:519,&#34;íĮ&#34;:520,&#34;Ġìŀ¬ë°Į&#34;:521,&#34;ıīìłĲ&#34;:522,&#34;ë¬&#34;:523,&#34;ĠìĪĺ&#34;:524,&#34;Ħ°&#34;:525,&#34;êµ¬&#34;:526,&#34;Ġëª¨&#34;:527,&#34;ì¦&#34;:528,&#34;íķ¨&#34;:529,&#34;ë£¨&#34;:530,&#34;ìĤ¬&#34;:531,&#34;ìĸ´ìļĶ&#34;:532,&#34;Ġìłķë§Ĳ&#34;:533,&#34;ĠìłĦ&#34;:534,&#34;ĠìĤ¬ëŀ&#34;:535,&#34;Ŀê°ģ&#34;:536,&#34;êµŃ&#34;:537,&#34;Ġìľ&#34;:538,&#34;ãħİ&#34;:539,&#34;Ġì¤&#34;:540,&#34;ìĭł&#34;:541,&#34;íĦ°&#34;:542,&#34;Ġìŀĺ&#34;:543,&#34;ì¢&#34;:544,&#34;ì¤ĳ&#34;:545,&#34;ĠìķĬ&#34;:546,&#34;Ġë¬´&#34;:547,&#34;ë¶Ħ&#34;:548,&#34;íĬ&#34;:549,&#34;ëŁ¬&#34;:550,&#34;ìħ&#34;:551,&#34;ãħĭãħĭãħĭãħĭ&#34;:552,&#34;ê²ł&#34;:553,&#34;ìĬµëĭĪëĭ¤&#34;:554,&#34;ìĿ´ëĭ¤&#34;:555,&#34;íİ&#34;:556,&#34;ĠëįĶ&#34;:557,&#34;ìĦ¸&#34;:558,&#34;ĠìķĪ&#34;:559,&#34;íķĺëĭ¤&#34;:560,&#34;ĠëĬ&#34;:561,&#34;Ġì¡&#34;:562,&#34;ëłĪ&#34;:563,&#34;Ġê±&#34;:564,&#34;Ġì£¼&#34;:565,&#34;ê°Ļ&#34;:566,&#34;°ìļ°&#34;:567,&#34;ë¥´&#34;:568,&#34;ĵ°&#34;:569,&#34;ëķĮ&#34;:570,&#34;ĠìĽ&#34;:571,&#34;ìĨĮ&#34;:572,&#34;ê°ľ&#34;:573,&#34;~~&#34;:574,&#34;ĠëŃ&#34;:575,&#34;ìŀĦ&#34;:576,&#34;íĨłë¦¬&#34;:577,&#34;Ġëĵľ&#34;:578,&#34;ĠìĥĿê°ģ&#34;:579,&#34;ìĥĿ&#34;:580,&#34;Ġì§Ħì§ľ&#34;:581,&#34;ãħ¡&#34;:582,&#34;ê°Ĳ&#34;:583,&#34;Ġë§Ī&#34;:584,&#34;ëł¥&#34;:585,&#34;ëĵł&#34;:586,&#34;ëįĺ&#34;:587,&#34;ĠìĿ¸&#34;:588,&#34;ìŀħ&#34;:589,&#34;ìĭ¤&#34;:590,&#34;Ġê°Ļ&#34;:591,&#34;Ġìµľê³ł&#34;:592,&#34;íģ&#34;:593,&#34;Ġì²&#34;:594,&#34;Ġë§Ĳ&#34;:595,&#34;Ġêµ&#34;:596,&#34;Ġëª»&#34;:597,&#34;ê·&#34;:598,&#34;ëĤľ&#34;:599,&#34;ëĵ¯&#34;:600,&#34;ëĿ¼ë§Ī&#34;:601,&#34;ëĵ¤ìĿ´&#34;:602,&#34;ë¬´&#34;:603,&#34;Ġê°ľ&#34;:604,&#34;ĠìĹ¬&#34;:605,&#34;ëħĦ&#34;:606,&#34;ìķħ&#34;:607,&#34;íĴ&#34;:608,&#34;ãħłãħł&#34;:609,&#34;ĠìŀĲ&#34;:610,&#34;ëĶĶ&#34;:611,&#34;Ġìłľ&#34;:612,&#34;ĠëĬĲ&#34;:613,&#34;Ġëģ&#34;:614,&#34;ê¹Įì§Ģ&#34;:615,&#34;ê¸Ī&#34;:616,&#34;ë¦Ħ&#34;:617,&#34;ĠìĻľ&#34;:618,&#34;ëĥ¥&#34;:619,&#34;íİ¸&#34;:620,&#34;Ġê´&#34;:621,&#34;íĥĢ&#34;:622,&#34;íķĺê²Į&#34;:623,&#34;ë¹Ħ&#34;:624,&#34;ë³¸&#34;:625,&#34;Ġë³¸&#34;:626,&#34;Ġì¶&#34;:627,&#34;ëłĩ&#34;:628,&#34;ĳĲ&#34;:629,&#34;ìĺĢ&#34;:630,&#34;Ġìĸ&#34;:631,&#34;ĠìķĮ&#34;:632,&#34;ĠëĤ¨&#34;:633,&#34;íı&#34;:634,&#34;Ġíĺ&#34;:635,&#34;ìĿ´ëĿ¼&#34;:636,&#34;íĬ¸&#34;:637,&#34;Ġê²ĥ&#34;:638,&#34;ì¤Ģ&#34;:639,&#34;Ġìĺ¤&#34;:640,&#34;ĠíıīìłĲ&#34;:641,&#34;ë³´ëĭ¤&#34;:642,&#34;ìĹĪëĭ¤&#34;:643,&#34;Ġê·&#34;:644,&#34;½Ķ&#34;:645,&#34;Ġë³´ê³ł&#34;:646,&#34;ìħĺ&#34;:647,&#34;Ġë³¼&#34;:648,&#34;ĠìĿ´ëŁ°&#34;:649,&#34;ìľł&#34;:650,&#34;ê±¸&#34;:651,&#34;;;&#34;:652,&#34;ìłĢ&#34;:653,&#34;ìłķë§Ĳ&#34;:654,&#34;ĠìĨĮ&#34;:655,&#34;ë§ī&#34;:656,&#34;Ġë©&#34;:657,&#34;ëįĶ&#34;:658,&#34;ê´&#34;:659,&#34;??&#34;:660,&#34;ì²´&#34;:661,&#34;ë¹&#34;:662,&#34;ì§Ħì§ľ&#34;:663,&#34;ìĶ&#34;:664,&#34;Ġë¹&#34;:665,&#34;Ġë¹Ħ&#34;:666,&#34;ëģ&#34;:667,&#34;ĽĦ&#34;:668,&#34;ìĭ¬&#34;:669,&#34;Ġê°ĲëıĻ&#34;:670,&#34;Ġê¹&#34;:671,&#34;Ġë§İ&#34;:672,&#34;ĠíĿ&#34;:673,&#34;ĠìķĦëĭ&#34;:674,&#34;ĠìĬ¤íĨłë¦¬&#34;:675,&#34;ìŀ¬ë¯¸&#34;:676,&#34;ëłĪê¸°&#34;:677,&#34;íĴĪ&#34;:678,&#34;íķ´ìĦľ&#34;:679,&#34;ìķĪ&#34;:680,&#34;ìĽĲ&#34;:681,&#34;Ġë¯¸&#34;:682,&#34;ĠëĶ&#34;:683,&#34;ĠëĪ&#34;:684,&#34;Ġìŀĳ&#34;:685,&#34;ë²Ħ&#34;:686,&#34;ĵ°ëłĪê¸°&#34;:687,&#34;ìĪ&#34;:688,&#34;Ġìľł&#34;:689,&#34;Ġìŀ¥&#34;:690,&#34;Ĳľ&#34;:691,&#34;¡ľ&#34;:692,&#34;Ġë²&#34;:693,&#34;ëĦĪë¬´&#34;:694,&#34;ĠìĤ¬ëŀĮ&#34;:695,&#34;ëĥĲ&#34;:696,&#34;Ġë¶Ģ&#34;:697,&#34;ë©´ìĦľ&#34;:698,&#34;Ġë§Įëĵ¤&#34;:699,&#34;ĠìĿ¼&#34;:700,&#34;Ġíĸ&#34;:701,&#34;ë¨&#34;:702,&#34;ëĭ¨&#34;:703,&#34;ëĲĺ&#34;:704,&#34;ì¢ĭ&#34;:705,&#34;Ġãħĭãħĭ&#34;:706,&#34;ìµľ&#34;:707,&#34;ê³Ħ&#34;:708,&#34;Īëį&#34;:709,&#34;Ġì§Ģë£¨&#34;:710,&#34;ë¬¸&#34;:711,&#34;ë²Ī&#34;:712,&#34;ĠëĵľëĿ¼ë§Ī&#34;:713,&#34;ĠìķĪë&#34;:714,&#34;ìłģìĿ¸&#34;:715,&#34;ĠìĤ¬&#34;:716,&#34;Ġì¤ĳ&#34;:717,&#34;ëªħ&#34;:718,&#34;ìĦł&#34;:719,&#34;íĭ&#34;:720,&#34;Ġê³µ&#34;:721,&#34;ëłĩê²Į&#34;:722,&#34;ëĭ¤ëĬĶ&#34;:723,&#34;Ħë¡ľ&#34;:724,&#34;ĠëģĿ&#34;:725,&#34;ìĺģ&#34;:726,&#34;ãħľ&#34;:727,&#34;Ġë°°ìļ°&#34;:728,&#34;ì§ģ&#34;:729,&#34;ìĸµ&#34;:730,&#34;ì¶ľ&#34;:731,&#34;ëĭ¹&#34;:732,&#34;ĠëĤ´ìļ©&#34;:733,&#34;ë¦¬ê³ł&#34;:734,&#34;ë¦°&#34;:735,&#34;ë§Ŀ&#34;:736,&#34;ë¦¬ë&#34;:737,&#34;ìĽĮ&#34;:738,&#34;£½&#34;:739,&#34;ëŀĳ&#34;:740,&#34;ĠëĲĺ&#34;:741,&#34;Ġì¡°&#34;:742,&#34;íļ&#34;:743,&#34;ëıĻ&#34;:744,&#34;ë¯&#34;:745,&#34;Ġìļ°&#34;:746,&#34;Ġì¢Ģ&#34;:747,&#34;Ġíķ&#34;:748,&#34;Ġíķ´&#34;:749,&#34;,,&#34;:750,&#34;ĦìłĦ&#34;:751,&#34;Ġ10&#34;:752,&#34;ê¹Ŀ&#34;:753,&#34;ì¡°&#34;:754,&#34;^^&#34;:755,&#34;ĠëŃĲ&#34;:756,&#34;ĠëĨ&#34;:757,&#34;ë³´ê³ł&#34;:758,&#34;Ġìķł&#34;:759,&#34;íĤ&#34;:760,&#34;ãħİãħİ&#34;:761,&#34;ë´¤&#34;:762,&#34;ìŀ¬&#34;:763,&#34;¡ìħĺ&#34;:764,&#34;ì§Ģë§ī&#34;:765,&#34;Ġê°Ĳëıħ&#34;:766,&#34;Ġ2&#34;:767,&#34;ê°Ĳëı&#34;:768,&#34;ë¬¼&#34;:769,&#34;Ġìŀ¬ë¯¸ìŀĪ&#34;:770,&#34;ë¥¸&#34;:771,&#34;Ġë´Ĳ&#34;:772,&#34;Ġìĭ¶&#34;:773,&#34;Ġê°Ĳ&#34;:774,&#34;ëĨ&#34;:775,&#34;ìľ¼ë©´&#34;:776,&#34;ĠìĺģíĻĶë¥¼&#34;:777,&#34;ìŀ¬ë°Į&#34;:778,&#34;Ġì¹&#34;:779,&#34;ĠíĮ&#34;:780,&#34;ìĤ¬ëŀ&#34;:781,&#34;ê¸´&#34;:782,&#34;ëª¨&#34;:783,&#34;ë¦´&#34;:784,&#34;ìķł&#34;:785,&#34;ĠìĤ¬ëŀĳ&#34;:786,&#34;ĠìłĢ&#34;:787,&#34;íĺĦ&#34;:788,&#34;ìĨį&#34;:789,&#34;ĠíĹ&#34;:790,&#34;íĿ&#34;:791,&#34;íı¬&#34;:792,&#34;Ġëªħ&#34;:793,&#34;Ġê³ł&#34;:794,&#34;Ġëĺ&#34;:795,&#34;Ġë°ĺ&#34;:796,&#34;Ġì¢ĭìķĦ&#34;:797,&#34;Īëįĺ&#34;:798,&#34;ĠìĽĥ&#34;:799,&#34;ëĳĲ&#34;:800,&#34;Ġê±°&#34;:801,&#34;Ġìŀ¬ë¯¸ìĹĨ&#34;:802,&#34;Ġëħ&#34;:803,&#34;ìĹŃ&#34;:804,&#34;Ġì°¸&#34;:805,&#34;ì¤Ħ&#34;:806,&#34;ë°Ķ&#34;:807,&#34;Ġë³´ëĬĶ&#34;:808,&#34;ì²ĺ&#34;:809,&#34;Ġê·¸ëĥ¥&#34;:810,&#34;Ġë´¤ëĬĶëį°&#34;:811,&#34;¬¼&#34;:812,&#34;íķĺì§Ģ&#34;:813,&#34;ĠìĹŃ&#34;:814,&#34;ì¡±&#34;:815,&#34;íħ&#34;:816,&#34;Ġë°Ķ&#34;:817,&#34;Ġìĺģ&#34;:818,&#34;Ġìĥģ&#34;:819,&#34;ëĸ&#34;:820,&#34;ìľĦ&#34;:821,&#34;ëĵ¤ìĿĺ&#34;:822,&#34;ê»&#34;:823,&#34;Ġìĵ°ëłĪê¸°&#34;:824,&#34;ë°ķ&#34;:825,&#34;ĠìĹĨëĬĶ&#34;:826,&#34;íĶĦ&#34;:827,&#34;ãĦ&#34;:828,&#34;OO&#34;:829,&#34;ĠìŀĳíĴĪ&#34;:830,&#34;ëĤ¨&#34;:831,&#34;Ġëĭ¤ìĭľ&#34;:832,&#34;¥¼&#34;:833,&#34;ëĭĺ&#34;:834,&#34;ëħ¸&#34;:835,&#34;ìĿ¸ê³µ&#34;:836,&#34;ì§ĢëĬĶ&#34;:837,&#34;Ġë§¤&#34;:838,&#34;ëŁ½&#34;:839,&#34;ìŀħëĭĪëĭ¤&#34;:840,&#34;íĹ&#34;:841,&#34;ìļ¸&#34;:842,&#34;ì²Ń&#34;:843,&#34;Ġê²°&#34;:844,&#34;ìĭĿ&#34;:845,&#34;ĠìĺģíĻĶëĬĶ&#34;:846,&#34;ìĭ¶&#34;:847,&#34;íıīìłĲ&#34;:848,&#34;ĠëĬĲëĤ&#34;:849,&#34;Ġìĭ¤&#34;:850,&#34;ë§Īë&#34;:851,&#34;ëŃ&#34;:852,&#34;Ħ¤&#34;:853,&#34;ë°ĺ&#34;:854,&#34;!!!&#34;:855,&#34;¬ë¦&#34;:856,&#34;ìŀ¼&#34;:857,&#34;ĠíĻ&#34;:858,&#34;ê²½&#34;:859,&#34;ĠìŀĪëĬĶ&#34;:860,&#34;ì§Ī&#34;:861,&#34;Ġì¢ĭìĿĢ&#34;:862,&#34;©ëĭĪëĭ¤&#34;:863,&#34;Ġì¢ĭìķĺ&#34;:864,&#34;ê´Ģ&#34;:865,&#34;ëĭ¤ê³ł&#34;:866,&#34;ìī&#34;:867,&#34;Ġìĭľê°Ħ&#34;:868,&#34;ê¸¸&#34;:869,&#34;ëĿ¼ê³ł&#34;:870,&#34;ìĹĶ&#34;:871,&#34;ĠìĤ´&#34;:872,&#34;êµ°&#34;:873,&#34;Ġìĭł&#34;:874,&#34;ìĹ°ê¸°&#34;:875,&#34;ìĦ¤&#34;:876,&#34;ìķ¼ê¸°&#34;:877,&#34;ĠìĺģíĻĶê°Ģ&#34;:878,&#34;ëĭ¤ê°Ģ&#34;:879,&#34;ë°ľ&#34;:880,&#34;ĠíķĺëĤĺ&#34;:881,&#34;ìĬ¨&#34;:882,&#34;ºĲ&#34;:883,&#34;íļĮ&#34;:884,&#34;ìĹĨëĬĶ&#34;:885,&#34;Ġíĥ&#34;:886,&#34;ê°ĻìĿĢ&#34;:887,&#34;Ġì´&#34;:888,&#34;ìĸ´ìĦľ&#34;:889,&#34;ĠëķĮ&#34;:890,&#34;ì¶Ķ&#34;:891,&#34;Ġë¨&#34;:892,&#34;âĻ&#34;:893,&#34;ëŀĢ&#34;:894,&#34;ë´Ĳ&#34;:895,&#34;ĳľ&#34;:896,&#34;ĠìĹĨëĭ¤&#34;:897,&#34;Ġì²ĺ&#34;:898,&#34;ìĦ¸ìļĶ&#34;:899,&#34;ĠìĺĪ&#34;:900,&#34;ìĿ´ëŁ°&#34;:901,&#34;Ġíķł&#34;:902,&#34;ìłģìĿ´&#34;:903,&#34;ìµľê³ł&#34;:904,&#34;ìģ&#34;:905,&#34;Ġëħ¸&#34;:906,&#34;ĠíķĺëĬĶ&#34;:907,&#34;ìĿ¸ëį°&#34;:908,&#34;ëĲľ&#34;:909,&#34;ĠëĤĺìĺ¤&#34;:910,&#34;ëĭµ&#34;:911,&#34;!!!!&#34;:912,&#34;ĠëĦĺ&#34;:913,&#34;ĠìķĦëĭĪ&#34;:914,&#34;ì¦Ī&#34;:915,&#34;Ġì£½&#34;:916,&#34;ì¦Ŀ&#34;:917,&#34;ĠíĶ&#34;:918,&#34;ľì°&#34;:919,&#34;ĠìĿĺ&#34;:920,&#34;ìĹĲê²Į&#34;:921,&#34;ìĺĪ&#34;:922,&#34;Ġìķ¡ìħĺ&#34;:923,&#34;ëĵ¤ìĿĢ&#34;:924,&#34;ë¯¼&#34;:925,&#34;ìĽĢ&#34;:926,&#34;ãħ¡ãħ¡&#34;:927,&#34;ì½Ķ&#34;:928,&#34;Ġê¼&#34;:929,&#34;Ġì½Ķ&#34;:930,&#34;ìķĬ&#34;:931,&#34;ê·¹&#34;:932,&#34;Ġëª¨ë¥´&#34;:933,&#34;Ġíı&#34;:934,&#34;êµĲ&#34;:935,&#34;Ġëª°&#34;:936,&#34;ĠìķĦê¹Ŀ&#34;:937,&#34;Ġì¶Ķ&#34;:938,&#34;ìł¸&#34;:939,&#34;ìłģìľ¼ë¡ľ&#34;:940,&#34;ìĿ´ëĤĺ&#34;:941,&#34;ìĺ¨&#34;:942,&#34;ì¼&#34;:943,&#34;ĠíĽĦ&#34;:944,&#34;Ġ3&#34;:945,&#34;Ġê¸°ëĮĢ&#34;:946,&#34;ì²ľ&#34;:947,&#34;ĮìĿ´&#34;:948,&#34;ê²łëĭ¤&#34;:949,&#34;íĮĲ&#34;:950,&#34;Ġìµľê³łìĿĺ&#34;:951,&#34;ìŀĪëĬĶ&#34;:952,&#34;ê²¨&#34;:953,&#34;Ġíŀ&#34;:954,&#34;íķĻ&#34;:955,&#34;»Ķ&#34;:956,&#34;ë¶ĢíĦ°&#34;:957,&#34;íĸī&#34;:958,&#34;Ġëĸ&#34;:959,&#34;ë©°&#34;:960,&#34;ìĶ¨&#34;:961,&#34;ì´&#34;:962,&#34;ĠìĦ±&#34;:963,&#34;ľì°®&#34;:964,&#34;ëĮĢë¡ľ&#34;:965,&#34;ĠìĿ´íķ´&#34;:966,&#34;ĠëĺĲ&#34;:967,&#34;ê¸ī&#34;:968,&#34;íķľëĭ¤&#34;:969,&#34;ì°¨&#34;:970,&#34;ĪëĦ¤&#34;:971,&#34;ëĤł&#34;:972,&#34;ë¡Ŀ&#34;:973,&#34;íĭ°&#34;:974,&#34;íĸĪëĭ¤&#34;:975,&#34;ëĬĲ&#34;:976,&#34;ĠíĺĦ&#34;:977,&#34;ìĭľê°Ħ&#34;:978,&#34;íĽĦ&#34;:979,&#34;ĠíĬ&#34;:980,&#34;ĠìĹ°ì¶ľ&#34;:981,&#34;ĠíĸĪ&#34;:982,&#34;Ġëĵ¤&#34;:983,&#34;Ġë§Īì§Ģë§ī&#34;:984,&#34;Ġë¶Ī&#34;:985,&#34;ë°°ìļ°&#34;:986,&#34;ĠìĿ´ëłĩê²Į&#34;:987,&#34;ìŀĶ&#34;:988,&#34;Ġë¶Ħ&#34;:989,&#34;Ġë©ĭ&#34;:990,&#34;ì£&#34;:991,&#34;Ġì²ĺìĿĮ&#34;:992,&#34;Ġê´Ģ&#34;:993,&#34;ĠìĽĲ&#34;:994,&#34;Ġì§ľ&#34;:995,&#34;ĠìĿ´ìķ¼ê¸°&#34;:996,&#34;Ġê·¹&#34;:997,&#34;ìłĪ&#34;:998,&#34;ìłķëıĦ&#34;:999,&#34;íķ©ëĭĪëĭ¤&#34;:1000,&#34;íĺ¸&#34;:1001,&#34;íĶ¼&#34;:1002,&#34;Ġê¸°ìĸµ&#34;:1003,&#34;ĠìľĦ&#34;:1004,&#34;ĠëĶ°&#34;:1005,&#34;ì§ĢëıĦ&#34;:1006,&#34;ĠíĽ&#34;:1007,&#34;Ġíģ&#34;:1008,&#34;ì£¼ëĬĶ&#34;:1009,&#34;ê·¸ëĥ¥&#34;:1010,&#34;ì¹ľ&#34;:1011,&#34;ĠëıĦ&#34;:1012,&#34;ĠìĿ´ê±´&#34;:1013,&#34;ìĬ´&#34;:1014,&#34; &#34; &#34; &#34; &#34;&#34;:1015,&#34;ë§¨&#34;:1016,&#34;ìĤ´&#34;:1017,&#34;Ġìŀ¥ë©´&#34;:1018,&#34;ë¸&#34;:1019,&#34;âĻ¥&#34;:1020,&#34;íĤ¤&#34;:1021,&#34;ë¡ł&#34;:1022,&#34;Ġìµľìķħ&#34;:1023,&#34;Ġê°ķ&#34;:1024,&#34;íĺĢ&#34;:1025,&#34;Ġë§İìĿ´&#34;:1026,&#34;ë¥ĺ&#34;:1027,&#34;ë¬¸ìĹĲ&#34;:1028,&#34;ĠìĦ¸&#34;:1029,&#34;Ġíıī&#34;:1030,&#34;ĠíķľêµŃ&#34;:1031,&#34;Ġê·¸ë¦¬ê³ł&#34;:1032,&#34;Ġë§Įëĵł&#34;:1033,&#34;ëĤĺëĬĶ&#34;:1034,&#34;Ġë¬&#34;:1035,&#34;ãħĭãħĭãħĭ&#34;:1036,&#34;Ġëªħìŀĳ&#34;:1037,&#34;ĠìĪ&#34;:1038,&#34;ĠëĳĲ&#34;:1039,&#34;ĪëĿ¼&#34;:1040,&#34;ĠíĻĶ&#34;:1041,&#34;ĠëıĻ&#34;:1042,&#34;ĠìĻĦìłĦ&#34;:1043,&#34;ìĿ´ê±°&#34;:1044,&#34;ë¦¬ëĬĶ&#34;:1045,&#34;ë³¼&#34;:1046,&#34;ëĿ¼ëĬĶ&#34;:1047,&#34;ê¸Ģ&#34;:1048,&#34;Ġìŀ¬ë°Įê²Į&#34;:1049,&#34;ĠìķĦê¹Į&#34;:1050,&#34;ëŁ¼&#34;:1051,&#34;ë¨¸&#34;:1052,&#34;ì¢Ģ&#34;:1053,&#34;ëª»&#34;:1054,&#34;ê°Ĳëıħ&#34;:1055,&#34;ìĹĨëĭ¤&#34;:1056,&#34;ĠëĤľ&#34;:1057,&#34;Ġë³Ħë¡ľ&#34;:1058,&#34;ĦìļĶ&#34;:1059,&#34;Ġê·¸ëŁ°&#34;:1060,&#34;ìķĺëĭ¤&#34;:1061,&#34;ë°©&#34;:1062,&#34;ĠìķĦìī&#34;:1063,&#34;ĠìºĲ&#34;:1064,&#34;ìķĮ&#34;:1065,&#34;Ġë³´ìĹ¬&#34;:1066,&#34;ë³´ëĬĶ&#34;:1067,&#34;ĶìĿ´&#34;:1068,&#34;00&#34;:1069,&#34;ë§¤&#34;:1070,&#34;Īë¬¼&#34;:1071,&#34;ë³Ħ&#34;:1072,&#34;Ġê´ľì°®&#34;:1073,&#34;ĠìĿ´ê±°&#34;:1074,&#34;ê²°&#34;:1075,&#34;Ġë°°&#34;:1076,&#34;ĠìķĦëĭĮ&#34;:1077,&#34;¿Ĳ&#34;:1078,&#34;ëł¸&#34;:1079,&#34;ëĪ&#34;:1080,&#34;Ġíİ&#34;:1081,&#34;ê²ĥëıĦ&#34;:1082,&#34;Ġë¡ľ&#34;:1083,&#34;ëŃĲ&#34;:1084,&#34;íķĺëĤĺ&#34;:1085,&#34;ãħĭãħĭãħĭãħĭãħĭãħĭãħĭãħĭ&#34;:1086,&#34;Ġë³Ħ&#34;:1087,&#34;ĠëıĪ&#34;:1088,&#34;ìĤ¬ëŀĮ&#34;:1089,&#34;ë¦Ń&#34;:1090,&#34;íĺķ&#34;:1091,&#34;ì©&#34;:1092,&#34;ë§ĮìĹĲ&#34;:1093,&#34;ìĥī&#34;:1094,&#34;ĠëĤ´ê°Ģ&#34;:1095,&#34;ì³&#34;:1096,&#34;ëģ¼&#34;:1097,&#34;ë¨¹&#34;:1098,&#34;ìĻľ&#34;:1099,&#34;ìŀĺ&#34;:1100,&#34;Ġìŀ¼&#34;:1101,&#34;ãĦ·&#34;:1102,&#34;ìĿĦê¹Į&#34;:1103,&#34;ê°ĢëĬĶ&#34;:1104,&#34;Ġê°ĻìĿĢ&#34;:1105,&#34;ëħĢ&#34;:1106,&#34;ìķĦìĦľ&#34;:1107,&#34;Ġìĸ´ëĸ&#34;:1108,&#34;ĠëŃĶ&#34;:1109,&#34;ĠìĹĨê³ł&#34;:1110,&#34;íħĮ&#34;:1111,&#34;Ġë°ľ&#34;:1112,&#34;ìĽł&#34;:1113,&#34;ê·¼&#34;:1114,&#34;Ġëĭ¹&#34;:1115,&#34;°ĭ&#34;:1116,&#34;ĠìķĦë¦Ħ&#34;:1117,&#34;ìĻĶ&#34;:1118,&#34;ê²©&#34;:1119,&#34;ë³µ&#34;:1120,&#34;Ġê·¸ëŀĺ&#34;:1121,&#34;ìĹĨìĿ´&#34;:1122,&#34;ê¹Ģ&#34;:1123,&#34;ë¦¼&#34;:1124,&#34;ìĪł&#34;:1125,&#34;ëª©&#34;:1126,&#34;........&#34;:1127,&#34;íĽ&#34;:1128,&#34;¬ë¦¬&#34;:1129,&#34;ìĹĪëĬĶëį°&#34;:1130,&#34;Ġì§Ģê¸Ī&#34;:1131,&#34;Ġê¹Ģ&#34;:1132,&#34;Ġìļ¸&#34;:1133,&#34;ĠíĬ¹&#34;:1134,&#34;ëĲ&#34;:1135,&#34;ìĿ¸ê°Ģ&#34;:1136,&#34;ìĬ¤íĨłë¦¬&#34;:1137,&#34;ĠìĹ¬ìŀĲ&#34;:1138,&#34;íķĺê¸°&#34;:1139,&#34;Ġíĳľ&#34;:1140,&#34;Ġê¼Ń&#34;:1141,&#34;ì½&#34;:1142,&#34;ĠëĬĲëĤĮ&#34;:1143,&#34;ëľ&#34;:1144,&#34;ìĽĥ&#34;:1145,&#34;Ġë§ī&#34;:1146,&#34;Ġíŀĺ&#34;:1147,&#34;ëĭĪë&#34;:1148,&#34;ëĤ´ìļ©&#34;:1149,&#34;Ġìĭ¬&#34;:1150,&#34;ãħī&#34;:1151,&#34;ĠìķĦê¹Ŀëĭ¤&#34;:1152,&#34;ë´ī&#34;:1153,&#34;ì§±&#34;:1154,&#34;ĠìĹĦ&#34;:1155,&#34;ê¼&#34;:1156,&#34;ìĹĩ&#34;:1157,&#34;íķĺë©´&#34;:1158,&#34;ãħľãħľ&#34;:1159,&#34;ìĺĢëĭ¤&#34;:1160,&#34;Ġë§ĪìĿĮ&#34;:1161,&#34;Ġãħłãħł&#34;:1162,&#34;ëĵľëĬĶ&#34;:1163,&#34;ĠíĹĪ&#34;:1164,&#34;Ġì¤Ħ&#34;:1165,&#34;ìĺģíĻĶëĬĶ&#34;:1166,&#34; &#34; &#34; &#34;&#34;:1167,&#34;ëĭĪê¹Į&#34;:1168,&#34;¬ëĿ¼&#34;:1169,&#34;ëĵľëĿ¼ë§Ī&#34;:1170,&#34;ìĪľ&#34;:1171,&#34;ëĤ´ê°Ģ&#34;:1172,&#34;Ġê·Ģ&#34;:1173,&#34;ê°ķ&#34;:1174,&#34;ì¹´&#34;:1175,&#34;ĠíĨ&#34;:1176,&#34;êµ¬ëĤĺ&#34;:1177,&#34;ĠìĿĮ&#34;:1178,&#34;íĮĮ&#34;:1179,&#34;ë§ĲìĿ´&#34;:1180,&#34;ì§ĳ&#34;:1181,&#34;ìĺģíĻĶê°Ģ&#34;:1182,&#34;ìĿ´ê²Į&#34;:1183,&#34;ĠìĦ¤&#34;:1184,&#34;Ġì£¼ìĿ¸ê³µ&#34;:1185,&#34;Ġë§Ŀ&#34;:1186,&#34;íķĺì§Ģë§Į&#34;:1187,&#34;Ġë³´ë©´&#34;:1188,&#34;ĠìĿ´ìĥģ&#34;:1189,&#34;Ġêµ¬&#34;:1190,&#34;ĠíıīìłĲìĿ´&#34;:1191,&#34;ĠìĹĲ&#34;:1192,&#34;Ġì°¨&#34;:1193,&#34;ĠëĲ&#34;:1194,&#34;ìķĦìļĶ&#34;:1195,&#34;Ġëĭ¨&#34;:1196,&#34;ĠìłĲ&#34;:1197,&#34;Ġë³´ê¸°&#34;:1198,&#34;ìĿ´ê³ł&#34;:1199,&#34;ĠìĺģíĻĶëĭ¤&#34;:1200,&#34;Ķì§ģ&#34;:1201,&#34;ê°ĲëıĻ&#34;:1202,&#34;ìĺģíĻĶë¥¼&#34;:1203,&#34;ëĵ±&#34;:1204,&#34;ë¹ł&#34;:1205,&#34;ë¯¸ëĶĶ&#34;:1206,&#34;ĠìĬ¬&#34;:1207,&#34;Ġì¡¸&#34;:1208,&#34;íģ¬&#34;:1209,&#34;ì»&#34;:1210,&#34;íĥľ&#34;:1211,&#34;Ġë¯&#34;:1212,&#34;ĠëĤ®&#34;:1213,&#34;ìĿ¸ì§Ģ&#34;:1214,&#34;Ġë§¤ëł¥&#34;:1215,&#34;ìĬ¤ëŁ½&#34;:1216,&#34;ĠìļĶ&#34;:1217,&#34;10&#34;:1218,&#34;Ġë§ŀ&#34;:1219,&#34;ĠíĺĦìĭ¤&#34;:1220,&#34;Ġê°Ģìŀ¥&#34;:1221,&#34;ëĬĶëĭ¤&#34;:1222,&#34;ëĬĶì§Ģ&#34;:1223,&#34;Ġê±¸&#34;:1224,&#34;ĠëĨĴ&#34;:1225,&#34;ìķĪë&#34;:1226,&#34;ì°¸&#34;:1227,&#34;į¼&#34;:1228,&#34;ĠìĨį&#34;:1229,&#34;íıī&#34;:1230,&#34;ìĥĿê°ģ&#34;:1231,&#34;ì¼Ģ&#34;:1232,&#34;ìĸ¸&#34;:1233,&#34;ĠìķĦìĿ´&#34;:1234,&#34;ìĸĳ&#34;:1235,&#34;Ġëª°ìŀħ&#34;:1236,&#34;ìĿ´ê±´&#34;:1237,&#34;ëĶ°&#34;:1238,&#34;Ġ.&#34;:1239,&#34;Ġë¹ł&#34;:1240,&#34;Ġë³¼ë§Į&#34;:1241,&#34;ìģĺ&#34;:1242,&#34;ì§Ģë£¨&#34;:1243,&#34;ë¦ŃíĦ°&#34;:1244,&#34;ĠìŀĪëĭ¤&#34;:1245,&#34;ĠìłķëıĦ&#34;:1246,&#34;ĠíĿ¥&#34;:1247,&#34;Ġì§ľì¦Ŀ&#34;:1248,&#34;íĮħ&#34;:1249,&#34;Ġë¦&#34;:1250,&#34;Ġ..&#34;:1251,&#34;Ġëĭ¤ë¥¸&#34;:1252,&#34;ì£¼ìĿ¸ê³µ&#34;:1253,&#34;Ġë¬´ìĬ¨&#34;:1254,&#34;ĠìĦł&#34;:1255,&#34;Ġìĸ¼&#34;:1256,&#34;ìĻĦìłĦ&#34;:1257,&#34;Ġë§Įëĵ¤ìĸ´&#34;:1258,&#34;ĠìŀĶ&#34;:1259,&#34;ìĶ¬&#34;:1260,&#34;Ġê³Ħ&#34;:1261,&#34;ìĹĪëįĺ&#34;:1262,&#34;Ġãħĭãħĭãħĭ&#34;:1263,&#34;ì£ł&#34;:1264,&#34;ìĹĲëĬĶ&#34;:1265,&#34;ĠëĮĢíķľ&#34;:1266,&#34;¨ìĸ´&#34;:1267,&#34;Ġìľłì¹ĺ&#34;:1268,&#34;Ġì¡´&#34;:1269,&#34;ĠëĪĪë¬¼&#34;:1270,&#34;ãħĩ&#34;:1271,&#34;ë°°&#34;:1272,&#34;ë°Ľ&#34;:1273,&#34;ìĬ¤ëŁ¬&#34;:1274,&#34;Ġì¶©&#34;:1275,&#34;ì§Ģê³ł&#34;:1276,&#34;ì§ĢìķĬ&#34;:1277,&#34;ĠìĿ´ê²Į&#34;:1278,&#34;ëĤĺìĦľ&#34;:1279,&#34;ìĤ¬ë&#34;:1280,&#34;Ġê³¼&#34;:1281,&#34;ëĶ©&#34;:1282,&#34;ĠìķĪëĲĺ&#34;:1283,&#34;Ġìłģ&#34;:1284,&#34;ĠìĹŃìĭľ&#34;:1285,&#34;ĠíķĦìļĶ&#34;:1286,&#34;ĠìĦľ&#34;:1287,&#34;ëĬ¥&#34;:1288,&#34;Ġãħİãħİ&#34;:1289,&#34;ìĤ°&#34;:1290,&#34;ĠìĥĿ&#34;:1291,&#34;ì²ĺëŁ¼&#34;:1292,&#34;Ġìļ°ë¦¬&#34;:1293,&#34;Ġëĵ¯&#34;:1294,&#34;ĠìłĦê°ľ&#34;:1295,&#34;ì±&#34;:1296,&#34;Ķì§ģíŀĪ&#34;:1297,&#34;Ġë°ĺìłĦ&#34;:1298,&#34;ëł¤ê³ł&#34;:1299,&#34;ìĵ°ëłĪê¸°&#34;:1300,&#34;ëĤĺìĺ¤&#34;:1301,&#34;íĽĪ&#34;:1302,&#34;Ġãħĭ&#34;:1303,&#34;ĠëĪĦ&#34;:1304,&#34;Ġê±´&#34;:1305,&#34;íĪ&#34;:1306,&#34;ë©Ķ&#34;:1307,&#34;ì¡Į&#34;:1308,&#34;ĠëĪĪ&#34;:1309,&#34;Ġê³µíı¬&#34;:1310,&#34;ĠëĤ¨ìŀĲ&#34;:1311,&#34;ëŀľ&#34;:1312,&#34;ĠìĬ¤ë¦´&#34;:1313,&#34;¾Į&#34;:1314,&#34;ì¦ĺ&#34;:1315,&#34;Ġë°©&#34;:1316,&#34;Ġì§ĳ&#34;:1317,&#34;ìŀ¬ë¯¸ìŀĪ&#34;:1318,&#34;ì³Ĳ&#34;:1319,&#34;ë§ģ&#34;:1320,&#34;ìĹĪìĿĮ&#34;:1321,&#34;Ġë°ķ&#34;:1322,&#34;ëĭ¤ëĭĪ&#34;:1323,&#34;ĠìĿ¸ìĥĿ&#34;:1324,&#34;Ġíı¬&#34;:1325,&#34;êµ¬ë&#34;:1326,&#34;êµ¿&#34;:1327,&#34;ĸìĹĲ&#34;:1328,&#34;ìŀ¡&#34;:1329,&#34;Ġì¦&#34;:1330,&#34;ĠëıĮ&#34;:1331,&#34;íģ¼&#34;:1332,&#34;Ġë»Ķ&#34;:1333,&#34;íĶĪ&#34;:1334,&#34;Ġì°¾&#34;:1335,&#34;ĠìķĦë¬´&#34;:1336,&#34;Ġíķĺì§Ģë§Į&#34;:1337,&#34;ĠìĿ¼ë³¸&#34;:1338,&#34;ĠìĪĺì¤Ģ&#34;:1339,&#34;ëĬĶê±°&#34;:1340,&#34;íĨµ&#34;:1341,&#34;ê»ĺ&#34;:1342,&#34;ë¶Ī&#34;:1343,&#34;ë§Īì§Ģë§ī&#34;:1344,&#34;ëĭ¤ìļ´&#34;:1345,&#34;íĥĦ&#34;:1346,&#34;ìĦĿ&#34;:1347,&#34;Ġê¸´&#34;:1348,&#34;Ġê°ĢìĬ´&#34;:1349,&#34;Ġë§İìĿĢ&#34;:1350,&#34;ìĤ¬ëŀĳ&#34;:1351,&#34;ìŁ&#34;:1352,&#34;Ġíķĺê³ł&#34;:1353,&#34;¸ìłľ&#34;:1354,&#34;ì¾Į&#34;:1355,&#34;ëĭ¬&#34;:1356,&#34;Ġãħ¡ãħ¡&#34;:1357,&#34;Ġë°Ľ&#34;:1358,&#34;ì¤ĳìĹĲ&#34;:1359,&#34;ĠëģĿê¹Įì§Ģ&#34;:1360,&#34;Ġìĸµ&#34;:1361,&#34;Īë°&#34;:1362,&#34;Ġì±&#34;:1363,&#34;ëĵ¤ìĿĦ&#34;:1364,&#34;ìĬ¤íĦ°&#34;:1365,&#34;į¨&#34;:1366,&#34;»ê²Į&#34;:1367,&#34;ë¦½&#34;:1368,&#34;Ġì§±&#34;:1369,&#34;ëĤĺëĿ¼&#34;:1370,&#34;ĠíĴ&#34;:1371,&#34;ĠìķĦëĭĪëĿ¼&#34;:1372,&#34;ĠìĿ¸ê°Ħ&#34;:1373,&#34;Ġìĺģìĥģ&#34;:1374,&#34;ĠOO&#34;:1375,&#34;ìĸ¼&#34;:1376,&#34;ìĿ´ì§Ģ&#34;:1377,&#34;Ĵ¤&#34;:1378,&#34;ê»´&#34;:1379,&#34;ë¦¬ì¦Ī&#34;:1380,&#34;ëįĶëĿ¼&#34;:1381,&#34;Ġíĭ&#34;:1382,&#34;Ġë´ĲëıĦ&#34;:1383,&#34;íĿ¬&#34;:1384,&#34;ĠëĲľ&#34;:1385,&#34;ê¸°ëıĦ&#34;:1386,&#34;Ġíĸī&#34;:1387,&#34;º¼&#34;:1388,&#34;ìĨ¡&#34;:1389,&#34;íĸĪëįĺ&#34;:1390,&#34;Ġëª¨ëĳĲ&#34;:1391,&#34;Ġì°į&#34;:1392,&#34;Ġê·¹ìŀ¥&#34;:1393,&#34;íĻ©&#34;:1394,&#34;ìŀ¥ë©´&#34;:1395,&#34;ĠìĪľ&#34;:1396,&#34;ì£½&#34;:1397,&#34;.....&#34;:1398,&#34;Ġíİ¸&#34;:1399,&#34;ĠíĶ¼&#34;:1400,&#34;ìĹŃìĭľ&#34;:1401,&#34;ëĲĺëĬĶ&#34;:1402,&#34;Ġìļķ&#34;:1403,&#34;ìłĳ&#34;:1404,&#34;Ġì¶Ķì²ľ&#34;:1405,&#34;ì£¼ê³ł&#34;:1406,&#34;ł¤&#34;:1407,&#34;Ġëª¨ëĵł&#34;:1408,&#34;ëĦĺ&#34;:1409,&#34;ê¶&#34;:1410,&#34;ë§İ&#34;:1411,&#34;Ġë´¤ëĭ¤&#34;:1412,&#34;ìŁģ&#34;:1413,&#34;ìĬ¤íĬ¸&#34;:1414,&#34;Ġê·¼&#34;:1415,&#34;ìĿĦëķĮ&#34;:1416,&#34;Ġìŀ¬&#34;:1417,&#34;ìķĦìĿ´&#34;:1418,&#34;Ġê°Ļëĭ¤&#34;:1419,&#34;ëĬĺ&#34;:1420,&#34;ĠìĿĮìķħ&#34;:1421,&#34;Ġìĭ¤ë§Ŀ&#34;:1422,&#34;Ġë¨¸&#34;:1423,&#34;ĪëĦ¤ìļĶ&#34;:1424,&#34;ë§Įëĵ¤&#34;:1425,&#34;ì¢ħ&#34;:1426,&#34;ë¿Ĳ&#34;:1427,&#34;Ġìĵ°&#34;:1428,&#34;ë¦¬ê°Ģ&#34;:1429,&#34;ìĹĲëıĦ&#34;:1430,&#34;ĠìĻ¸&#34;:1431,&#34;Ġëªĩ&#34;:1432,&#34;ĪëĮĢ&#34;:1433,&#34;ìĿ´ìĥģ&#34;:1434,&#34;ìĿ´ëŀĳ&#34;:1435,&#34;ê±´ì§Ģ&#34;:1436,&#34;ëĨĵ&#34;:1437,&#34;ìĹĨê³ł&#34;:1438,&#34;ĠìĻĦ&#34;:1439,&#34;ìĦŃ&#34;:1440,&#34;Ġê²Į&#34;:1441,&#34;Ġ&#39;&#34;:1442,&#34;ĠìķĦì§ģ&#34;:1443,&#34;ëĺ&#34;:1444,&#34;ĠíĤ&#34;:1445,&#34;ìĪĺë¡Ŀ&#34;:1446,&#34;ĠëĤĺìĺ¨&#34;:1447,&#34;ĠìłĦíĺĢ&#34;:1448,&#34;íĸĪëĬĶëį°&#34;:1449,&#34;ĵ¤&#34;:1450,&#34;ĠìĹ´&#34;:1451,&#34;Ġë¨¹&#34;:1452,&#34;ë´ĲëıĦ&#34;:1453,&#34;ìĻ¸&#34;:1454,&#34;Ġëª¨ìĬµ&#34;:1455,&#34;ĠìĹ°ê¸°ëł¥&#34;:1456,&#34;Ġíķľë²Ī&#34;:1457,&#34;Ġìĸµì§Ģ&#34;:1458,&#34;Ġì¤Ģ&#34;:1459,&#34;ëľ»&#34;:1460,&#34;Ġ4&#34;:1461,&#34;íĬ¹&#34;:1462,&#34;ìłĲëıĦ&#34;:1463,&#34;Ġê²½&#34;:1464,&#34;Ġ...&#34;:1465,&#34;ĠìºĲë¦ŃíĦ°&#34;:1466,&#34;ìŀ¥ê°Ĳ&#34;:1467,&#34;ìĿ´ëĿ¼ëĬĶ&#34;:1468,&#34;ëĵ¤ëıĦ&#34;:1469,&#34;Ŀ½&#34;:1470,&#34;ìĿ´ëĬĶ&#34;:1471,&#34;ĠëĤ´ëĤ´&#34;:1472,&#34;Ġê²°ë§Ĳ&#34;:1473,&#34;íį¼&#34;:1474,&#34;ëıħ&#34;:1475,&#34;ê¸°ëĬĶ&#34;:1476,&#34;ìĬ¹&#34;:1477,&#34;Ġì¢ĭëĭ¤&#34;:1478,&#34;ĠíĳľíĺĦ&#34;:1479,&#34;ëĮĢì²´&#34;:1480,&#34;Ġê³µê°Ĳ&#34;:1481,&#34;Ġë³´ì§Ģ&#34;:1482,&#34;ìĪĺê°Ģ&#34;:1483,&#34;ĠëĨĢ&#34;:1484,&#34;Ġì¹ĺ&#34;:1485,&#34;ĠìķĬê³ł&#34;:1486,&#34;Ġê³ĦìĨį&#34;:1487,&#34;©ĶìĿ´&#34;:1488,&#34;íĥĢìŀĦ&#34;:1489,&#34;Ġê°Ħ&#34;:1490,&#34;Ġíķ¨&#34;:1491,&#34;ëıĪ&#34;:1492,&#34;Ġì¶ľ&#34;:1493,&#34;ë§ŀ&#34;:1494,&#34;ê¸°ëĮĢ&#34;:1495,&#34;ìĸ´ìķ¼&#34;:1496,&#34;íķĺëĦ¤ìļĶ&#34;:1497,&#34;ìĹĪìĸ´ìļĶ&#34;:1498,&#34;Ġ8&#34;:1499,&#34;ĠìĹ¬ìļ´&#34;:1500,&#34;ëŁ¬ë&#34;:1501,&#34;Ġì½Ķë¯¸ëĶĶ&#34;:1502,&#34;ì¢ĭìĿĢ&#34;:1503,&#34;íĳľ&#34;:1504,&#34;ĠìĿ´ìłľ&#34;:1505,&#34;Ġë§ĲìĿ´&#34;:1506,&#34;ë¸Į&#34;:1507,&#34;ľ´&#34;:1508,&#34;ì¡´&#34;:1509,&#34;Ġ9&#34;:1510,&#34;íķĺëĦ¤&#34;:1511,&#34;ĠìĺģíĻĶìĹĲ&#34;:1512,&#34;ê¾&#34;:1513,&#34;ëĤ´ëĤ´&#34;:1514,&#34;ëķ&#34;:1515,&#34;ëĿ¼ëıĦ&#34;:1516,&#34;Ġëĵ±&#34;:1517,&#34;íĻĺ&#34;:1518,&#34;ìłĦìĹĲ&#34;:1519,&#34;Ġë²Ħ&#34;:1520,&#34;ĠëĮĢëĭ¨&#34;:1521,&#34;ëķĮë¬¸ìĹĲ&#34;:1522,&#34;Ġê¶&#34;:1523,&#34;Ġì»&#34;:1524,&#34;ĠìĹĦì²Ń&#34;:1525,&#34;íĹĪ&#34;:1526,&#34;ĠëĶ±&#34;:1527,&#34;ĠëĤĺìĺ¤ëĬĶ&#34;:1528,&#34;ê·¸ëŀĺ&#34;:1529,&#34;Ġëĭµ&#34;:1530,&#34;ëģĿ&#34;:1531,&#34;Ġ5&#34;:1532,&#34;ëĭ´&#34;:1533,&#34;ë»Ķ&#34;:1534,&#34;ê°Ŀ&#34;:1535,&#34;Ġì¦Ĳ&#34;:1536,&#34;ĠëĿ¼&#34;:1537,&#34;ĠìķĦëĭĪëĭ¤&#34;:1538,&#34;Ġëĸ¨ìĸ´&#34;:1539,&#34;ĠêµĲ&#34;:1540,&#34;ëĿ¼ë¦¬&#34;:1541,&#34;ĠìĹī&#34;:1542,&#34;ĠìķĬìĿĢ&#34;:1543,&#34;~~~&#34;:1544,&#34;ĠëĬĲê»´&#34;:1545,&#34;ìĿ´ê°Ģ&#34;:1546,&#34;ëŀĮ&#34;:1547,&#34;ë²Ķ&#34;:1548,&#34;íķľíħĮ&#34;:1549,&#34;ê¸°ìĹĲ&#34;:1550,&#34;Ġê°Ī&#34;:1551,&#34;Ł¬&#34;:1552,&#34;ìĸ´ëıĦ&#34;:1553,&#34;Ġ7&#34;:1554,&#34;ìķ¡ìħĺ&#34;:1555,&#34;ë¦¬ìĺ¤&#34;:1556,&#34;Ġê·¸ëłĩ&#34;:1557,&#34;ìķ½&#34;:1558,&#34;ë§Įíķľ&#34;:1559,&#34;Ġë¯¿&#34;:1560,&#34;ĠìĺģíĻĶìĿĺ&#34;:1561,&#34;ì´Ī&#34;:1562,&#34;ìłĲìĿ´&#34;:1563,&#34;Ġìŀħ&#34;:1564,&#34;Ġíĺ¸&#34;:1565,&#34;ëĭ¤ë©´&#34;:1566,&#34;íķ´ìļĶ&#34;:1567,&#34;ĠìķĦìī½&#34;:1568,&#34;íķĺë©´ìĦľ&#34;:1569,&#34;Ġìķ½&#34;:1570,&#34;ìĦ±ìĿ´&#34;:1571,&#34;Ġë§ĮëĵľëĬĶ&#34;:1572,&#34;ĠìĹ°ê¸°ê°Ģ&#34;:1573,&#34;ëĿ¼ë§Īë&#34;:1574,&#34;ìĵ°&#34;:1575,&#34;ì²ĺìĿĮ&#34;:1576,&#34;ë¥Ń&#34;:1577,&#34;ìĿ´ëĿ¼ê³ł&#34;:1578,&#34;ëĭ¤ìĭľ&#34;:1579,&#34;ìĹĦ&#34;:1580,&#34;ĠìŀĲì²´&#34;:1581,&#34;ëĿ½&#34;:1582,&#34;Ġê°ľë´ī&#34;:1583,&#34;ãĦ·ãĦ·&#34;:1584,&#34;ë³ĳ&#34;:1585,&#34;íģĲ&#34;:1586,&#34;ìŀĩ&#34;:1587,&#34;íĸ¥&#34;:1588,&#34;ĠìĨĲ&#34;:1589,&#34;ìĹħ&#34;:1590,&#34;Ġê¿&#34;:1591,&#34;ĶĶ&#34;:1592,&#34;łĪ&#34;:1593,&#34;ë§Įíģ¼&#34;:1594,&#34;ĠëŃĶê°Ģ&#34;:1595,&#34;ìµľê³łìĿĺ&#34;:1596,&#34;ĠíĮĮ&#34;:1597,&#34;Ġìĸ´ëĸ»ê²Į&#34;:1598,&#34;Ġëĭ´&#34;:1599,&#34;Ġëĸł&#34;:1600,&#34;Ġê¸°ë¶Ħ&#34;:1601,&#34;ĠìĽĲìŀĳ&#34;:1602,&#34;ĠíĿ¥ë¯¸&#34;:1603,&#34;ĠìĻĢ&#34;:1604,&#34;Ġë´Ĳìķ¼&#34;:1605,&#34;ìľ¼ëĤĺ&#34;:1606,&#34;ĠìķĦìī¬&#34;:1607,&#34;ê°Ļëĭ¤&#34;:1608,&#34;Ġìĭ¸&#34;:1609,&#34;Ġì¹ľ&#34;:1610,&#34;Įë¥Ń&#34;:1611,&#34;ë´¤ëĬĶëį°&#34;:1612,&#34;ìķĦëĭĪ&#34;:1613,&#34;ëįĺëį°&#34;:1614,&#34;Ġë¬¼&#34;:1615,&#34;ìĿ¸ëĵ¯&#34;:1616,&#34;Īë°ĺ&#34;:1617,&#34;Īë¡ľ&#34;:1618,&#34;ëĶ´&#34;:1619,&#34;ëĤ¬&#34;:1620,&#34;Ġìŀ¬ë¯¸ìŀĪê²Į&#34;:1621,&#34;ĳĺ&#34;:1622,&#34;ê¸°ê°Ģ&#34;:1623,&#34;ĠëĤĺìĻĶ&#34;:1624,&#34;ìŀĪëĭ¤&#34;:1625,&#34;ëĬĶê²Į&#34;:1626,&#34;íĺ¼&#34;:1627,&#34;Ġãħĭãħĭãħĭãħĭ&#34;:1628,&#34;ĠìµľìķħìĿĺ&#34;:1629,&#34;Ġê°Ģì¡±&#34;:1630,&#34;íķľêµŃ&#34;:1631,&#34;ì°½&#34;:1632,&#34;ìĿ´ëŀĢ&#34;:1633,&#34;Ġê³&#34;:1634,&#34;ĠìķĦì£¼&#34;:1635,&#34;Ġë¶Ģì¡±&#34;:1636,&#34;ìŀ¬ë°ĭ&#34;:1637,&#34;Ġ-&#34;:1638,&#34;Ġê·¸ëŀĺëıĦ&#34;:1639,&#34;ĠìĹ°ê¸°ëıĦ&#34;:1640,&#34;Ġìķħ&#34;:1641,&#34;ĠìłľìĿ¼&#34;:1642,&#34;Ġëıħ&#34;:1643,&#34;ëħĦëĮĢ&#34;:1644,&#34;ĠìķĦëĭĪê³ł&#34;:1645,&#34;Ġë¸&#34;:1646,&#34;ĠìĤ¶&#34;:1647,&#34;ëĤľëĭ¤&#34;:1648,&#34;ĠìķĦê¹Įìļ´&#34;:1649,&#34;ìĹĨìĿĮ&#34;:1650,&#34;ë³Ħë¡ľ&#34;:1651,&#34;ìģľ&#34;:1652,&#34;ìºĲ&#34;:1653,&#34;ì§Ģê¸Ī&#34;:1654,&#34;ĠìķĬëĬĶ&#34;:1655,&#34;ĠëĮĢë°ķ&#34;:1656,&#34;ë³´ë©´&#34;:1657,&#34;ĠìłľëĮĢë¡ľ&#34;:1658,&#34;Ġê·¼ëį°&#34;:1659,&#34;ĠìĹ¬ë&#34;:1660,&#34;ì¹ĺëĬĶ&#34;:1661,&#34;©´&#34;:1662,&#34;ê¿&#34;:1663,&#34;ìį¨&#34;:1664,&#34;ãħīãħī&#34;:1665,&#34;ì§Ĳ&#34;:1666,&#34;íķ´ëıĦ&#34;:1667,&#34;Įį&#34;:1668,&#34;Ġê½&#34;:1669,&#34;Ġìŀł&#34;:1670,&#34;Ġìĸ´ëĶĶ&#34;:1671,&#34;Ġãħ&#34;:1672,&#34;ĠìŀĬ&#34;:1673,&#34;ĠíĥĢ&#34;:1674,&#34;ĠìĶ&#34;:1675,&#34;íĮ¨&#34;:1676,&#34;ë¹Ļ&#34;:1677,&#34;Ġë³´ëĭ¤&#34;:1678,&#34;ĠëķĮë¬¸ìĹĲ&#34;:1679,&#34;Ġìŀ¬ë°ĭ&#34;:1680,&#34;ìĹ¬ìŀĲ&#34;:1681,&#34;íıīìłĲìĿ´&#34;:1682,&#34;ĠìĨĮìŀ¬&#34;:1683,&#34;Ġëª©&#34;:1684,&#34;êº¼&#34;:1685,&#34;ìĹ¬ë&#34;:1686,&#34;ìĺ¬&#34;:1687,&#34;íķłìĪĺ&#34;:1688,&#34;ĠìĿ´ìľł&#34;:1689,&#34;íĪ¬&#34;:1690,&#34;·¨&#34;:1691,&#34;ìĨĶì§ģíŀĪ&#34;:1692,&#34;Ġì¡°ê¸Ī&#34;:1693,&#34;ì¸&#34;:1694,&#34;ìĻķ&#34;:1695,&#34;Ġë©Ķ&#34;:1696,&#34;ĠëĤł&#34;:1697,&#34;ìĹĲìļĶ&#34;:1698,&#34;Ġì§Ī&#34;:1699,&#34;íģ´&#34;:1700,&#34;ëĤĺê³ł&#34;:1701,&#34;ëĤĺëıĦ&#34;:1702,&#34;ìµľìķħ&#34;:1703,&#34;ĠìĺģíĻĶëĿ¼ê³ł&#34;:1704,&#34;ë£¡&#34;:1705,&#34;ĠëĤ´ìļ©ìĿ´&#34;:1706,&#34;ĠëĲł&#34;:1707,&#34;ìĭ¶ëĭ¤&#34;:1708,&#34;ë²½&#34;:1709,&#34;ê°Ī&#34;:1710,&#34;ë¦¬ë¥¼&#34;:1711,&#34;ì§Ħëĭ¤&#34;:1712,&#34;~~~~&#34;:1713,&#34;Ġìĭ¶ìĿĢ&#34;:1714,&#34;ĵ¸&#34;:1715,&#34;ìĿ´ëłĩê²Į&#34;:1716,&#34;Ġë³´ê²Į&#34;:1717,&#34;ìķĺëĬĶëį°&#34;:1718,&#34;ë§Īëĭ¤&#34;:1719,&#34;Ġì¹´&#34;:1720,&#34;ëĤĺë¦¬ìĺ¤&#34;:1721,&#34;¬ë§ģ&#34;:1722,&#34;Ġë²ł&#34;:1723,&#34;Ĳëĭ¤&#34;:1724,&#34;ëĪĦ&#34;:1725,&#34;ìĿ´ëĦ¤&#34;:1726,&#34;ê¸°ë¥¼&#34;:1727,&#34;ĠëĤĺìĻĢ&#34;:1728,&#34;ìłģìĿ´ê³ł&#34;:1729,&#34;Ġëª¨ë¥´ê²ł&#34;:1730,&#34;íķĺëĬĶëį°&#34;:1731,&#34;êµ°ìļĶ&#34;:1732,&#34;ê¶Į&#34;:1733,&#34;ëıĮ&#34;:1734,&#34;ìĬ¤íĮħ&#34;:1735,&#34;ĠëĬĲëģ¼&#34;:1736,&#34;Ġë°°ìļ°ëĵ¤&#34;:1737,&#34;Ġê¸´ìŀ¥ê°Ĳ&#34;:1738,&#34;ê¾¸&#34;:1739,&#34;ìĿ´ìķ¼&#34;:1740,&#34;Ġìķŀ&#34;:1741,&#34;ëĤĺìļĶ&#34;:1742,&#34;ëŀľë§ĮìĹĲ&#34;:1743,&#34;ĠìĤ´ìķĦ&#34;:1744,&#34;Ġìŀ¬ë°Įëĭ¤&#34;:1745,&#34;ê³¤&#34;:1746,&#34;ìłĲìĿĢ&#34;:1747,&#34;ĠìĺģíĻĶìŀħëĭĪëĭ¤&#34;:1748,&#34;Ġíĺķ&#34;:1749,&#34;ìĬ¤ëŁ¬ìļ´&#34;:1750,&#34;ĠíĨµ&#34;:1751,&#34;ê²ģ&#34;:1752,&#34;ìĺģíĻĶìĿĺ&#34;:1753,&#34;ë°ĸìĹĲ&#34;:1754,&#34;ĠíĬ¹íŀĪ&#34;:1755,&#34;ĠìĺģíĻĶë¡ľ&#34;:1756,&#34;ë¸Ķ&#34;:1757,&#34;êµ´&#34;:1758,&#34;Ġìĭ¶ëĭ¤&#34;:1759,&#34;ĠìĿĺë¯¸&#34;:1760,&#34;ĠìĺģíĻĶìĺĢ&#34;:1761,&#34;ì¤ĺ&#34;:1762,&#34;ìĹĪìĬµëĭĪëĭ¤&#34;:1763,&#34;Ġìłķìĭł&#34;:1764,&#34;ìľ¼ë¡ľëıĦ&#34;:1765,&#34;Ġêµ¿&#34;:1766,&#34;Ġë§īìŀ¥&#34;:1767,&#34;Ľ°&#34;:1768,&#34;ìłķìĿ´&#34;:1769,&#34;ĠëĮĢìĤ¬&#34;:1770,&#34;Ġì£¼ëĬĶ&#34;:1771,&#34;Ġìĭ«&#34;:1772,&#34;Ġìĭľìŀĳ&#34;:1773,&#34;ìļ±&#34;:1774,&#34;ĠìłĪëĮĢ&#34;:1775,&#34;Ġì¢ĭê³ł&#34;:1776,&#34;Ġìłľìŀĳ&#34;:1777,&#34;âĻ¥âĻ¥&#34;:1778,&#34;ìķĦëĭ&#34;:1779,&#34;ê·Ģ&#34;:1780,&#34;ĠëĤ´ìļ©ëıĦ&#34;:1781,&#34;Ġëħ¸ëŀĺ&#34;:1782,&#34;Ġëį°&#34;:1783,&#34;ĠíĽĮë¥Ń&#34;:1784,&#34;Ġì²ľ&#34;:1785,&#34;Ġìĸ´ì©&#34;:1786,&#34;Ġìķ¼&#34;:1787,&#34;Ġê°ģ&#34;:1788,&#34;ëĦĪ&#34;:1789,&#34;ĠëĴ¤&#34;:1790,&#34;ĠëĲĺëĬĶ&#34;:1791,&#34;ĠìķĦë¦Ħëĭ¤ìļ´&#34;:1792,&#34;ëįķ&#34;:1793,&#34;ëł¨&#34;:1794,&#34;íķ´ìķ¼&#34;:1795,&#34;ĠëĤ¨ëĬĶ&#34;:1796,&#34;Ġ^^&#34;:1797,&#34;ĠíĽ¨&#34;:1798,&#34;ĠìĽĥê¸°&#34;:1799,&#34;íĬ¼&#34;:1800,&#34;ë¯¹&#34;:1801,&#34;ì§Ģê°Ģ&#34;:1802,&#34;ì§¸&#34;:1803,&#34;Ġë¶Ģë¶Ħ&#34;:1804,&#34;ëĨĪ&#34;:1805,&#34;ëĭĪë©ĶìĿ´&#34;:1806,&#34;Ġì¶ľìĹ°&#34;:1807,&#34;ĠìĪĺìŀĳ&#34;:1808,&#34;Ġì´Ī&#34;:1809,&#34;ĥĲ&#34;:1810,&#34;Ġë¦¬&#34;:1811,&#34;ëĤ¸&#34;:1812,&#34;ì¢ĭìķĦ&#34;:1813,&#34;ìĿ¸ìłģìľ¼ë¡ľ&#34;:1814,&#34;ĪëĶ&#34;:1815,&#34;ì¤Ģëĭ¤&#34;:1816,&#34;ëĭĪë©ĶìĿ´ìħĺ&#34;:1817,&#34;íķ©&#34;:1818,&#34;Ġëľ&#34;:1819,&#34;ìĭ¶ìĿĢ&#34;:1820,&#34;íľ´&#34;:1821,&#34;ëĤĺê²Į&#34;:1822,&#34;Ġë³µ&#34;:1823,&#34;ĠìĹĨìĿĮ&#34;:1824,&#34;???&#34;:1825,&#34;ë§ĪëĤĺ&#34;:1826,&#34;Ġì¤ĳê°Ħ&#34;:1827,&#34;ìĿ¸ìĿ´&#34;:1828,&#34;ë²ķ&#34;:1829,&#34;Ġãħł&#34;:1830,&#34;ìĬ¬&#34;:1831,&#34;ĠëłĪ&#34;:1832,&#34;Ģìĸ´&#34;:1833,&#34;ìĽĲìŀĳ&#34;:1834,&#34;íķľëį°&#34;:1835,&#34;Ġë´¤ìĬµëĭĪëĭ¤&#34;:1836,&#34;Ġë¹¼&#34;:1837,&#34;ĠëĶ°ëľ»&#34;:1838,&#34;ëŃĶ&#34;:1839,&#34;ì¦Į&#34;:1840,&#34;;;;&#34;:1841,&#34;_-&#34;:1842,&#34;ì¯&#34;:1843,&#34;Ġë´¤ëįĺ&#34;:1844,&#34;Ġë¡ľë§¨&#34;:1845,&#34;´Ĳ&#34;:1846,&#34;ìĮį&#34;:1847,&#34;ë°±&#34;:1848,&#34;ëĵĿ&#34;:1849,&#34;Ġìĭľë¦¬ì¦Ī&#34;:1850,&#34;íļ¨&#34;:1851,&#34;Ġ20&#34;:1852,&#34;ì§ĵ&#34;:1853,&#34;ìĿ¸ìĥĿ&#34;:1854,&#34;ìĦ±ëıĦ&#34;:1855,&#34;ê²ĥìĿ´&#34;:1856,&#34;ì¹ĺê³ł&#34;:1857,&#34;íħĲ&#34;:1858,&#34;ìĥĪ&#34;:1859,&#34;Ġë¬´ìĦľ&#34;:1860,&#34;Ġì¢ĭìķĺëĭ¤&#34;:1861,&#34;ìŀĳíĴĪ&#34;:1862,&#34;Ġë¬´ìĹĩ&#34;:1863,&#34;ê´ĳ&#34;:1864,&#34;ĠëĶĶ&#34;:1865,&#34;ìķĦê¹Ŀ&#34;:1866,&#34;Ġìĸ´ìĦ¤&#34;:1867,&#34;ĠìķĮë°Ķ&#34;:1868,&#34;ëĭ¥&#34;:1869,&#34;íķľê±°&#34;:1870,&#34;Ġì¢ĭìķĦíķĺëĬĶ&#34;:1871,&#34;íĹĺ&#34;:1872,&#34;ĠìĤ¼&#34;:1873,&#34;Ġìŀ¬ë¯¸ëıĦ&#34;:1874,&#34;Ġíĸīë³µ&#34;:1875,&#34;Ġë³´ëĭ¤ê°Ģ&#34;:1876,&#34;ì§Ŀ&#34;:1877,&#34;ìŀĸ&#34;:1878,&#34;ìĿ¼ë³¸&#34;:1879,&#34;ĠêµŃ&#34;:1880,&#34;oo&#34;:1881,&#34;ë©ĭ&#34;:1882,&#34;Ġìŀ¬ë¯¸ìĹĨëĭ¤&#34;:1883,&#34;ĠìĿ´íķ´ê°Ģ&#34;:1884,&#34;ĠìĤ°&#34;:1885,&#34;íĶĮ&#34;:1886,&#34;ìĹ´&#34;:1887,&#34;Ġê¹Ĭ&#34;:1888,&#34;ê²¬&#34;:1889,&#34;ĠìĿ´ê±¸&#34;:1890,&#34;ĠìĥĿê°ģìĿ´&#34;:1891,&#34;¬ë§ģíĥĢìŀĦ&#34;:1892,&#34;ì¶©&#34;:1893,&#34;ĠíĮĲ&#34;:1894,&#34;ëĶĶìĺ¤&#34;:1895,&#34;ìłĲìĿĦ&#34;:1896,&#34;Ġì§Ħìĭ¬&#34;:1897,&#34;ìķĦë¬´&#34;:1898,&#34;Ġë³Ģ&#34;:1899,&#34;ìĿ´ëĦ¤ìļĶ&#34;:1900,&#34;ìķĦê¹Į&#34;:1901,&#34;ë¶Ģë¶Ħ&#34;:1902,&#34;Ġìĭľê°ĦìĿ´&#34;:1903,&#34;ìļķ&#34;:1904,&#34;êµ¬ë§Į&#34;:1905,&#34;ĠíĻį&#34;:1906,&#34;,,,&#34;:1907,&#34;ĠìĿ¸ìĥģ&#34;:1908,&#34;ĠìĬ¤íĨłë¦¬ëıĦ&#34;:1909,&#34;ë¦¬ì§Ģ&#34;:1910,&#34;ĠëŃĺ&#34;:1911,&#34;ìĤ¼&#34;:1912,&#34;Ġìĸ´ìĥī&#34;:1913,&#34;Ġë¬´ìĦŃ&#34;:1914,&#34;ĠìłĲìĪĺ&#34;:1915,&#34;ĠìĹĨìĿ´&#34;:1916,&#34;ë§Ľ&#34;:1917,&#34;ëıĻìķĪ&#34;:1918,&#34;ìĹ½&#34;:1919,&#34;Ġíŀĺëĵ¤&#34;:1920,&#34;ìłĲëĮĢ&#34;:1921,&#34;Ġìŀĳê°Ģ&#34;:1922,&#34;Ġëĵ¤ìĸ´&#34;:1923,&#34;ĠìķĦì§ģëıĦ&#34;:1924,&#34;ĽëĤł&#34;:1925,&#34;ë²ł&#34;:1926,&#34;ĠìĬ¤íĨłë¦¬ê°Ģ&#34;:1927,&#34;Ġì¼&#34;:1928,&#34;ëŁ½ê²Į&#34;:1929,&#34;Ġëª»íķľ&#34;:1930,&#34;Ġíķ¨ê»ĺ&#34;:1931,&#34;ĠìĿ´ìĺģíĻĶ&#34;:1932,&#34;ìļ°ë¦¬&#34;:1933,&#34;Ġìłľëª©&#34;:1934,&#34;ĠìķłëĭĪ&#34;:1935,&#34;ëģĶ&#34;:1936,&#34;ëĤ¨ìŀĲ&#34;:1937,&#34;Ġê°ĳ&#34;:1938,&#34;ì¶ĺ&#34;:1939,&#34;ìĿĦëĵ¯&#34;:1940,&#34;Ġìŀ¡&#34;:1941,&#34;Ġê·¸ëŁ¬&#34;:1942,&#34;ĠìĹ¬ìļ´ìĿ´&#34;:1943,&#34;ĠìķĪë³´&#34;:1944,&#34;ĠíĻķ&#34;:1945,&#34;Ł¬ë&#34;:1946,&#34;ĠëĦ¤&#34;:1947,&#34;ĠìĤ¬ìĭ¤&#34;:1948,&#34;Ġëĳĺ&#34;:1949,&#34;Ġê¸¸&#34;:1950,&#34;Ġìĭľì²Ń&#34;:1951,&#34;Ġê¶ģ&#34;:1952,&#34;ĠìĨĮë¦Ħ&#34;:1953,&#34;ì¹¨&#34;:1954,&#34;Ġëĭµëĭµ&#34;:1955,&#34;ëħ¸ìŀ¼&#34;:1956,&#34;ĠìŀĲìĭł&#34;:1957,&#34;ëĵ¤ìĹĲê²Į&#34;:1958,&#34;Ġë³´ë©´ìĦľ&#34;:1959,&#34;Ġê°ĲëıħìĿĺ&#34;:1960,&#34;ìħ¨&#34;:1961,&#34;Ġìī&#34;:1962,&#34;Ġë¬¸ìłľ&#34;:1963,&#34;~!&#34;:1964,&#34;Ńë¹Ħ&#34;:1965,&#34;Ġì°¾ìķĦ&#34;:1966,&#34;ì¿&#34;:1967,&#34;Ġë¿Ĳ&#34;:1968,&#34;ĠëĽ°&#34;:1969,&#34;ìĿ´ì§Ģë§Į&#34;:1970,&#34;ëĺĲ&#34;:1971,&#34;ĠìĭłìĦł&#34;:1972,&#34;ìĿĮìķħ&#34;:1973,&#34;ìĽĶ&#34;:1974,&#34;íĺľ&#34;:1975,&#34;Ġë©ĭì§Ħ&#34;:1976,&#34;ìĿ´ìķ¼ê¸°&#34;:1977,&#34;Ġê¹¨&#34;:1978,&#34;Ġíĭ°&#34;:1979,&#34;ê±°ë¦¬&#34;:1980,&#34;ê±´ê°Ģ&#34;:1981,&#34;Ġíķĺì§Ģ&#34;:1982,&#34;Ġìĸ´ìĿ´&#34;:1983,&#34;Ġê´ľì°®ìĿĢ&#34;:1984,&#34;ê²¼&#34;:1985,&#34;ìŀĲê¸°&#34;:1986,&#34;ĠëĤĺë¦Ħ&#34;:1987,&#34;ëįĶëĭĪ&#34;:1988,&#34;ĪëįĶ&#34;:1989,&#34;Ġ6&#34;:1990,&#34;íķĺìĭľ&#34;:1991,&#34;Ġê°ĲëıħìĿ´&#34;:1992,&#34;Īë³´&#34;:1993,&#34;Ġë¹¨&#34;:1994,&#34;ìĬ·&#34;:1995,&#34;Ġë¶ĦìľĦ&#34;:1996,&#34;ĠíĹĪìłĳ&#34;:1997,&#34;ĠìĬ¤ë¦´ëŁ¬&#34;:1998,&#34;ĠìĹĶ&#34;:1999,&#34;ĠëĤļ&#34;:2000,&#34;ëĿ¼ìĿ´&#34;:2001,&#34;ìĨĮë¦¬&#34;:2002,&#34;ëĭ¤ë¥¸&#34;:2003,&#34;Īëģ&#34;:2004,&#34;êµ¬ìļĶ&#34;:2005,&#34;Ġê´Ģê°Ŀ&#34;:2006,&#34;ê²Ł&#34;:2007,&#34;ì£¼ìĿĺ&#34;:2008,&#34;Ġìļ©&#34;:2009,&#34;ëĤĺë§Ī&#34;:2010,&#34;ĠìĦ¸ìĥģ&#34;:2011,&#34;ĠC&#34;:2012,&#34;ì£Ħ&#34;:2013,&#34;Ġë³´ìĦ¸ìļĶ&#34;:2014,&#34;Ġë¯¸êµŃ&#34;:2015,&#34;ĠìķĪíĥĢ&#34;:2016,&#34;ĠìŀĶìŀĶ&#34;:2017,&#34;Ġìŀ¼ìŀĪ&#34;:2018,&#34;ëª°&#34;:2019,&#34;âĻ¡&#34;:2020,&#34;Ġíļ&#34;:2021,&#34;Ġ &#34; &#34; &#34; &#34;&#34;:2022,&#34;ëĳ&#34;:2023,&#34;Ġìŀ¬ë¯¸ê°Ģ&#34;:2024,&#34;Ġë¦¬ë&#34;:2025,&#34;ĠìĭľëĤĺë¦¬ìĺ¤&#34;:2026,&#34;Ġíģ°&#34;:2027,&#34;ìľ¤&#34;:2028,&#34;ì¤ĳê°Ħ&#34;:2029,&#34;Ġë§ĺ&#34;:2030,&#34;ë§Įëĵł&#34;:2031,&#34;Ġì¡¸ìŀĳ&#34;:2032,&#34;Īë²&#34;:2033,&#34;ĠíĿĲ&#34;:2034,&#34;ĠíĻ©&#34;:2035,&#34;ì»¤&#34;:2036,&#34;íķľìĺģíĻĶ&#34;:2037,&#34;íķĺë©°&#34;:2038,&#34;íķ¨ìĿĦ&#34;:2039,&#34;Ġ0&#34;:2040,&#34;ĠìļĶì¦ĺ&#34;:2041,&#34;ìłĦê°ľ&#34;:2042,&#34;ì¡¸&#34;:2043,&#34;ĠìĹ°ê¸°ëĬĶ&#34;:2044,&#34;ë¹Ī&#34;:2045,&#34;ì±ħ&#34;:2046,&#34;ë§ĪëĿ¼&#34;:2047,&#34;Ġê¸Ģ&#34;:2048,&#34;íĥĿ&#34;:2049,&#34;ê°ĻìĿ´&#34;:2050,&#34;Ġì°¨ëĿ¼ë¦¬&#34;:2051,&#34;ĠìŀĪìĹĪ&#34;:2052,&#34;Ġë§ĮíĻĶ&#34;:2053,&#34;ì°¬&#34;:2054,&#34;Ġìĸ¼ë§ĪëĤĺ&#34;:2055,&#34;ĠëıĮìķĦ&#34;:2056,&#34;ĠëĤĺëĬĶ&#34;:2057,&#34;ëłĪìĿ´&#34;:2058,&#34;Ġë°°ê²½&#34;:2059,&#34;ĠìĬ¬íĶĦ&#34;:2060,&#34;Ġìĸ¸ìłľ&#34;:2061,&#34;Ġê°ķì¶Ķ&#34;:2062,&#34;Ġì²¨&#34;:2063,&#34;ë§ĪëĶĶ&#34;:2064,&#34;ĠíĻĺ&#34;:2065,&#34;ĠíĽĦíļĮ&#34;:2066,&#34;Ġì©&#34;:2067,&#34;ì²Ļ&#34;:2068,&#34;ĠëĬĲëĤĮìĿ´&#34;:2069,&#34;Ġì¼Ģ&#34;:2070,&#34;ê¸¸ëŀĺ&#34;:2071,&#34;ĠìĻĦë²½&#34;:2072,&#34;ĠëĤ«&#34;:2073,&#34;ë³´ëĭ¨&#34;:2074,&#34;Ġíĺ¼&#34;:2075,&#34;!!!!!!!!&#34;:2076,&#34;Ġìĸ´ëĸ¤&#34;:2077,&#34;ĠìķĦë¦Ħëĭµ&#34;:2078,&#34;ê°Ģì§Ģ&#34;:2079,&#34;ëĮĢíķľ&#34;:2080,&#34;Ġê·ĢìĹ¬&#34;:2081,&#34;st&#34;:2082,&#34;Ġëª¸&#34;:2083,&#34;íĺĦìĭ¤&#34;:2084,&#34;ì±Ħ&#34;:2085,&#34;íĭ±&#34;:2086,&#34;ëĭ¹íŀĪ&#34;:2087,&#34;ĠìĺģíĻĶëĿ¼&#34;:2088,&#34;ëŀĦ&#34;:2089,&#34;ĠìķĬìķĺ&#34;:2090,&#34;Ġìĸĳ&#34;:2091,&#34;ê¹Ĭ&#34;:2092,&#34;ë³´ëĭĪ&#34;:2093,&#34;ëªĩ&#34;:2094,&#34;íĸĪìĿĮ&#34;:2095,&#34;Ġê·¸ìłĢ&#34;:2096,&#34;ìĻĦ&#34;:2097,&#34;ĠìĤ¬ëŀĮìĿ´&#34;:2098,&#34;íķĻêµĲ&#34;:2099,&#34;Ġë»Ķíķľ&#34;:2100,&#34;Ġì£¼ê³ł&#34;:2101,&#34;ĠìķĮê³ł&#34;:2102,&#34;ĠìĭĿ&#34;:2103,&#34;Ġê²ĥìĿ´&#34;:2104,&#34;ì¤Į&#34;:2105,&#34;Ġëĭ¤íģĲ&#34;:2106,&#34;ãħłãħłãħłãħł&#34;:2107,&#34;ĠìķłëĭĪë©ĶìĿ´ìħĺ&#34;:2108,&#34;ĠíĨł&#34;:2109,&#34;Ġë²Ķ&#34;:2110,&#34;ëĬĲëĤ&#34;:2111,&#34;ìŀĪê³ł&#34;:2112,&#34;íĥĪ&#34;:2113,&#34;ìķĪëĲĺ&#34;:2114,&#34;íħĲëį°&#34;:2115,&#34;ĠìŀĪê³ł&#34;:2116,&#34;ĠëĵľëĿ¼ë§Īë&#34;:2117,&#34;ìĿ¸ì¤Ħ&#34;:2118,&#34;Ġìŀ¬ë°ĮëĬĶ&#34;:2119,&#34;Ġìĸĺ&#34;:2120,&#34;ìĿ´ë²Ħ&#34;:2121,&#34;ĠìĺģíĻĶëıĦ&#34;:2122,&#34;ìľłì¹ĺ&#34;:2123,&#34;íıŃ&#34;:2124,&#34;Ġì´Ŀ&#34;:2125,&#34;Ġì²Ń&#34;:2126,&#34;ìŀ¬ë¯¸ìĹĨ&#34;:2127,&#34;Ġì¶Ķìĸµ&#34;:2128,&#34;Ġãħİ&#34;:2129,&#34;ĠìĽĥìĿĮ&#34;:2130,&#34;ìĽħ&#34;:2131,&#34;Ġëª¨ë¥´ê²łëĭ¤&#34;:2132,&#34;ĠíĿ¬&#34;:2133,&#34;Ġê¸°ìĸµìĹĲ&#34;:2134,&#34;ìĭ¸&#34;:2135,&#34;Ġìŀ¥ëĤľ&#34;:2136,&#34;ĠìĭľëĮĢ&#34;:2137,&#34;ĠìłĦìŁģ&#34;:2138,&#34;Ġê°ĻìĿ´&#34;:2139,&#34;Ġê·¸ëłĩê²Į&#34;:2140,&#34;ìĭľê¸¸&#34;:2141,&#34;ëªħìŀĳ&#34;:2142,&#34;Ġê¶ģê¸Ī&#34;:2143,&#34;ê°ĳ&#34;:2144,&#34;ê±°ì§Ģ&#34;:2145,&#34;ì¼ľ&#34;:2146,&#34;íı¬ë&#34;:2147,&#34;ìĽłëĭ¤&#34;:2148,&#34;ëĵ¤ê³¼&#34;:2149,&#34;Ġì¶©ë¶Ħ&#34;:2150,&#34;ëŁ´&#34;:2151,&#34;Ġíķľëĭ¤&#34;:2152,&#34;ëł¤ëĬĶ&#34;:2153,&#34;ĠìĹĶëĶ©&#34;:2154,&#34;Ġê°Ĳìłķ&#34;:2155,&#34;ê´ĢìĹĲìĦľ&#34;:2156,&#34;Ġê²°êµŃ&#34;:2157,&#34;ì½©&#34;:2158,&#34;ìĿ´ê±¸&#34;:2159,&#34;ì°į&#34;:2160,&#34;ë¬´ìĬ¨&#34;:2161,&#34;20&#34;:2162,&#34;Ġë´¤ìĸ´ìļĶ&#34;:2163,&#34;ê²ĥê°Ļ&#34;:2164,&#34;Ġê¹Į&#34;:2165,&#34;ëĭĿ&#34;:2166,&#34;ìĬ¤íĥĢ&#34;:2167,&#34;ì°°&#34;:2168,&#34;ë´Ħ&#34;:2169,&#34;ë¥´ëĬĶ&#34;:2170,&#34;ëł¥ìĿ´&#34;:2171,&#34;ĠìķĪëĲĺëĬĶ&#34;:2172,&#34;Ģìŀ¼&#34;:2173,&#34;ĠíĿĺ&#34;:2174,&#34;Ġì§Ģë£¨íķľ&#34;:2175,&#34;ìłķíķľ&#34;:2176,&#34;Ġë¹łìł¸&#34;:2177,&#34;ĠìĬ¤íĥĢ&#34;:2178,&#34;Ġì§ĳì¤ĳ&#34;:2179,&#34;Ġë¬¸&#34;:2180,&#34;Ġê¿Ī&#34;:2181,&#34;ìĿ¸ê°Ħ&#34;:2182,&#34;ìķ¼ì§Ģ&#34;:2183,&#34;ë²Ħë¦°&#34;:2184,&#34;Ġì£¼ìĹ°&#34;:2185,&#34;íķ¨ìĿ´&#34;:2186,&#34;Ġê°ľìĹ°&#34;:2187,&#34;ĠëĶ°ëĿ¼&#34;:2188,&#34;Ġìĸ´ë¦°&#34;:2189,&#34;ìłľëª©&#34;:2190,&#34;Ġë°°ìļ°ëĵ¤ìĿĺ&#34;:2191,&#34;°°ìļ°&#34;:2192,&#34;Ġíħ&#34;:2193,&#34;ëŁŃ&#34;:2194,&#34;ë°Ģ&#34;:2195,&#34;Ġì¢ħ&#34;:2196,&#34;ĪëĶ©&#34;:2197,&#34;íİĺ&#34;:2198,&#34;ê´´&#34;:2199,&#34;īìŀ¥&#34;:2200,&#34;Ġì£&#34;:2201,&#34;ê°Ķ&#34;:2202,&#34;ìĦ±ìĿĦ&#34;:2203,&#34;ĠíıŃ&#34;:2204,&#34;ëł¸ëĭ¤&#34;:2205,&#34;ĠíķĺëĤĺëıĦ&#34;:2206,&#34;íĻľ&#34;:2207,&#34;ĠìķĶ&#34;:2208,&#34;ĠìĺģíĻĶì¤ĳ&#34;:2209,&#34;Ġì¶©ê²©&#34;:2210,&#34;ë³Ģ&#34;:2211,&#34;ìŀ¬ë°Įê²Į&#34;:2212,&#34;ëĲł&#34;:2213,&#34;ĠìĺģíĻĶëĦ¤ìļĶ&#34;:2214,&#34;ĠíķĻ&#34;:2215,&#34;ĠíĶĦ&#34;:2216,&#34;íĸĪì§Ģë§Į&#34;:2217,&#34;ĠíĪ&#34;:2218,&#34;ëģĦ&#34;:2219,&#34;ĠìĺĪìĪł&#34;:2220,&#34;ë¡Ń&#34;:2221,&#34;íİ¸ìĿ´&#34;:2222,&#34;ĠìľĦíķ´&#34;:2223,&#34;ĠB&#34;:2224,&#34;ĠëģĮ&#34;:2225,&#34;ëĨĵê³ł&#34;:2226,&#34;ìĪĺì¤Ģ&#34;:2227,&#34;Ġì½Ķë¯¹&#34;:2228,&#34;ëĮĢë°ķ&#34;:2229,&#34;ìŀĲì²´&#34;:2230,&#34;Ġt&#34;:2231,&#34;Ġãħľãħľ&#34;:2232,&#34;ĠìķĬëĬĶëĭ¤&#34;:2233,&#34;ìĺģìĥģ&#34;:2234,&#34;Ġì§Ħë¶Ģ&#34;:2235,&#34;Ġìŀ¬ë°Įìĸ´ìļĶ&#34;:2236,&#34;íķĺíķĺ&#34;:2237,&#34;ĠìŀĦ&#34;:2238,&#34;ĠíĦ°&#34;:2239,&#34;......&#34;:2240,&#34;ĠëĽ°ìĸ´&#34;:2241,&#34;ìĭľëĮĢ&#34;:2242,&#34;ĠìĬ¤íĨł&#34;:2243,&#34;Ġëıĭ&#34;:2244,&#34;????&#34;:2245,&#34;Įĵ&#34;:2246,&#34;ì¹ł&#34;:2247,&#34;ëĿ¼ë©´&#34;:2248,&#34;ĠìľĦíķľ&#34;:2249,&#34;ìĿ´ìĺģíĻĶ&#34;:2250,&#34;ê¸°ë§Į&#34;:2251,&#34;íķ´ì§ĢëĬĶ&#34;:2252,&#34;ìĪĺìŀĪ&#34;:2253,&#34;ê³µíı¬&#34;:2254,&#34;Ġë¯¼&#34;:2255,&#34;ĠìĿ´ìģĺ&#34;:2256,&#34;íŀĪë&#34;:2257,&#34;Ġì§Ģë£¨íķĺê³ł&#34;:2258,&#34;Ġì»¤&#34;:2259,&#34;ĠìĻľìĿ´&#34;:2260,&#34;ìĽĮìĦľ&#34;:2261,&#34;ëĲľëĭ¤&#34;:2262,&#34;ë¦¬ìĬ¤&#34;:2263,&#34;Ġíĥľ&#34;:2264,&#34;ĠìĹĨìĹĪëĭ¤&#34;:2265,&#34;ĠëĤĺëıĦ&#34;:2266,&#34;ìī¬&#34;:2267,&#34;ìķĦì£¼&#34;:2268,&#34;ë³´ëĭ¤ê°Ģ&#34;:2269,&#34;ĠíĮ¨&#34;:2270,&#34;ê°ĢìĦľ&#34;:2271,&#34;ìĿ´ëĿ¼ëıĦ&#34;:2272,&#34;Ġë¹ĦìĬ·&#34;:2273,&#34;ĵ´&#34;:2274,&#34;ëĭ¹ìĭľ&#34;:2275,&#34;Ġëª°ìŀħëıĦ&#34;:2276,&#34;ìħĶ&#34;:2277,&#34;ľë¡ľ&#34;:2278,&#34;íĻį&#34;:2279,&#34;ĠìĿ´ë¦Ħ&#34;:2280,&#34;ì²ł&#34;:2281,&#34;ĠìĿ½&#34;:2282,&#34;Ġì±ħ&#34;:2283,&#34;ìłł&#34;:2284,&#34;ê²ĥìĿĦ&#34;:2285,&#34;Ġë§Įëĵ¤ìĹĪ&#34;:2286,&#34;ê·¸ë¦¬ê³ł&#34;:2287,&#34;ĠìĨĶì§ģíŀĪ&#34;:2288,&#34;Ġë°±&#34;:2289,&#34;íĺ¹&#34;:2290,&#34;Ġê±į&#34;:2291,&#34;ĠíĥĦ&#34;:2292,&#34;Ġíģ´&#34;:2293,&#34;Ġ,&#34;:2294,&#34;ê·¸ëŁ°&#34;:2295,&#34;ëĵ¯íķľ&#34;:2296,&#34;ĠìĤ¬ëŀĮëĵ¤&#34;:2297,&#34;ìĺ´&#34;:2298,&#34;Ġì§Ģë£¨íķĺëĭ¤&#34;:2299,&#34;ĠìºĲìĬ¤íĮħ&#34;:2300,&#34;ë³´ê¸°&#34;:2301,&#34;ì½Ķë¯¸ëĶĶ&#34;:2302,&#34;íĸĩ&#34;:2303,&#34;Ġê´´&#34;:2304,&#34;ëĨĢ&#34;:2305,&#34;Ġì£¼ìłľ&#34;:2306,&#34;Ġìľłì¾Į&#34;:2307,&#34;ĠíĮ¬&#34;:2308,&#34;ĠíĽ¨ìĶ¬&#34;:2309,&#34;ìĿ´ìłľ&#34;:2310,&#34;Ġë¨¼&#34;:2311,&#34;ìĺ¬ë&#34;:2312,&#34;Ġê·¸ë§Į&#34;:2313,&#34;Ġìĸ´ëĬĲ&#34;:2314,&#34;Ġë¹ĦêµĲ&#34;:2315,&#34;ãĦ±&#34;:2316,&#34;Ġë¶ĪìĮį&#34;:2317,&#34;Ġìļ°ë¦¬ëĤĺëĿ¼&#34;:2318,&#34;ì°Į&#34;:2319,&#34;Ġ!&#34;:2320,&#34;ìĿ¸ìĿĺ&#34;:2321,&#34;ë°ĺìłĦ&#34;:2322,&#34;Ġìĸ¼êµ´&#34;:2323,&#34;Ġìĥģìĥģ&#34;:2324,&#34;ìĨĮìŀ¬&#34;:2325,&#34;Ġëĺĳ&#34;:2326,&#34;Ġê³µíı¬ìĺģíĻĶ&#34;:2327,&#34;ĠOOO&#34;:2328,&#34;ìĸ´ëĸ&#34;:2329,&#34;Ġë³ĳ&#34;:2330,&#34;ë³´ì§Ģ&#34;:2331,&#34;Ġë¶Īë&#34;:2332,&#34;ê²łì§Ģë§Į&#34;:2333,&#34;íĿ¥&#34;:2334,&#34;Ġê±¸ìŀĳ&#34;:2335,&#34;ĠíĶĦë¡ľ&#34;:2336,&#34;ĠëĪĪë¬¼ìĿ´&#34;:2337,&#34;ĠëįĶë¹Ļ&#34;:2338,&#34;Ġìĺ¤ëŀĺ&#34;:2339,&#34;ìŀĶìŀĶ&#34;:2340,&#34;ĠëıĦëĮĢì²´&#34;:2341,&#34;¬ëĭ¤&#34;:2342,&#34;ê¼Ń&#34;:2343,&#34;Ġìµľê³łëĭ¤&#34;:2344,&#34;ì§Ģì§Ģ&#34;:2345,&#34;Ġë§Īì§Ģë§īìĹĲ&#34;:2346,&#34;Ġì±Ħ&#34;:2347,&#34;Ġê²ĥìĿĦ&#34;:2348,&#34;Ġê°ĲëıĻëıĦ&#34;:2349,&#34;ìĭľíĤ¤&#34;:2350,&#34;ĠìĹ°ê¸°ë¥¼&#34;:2351,&#34;íĥĢì§Ģ&#34;:2352,&#34;ĠìķĮìķĺ&#34;:2353,&#34;Ġë²Ī&#34;:2354,&#34;ĠìĦ¤ìłķ&#34;:2355,&#34;íķľë²Ī&#34;:2356,&#34;Ġìĥī&#34;:2357,&#34;Ġë³´ìĹ¬ì£¼ëĬĶ&#34;:2358,&#34;ľìĹĲ&#34;:2359,&#34;ìľ¼ëĭĪ&#34;:2360,&#34;ìłķëıĦë¡ľ&#34;:2361,&#34;ìĿ´ìĹĪëĭ¤&#34;:2362,&#34;ë¥ł&#34;:2363,&#34;¬ë§ģíĥĢìŀĦìļ©&#34;:2364,&#34;ĠìŀĪìĿĦ&#34;:2365,&#34;Ġê¸°ìĸµìĿ´&#34;:2366,&#34;ìļĶì¦ĺ&#34;:2367,&#34;Ġë°ĸìĹĲ&#34;:2368,&#34;ĠìĹĨìĸ´&#34;:2369,&#34;ë£Į&#34;:2370,&#34;íĶ½&#34;:2371,&#34;ëĤĺìĺ¨&#34;:2372,&#34;ë´£&#34;:2373,&#34;ê²łì§Ģ&#34;:2374,&#34;ê·¹ìŀ¥&#34;:2375,&#34;Ġë§¤ìļ°&#34;:2376,&#34;ĠìĿ´ëĶ´&#34;:2377,&#34;Ġê°ĸ&#34;:2378,&#34;Ġê²ĥëıĦ&#34;:2379,&#34;ãħĩãħĩ&#34;:2380,&#34;ĠìĹīìĦ±&#34;:2381,&#34;ë§īìŀ¥&#34;:2382,&#34;ì¯¤&#34;:2383,&#34;ëĶ±&#34;:2384,&#34;ìĹ°ì¶ľ&#34;:2385,&#34;ĠëĬĲëĤĦ&#34;:2386,&#34;£¨&#34;:2387,&#34;ë»&#34;:2388,&#34;ìĬ¤ëŁ½ëĭ¤&#34;:2389,&#34;íķĦìļĶ&#34;:2390,&#34;ood&#34;:2391,&#34;ê°ĢìĬ´&#34;:2392,&#34;ë³´ë©´ìĦľ&#34;:2393,&#34;ìĬ¤ë¦´&#34;:2394,&#34;ì§Ħìĭ¬&#34;:2395,&#34;ìĹĶëĶ©&#34;:2396,&#34;ìĬ¤ê°Ģ&#34;:2397,&#34;ë§ĪìĿĮ&#34;:2398,&#34;ìĿ´ëĿ¼ë©´&#34;:2399,&#34;ĠìķĮê²Į&#34;:2400,&#34;Ġê°ĲëıĻìłģìĿ´&#34;:2401,&#34;ë¨¼&#34;:2402,&#34;íģ¬ë&#34;:2403,&#34;Ġì¢ĭìķĦìļĶ&#34;:2404,&#34;ĠìĪľìĪĺ&#34;:2405,&#34;ê½&#34;:2406,&#34;ëŀĲ&#34;:2407,&#34;ĠìĥģíĻ©&#34;:2408,&#34;ĩ¼&#34;:2409,&#34;ì§ķ&#34;:2410,&#34;ãħħ&#34;:2411,&#34;ìĭľìłĪ&#34;:2412,&#34;ë§Ĳê³ł&#34;:2413,&#34;Ġê´ĳ&#34;:2414,&#34;Ġë§Ľ&#34;:2415,&#34;ĠëĮĢíķ´&#34;:2416,&#34;Ġìŀ¬ë°ĮìĿĮ&#34;:2417,&#34;ê°ľëıĦ&#34;:2418,&#34;ëħĦëıĦ&#34;:2419,&#34;ë²Ħì§Ģ&#34;:2420,&#34;ĠëĨĵ&#34;:2421,&#34;ĠëĭĪ&#34;:2422,&#34;ë´¤ëĭ¤&#34;:2423,&#34;ë§İìĿĢ&#34;:2424,&#34;ì¸ł&#34;:2425,&#34;ĠìŀĶìĿ¸&#34;:2426,&#34;ĠìĺģíĻĶìĺĢëĭ¤&#34;:2427,&#34;ë¡łê°Ģ&#34;:2428,&#34;ìĸ´ë¦´&#34;:2429,&#34;ê¹Ĳ&#34;:2430,&#34;ê²Ĳ&#34;:2431,&#34;ìłģìĿ´ëĭ¤&#34;:2432,&#34;Ġë§ĲëıĦ&#34;:2433,&#34;Ġì§Ģë£¨íķ¨&#34;:2434,&#34;ĠíĽĦë°ĺ&#34;:2435,&#34;Ġê½¤&#34;:2436,&#34;´¤&#34;:2437,&#34;ìķĹ&#34;:2438,&#34;ì§ľì¦Ŀ&#34;:2439,&#34;Ġêµ°&#34;:2440,&#34;ë¹¨&#34;:2441,&#34;ĠìķĬëĭ¤&#34;:2442,&#34;íķĻìĥĿ&#34;:2443,&#34;ª½&#34;:2444,&#34;Ġëķ&#34;:2445,&#34;ìľ¼ë©´ìĦľ&#34;:2446,&#34;ìĺ¤ëŀľë§ĮìĹĲ&#34;:2447,&#34;íİ¸ìĿĢ&#34;:2448,&#34;ĠìĨĮìŀ¬ë&#34;:2449,&#34;ìĵ¸&#34;:2450,&#34;Ġì£Ħ&#34;:2451,&#34;ë³´ê²Į&#34;:2452,&#34;Ġëĭ¹ìĭľ&#34;:2453,&#34;Ġê·¹ìŀ¥ìĹĲìĦľ&#34;:2454,&#34;´ĲëıĦ&#34;:2455,&#34;ëı¼&#34;:2456,&#34;Ġê·¸ëĤĺë§Ī&#34;:2457,&#34;ìĹĪê³ł&#34;:2458,&#34;Ġê°ĻìķĦìļĶ&#34;:2459,&#34;íĤ¨&#34;:2460,&#34;Ġë¸Ķ&#34;:2461,&#34;Ġì¢ĭê²ł&#34;:2462,&#34;Ġë°Ķë¡ľ&#34;:2463,&#34;ëĪĪ&#34;:2464,&#34;TV&#34;:2465,&#34;ëŀį&#34;:2466,&#34;ê°ĲìĿ´&#34;:2467,&#34;Ġìłľë°ľ&#34;:2468,&#34;;;;;&#34;:2469,&#34;ê±°ê°Ļ&#34;:2470,&#34;ĠìĿ¸ë¬¼&#34;:2471,&#34;Ġê°ĪìĪĺë¡Ŀ&#34;:2472,&#34;Ġë³´ëĬĶëĤ´ëĤ´&#34;:2473,&#34;ì³¤&#34;:2474,&#34;ìķĦê¹Ŀëĭ¤&#34;:2475,&#34;ìŀĸìķĦ&#34;:2476,&#34;Ġë³´ìķĺ&#34;:2477,&#34;ĠìĹŃìĤ¬&#34;:2478,&#34;ê´ľì°®&#34;:2479,&#34;ëĴ¤&#34;:2480,&#34;ĠìĻł&#34;:2481,&#34;ê±´ëį°&#34;:2482,&#34;Ġì·¨&#34;:2483,&#34;Ġë³´ëĭĪ&#34;:2484,&#34;Ġë¯¸ì¹ľ&#34;:2485,&#34;Ġëĺ¥&#34;:2486,&#34;Ġê°ĲëıĻìĿ´&#34;:2487,&#34;ĠìĤ¬ëŀĮëĵ¤ìĿ´&#34;:2488,&#34;er&#34;:2489,&#34;íķ´ëĿ¼&#34;:2490,&#34;ëħĦìĿ´&#34;:2491,&#34;ê³¡&#34;:2492,&#34;ìŀ¬ë°Įìĸ´ìļĶ&#34;:2493,&#34;Ġ~&#34;:2494,&#34;ìĨĲ&#34;:2495,&#34;ìŀ¬ë¯¸ìĹĨëĭ¤&#34;:2496,&#34;íĭĢ&#34;:2497,&#34;Ġo&#34;:2498,&#34;ìĪĺë¥¼&#34;:2499,&#34;ìĭłìĿ´&#34;:2500,&#34;Ġë¡ľë§¨ìĬ¤&#34;:2501,&#34;ê°Ģì¡±&#34;:2502,&#34;ĠìĿ´íĽĦ&#34;:2503,&#34;ì§ľë¦¬&#34;:2504,&#34;ìĹ°íŀĪ&#34;:2505,&#34;ĠìķĦëĭĺ&#34;:2506,&#34;ëª¨ë¥´&#34;:2507,&#34;ìŀĲê°Ģ&#34;:2508,&#34;īìŀ¥íŀĪ&#34;:2509,&#34;ĠìĺģíĻĶìŀĦ&#34;:2510,&#34;ëĵ¤ìĸ´&#34;:2511,&#34;ìŀ¬ë°Įëĭ¤&#34;:2512,&#34;ìķĮë°Ķ&#34;:2513,&#34;ëĤĺìĺ¤ëĬĶ&#34;:2514,&#34;Ġíķ´ìĦľ&#34;:2515,&#34;ê°Ģê³ł&#34;:2516,&#34;Ġë§ĺìĹĲ&#34;:2517,&#34;ìķĦëĭĮ&#34;:2518,&#34;íĦ&#34;:2519,&#34;ê±°ìķ¼&#34;:2520,&#34;ëł¤ìĦľ&#34;:2521,&#34;ĠíĸĪëĬĶëį°&#34;:2522,&#34;ìľ¨&#34;:2523,&#34;ê°ľë´ī&#34;:2524,&#34;Ġë§ĪìĿĮìĿ´&#34;:2525,&#34;ĵľ&#34;:2526,&#34;ãħĭãħĭãħĭãħĭãħĭãħĭãħĭãħĭãħĭãħĭãħĭãħĭãħĭãħĭãħĭãħĭ&#34;:2527,&#34;Ġìķ½ê°Ħ&#34;:2528,&#34;Ġê°ĲìĤ¬&#34;:2529,&#34;ê·¸ëŀĺëıĦ&#34;:2530,&#34;ĠìĿĢ&#34;:2531,&#34;ì£¼ìĦ¸ìļĶ&#34;:2532,&#34;ĠëĦĪë¬´ëĤĺ&#34;:2533,&#34;ĠëĬĺ&#34;:2534,&#34;ìĶ©&#34;:2535,&#34;ëł¹&#34;:2536,&#34;êµ³&#34;:2537,&#34;íĴį&#34;:2538,&#34;íķĦ&#34;:2539,&#34;íķłëķĮ&#34;:2540,&#34;Ġìŀĺëª»&#34;:2541,&#34;ĠìķĪëĲ&#34;:2542,&#34;ì´Īë°ĺ&#34;:2543,&#34;Ġíıīê°Ģ&#34;:2544,&#34;ĠìĥĿê°ģìĿĦ&#34;:2545,&#34;Ġë²Į&#34;:2546,&#34;Ġëĭ¬&#34;:2547,&#34;ĠìłĦë¶Ģ&#34;:2548,&#34;Ġìĺ¤ê¸Ģ&#34;:2549,&#34;Ġìĺ¤ëĬĺ&#34;:2550,&#34;ì¡Įëĭ¤&#34;:2551,&#34;,.&#34;:2552,&#34;ìĹ¬ìĦľ&#34;:2553,&#34;Ġì¤ĳêµŃ&#34;:2554,&#34;Ġë°ľìĹ°ê¸°&#34;:2555,&#34;Ġì³&#34;:2556,&#34;ëĤ®&#34;:2557,&#34;Ġëĭ¤ìĿĮ&#34;:2558,&#34;ĠìĹ¬ê¸°&#34;:2559,&#34;ê²¹&#34;:2560,&#34;Ġê·¸ëĮĢë¡ľ&#34;:2561,&#34;Ġì²«&#34;:2562,&#34;Ġê·¸ëŀĺìĦľ&#34;:2563,&#34;ĠëĨĴìĿĢ&#34;:2564,&#34;ĠíĴį&#34;:2565,&#34;Ġë¸Į&#34;:2566,&#34;ëĬĲëĤĮ&#34;:2567,&#34;ëļ&#34;:2568,&#34;ê±°ëĤĺ&#34;:2569,&#34;ĠìŀĪìĿĦê¹Į&#34;:2570,&#34;Ġì²ł&#34;:2571,&#34;®¤&#34;:2572,&#34;ìĽĮìļĶ&#34;:2573,&#34;ĠìłķëıĦë¡ľ&#34;:2574,&#34;ìĪĻ&#34;:2575,&#34;ëĲ¨&#34;:2576,&#34;íĶĶ&#34;:2577,&#34;ë¦°ëĭ¤&#34;:2578,&#34;Ġì´Īë°ĺ&#34;:2579,&#34;Ġìĺģìĥģë¯¸&#34;:2580,&#34;Ġìĸ´ìļ¸&#34;:2581,&#34;ĠìķĦìī½ëĭ¤&#34;:2582,&#34;ĠíĪ¬&#34;:2583,&#34;íķĺìŀĲ&#34;:2584,&#34;ëħĲ&#34;:2585,&#34;Ġì§ĢëĤĺ&#34;:2586,&#34;ëŃĶê°Ģ&#34;:2587,&#34;Ġëĭ¤ë¥´&#34;:2588,&#34;ê°Ħëĭ¤&#34;:2589,&#34;ĠíĿĶ&#34;:2590,&#34;ë¨¸ëĭĪ&#34;:2591,&#34;Ġê°ĻìĿĢëį°&#34;:2592,&#34;Ńìĥģ&#34;:2593,&#34;ĠìĿ´ë¯¸&#34;:2594,&#34;ìķĦìķ¼&#34;:2595,&#34;ë§ĪìĦ¸ìļĶ&#34;:2596,&#34;ĠìŀĪì§Ģë§Į&#34;:2597,&#34;Ġê·ĢìĹ½&#34;:2598,&#34;ĠíĤ¤&#34;:2599,&#34;ê·¸ëŀ&#34;:2600,&#34;Ġë´ĲìĦľ&#34;:2601,&#34;Ĳë¦¬&#34;:2602,&#34;Ġë§Īë&#34;:2603,&#34;Ġê¸°ëĭ¤&#34;:2604,&#34;ê·¼ëį°&#34;:2605,&#34;ë¶Ħëĵ¤&#34;:2606,&#34;ìĭľê°ĦìĿ´&#34;:2607,&#34;ĠìĺģíĻĶìĿ¸ëį°&#34;:2608,&#34;ìĺģíĻĶìĹĲ&#34;:2609,&#34;ìĹĲìĦľëıĦ&#34;:2610,&#34;Ġìĸ¸&#34;:2611,&#34;ĠëĶ¸&#34;:2612,&#34;ĠCG&#34;:2613,&#34;ãħĤ&#34;:2614,&#34;ëĤŃë¹Ħ&#34;:2615,&#34;ëĿ¼ìĦľ&#34;:2616,&#34;ë³´ëĭ¤ëĬĶ&#34;:2617,&#34;ë´¤ìĬµëĭĪëĭ¤&#34;:2618,&#34;Ġëĵ±ìŀ¥&#34;:2619,&#34;ĠëĤĺìĻĢìĦľ&#34;:2620,&#34;-_-&#34;:2621,&#34;ëĤĺìĻĢ&#34;:2622,&#34;Ġìĺ¨&#34;:2623,&#34;Ġìŀ¥ë¥´&#34;:2624,&#34;ĠìķĪëĲľ&#34;:2625,&#34;ê°ĲëıħìĿ´&#34;:2626,&#34;ĠêµĲíĽĪ&#34;:2627,&#34;ĠëĮĢì²´&#34;:2628,&#34;ìķĶ&#34;:2629,&#34;Ġë´¤ì§Ģë§Į&#34;:2630,&#34;Įĵê¸Ģ&#34;:2631,&#34;ìĺ¥&#34;:2632,&#34;Ġíķĺëĭ¤&#34;:2633,&#34;ìŀĳê°Ģ&#34;:2634,&#34;Ġìŀ¬ë°Įê³ł&#34;:2635,&#34;Ġc&#34;:2636,&#34;ìĿĦìĪĺ&#34;:2637,&#34;ìĿĦíħĲëį°&#34;:2638,&#34;Ġì¢ĭìĿĢëį°&#34;:2639,&#34;ĠìķĦë¦Ħëĭ¤&#34;:2640,&#34;Ġãħīãħī&#34;:2641,&#34;ìĺģíĻĶëĭ¤&#34;:2642,&#34;ĠìĪ¨&#34;:2643,&#34;................&#34;:2644,&#34;¬ë¦¬ìĬ¤&#34;:2645,&#34;ìĤ¬ë¥¼&#34;:2646,&#34;ĠìłĦì²´&#34;:2647,&#34;Ġë³´ê³łìĭ¶&#34;:2648,&#34;ĠëĤ´ìļ©ìĿĢ&#34;:2649,&#34;ì·¨&#34;:2650,&#34;Ġìı&#34;:2651,&#34;ìĹī&#34;:2652,&#34;ìŀĪëĦ¤ìļĶ&#34;:2653,&#34;ìĹĪì§Ģë§Į&#34;:2654,&#34;Ġë³¼ìĪĺ&#34;:2655,&#34;Ġì¤Ģëĭ¤&#34;:2656,&#34;ĠìłĪ&#34;:2657,&#34;ìķĦë¦Ħ&#34;:2658,&#34;ìķĦì§ģ&#34;:2659,&#34;ĠìĤ¬íļĮ&#34;:2660,&#34;ãĦ´&#34;:2661,&#34;ë§ĪëĶĶë¡ľ&#34;:2662,&#34;Ġb&#34;:2663,&#34;ìķŀ&#34;:2664,&#34;ĠìĥĪë¡ľ&#34;:2665,&#34;Ġê°ĲëıĻìĿĦ&#34;:2666,&#34;íķĺëĥĲ&#34;:2667,&#34;ë©ĺ&#34;:2668,&#34;ìĽĥìĿĮ&#34;:2669,&#34;Ġì§ģ&#34;:2670,&#34;íĥķ&#34;:2671,&#34;Ġê°ľìĿ¸ìłģìľ¼ë¡ľ&#34;:2672,&#34;Ġë¹ĦëĶĶìĺ¤&#34;:2673,&#34;ìĿ´íķ´&#34;:2674,&#34;¬ë¦¬ë&#34;:2675,&#34;ì§Ģë¥¼&#34;:2676,&#34;ĪëĥĲ&#34;:2677,&#34;ê·ľ&#34;:2678,&#34;¸Į&#34;:2679,&#34;ìĺĢìĿĮ&#34;:2680,&#34;Ġë©į&#34;:2681,&#34;¥´&#34;:2682,&#34;âĺ&#34;:2683,&#34;ê³łëĬĶ&#34;:2684,&#34;Ġìŀĥ&#34;:2685,&#34;Ġìķķ&#34;:2686,&#34;ĠìĦ¹&#34;:2687,&#34;ë°°ìļ°ëĵ¤&#34;:2688,&#34;Ġì«&#34;:2689,&#34;Ġë´£&#34;:2690,&#34;ìĹĲìĦľëĬĶ&#34;:2691,&#34;ĠëįĶìļ±&#34;:2692,&#34;ĠíķľêµŃìĺģíĻĶ&#34;:2693,&#34;Ġì¡´ìŀ¬&#34;:2694,&#34;ìĭŃ&#34;:2695,&#34;Ġê±°ìĿĺ&#34;:2696,&#34;Ġêµ¬ìĦ±&#34;:2697,&#34;Ġ?&#34;:2698,&#34;ëŁī&#34;:2699,&#34;ëŀĳìĬ¤&#34;:2700,&#34;ĠìĻķ&#34;:2701,&#34;ëĭ¤ëĬĶê²Į&#34;:2702,&#34;Ġëĭ¤ìļ´&#34;:2703,&#34;ìĤ¬ê°Ģ&#34;:2704,&#34;Ġíĺ¼ìŀĲ&#34;:2705,&#34;¶Ģ&#34;:2706,&#34;ìĹĲìĦł&#34;:2707,&#34;ëĪĪë¬¼&#34;:2708,&#34;ĠS&#34;:2709,&#34;ë¡ľìļ´&#34;:2710,&#34;ìĭľë¦¬ì¦Ī&#34;:2711,&#34;Ġê°Ģì¹ĺ&#34;:2712,&#34;íĮ¬&#34;:2713,&#34;ìĭ¤ë§Ŀ&#34;:2714,&#34;Ġìŀ¬ë¯¸ìĹĨìĿĮ&#34;:2715,&#34;ì¶Ķì²ľ&#34;:2716,&#34;ìĺĪìļĶ&#34;:2717,&#34;ĠëĤ®ìĿĢ&#34;:2718,&#34;ĠëĪĦê°Ģ&#34;:2719,&#34;Ġíı¬ìĬ¤íĦ°&#34;:2720,&#34;ĩĮ&#34;:2721,&#34;ĠìŀĪìĸ´ìĦľ&#34;:2722,&#34;Ġìŀ¥ë©´ìĿ´&#34;:2723,&#34;Ġê°ĢìĬ´ìĿ´&#34;:2724,&#34;ìĿ´íĮħ&#34;:2725,&#34;íĭ´&#34;:2726,&#34;ëĨĶ&#34;:2727,&#34;ìĿ¼ìĿ´&#34;:2728,&#34;ĠíĬ¸&#34;:2729,&#34;ìĭľëĭ¤&#34;:2730,&#34;ìĪ¨&#34;:2731,&#34;ĠíĹĪë¬´&#34;:2732,&#34;Ġs&#34;:2733,&#34;ëĵ¬&#34;:2734,&#34;ìĤ¬íļĮ&#34;:2735,&#34;ĠìĹ¬ì£¼ìĿ¸ê³µ&#34;:2736,&#34;Ġì½&#34;:2737,&#34;ìĺ¤ëĬĺ&#34;:2738,&#34;Ġëĵ£&#34;:2739,&#34;ë§İìĿ´&#34;:2740,&#34;íĮĮìĿ´&#34;:2741,&#34;ë²Īì§¸&#34;:2742,&#34;ëıĦëĮĢì²´&#34;:2743,&#34;íķľê²Į&#34;:2744,&#34;ĠëĤĺìĺ¬&#34;:2745,&#34;Ġê°ĲëıĻìłģìĿ¸&#34;:2746,&#34;ĠìłĢëŁ°&#34;:2747,&#34;~!!&#34;:2748,&#34;ìĿ´íĬ¸&#34;:2749,&#34;Ġê·¸ë¦¬&#34;:2750,&#34;ĠìĥĿê°ģíķĺê²Į&#34;:2751,&#34;good&#34;:2752,&#34;ëĦĲ&#34;:2753,&#34;ìĨįìĹĲ&#34;:2754,&#34;Ġë§ĪìĿĮìĹĲ&#34;:2755,&#34;ĠìķĦë¬´ë¦¬&#34;:2756,&#34;ìĹĲê²Ĳ&#34;:2757,&#34;ĠìĿ´ê²ĥ&#34;:2758,&#34;ìĿ¸ëĭ¤&#34;:2759,&#34;ìĿ´ëĿ¼ëĭĪ&#34;:2760,&#34;ĠìĹĦë§Ī&#34;:2761,&#34;ĠBê¸ī&#34;:2762,&#34;Ġìĵ¸&#34;:2763,&#34;íĻķ&#34;:2764,&#34;Ġë°©ìĨ¡&#34;:2765,&#34;ĠìĿ´ìłķëıĦ&#34;:2766,&#34;ìĸ´ë¦°&#34;:2767,&#34;ì¢ĭëĭ¤&#34;:2768,&#34;ë©ĶëĶĶ&#34;:2769,&#34;ĠìŀĲì²´ê°Ģ&#34;:2770,&#34;ë§ĮíĻĶ&#34;:2771,&#34;ĠìŀĪìĸ´&#34;:2772,&#34;ê²°ë§Ĳ&#34;:2773,&#34;Ġëĭ¨ìĪľ&#34;:2774,&#34;ëłµ&#34;:2775,&#34;ĠìŀĪìĹĪëĭ¤&#34;:2776,&#34;ìķĺìĿĮ&#34;:2777,&#34;Ġë©ľë¡ľ&#34;:2778,&#34;Ġë´ĲëĿ¼&#34;:2779,&#34;Īëģ¼&#34;:2780,&#34;ìĹ¬ìļ´&#34;:2781,&#34;ìłĢíŀĪ&#34;:2782,&#34;,,,,&#34;:2783,&#34;ë³´ëĬĶëĤ´ëĤ´&#34;:2784,&#34;Ġìį¨&#34;:2785,&#34;ëĿ¼ëĭĪ&#34;:2786,&#34;ë¶ģ&#34;:2787,&#34;ĠìĦ¸ê³Ħ&#34;:2788,&#34;ìĿµ&#34;:2789,&#34;ê¸°ê³ł&#34;:2790,&#34;Ġë¹µ&#34;:2791,&#34;Ġìķłëĵ¤&#34;:2792,&#34;ĠìĺĪìģĺ&#34;:2793,&#34;Ġ30&#34;:2794,&#34;Ġãħ¡&#34;:2795,&#34;ê¸Īë&#34;:2796,&#34;Ġëĭ¤ëĵ¤&#34;:2797,&#34;Ġë´¤ìĿĮ&#34;:2798,&#34;Ġëª»íķĺëĬĶ&#34;:2799,&#34;ìĭ«&#34;:2800,&#34;ìĺģíĻĶì¤ĳ&#34;:2801,&#34;Ġë´Ħ&#34;:2802,&#34;ì½ľ&#34;:2803,&#34;ì¥&#34;:2804,&#34;ê¸°ìĸµ&#34;:2805,&#34;íĸĪìĸ´ìļĶ&#34;:2806,&#34;ëŁ¬ìļ´&#34;:2807,&#34;ëĤĺë¦Ħ&#34;:2808,&#34;Ġ100&#34;:2809,&#34;ĠìĺĪìĥģ&#34;:2810,&#34;ĠíĸĪëĭ¤&#34;:2811,&#34;ëĤ´ìļ©ìĿ´&#34;:2812,&#34;Ġê°ģë³¸&#34;:2813,&#34;íķĺëĭĪ&#34;:2814,&#34;ĠìŀĪëĬĶëį°&#34;:2815,&#34;ĠìĺĽëĤł&#34;:2816,&#34;Ġë§Įëĵľ&#34;:2817,&#34;ëħĦìłĦ&#34;:2818,&#34;Ġë¹Ľ&#34;:2819,&#34;ëĲĺê³ł&#34;:2820,&#34;Ġì¤ĳìļĶ&#34;:2821,&#34;íķĺì§ĢìķĬ&#34;:2822,&#34;¬ë¦°&#34;:2823,&#34;ĠíĻĶëł¤&#34;:2824,&#34;ì§Ģê²Į&#34;:2825,&#34;ìĸ´ê°Ģ&#34;:2826,&#34;Ġì°©&#34;:2827,&#34;ì°¨ëĿ¼ë¦¬&#34;:2828,&#34;Ġê·¸ëŁ°ì§Ģ&#34;:2829,&#34;ìĬ¤ëŁ½ê³ł&#34;:2830,&#34;Ġì¹ľêµ¬&#34;:2831,&#34;ë¦¬íĭ°&#34;:2832,&#34;ìĬ¤ìĿĺ&#34;:2833,&#34;ĠìĥĿê°ģíķ´&#34;:2834,&#34;Ġê°ľê·¸&#34;:2835,&#34;ĠëģĿëĤĺ&#34;:2836,&#34;ĠìŀĲìĹ°&#34;:2837,&#34;ìľłìĿĺ&#34;:2838,&#34;ĠìķĦëĭĲ&#34;:2839,&#34;·°&#34;:2840,&#34;Ġìŀ¬ë¯¸ìŀĪëĬĶ&#34;:2841,&#34;ĠìĤ¼ë¥ĺ&#34;:2842,&#34;Ġì³Ĳ&#34;:2843,&#34;ê³¨&#34;:2844,&#34;ëĵ¤ìķĦ&#34;:2845,&#34;ìļ°ëĵľ&#34;:2846,&#34;Ġê°Ģì§Ģê³ł&#34;:2847,&#34;ĠíıīìłĲìĿĦ&#34;:2848,&#34;ìĸµì§Ģ&#34;:2849,&#34;ĠìĬ¬íĶĪ&#34;:2850,&#34;Ġ(&#34;:2851,&#34;Ġíĺ¹&#34;:2852,&#34;Ġìĥģëĭ¹íŀĪ&#34;:2853,&#34;Ġëıĭë³´&#34;:2854,&#34;ëıĦë¡Ŀ&#34;:2855,&#34;ĠìĹĨìĸ´ìĦľ&#34;:2856,&#34;ĠìŀĲê¸°&#34;:2857,&#34;Ġê·¹ìŀ¥íĮĲ&#34;:2858,&#34;99&#34;:2859,&#34;ĠìĻĶ&#34;:2860,&#34;Ġë¶Īíİ¸&#34;:2861,&#34;Ġíĭ°ë¹Ħ&#34;:2862,&#34;ìĿ´ì½Ķ&#34;:2863,&#34;ìķĺëįĺ&#34;:2864,&#34;Ġíĸ¥&#34;:2865,&#34;Ġê²°ë§ĲìĿ´&#34;:2866,&#34;Ġìį&#34;:2867,&#34;¬ëį&#34;:2868,&#34;ì§Ħì§Ħ&#34;:2869,&#34;ìŀ¥ëĤľ&#34;:2870,&#34;ê°ľìĿ¸ìłģìľ¼ë¡ľ&#34;:2871,&#34;Ġë¹Ħíķ´&#34;:2872,&#34;Ġíķ´ëıĦ&#34;:2873,&#34;Ġë³´ìĹ¬ì£¼&#34;:2874,&#34;Ġ....&#34;:2875,&#34;íı¬ìĬ¤íĦ°&#34;:2876,&#34;Ġì¦Ĳê±°&#34;:2877,&#34;Ġìĸ´ìĦ¤íĶĪ&#34;:2878,&#34;ìĿĳ&#34;:2879,&#34;¬ëł¤&#34;:2880,&#34;ìĿ¸ë¬¼&#34;:2881,&#34;Ġìĵ°ëłĪê¸°ìĺģíĻĶ&#34;:2882,&#34;Ġì´ĪëĶ©&#34;:2883,&#34;Ġë¬ĺ&#34;:2884,&#34;ë§Īì§Ģë§īìĹĲ&#34;:2885,&#34;Ġê·¸ëŁ¬ëĤĺ&#34;:2886,&#34;ëıĭ&#34;:2887,&#34;íĸĪê³ł&#34;:2888,&#34;Ġêµ³&#34;:2889,&#34;Ġë²Ĺ&#34;:2890,&#34;ĠìĤ¬ëŀĮìĿĢ&#34;:2891,&#34;Ġíķ©ëĭĪëĭ¤&#34;:2892,&#34;ì¡°ê±´&#34;:2893,&#34;ĠíŀĪ&#34;:2894,&#34;ĠìķĦëĭĮê°Ģ&#34;:2895,&#34;in&#34;:2896,&#34;ë¯¼êµŃ&#34;:2897,&#34;Ġì¡´ëĤĺ&#34;:2898,&#34;ħëĭĪëĭ¤&#34;:2899,&#34;ìľ¼ë©°&#34;:2900,&#34;ìłĦìŁģ&#34;:2901,&#34;ëĭĺìĿĺ&#34;:2902,&#34;Ġìĭ¤íĻĶ&#34;:2903,&#34;ìĺģíĻĶë¡ľ&#34;:2904,&#34;Ġìĭ¤ìłľ&#34;:2905,&#34;Ġì¤ĳê°ĦìĹĲ&#34;:2906,&#34;íĺĳ&#34;:2907,&#34;ìĦ¸ìĥģ&#34;:2908,&#34;Ġìĺ¤ëŀľë§ĮìĹĲ&#34;:2909,&#34;ëĭ¹íķľ&#34;:2910,&#34;Ġìŀ¬ë¯¸ìĹĨëĬĶ&#34;:2911,&#34;Īë¡&#34;:2912,&#34;ëķĮë§Īëĭ¤&#34;:2913,&#34;Ġë°°ìļ°ëĵ¤ìĿ´&#34;:2914,&#34;íķĺì§ĢëıĦ&#34;:2915,&#34;Ġë³¼ë§Įíķľ&#34;:2916,&#34;ê±°ëĭ¤&#34;:2917,&#34;ëª¨ëĵł&#34;:2918,&#34;Ġëħ¸ìŀ¼&#34;:2919,&#34;ì¿ł&#34;:2920,&#34;Ġêº¼&#34;:2921,&#34;ìĸ´ëł¸&#34;:2922,&#34;ë¯¸êµŃ&#34;:2923,&#34;Ġê²ĥìĿĢ&#34;:2924,&#34;íĭ°ë¹Ħ&#34;:2925,&#34;ĠìķĦê¹ĮìĽĢ&#34;:2926,&#34;ĳ¸&#34;:2927,&#34;ìŀĪê²Į&#34;:2928,&#34;íŀĺ&#34;:2929,&#34;ìĿ¼ê¹Į&#34;:2930,&#34;ëįĺê°Ģ&#34;:2931,&#34;ë¹µ&#34;:2932,&#34;ë¦¿&#34;:2933,&#34;ĠìĤ¬ë&#34;:2934,&#34;ë´¤ìĸ´ìļĶ&#34;:2935,&#34;ë§Įìľ¼ë¡ľëıĦ&#34;:2936,&#34;ë¦¬ìĿĺ&#34;:2937,&#34;ë³¼ë§Į&#34;:2938,&#34;ëİ&#34;:2939,&#34;ìľ¡&#34;:2940,&#34;ê¹¨&#34;:2941,&#34;ëĵľëĿ¼ë§Īë&#34;:2942,&#34;ĠëĬ¥&#34;:2943,&#34;íŀĪëł¤&#34;:2944,&#34;ìķĦëıĦ&#34;:2945,&#34;ĠíĴĢìĸ´&#34;:2946,&#34;ë»Ķíķľ&#34;:2947,&#34;ĠìĺģíĻĶê´ĢìĹĲìĦľ&#34;:2948,&#34;íİ¸ìĿĺ&#34;:2949,&#34;ëķĲ&#34;:2950,&#34;ĠìĹ¬ë°°ìļ°&#34;:2951,&#34;ĠíĮĲíĥĢì§Ģ&#34;:2952,&#34;ê±į&#34;:2953,&#34;ĠìĹĨëĦ¤&#34;:2954,&#34;ìĹĪìľ¼ë©´&#34;:2955,&#34;ì°©&#34;:2956,&#34;ĠìĪĺê°Ģ&#34;:2957,&#34;ìº&#34;:2958,&#34;Ġêµīìŀ¥íŀĪ&#34;:2959,&#34;ì¡°ì°¨&#34;:2960,&#34;ìĸ´ì§ĢëĬĶ&#34;:2961,&#34;ëĤ´ëĬĶ&#34;:2962,&#34;ĠìĬ¤íĨłë¦¬ëĬĶ&#34;:2963,&#34;ĠíĿ¥íĸī&#34;:2964,&#34;ĠëıħíĬ¹&#34;:2965,&#34;ĠìķĪë³&#34;:2966,&#34;ìķĦë¬´ë¦¬&#34;:2967,&#34;¥ľ&#34;:2968,&#34;¬ìĺģ&#34;:2969,&#34;íķĺê¸´&#34;:2970,&#34;ë§ĮìĿĺ&#34;:2971,&#34;ëłĪë&#34;:2972,&#34;ê²ĥê°Ļëĭ¤&#34;:2973,&#34;ìłľê°Ģ&#34;:2974,&#34;Ġìĥģìĺģ&#34;:2975,&#34;ë¦½ëĭĪëĭ¤&#34;:2976,&#34;Ġê°ĳìŀĲê¸°&#34;:2977,&#34;ĠíĥĦíĥĦ&#34;:2978,&#34;Ġíķĺê²Į&#34;:2979,&#34;Ġìļ´&#34;:2980,&#34;ìłĢìĶ¨&#34;:2981,&#34;ĠìĦłíĥĿ&#34;:2982,&#34;Ġê¶Į&#34;:2983,&#34;ĠëĦ¤ìĿ´ë²Ħ&#34;:2984,&#34;ĠìĹĲë¡ľ&#34;:2985,&#34;Ġì§Ħíĸī&#34;:2986,&#34;Ġê°ĲìĦ±&#34;:2987,&#34;Ġìĸ´ì©Į&#34;:2988,&#34;Ġìĭľì²Ńë¥ł&#34;:2989,&#34;ĠíļĮ&#34;:2990,&#34;ë§ĮìĿ´&#34;:2991,&#34;ê²ĥìĿĢ&#34;:2992,&#34;ĠíķŃìĥģ&#34;:2993,&#34;ĠìĪľê°Ħ&#34;:2994,&#34;ë¿&#34;:2995,&#34;Ġìĭľì¦Į&#34;:2996,&#34;ĠìĤ¬ëŀĮëĵ¤ìĿĢ&#34;:2997,&#34;Ġìŀ¬ë¯¸ìŀĪëĭ¤&#34;:2998,&#34;Ġì¶©ë¶ĦíŀĪ&#34;:2999,&#34;Īëĭ¤&#34;:3000,&#34;ìĸ´ëĤĺ&#34;:3001,&#34;Ġëĵł&#34;:3002,&#34;Ġìĸ´ë¥¸&#34;:3003,&#34;Ġê°ĢëĬĶ&#34;:3004,&#34;Ġë¹Į&#34;:3005,&#34;ìŀ¬ë¯¸ëıĦ&#34;:3006,&#34;ĠëĲľëĭ¤&#34;:3007,&#34;íķĺëĭ¤ê³ł&#34;:3008,&#34;Ġê·¸ëħĢ&#34;:3009,&#34;ì¤¬&#34;:3010,&#34;ĠëĦĪ&#34;:3011,&#34;ì²¨&#34;:3012,&#34;Ġë§Įì¡±&#34;:3013,&#34;ĠëĬĲê¼&#34;:3014,&#34;ĠíķĦ&#34;:3015,&#34;ëĭĺìĿ´&#34;:3016,&#34;ì½¤&#34;:3017,&#34;ĠíħĮ&#34;:3018,&#34;íķĺìĹ¬&#34;:3019,&#34;Ġê²ģ&#34;:3020,&#34;ĠìĭľìłĪ&#34;:3021,&#34;íĸĪìĬµëĭĪëĭ¤&#34;:3022,&#34;Ġì¢ĭê²łëĭ¤&#34;:3023,&#34;Ġì¢Ģë¹Ħ&#34;:3024,&#34;ĠìĹīë§Ŀ&#34;:3025,&#34;Ġìĸĺê¸°&#34;:3026,&#34;ê³³&#34;:3027,&#34;ìŀĪëĦ¤&#34;:3028,&#34;Ġë³´ëĬĶëį°&#34;:3029,&#34;ĠíĿĳ&#34;:3030,&#34; &#34; &#34; &#34; &#34; &#34; &#34; &#34;&#34;:3031,&#34;ëĤ´ìļ©ëıĦ&#34;:3032,&#34;Ġë¶ĦìľĦê¸°&#34;:3033,&#34;ìĹĺ&#34;:3034,&#34;ëŀ¬&#34;:3035,&#34;ë³į&#34;:3036,&#34;Ġìī½&#34;:3037,&#34;.......&#34;:3038,&#34;ìĭ¤íŀĪ&#34;:3039,&#34;ĠìĿĺëıĦ&#34;:3040,&#34;Ġë¨¸ë¦¬&#34;:3041,&#34;ĠìĿ´ë²Ī&#34;:3042,&#34;Ġê¸ī&#34;:3043,&#34;íĶĦë¡ľ&#34;:3044,&#34;ĠíĹ¤&#34;:3045,&#34;ĠíĽĪ&#34;:3046,&#34;ê°ķì¶Ķ&#34;:3047,&#34;ëķľìĹĲ&#34;:3048,&#34;ìĹĦì²Ń&#34;:3049,&#34;Ġë¦¬ìĸ¼&#34;:3050,&#34;íĢ&#34;:3051,&#34;Ġìĵ´&#34;:3052,&#34;ìĿ´ëĥĲ&#34;:3053,&#34;ìļ°ëĬĶ&#34;:3054,&#34;Ġìŀ¬ë¯¸ëĬĶ&#34;:3055,&#34;Ġìŀĺë§Įëĵ¤&#34;:3056,&#34;ĠëĪĪë&#34;:3057,&#34;Ġíķ´ìķ¼&#34;:3058,&#34;//&#34;:3059,&#34;ì§Ģëĭ¤&#34;:3060,&#34;ëł¬&#34;:3061,&#34;ĠëĨĪ&#34;:3062,&#34;íĿĲ&#34;:3063,&#34;ì´Ŀ&#34;:3064,&#34;ĠíĽĮë¥Ńíķľ&#34;:3065,&#34;ìļ°ë¦¬ëĤĺëĿ¼&#34;:3066,&#34;ĠíĻĶë©´&#34;:3067,&#34;Ġë¯¿ê³ł&#34;:3068,&#34;Ġìĸ´ì©Ķ&#34;:3069,&#34;ĠìĥĪë¡ľìļ´&#34;:3070,&#34;Ġê°Ķ&#34;:3071,&#34;ìĭľê³ł&#34;:3072,&#34;Ġì¢ĭëĦ¤ìļĶ&#34;:3073,&#34;ĠìķĪíĥĢê¹Ŀ&#34;:3074,&#34;ìĿ´íķĺ&#34;:3075,&#34;ĠìĺģíĻĶìĿ¸&#34;:3076,&#34;Ġê·¸ê²Į&#34;:3077,&#34;ĠëĤĺìĿĺ&#34;:3078,&#34;Ġê²Ģ&#34;:3079,&#34;íķĺëĬĶê±°&#34;:3080,&#34;Ġëª¨ë¥´ê³ł&#34;:3081,&#34;ë°°ìļ°ëĵ¤ìĿĺ&#34;:3082,&#34;Ġë¹¨ë¦¬&#34;:3083,&#34;ĠM&#34;:3084,&#34;Ġìĸ´ëł¤&#34;:3085,&#34;ìłľë°ľ&#34;:3086,&#34;Ġìŀ¬ë°ĮëĦ¤ìļĶ&#34;:3087,&#34;ë³¸ëĭ¤&#34;:3088,&#34;ì¢ĭìķĦìļĶ&#34;:3089,&#34;ĠìĤ´ìĿ¸&#34;:3090,&#34;ìĺĽëĤł&#34;:3091,&#34;ìĺ¤ëĬĶ&#34;:3092,&#34;ìĦ¸ê³Ħ&#34;:3093,&#34;ìłĢëıĦ&#34;:3094,&#34;ĠìķĦëĭĪë&#34;:3095,&#34;Ġì°¸ê³ł&#34;:3096,&#34;ë´Ĳìķ¼&#34;:3097,&#34;ìĬ¤ëŁ°&#34;:3098,&#34;ĠìŀĪìĿĮ&#34;:3099,&#34;ê·ł&#34;:3100,&#34;ëħĦìĹĲ&#34;:3101,&#34;ĠëŃĲê°Ģ&#34;:3102,&#34;Ġíŀĺëĵł&#34;:3103,&#34;ëª°ìŀħ&#34;:3104,&#34;Ġì§Ŀ&#34;:3105,&#34;ìĺģíĻĶëıĦ&#34;:3106,&#34;ĠìĹ¬ìłĦ&#34;:3107,&#34;ĠëŃĲëĥĲ&#34;:3108,&#34;Ġë¬»&#34;:3109,&#34;íĺķìłģìĿ¸&#34;:3110,&#34;ĠìķĦìī¬ìļ´&#34;:3111,&#34;ĠìķĪíĥĢê¹Į&#34;:3112,&#34;ê·¸ëŀ¨&#34;:3113,&#34;ĠO&#34;:3114,&#34;ìĭľëĬĶ&#34;:3115,&#34;ë²Īë&#34;:3116,&#34;ê°Ħë§ĮìĹĲ&#34;:3117,&#34;Ġì§Ħìłķíķľ&#34;:3118,&#34;Ġë§ĪìĿ´&#34;:3119,&#34;ëĨĴ&#34;:3120,&#34;ê¿Ģìŀ¼&#34;:3121,&#34;ìµľìķħìĿĺ&#34;:3122,&#34;ìĩ¼&#34;:3123,&#34;ĳìĹĲ&#34;:3124,&#34;Ġë§¨&#34;:3125,&#34;ëĤ´ê³ł&#34;:3126,&#34;Ġìľ¼&#34;:3127,&#34;Ġê´ľ&#34;:3128,&#34;Ġê²ĥìĿ´ëĭ¤&#34;:3129,&#34;íĶĦëĭ¤&#34;:3130,&#34;Ġê·¸ëķĮ&#34;:3131,&#34;ê²łëĦ¤&#34;:3132,&#34;ĠëĮĢëĭ¨íķľ&#34;:3133,&#34;ĠëŁ¬&#34;:3134,&#34;ìĿ´ë©´&#34;:3135,&#34;ìĸ´ë¡ľ&#34;:3136,&#34;ìŀĲìĿĺ&#34;:3137,&#34;OOO&#34;:3138,&#34;Ġë©ĭìŀĪ&#34;:3139,&#34;Ġíģ¬&#34;:3140,&#34;Ġìĸ´ëĶĶìĦľ&#34;:3141,&#34;ìĹĪëĦ¤ìļĶ&#34;:3142,&#34;ĠìĨĮìĦ¤&#34;:3143,&#34;ëĲĺìĸ´&#34;:3144,&#34;Ħ¤ìļĶ&#34;:3145,&#34;ĠíĢ&#34;:3146,&#34;ĠìŀĪëĭ¤ëĬĶ&#34;:3147,&#34;ĠìĿ´ìĺģíĻĶë¥¼&#34;:3148,&#34;ĠìĬ¹&#34;:3149,&#34;Ġíķľìĭ¬&#34;:3150,&#34;íķ¨ê³¼&#34;:3151,&#34;ìłľìŀĳ&#34;:3152,&#34;Ġê°Ĳìĥģ&#34;:3153,&#34;ìĻł&#34;:3154,&#34;ê·¸ëŁ¬&#34;:3155,&#34;Ġë¨¹ë¨¹&#34;:3156,&#34;íĦ´&#34;:3157,&#34;ìĬ¤ë¥¼&#34;:3158,&#34;ĠëĦ£&#34;:3159,&#34;Ġë´¤ëĦ¤ìļĶ&#34;:3160,&#34;ĠìĨĮì¤ĳ&#34;:3161,&#34;ĠëŃĲì§Ģ&#34;:3162,&#34;ìĤ¬ëŀĮìĿ´&#34;:3163,&#34;ĠìĦ±ìļ°&#34;:3164,&#34;Ġëĭ¹ìĭł&#34;:3165,&#34;ìĬ¤íĨłë¦¬ê°Ģ&#34;:3166,&#34;íıīê°Ģ&#34;:3167,&#34;ĠíĤ¬ë§ģíĥĢìŀĦìļ©&#34;:3168,&#34;ĠìķĪëĲľëĭ¤&#34;:3169,&#34;¬ê¸Ī&#34;:3170,&#34;ĠìĹĨìĿĦ&#34;:3171,&#34;ĠìĹĨëĦ¤ìļĶ&#34;:3172,&#34;ë²Į&#34;:3173,&#34;ĠìĨ¡&#34;:3174,&#34;ĠëĲĺìĸ´&#34;:3175,&#34;ĠëĬĲëģ¼ê²Į&#34;:3176,&#34;Ġê°ľìĹ°ìĦ±&#34;:3177,&#34;Ġì°Į&#34;:3178,&#34;ìĿ´ë¸Ķ&#34;:3179,&#34;ê³łìĭ¶&#34;:3180,&#34;ëłĮ&#34;:3181,&#34;ê²ĥìĿ´ëĭ¤&#34;:3182,&#34;ĠìķĮëł¤&#34;:3183,&#34;Ġíıīë²Ķ&#34;:3184,&#34;ëľ¨&#34;:3185,&#34;ìłķìĭł&#34;:3186,&#34;ìħĪ&#34;:3187,&#34;ë¦¬ë¡ľ&#34;:3188,&#34;ìĽĢìĿ´&#34;:3189,&#34;Ġë§Ŀìŀĳ&#34;:3190,&#34;Ġë¬¼ë¡ł&#34;:3191,&#34;ìºĲë¦ŃíĦ°&#34;:3192,&#34;ĠãĦ·ãĦ·&#34;:3193,&#34;¬ëŀĳ&#34;:3194,&#34;Ġê°ĢëĬ¥&#34;:3195,&#34;ĠëŃĲìķ¼&#34;:3196,&#34;Ġíİ¸ì§ĳ&#34;:3197,&#34;Ġíľ´&#34;:3198,&#34;Ġë°Ģ&#34;:3199,&#34;ìĹĨìĸ´&#34;:3200,&#34;Ġíķĺë©´&#34;:3201,&#34;ìķłëĭĪ&#34;:3202,&#34;Ġê´ĢëŀĮ&#34;:3203,&#34;ëŀĻ&#34;:3204,&#34;Ġìľ¤&#34;:3205,&#34;ìĺĢëĬĶëį°&#34;:3206,&#34;ãĦ¹&#34;:3207,&#34;íĹĲ&#34;:3208,&#34;ĠìłĲìłĲ&#34;:3209,&#34;ĠìļĶìĨĮ&#34;:3210,&#34;Ġë§ĮìłĲ&#34;:3211,&#34;íŀĮ&#34;:3212,&#34;ĠìŀĲê·¹&#34;:3213,&#34;ëħ¸ëŀĺ&#34;:3214,&#34;Ġ-_-&#34;:3215,&#34;Ġìĺ¤ê¸Ģê±°&#34;:3216,&#34;ST&#34;:3217,&#34;ëĢ&#34;:3218,&#34;ìª½&#34;:3219,&#34;Ġëĥ&#34;:3220,&#34;ìŀĲëĵ¤&#34;:3221,&#34;Ġì¤ĺ&#34;:3222,&#34;ìĸ´ëĸ»ê²Į&#34;:3223,&#34;Ġm&#34;:3224,&#34;ìĦ¼&#34;:3225,&#34;íķĺëĬĶê²Į&#34;:3226,&#34;ãħĭãħĭãħĭãħĭãħĭ&#34;:3227,&#34;Ġë°ĶëĿ¼&#34;:3228,&#34;ìĺĪìĤ°&#34;:3229,&#34;ì»¬&#34;:3230,&#34;ª¨&#34;:3231,&#34;íĻĶê°Ģ&#34;:3232,&#34;Ġê¹Ķ&#34;:3233,&#34;Ġ200&#34;:3234,&#34;ĠìĤ¬ëŀĳìĿĦ&#34;:3235,&#34;Ġì£½ëĬĶ&#34;:3236,&#34;Ġë³ĦìłĲ&#34;:3237,&#34;Ġëĵ¯íķľ&#34;:3238,&#34;--&#34;:3239,&#34;12&#34;:3240,&#34;ê¸°ìĹĶ&#34;:3241,&#34;Ġë²ķ&#34;:3242,&#34;Ġë§Įëĵ¤ìĹĪëĭ¤&#34;:3243,&#34;ì©Į&#34;:3244,&#34;ĠëĤ«ëĭ¤&#34;:3245,&#34;Ġì¿&#34;:3246,&#34;Ġë½&#34;:3247,&#34;ìł¤&#34;:3248,&#34;ĠëĤĺìģľ&#34;:3249,&#34;Ġì¢ĭìĿĮ&#34;:3250,&#34;ĠìĥĪ&#34;:3251,&#34;Ġìŀ¬ë°ĮìĹĪëĭ¤&#34;:3252,&#34;ë¹¼&#34;:3253,&#34;ìĭ¬ìĿĦ&#34;:3254,&#34;Ġëª¨ë¥´ëĬĶ&#34;:3255,&#34;ĠìłĦê°ľê°Ģ&#34;:3256,&#34;ĠìĭĿìĥģ&#34;:3257,&#34;ìį&#34;:3258,&#34;ìĿ´ëĶ´&#34;:3259,&#34;íķľëĵ¯&#34;:3260,&#34;íİĳ&#34;:3261,&#34;ĠíıīìłĲìĿĢ&#34;:3262,&#34;ìķĪíķĺê³ł&#34;:3263,&#34;ĠìŀħëĭĪëĭ¤&#34;:3264,&#34;Ġë§¥&#34;:3265,&#34;ĠëģĿëĤ´&#34;:3266,&#34;Ġìŀ¬ë¯¸ìŀĪìĸ´ìļĶ&#34;:3267,&#34;ê°ĻìĿĢëį°&#34;:3268,&#34;ìµľê³łëĭ¤&#34;:3269,&#34;ĠëĲĲ&#34;:3270,&#34;ĠìĤ¬ëĿ¼&#34;:3271,&#34;ìĹĨëĦ¤&#34;:3272,&#34;ĠëĤĺìĿ´&#34;:3273,&#34;íĴĭ&#34;:3274,&#34;ĠìŀĲê¾¸&#34;:3275,&#34;ĠìĿ´ìķ¼ê¸°ë¥¼&#34;:3276,&#34;ĠíĿ¥ë¯¸ì§Ħì§Ħ&#34;:3277,&#34;ĠìĶ¨&#34;:3278,&#34;ìİ&#34;:3279,&#34;ìı&#34;:3280,&#34;ë³´ìĦ¸ìļĶ&#34;:3281,&#34;ĠìĹ¬ì£¼&#34;:3282,&#34;ëŀ«&#34;:3283,&#34;ĠìķĮìķĺëĭ¤&#34;:3284,&#34;íıĲ&#34;:3285,&#34;ĠíĭĢ&#34;:3286,&#34;Ġ!!&#34;:3287,&#34;Ġìĺ¤íŀĪëł¤&#34;:3288,&#34;ê»ı&#34;:3289,&#34;Ġê¼¬&#34;:3290,&#34;ìĽłëįĺ&#34;:3291,&#34;Ġë²Ķì£Ħ&#34;:3292,&#34;ĠìĨĮë¦¬&#34;:3293,&#34;Ġìĭ«ìĸ´&#34;:3294,&#34;ëŀĦê¹Į&#34;:3295,&#34;ìķĪëĲĺëĬĶ&#34;:3296,&#34;ĠëĮĵê¸Ģ&#34;:3297,&#34;ëĭ¿&#34;:3298,&#34;ëĤĺë©´&#34;:3299,&#34;ìķĦìķĦ&#34;:3300,&#34;ãħłãħłãħł&#34;:3301,&#34;ìĭ¬ìĿ´&#34;:3302,&#34;Ġë§Įëĵ¤ì§Ģ&#34;:3303,&#34;ìĭĿìĿ´&#34;:3304,&#34;Ġì¢ĭìķĺìĸ´ìļĶ&#34;:3305,&#34;ĠíĿĺëŁ¬&#34;:3306,&#34;âĢ&#34;:3307,&#34;ì°¾&#34;:3308,&#34;Ġì°½&#34;:3309,&#34;Ġë¯¸íĻĶ&#34;:3310,&#34;Ġãħħ&#34;:3311,&#34;ĠìĿ´ë¦¬&#34;:3312,&#34;ìĸ´ìļ¸&#34;:3313,&#34;ĠëĤĺëĿ¼&#34;:3314,&#34;Ġì§Ħì§Ģ&#34;:3315,&#34;íİ¸ìĿĦ&#34;:3316,&#34;ĠìĽĥê¸´&#34;:3317,&#34;ë©ĶëĿ¼&#34;:3318,&#34;Ġëª¨ìĬµìĿ´&#34;:3319,&#34;ìĹĪëĦ¤&#34;:3320,&#34;ĠìķĮìķĺëĬĶëį°&#34;:3321,&#34;ê¼¬&#34;:3322,&#34;êµ¿êµ¿&#34;:3323,&#34;ë³´ëĬĶëį°&#34;:3324,&#34;ĠìĺģìĽħ&#34;:3325,&#34;ë´ĲìĦľ&#34;:3326,&#34;ĠìĦ¤ëªħ&#34;:3327,&#34;ìºĲìĬ¤íĮħ&#34;:3328,&#34;Ġë£¨&#34;:3329,&#34;Ġëĭ¤íĸī&#34;:3330,&#34;ìĦ¸ê°Ģ&#34;:3331,&#34;ë²ĪìĿĦ&#34;:3332,&#34;Ġìŀ¥ë©´ìĿĢ&#34;:3333,&#34;Ġì£¼ìĿ¸ê³µìĿ´&#34;:3334,&#34;êµ¬ëĵ¤&#34;:3335,&#34;ì§Īë&#34;:3336,&#34;ĠìłĬ&#34;:3337,&#34;ìķĦë¨¹&#34;:3338,&#34;Ġê²¨&#34;:3339,&#34;ìĸĺ&#34;:3340,&#34;ìĨĮìĦ¤&#34;:3341,&#34;Ġë§Ĳê³ł&#34;:3342,&#34;ëĺ¥&#34;:3343,&#34;Ġë©įì²Ń&#34;:3344,&#34;Ġa&#34;:3345,&#34;Ġê»&#34;:3346,&#34;Ġê·¸ëŁ´&#34;:3347,&#34;ìĥģìĿĦ&#34;:3348,&#34;ìī½&#34;:3349,&#34;Ġìĭłê¸°&#34;:3350,&#34;ĠìĹĦì²ŃëĤľ&#34;:3351,&#34;ĠìķĦë¹ł&#34;:3352,&#34;ìłĲì¤Ģ&#34;:3353,&#34;ĠìĦ±ë£¡&#34;:3354,&#34;Ġë©ĶìĦ¸&#34;:3355,&#34;he&#34;:3356,&#34;Ġê¾&#34;:3357,&#34;ëª½&#34;:3358,&#34;Ġë¬´ì¡°ê±´&#34;:3359,&#34;Ġì¤ĳìĹĲ&#34;:3360,&#34;ìĹ°ê¸°ëıĦ&#34;:3361,&#34;ĠíĸīëıĻ&#34;:3362,&#34;ìĸ´ëĶĶ&#34;:3363,&#34;Ġì§§&#34;:3364,&#34;ĠìłĦê¸°&#34;:3365,&#34;íĶĦê³ł&#34;:3366,&#34;Ġë³´ìĹ¬ì¤Ģ&#34;:3367,&#34;ìĭ±&#34;:3368,&#34;ë§Įíķĺë©´&#34;:3369,&#34;ìĬ¤ë¡ľ&#34;:3370,&#34;ê·¸ìłĢ&#34;:3371,&#34;ì¤ĦìķĮ&#34;:3372,&#34;ì¹ľêµ¬&#34;:3373,&#34;ĠíĻĶìĿ´íĮħ&#34;:3374,&#34;Ġ90&#34;:3375,&#34;ĠìĺģíĻĶìĺĢìĬµëĭĪëĭ¤&#34;:3376,&#34;¶Ħ&#34;:3377,&#34;Ġì¥&#34;:3378,&#34;ê¸°ëĭ¤&#34;:3379,&#34;ìĭľì¦Į&#34;:3380,&#34;íĤ¹&#34;:3381,&#34;ĠìĹ°ì¶ľëł¥&#34;:3382,&#34;ê°ĲëıħìĿĺ&#34;:3383,&#34;ĠìĬ¤íĥĢìĿ¼&#34;:3384,&#34;ìŀł&#34;:3385,&#34;ìķĻ&#34;:3386,&#34;ìĸ´ìĿ´&#34;:3387,&#34;ë¦¬ìķĦ&#34;:3388,&#34;Ġê·¸ë¦¼&#34;:3389,&#34;ĠëĮĢìŀĳ&#34;:3390,&#34;Ġì£½ìĿĮ&#34;:3391,&#34;?)&#34;:3392,&#34;ë½&#34;:3393,&#34;íķĺê²ł&#34;:3394,&#34;ëĤĺìĿ´&#34;:3395,&#34;ë¦¬ê²Į&#34;:3396,&#34;íĮĶ&#34;:3397,&#34;ìĨĮíķľ&#34;:3398,&#34;Ġëģ¼&#34;:3399,&#34;Ĵ·&#34;:3400,&#34;Ġë®¤&#34;:3401,&#34;ìĿ¸ìĿĦ&#34;:3402,&#34;Ġê·¸ëĭ¥&#34;:3403,&#34;ĠíķĺëĬĶëį°&#34;:3404,&#34;Ġìĸ´ë¦´&#34;:3405,&#34;ĠìŀĳíĴĪìĿ´&#34;:3406,&#34;Ġëħ¸ëł¥&#34;:3407,&#34;ĠìŀĬíĺĢ&#34;:3408,&#34;200&#34;:3409,&#34;ìłķìĿĦ&#34;:3410,&#34;Ġê°ĻëĦ¤ìļĶ&#34;:3411,&#34;Ġë©´&#34;:3412,&#34;Ġìľłë¨¸&#34;:3413,&#34;ë¦¬ëĿ¼&#34;:3414,&#34;ìŀ¬ë°ĮìĿĮ&#34;:3415,&#34;Ġê´Ģê³Ħ&#34;:3416,&#34;ĠìŀĶìŀĶíķľ&#34;:3417,&#34;ĠíĿ¬ë§Ŀ&#34;:3418,&#34;ê¸Īë´ĲëıĦ&#34;:3419,&#34;ĠìĿ´ìĸ´&#34;:3420,&#34;Ġë§Īë¬´&#34;:3421,&#34;ìĿ¸ê±°&#34;:3422,&#34;Ġëįķ&#34;:3423,&#34;ìĤ¬ëĬĶ&#34;:3424,&#34;Ġíķ©&#34;:3425,&#34;Ġê²°íĺ¼&#34;:3426,&#34;Ġì¢ĭìķĺê³ł&#34;:3427,&#34;ĠìĺģíĻĶìĹĲìĦľ&#34;:3428,&#34;ë§Ĳë¡ľ&#34;:3429,&#34;ìŀĲëĬĶ&#34;:3430,&#34;ìŀĪìĸ´ìļĶ&#34;:3431,&#34;íĥģ&#34;:3432,&#34;Ġê°ĢëĵĿ&#34;:3433,&#34;ì¹ĺê²Į&#34;:3434,&#34;ĠíĹĲë¦¬&#34;:3435,&#34;ĠìĽĥê²¨&#34;:3436,&#34;ë°©ìĨ¡&#34;:3437,&#34;Ġë¬´ìĦľìļ´&#34;:3438,&#34;ĩ´&#34;:3439,&#34;Ġë§Įíģ¼&#34;:3440,&#34;ìĹ¬ì£¼&#34;:3441,&#34;ë¶ĦìĿ´&#34;:3442,&#34;Ġì°¸ìĭł&#34;:3443,&#34;ĠëıĪì£¼ê³ł&#34;:3444,&#34;ĠìķĦë¬´ê²ĥëıĦ&#34;:3445,&#34;©ĶìĿ´íģ¬&#34;:3446,&#34;ìĿ¸ìĿĢ&#34;:3447,&#34;Ġëª»ë³´&#34;:3448,&#34;ìĤ¬ëŀĮëĵ¤&#34;:3449,&#34;íķĺë©´ìĦľëıĦ&#34;:3450,&#34;Ġê·¸ëł¤&#34;:3451,&#34;ê·¸ëĿ¼&#34;:3452,&#34;Ġ19&#34;:3453,&#34;Ġì¢ĭìķĺìĬµëĭĪëĭ¤&#34;:3454,&#34;ĠëĺĲíķľ&#34;:3455,&#34;ĠíĬ¹ìľłìĿĺ&#34;:3456,&#34;ĠíĽĪíĽĪ&#34;:3457,&#34;íī&#34;:3458,&#34;íķľê±´&#34;:3459,&#34;ìĭľìŀĳ&#34;:3460,&#34;Ġìĺ¬&#34;:3461,&#34;ìĺĢìĬµëĭĪëĭ¤&#34;:3462,&#34;ĠìĬ¤íĨłë¦¬ìĹĲ&#34;:3463,&#34;ê¸´ìŀ¥ê°Ĳ&#34;:3464,&#34;ĠìķĦëĭĪì§Ģë§Į&#34;:3465,&#34;ìŀ¬ë¯¸ìŀĪê²Į&#34;:3466,&#34;Ġìĸµì§Ģë¡ľ&#34;:3467,&#34;Ġì¦Ĳê²ģ&#34;:3468,&#34;ê±¸ê¹Į&#34;:3469,&#34;ë´ĲëĿ¼&#34;:3470,&#34;Ġì½Ķë©ĶëĶĶ&#34;:3471,&#34;ì½ĺ&#34;:3472,&#34;ĠëĨĢëĿ¼&#34;:3473,&#34;ĠëĿ¼ëĬĶ&#34;:3474,&#34;ìķĦëĭĪê³ł&#34;:3475,&#34;Ġë¡ľë§¨íĭ±&#34;:3476,&#34;Ġë³ĳë§Ľ&#34;:3477,&#34;ĠTV&#34;:3478,&#34;ĠìĿ´ëĶ°&#34;:3479,&#34;íķ´ì£¼&#34;:3480,&#34;ìŀĲë¥¼&#34;:3481,&#34;ë¶ĦìĹĲ&#34;:3482,&#34;ëĦĪë¬´ëĦĪë¬´&#34;:3483,&#34;ĠìĻĦìĦ±ëıĦ&#34;:3484,&#34;Ġê·¸ëłĩê³ł&#34;:3485,&#34;ĠìĻĦë²½íķľ&#34;:3486,&#34;ëĮ&#34;:3487,&#34;ìĹ¼&#34;:3488,&#34;ìłĲì¤Ģëĭ¤&#34;:3489,&#34;ĠëĤĺìģĺ&#34;:3490,&#34;Ġì§Ħìĭ¤&#34;:3491,&#34;ë¥´ê³ł&#34;:3492,&#34;Ġìķ¡ìħĺëıĦ&#34;:3493,&#34;Ġëª¨ìĬµìĿĦ&#34;:3494,&#34;Ġê¿Ģìŀ¼&#34;:3495,&#34;²Ħ&#34;:3496,&#34;ì¦Īë&#34;:3497,&#34;ĠìķĬìĿĦ&#34;:3498,&#34;ĠìĥĿê°ģë³´ëĭ¤&#34;:3499,&#34;ìķłëĵ¤&#34;:3500,&#34;ëŃĲìķ¼&#34;:3501,&#34;âĺħ&#34;:3502,&#34;ĠìķĦëĭĲê¹Į&#34;:3503,&#34;~^^&#34;:3504,&#34;ìŀĪëĬĶëį°&#34;:3505,&#34;ĠìĥĿê°ģíķľëĭ¤&#34;:3506,&#34;Ġëħ¸ì¶ľ&#34;:3507,&#34;Ġê¸°ëĮĢíķĺê³ł&#34;:3508,&#34;ĠìĦ±ìŀ¥&#34;:3509,&#34;ëĵ±íķĻêµĲ&#34;:3510,&#34;Ġê¹ĬìĿĢ&#34;:3511,&#34;íĻĶë¥¼&#34;:3512,&#34;ëĵľê°Ģ&#34;:3513,&#34;ê°ĲìĿĦ&#34;:3514,&#34;ĠëıĦìłĢíŀĪ&#34;:3515,&#34;Ġë³µìĪĺ&#34;:3516,&#34;ë»Ĳ&#34;:3517,&#34;ëĳĺ&#34;:3518,&#34;ê³łíİ¸&#34;:3519,&#34;íķĺëįĺ&#34;:3520,&#34;ê³¼ëĬĶ&#34;:3521,&#34;Ġë¶ģ&#34;:3522,&#34;ĠìķĬìķĺëĭ¤&#34;:3523,&#34;ìĺĢëįĺ&#34;:3524,&#34;ãħİãħİãħİ&#34;:3525,&#34;Ġê°ĲëıħìĿĢ&#34;:3526,&#34;ìł¸ìĦľ&#34;:3527,&#34;ëĤ¬ëĭ¤&#34;:3528,&#34;ĠíĽĦë°ĺë¶Ģ&#34;:3529,&#34;ĠìĿ¸ìłķ&#34;:3530,&#34;Ġë§Ĳíķĺê³ł&#34;:3531,&#34;ĠíĮĶ&#34;:3532,&#34;Ġíıīë¡łê°Ģ&#34;:3533,&#34;Ġê·¸ëŀĺíĶ½&#34;:3534,&#34;Ġë¶Ģë¶ĦìĿ´&#34;:3535,&#34;ī´&#34;:3536,&#34;ìĿ´ìĹĲìļĶ&#34;:3537,&#34;ĠìĺģíĻĶì¤ĳìĹĲ&#34;:3538,&#34;ĠìķĦë²Ħì§Ģ&#34;:3539,&#34;íķĺëĬĶì§Ģ&#34;:3540,&#34;ëł¤ë©´&#34;:3541,&#34;Ġë³¸ëĭ¤&#34;:3542,&#34;ì¢ĭê³ł&#34;:3543,&#34;ĠíĻįì½©&#34;:3544,&#34;íķľëĭ¤ëĬĶ&#34;:3545,&#34;ëĤĺìĻĶ&#34;:3546,&#34;ĠëįĶëŁ½ê²Į&#34;:3547,&#34;ĠìķĪë§ŀ&#34;:3548,&#34;Ġëª»íķĺê³ł&#34;:3549,&#34;Ġìľłëªħ&#34;:3550,&#34;ìģ¨&#34;:3551,&#34;ĠëıĮëł¤&#34;:3552,&#34;Ġê³¨&#34;:3553,&#34;ĠëĶ°ëľ»íķľ&#34;:3554,&#34;Ġë¹ĦìĬ·íķľ&#34;:3555,&#34;ìķĦë¦Ħëĭ¤ìļ´&#34;:3556,&#34;ëĭ«&#34;:3557,&#34;ìĽ¨&#34;:3558,&#34;ìĹĪëĤĺ&#34;:3559,&#34;ĠìķĬìĿĮ&#34;:3560,&#34;Ġìłľê°Ģ&#34;:3561,&#34;Ġíİĺ&#34;:3562,&#34;ì§Ģë£¨íķĺê³ł&#34;:3563,&#34;Ġëľ¬ê¸Ī&#34;:3564,&#34;ì§Ģëª»&#34;:3565,&#34;¬ëĵ¤&#34;:3566,&#34;ĠìĺģíĻĶìĿ´ëĭ¤&#34;:3567,&#34;Ġìłĳ&#34;:3568,&#34;ìŀ¥ìĿ´&#34;:3569,&#34;ĠìķĪëĤĺìĺ¤&#34;:3570,&#34;ë¯¿&#34;:3571,&#34;Ġì´Į&#34;:3572,&#34;Ġë¶Ħëªħ&#34;:3573,&#34;Ġê³¼ê±°&#34;:3574,&#34;or&#34;:3575,&#34;ìłĪëĮĢ&#34;:3576,&#34;ì§ĢëĦ¤ìļĶ&#34;:3577,&#34;íķ´ì£¼ëĬĶ&#34;:3578,&#34;ëģĮ&#34;:3579,&#34;íĿĳ&#34;:3580,&#34;íĹ¤&#34;:3581,&#34;ĠìĹ°ì¶ľìĿ´&#34;:3582,&#34;ìĪľê°Ħ&#34;:3583,&#34;Ġë¨¼ìłĢ&#34;:3584,&#34;Ģë¡ľ&#34;:3585,&#34;ìĹ¿&#34;:3586,&#34;ë¶Īë&#34;:3587,&#34;ìĪĺìŀĪëĬĶ&#34;:3588,&#34;ìĿ¼ë¿Ĳ&#34;:3589,&#34;ĠìŀĺìĥĿ&#34;:3590,&#34;ë§¹&#34;:3591,&#34;ìĪĺëıĦ&#34;:3592,&#34;ĠìĺĪë&#34;:3593,&#34;ì¶ķ&#34;:3594,&#34;íĸĪìľ¼ë©´&#34;:3595,&#34;Ġê°ĻìĬµëĭĪëĭ¤&#34;:3596,&#34;ëįĶêµ°ìļĶ&#34;:3597,&#34;Ġíķ´ì£¼ëĬĶ&#34;:3598,&#34;Ġê±°ì§Ģ&#34;:3599,&#34;Ġë°Ķë³´&#34;:3600,&#34;ëĸ¨ìĸ´&#34;:3601,&#34;Ġì´¬ìĺģ&#34;:3602,&#34;ëĭµëĭµ&#34;:3603,&#34;ĠìĦľë¡ľ&#34;:3604,&#34;ê¸Īë³´&#34;:3605,&#34;ìŀĪìĿĮ&#34;:3606,&#34;ĠìĬĪ&#34;:3607,&#34;ĠìķĮê²ł&#34;:3608,&#34;Ġë¹Ī&#34;:3609,&#34;ëģĿê¹Įì§Ģ&#34;:3610,&#34;ĠìķĦëĭĪë©´&#34;:3611,&#34;ê°ĢìļĶ&#34;:3612,&#34;ëĵłëĭ¤&#34;:3613,&#34;ĠìĤ¬ê±´&#34;:3614,&#34;ĠëŃĶì§Ģ&#34;:3615,&#34;ĠëĤĺìĺ¨ëĭ¤&#34;:3616,&#34;ìĹĦë§Ī&#34;:3617,&#34;ĠSF&#34;:3618,&#34;ìŀī&#34;:3619,&#34;ìĥĪëģ¼&#34;:3620,&#34;íķłëĵ¯&#34;:3621,&#34;ìĦ±ìķł&#34;:3622,&#34;Ġë°°ìļ°ê°Ģ&#34;:3623,&#34;ìĹ°ê¸°ê°Ģ&#34;:3624,&#34;ìłĪíķľ&#34;:3625,&#34;ëĲĲ&#34;:3626,&#34;Ġãħľ&#34;:3627,&#34;..?&#34;:3628,&#34;ëĮĢìĤ¬&#34;:3629,&#34;íģ°&#34;:3630,&#34;ëįĶë¹Ļ&#34;:3631,&#34;ìĶĢ&#34;:3632,&#34;Ġê¹ľ&#34;:3633,&#34;ìĬ¤íĨłë¦¬ëıĦ&#34;:3634,&#34;ĠíĶ¼íķ´&#34;:3635,&#34;íĬ¹íŀĪ&#34;:3636,&#34;Īë²½&#34;:3637,&#34;ĠëŁ¬ë&#34;:3638,&#34;ìĿĺë¯¸&#34;:3639,&#34;ë°ĭ&#34;:3640,&#34;ìłĲì§ľë¦¬&#34;:3641,&#34;ĠìŀĪìĹĪëįĺ&#34;:3642,&#34;ìĺ¤ëŀĺ&#34;:3643,&#34;ëĤ´ìļĶ&#34;:3644,&#34;ëĶ¸&#34;:3645,&#34;ĠëĤ¨ìķĦ&#34;:3646,&#34;ì§ĢëıĦìķĬ&#34;:3647,&#34;ĠìĿ¸ê°ĦìĿĺ&#34;:3648,&#34;ëĨĵìĿĢ&#34;:3649,&#34;ĠìĤ¶ìĿĦ&#34;:3650,&#34;ĠíĶĦëŀĳìĬ¤&#34;:3651,&#34;ìĬ¤ë¦´ëŁ¬&#34;:3652,&#34;Ģëĭ¤&#34;:3653,&#34;ĠìĺģíĻĶë³´ëĭ¤&#34;:3654,&#34;ë§ĪìĿ´&#34;:3655,&#34;ì¶°&#34;:3656,&#34;Ġë°ĶëŀĮ&#34;:3657,&#34;ĠìĺģìĽĲ&#34;:3658,&#34;Ġì¢ĭìķĺìĿĮ&#34;:3659,&#34;ĠëĬĲê»´ì§ĢëĬĶ&#34;:3660,&#34;Ġë¬´ìĹĩë³´ëĭ¤&#34;:3661,&#34;ëĤĺìĺ¨ëĭ¤&#34;:3662,&#34;ìĸ´ìĦ¤&#34;:3663,&#34;ĠëĤŃë¹Ħ&#34;:3664,&#34;ë§Įìľ¼ë¡ľ&#34;:3665,&#34;ëĮĢëĭ¨&#34;:3666,&#34;ìķĺìĸ´ìļĶ&#34;:3667,&#34;ë¬ĺ&#34;:3668,&#34;ĠìłĢì§Ī&#34;:3669,&#34;Ġì¢ĭìĿĢìĺģíĻĶ&#34;:3670,&#34;Ġëª°ëŀĲ&#34;:3671,&#34;Ġíģ¬ë¦¬ìĬ¤&#34;:3672,&#34;Ġì§Ģê¸ĪëıĦ&#34;:3673,&#34;ĠìĿ´ìĥģíķľ&#34;:3674,&#34;Ġëĭ¤ìļ´ë°Ľ&#34;:3675,&#34;Ġãħĭãħĭãħĭãħĭãħĭãħĭãħĭãħĭ&#34;:3676,&#34;íķ´ë³´&#34;:3677,&#34;ìĬ¤ëĬĶ&#34;:3678,&#34;ìĺ¤ê¸Ģ&#34;:3679,&#34;Ġì§ĢëĤľ&#34;:3680,&#34;ìĦ±ë£¡&#34;:3681,&#34;íķĺëĭ¤ëĬĶ&#34;:3682,&#34;ìĨĮëħĦ&#34;:3683,&#34;ë¦¬ëĵ¤&#34;:3684,&#34;íĹĮ&#34;:3685,&#34;ìĤ¬ëĵ¤&#34;:3686,&#34;Ġd&#34;:3687,&#34;ĠìĿ´ìĺģíĻĶëĬĶ&#34;:3688,&#34;Ġê·¸ìĿĺ&#34;:3689,&#34;Ġëĭ¤ê°Ģ&#34;:3690,&#34;ĠìłĦìĦ¤&#34;:3691,&#34;Ġê°Ĳëıħëĭĺ&#34;:3692,&#34;íĿł&#34;:3693,&#34;ìĸ¸ìłľ&#34;:3694,&#34;Ġì¦Ŀ&#34;:3695,&#34;Ġê²½ì°°&#34;:3696,&#34;Ġë¶Ģì¡±íķľ&#34;:3697,&#34;Ġì§Īì§Ī&#34;:3698,&#34;Ġì²ľìŀ¬&#34;:3699,&#34;ĠíĻĺìĥģ&#34;:3700,&#34;ëĭĿíĥĢìŀĦ&#34;:3701,&#34;ĠìĻľìĿ´ë¦¬&#34;:3702,&#34;ìĸ´ë¦´ëķĮ&#34;:3703,&#34;¹Ľ&#34;:3704,&#34;ëĭ¤íģĲ&#34;:3705,&#34;ĠëĤĺë¨¸&#34;:3706,&#34;ĠíĸĪëįĺ&#34;:3707,&#34;ëª¨ìĬµ&#34;:3708,&#34;Ġê·¸ëŁ°ëį°&#34;:3709,&#34;ìĬ¤ëŁ½ê²Į&#34;:3710,&#34;80&#34;:3711,&#34;ìĭľì¼ľ&#34;:3712,&#34;Ġìĸ»&#34;:3713,&#34;ĠìĦ±ê³µ&#34;:3714,&#34;Ġë§ĪìĿĮìĿĦ&#34;:3715,&#34;ĠìĿ¸ìĥģê¹Ĭ&#34;:3716,&#34;tv&#34;:3717,&#34;ľĺ&#34;:3718,&#34;ë¦¬ëĭ¤&#34;:3719,&#34;Ġì§ĵ&#34;:3720,&#34;ìĤ¶&#34;:3721,&#34;íı°&#34;:3722,&#34;Ġë¹Ħì¶Ķ&#34;:3723,&#34;ìĭ¬íŀĪ&#34;:3724,&#34;Ġë¯¸ìĨĮ&#34;:3725,&#34;ĠìĹŃëĮĢ&#34;:3726,&#34;Ġì¢ĭìķĺëĬĶëį°&#34;:3727,&#34;ìĽĢìĿĦ&#34;:3728,&#34;ĠíĸĪì§Ģë§Į&#34;:3729,&#34;ĠìĿ´ìķ¼ê¸°ê°Ģ&#34;:3730,&#34;êµ¬ëł¤&#34;:3731,&#34;Ġëŀ&#34;:3732,&#34;ìĦľëĬĶ&#34;:3733,&#34;ìĸ´ëĿ¼&#34;:3734,&#34;Ġìĸ´ëłµ&#34;:3735,&#34;ìłĢëŁŃ&#34;:3736,&#34;ê³ĦìĨį&#34;:3737,&#34;ĠìĻĢëĭ¿&#34;:3738,&#34;Ġ:&#34;:3739,&#34;íķĺìĦ¸ìļĶ&#34;:3740,&#34;ê¸°ë¡ľ&#34;:3741,&#34;ë¦¬ìĹĲ&#34;:3742,&#34;ìķĦëĿ¼&#34;:3743,&#34;ëĦ¤ìĹ¬&#34;:3744,&#34;ìĹĪìĿĦ&#34;:3745,&#34;Ġë¶Ģëª¨&#34;:3746,&#34;ëĵ±íķĻìĥĿ&#34;:3747,&#34;ĠìĹ¬ëŁ¬&#34;:3748,&#34;Ġëĵłëĭ¤&#34;:3749,&#34;íĺģ&#34;:3750,&#34;ëıĦëĬĶ&#34;:3751,&#34;ëĤĺê°Ģ&#34;:3752,&#34;ìĬĪ&#34;:3753,&#34;ìķĦê°Ģ&#34;:3754,&#34;ê¹Ķ&#34;:3755,&#34;Ġíķľê³Ħ&#34;:3756,&#34;ĠëĵľëĬĶ&#34;:3757,&#34;ë¹ĦëĶĶìĺ¤&#34;:3758,&#34;Ġì¡°ìĹ°&#34;:3759,&#34;ĠëĤĺìĺ¤ê³ł&#34;:3760,&#34;ĠëªħìŀĳìĿ´ëĭ¤&#34;:3761,&#34;ĠìķĦëĭĮëį°&#34;:3762,&#34;ĠíĹĪìĪł&#34;:3763,&#34;ìĻ¸ë¡ľ&#34;:3764,&#34;ĠíĶĦë¡ľê·¸ëŀ¨&#34;:3765,&#34;Ĳë§ģ&#34;:3766,&#34;ìĿ´ìľł&#34;:3767,&#34;ìķĺìĬµëĭĪëĭ¤&#34;:3768,&#34;Ġíķ´ì¤Ģ&#34;:3769,&#34;Ġìĭ¤íĮ¨&#34;:3770,&#34;ĠëĦĺìĸ´&#34;:3771,&#34;Ġì²ĺìĿĮìĿ´ëĭ¤&#34;:3772,&#34;ë°°ê²½&#34;:3773,&#34;©°&#34;:3774,&#34;ĠìĺģíĻĶì§Ģë§Į&#34;:3775,&#34;ëĮĢê°Ģ&#34;:3776,&#34;Ġê°ĻìĿĮ&#34;:3777,&#34;Ġì¶¤&#34;:3778,&#34;Ġë©Ģ&#34;:3779,&#34;ĠëıĪìĿ´&#34;:3780,&#34;ì§ĢìķĬëĬĶ&#34;:3781,&#34;ì¡´ëĤĺ&#34;:3782,&#34;Ġ;;&#34;:3783,&#34;ë¦¬ëıĦ&#34;:3784,&#34;ìĹ¬ì£¼ìĿ¸ê³µ&#34;:3785,&#34;ĠíĿł&#34;:3786,&#34;ë¦¬ë©´&#34;:3787,&#34;Ġë§ŀëĬĶ&#34;:3788,&#34;ê°ĪìĪĺë¡Ŀ&#34;:3789,&#34;ê·¹ìŀ¥ìĹĲìĦľ&#34;:3790,&#34;Ġost&#34;:3791,&#34;ĠëĴ·&#34;:3792,&#34;ìĿ´ìĿĺ&#34;:3793,&#34;ëĤĺìĺ´&#34;:3794,&#34;ìĦľìķ¼&#34;:3795,&#34;ëģĪ&#34;:3796,&#34;ĠëĵľëĿ¼ë§Īê°Ģ&#34;:3797,&#34;ëªħìĿ´&#34;:3798,&#34;ĠëıĻíĻĶ&#34;:3799,&#34;ìķĦì§ģëıĦ&#34;:3800,&#34;Ħë¦¬íĭ°&#34;:3801,&#34;ìĿ´ìĬ¤&#34;:3802,&#34;ìķĦëĤĺ&#34;:3803,&#34;ìŀ¬ë¯¸ìĹĨìĿĮ&#34;:3804,&#34;ĠìĽĲëŀĺ&#34;:3805,&#34;Ġãħİãħİãħİ&#34;:3806,&#34;Ġê³³&#34;:3807,&#34;Ġëª©ìĨĮë¦¬&#34;:3808,&#34;(?)&#34;:3809,&#34;14&#34;:3810,&#34;ĠìķĦëĬĶ&#34;:3811,&#34;ë§ĲëıĦ&#34;:3812,&#34;ìĹ°ê±¸&#34;:3813,&#34;Ġì§Ģë£¨íķ´&#34;:3814,&#34;ë³´ê³łìĭ¶&#34;:3815,&#34;ĠìĤ¬ëŀĳìĿ´&#34;:3816,&#34;ë°ľìĿ´&#34;:3817,&#34;íĽĦë°ĺ&#34;:3818,&#34;íķĺê¸°ë§Į&#34;:3819,&#34;ĠìĽĲìŀĳìĿĦ&#34;:3820,&#34;Ġì²Ńì¶ĺ&#34;:3821,&#34;ëŁŃìłĢëŁŃ&#34;:3822,&#34;¥ĺ&#34;:3823,&#34;ĠìĦ¬&#34;:3824,&#34;ĠìŀĲìľł&#34;:3825,&#34;Ġë³´ê³łìĭ¶ìĿĢ&#34;:3826,&#34;Ġíķ´íĶ¼&#34;:3827,&#34;Ġê°ĲíĥĦ&#34;:3828,&#34;ĠíĶĮ&#34;:3829,&#34;ĠëĤľëĭ¤&#34;:3830,&#34;Ġê²ĮìŀĦ&#34;:3831,&#34;Ġê°Ħë§ĮìĹĲ&#34;:3832,&#34;íĳ¸&#34;:3833,&#34;ĠìĿ´ëŁ°ê±°&#34;:3834,&#34;Ġë¯¸ëŀĺ&#34;:3835,&#34;Ġìŀ¬ë¯¸ìĹĨê³ł&#34;:3836,&#34;ëŁ½ëĭ¤&#34;:3837,&#34;ìĭĿìľ¼ë¡ľ&#34;:3838,&#34;Ġëľ¨&#34;:3839,&#34;ĠëĵľëĿ¼ë§Īë¥¼&#34;:3840,&#34;ëıĦê°Ģ&#34;:3841,&#34;Ġë§ĪëĿ¼&#34;:3842,&#34;ë§ĮëĵľëĬĶ&#34;:3843,&#34;ìĺ¤ë¹ł&#34;:3844,&#34;ĠìĬ¤ì¼Ģ&#34;:3845,&#34;ìĦ±ìĿĢ&#34;:3846,&#34;ĠìĹ°ê¸°ìĹĲ&#34;:3847,&#34;ĠìĽĮ&#34;:3848,&#34;Ġíķ´ì£¼&#34;:3849,&#34;íħĶ&#34;:3850,&#34;ê´Ģê°Ŀ&#34;:3851,&#34;ì¶Ķìĸµ&#34;:3852,&#34;ëĶ°ëľ»&#34;:3853,&#34;Ġìł¤&#34;:3854,&#34;ëĵ¤ë§Į&#34;:3855,&#34;Ġë©Ķìĭľ&#34;:3856,&#34;Ġìķŀìľ¼ë¡ľ&#34;:3857,&#34;Ġì·¨íĸ¥&#34;:3858,&#34;ëļ±&#34;:3859,&#34;ëĩĮ&#34;:3860,&#34;Ġë¶Ļ&#34;:3861,&#34;íĴĢ&#34;:3862,&#34;ìĺĢìĸ´ìļĶ&#34;:3863,&#34;ë©´ìĦľëıĦ&#34;:3864,&#34;ĠìĿ¼ìĸ´&#34;:3865,&#34;Ġê³łë¯¼&#34;:3866,&#34;Ġë°ĶëĢ&#34;:3867,&#34;Ġì²ĺìĿĮë¶ĢíĦ°&#34;:3868,&#34;ìĥĿê°ģë³´ëĭ¤&#34;:3869,&#34;ĠëĪĪìĿĦ&#34;:3870,&#34;Ġëĸ¨ìĸ´ì§ĢëĬĶ&#34;:3871,&#34;Ġë¶Īë¥ľ&#34;:3872,&#34;Ġíį¼&#34;:3873,&#34;ĠìĿĳ&#34;:3874,&#34;ĠìĿ´íķĺ&#34;:3875,&#34;ê±°ëĥĲ&#34;:3876,&#34;ìĹĨìĸ´ìĦľ&#34;:3877,&#34;ì¦Ĳ&#34;:3878,&#34;Ġìŀĺë§Įëĵł&#34;:3879,&#34;Ġê·Ģìĭł&#34;:3880,&#34;ĠìĨĮìŀ¬ë¥¼&#34;:3881,&#34;ĠD&#34;:3882,&#34;Ġë³´ìĿ´ëĬĶ&#34;:3883,&#34;ë°¥&#34;:3884,&#34;ìĭľì²Ń&#34;:3885,&#34;ê·¸ëłĩ&#34;:3886,&#34;ĠìłĦë¬¸&#34;:3887,&#34;ë¬´ìĦŃ&#34;:3888,&#34;Ġê°ĲìłķìĿ´&#34;:3889,&#34;Ġëħ¼&#34;:3890,&#34;ĠìĿ´ìľłê°Ģ&#34;:3891,&#34;Ġëļ&#34;:3892,&#34;ë§¥&#34;:3893,&#34;ìĥ¤&#34;:3894,&#34;ìĻĢìĦľ&#34;:3895,&#34;íĸĪìĿĦ&#34;:3896,&#34;ĠëĬĻ&#34;:3897,&#34;ĠëĤ¨ëĬĶëĭ¤&#34;:3898,&#34;ĠìĬ¤íĨłë¦¬ìĻĢ&#34;:3899,&#34;Ġë¯¸ìķĪ&#34;:3900,&#34;ĠìķĪë´¤&#34;:3901,&#34;Ġê³µíı¬ë&#34;:3902,&#34;Ġë³´ëĬĶê²Į&#34;:3903,&#34;ĠìķĦê¹ĮìĽĮ&#34;:3904,&#34;ĠëĪĪìĿ´&#34;:3905,&#34;Ġì°įìĿĢ&#34;:3906,&#34;ê²Łëĭ¤&#34;:3907,&#34;90&#34;:3908,&#34;ë©ĶìĿ´&#34;:3909,&#34;ĠìķĦë§Ī&#34;:3910,&#34;Ġìĸ´ì°Į&#34;:3911,&#34;ĠëģĬ&#34;:3912,&#34;ë¹Ħê°Ģ&#34;:3913,&#34;ĠëĮĢíķľë¯¼êµŃ&#34;:3914,&#34;ĠëĪĦêµ°&#34;:3915,&#34;Ġë¡&#34;:3916,&#34;ê°Ģìŀ¥&#34;:3917,&#34;ëĵ¤ê³ł&#34;:3918,&#34;ìķĦë²Ħì§Ģ&#34;:3919,&#34;ĠëĤĺìĦľ&#34;:3920,&#34;ëł¤ëĭ¤&#34;:3921,&#34;ĠìĻľìĿ´ëłĩê²Į&#34;:3922,&#34;ĠìĤ¬ëŀĮìĿĦ&#34;:3923,&#34;ĠíķĺëĤĺíķĺëĤĺ&#34;:3924,&#34;Ġê·¸ëŁ°ê°Ģ&#34;:3925,&#34;ëŃĲì§Ģ&#34;:3926,&#34;ĠìŀĪëĭ¤ë©´&#34;:3927,&#34;Ġìľłì¹ĺíķľ&#34;:3928,&#34;ìŀ¬ë¯¸ìŀĪìĸ´ìļĶ&#34;:3929,&#34;ĠìĹ¬ëŁ¬ë&#34;:3930,&#34;ĠíĨµíķ´&#34;:3931,&#34;¬ë¡ľ&#34;:3932,&#34;³´ëĭ¤&#34;:3933,&#34;ĠìĿ´ëŀĺ&#34;:3934,&#34;ìľ¼ë¡ł&#34;:3935,&#34;Ġê¸Ī&#34;:3936,&#34;ì¤ĳêµŃ&#34;:3937,&#34;ìłĢëĬĶ&#34;:3938,&#34;Ġë§¤ëł¥ìĿ´&#34;:3939,&#34;ëĳ¥&#34;:3940,&#34;Ġë¦¬ë©ĶìĿ´íģ¬&#34;:3941,&#34;Ġê°ĲìĤ¬íķ©ëĭĪëĭ¤&#34;:3942,&#34;Ġ+&#34;:3943,&#34;ëĭ¤ì§Ģ&#34;:3944,&#34;ëĬĶê°Ģ&#34;:3945,&#34;ìĺģíĻĶëĿ¼&#34;:3946,&#34;ìĺģíĻĶëĿ¼ê³ł&#34;:3947,&#34;Ġê°ĢìĦľ&#34;:3948,&#34;ìĹ°ê¸°ëł¥&#34;:3949,&#34;ĠíĻĶê°Ģ&#34;:3950,&#34;Ġì¤Ħê±°ë¦¬&#34;:3951,&#34;Ġìłģëĭ¹&#34;:3952,&#34;ĠëĤĺìĻĶìľ¼ë©´&#34;:3953,&#34;ĠëŁ¬ë¸Į&#34;:3954,&#34;11&#34;:3955,&#34;ĠìĺģíĻĶëĥĲ&#34;:3956,&#34;ëĦ¤ìĿ´ë²Ħ&#34;:3957,&#34;Ġë´¤ëĭ¤ê°Ģ&#34;:3958,&#34;ìĹ¬ê¸°&#34;:3959,&#34;ĠìķĮìķĦ&#34;:3960,&#34;ĠìĿ´ëŁ°ìĺģíĻĶ&#34;:3961,&#34;Ġìŀ¬ë¯¸ìŀĪê³ł&#34;:3962,&#34;Ġëħ¹&#34;:3963,&#34;ì§±ì§±&#34;:3964,&#34;ê·¸ëŀĺìĦľ&#34;:3965,&#34;Ġëıħë¦½&#34;:3966,&#34;ĠìĬ¤íĨłë¦¬ë¥¼&#34;:3967,&#34;ìĸ´ëł¸ìĿĦëķĮ&#34;:3968,&#34;ë³įê²Į&#34;:3969,&#34;ĠìĹ¬ìłĦíŀĪ&#34;:3970,&#34;ìİĦ&#34;:3971,&#34;ì¨&#34;:3972,&#34;íķľì§Ģ&#34;:3973,&#34;ëĿ¼ìĬ¤&#34;:3974,&#34;ëŀĲëĭ¤&#34;:3975,&#34;Ġìĺ¬ëĿ¼&#34;:3976,&#34;ìĻĢë¥´&#34;:3977,&#34;Ġíķµ&#34;:3978,&#34;ĠìłĢëĬĶ&#34;:3979,&#34;ĠìĹŃíķł&#34;:3980,&#34;ìľĦíķ´&#34;:3981,&#34;ê²°êµŃ&#34;:3982,&#34;ĠìķĪëĲĺê³ł&#34;:3983,&#34;Ġ80&#34;:3984,&#34;íļ¨ê³¼&#34;:3985,&#34;ĠìķĪë³¸&#34;:3986,&#34;µĿ&#34;:3987,&#34;ìĵ´&#34;:3988,&#34;ìĿ´íĦ°&#34;:3989,&#34;ëĭĪìķĦ&#34;:3990,&#34;Ġë³´ëŁ¬&#34;:3991,&#34;íķłê¹Į&#34;:3992,&#34;Ġëįĺ&#34;:3993,&#34;ĠëĤ´ìļ©ìĿĦ&#34;:3994,&#34;Ġìļ°ìļ¸&#34;:3995,&#34;Ġìĭľê°ĦëĤŃë¹Ħ&#34;:3996,&#34;Ġì²ĺìĿĮìľ¼ë¡ľ&#34;:3997,&#34;Ġíķľíİ¸&#34;:3998,&#34;ĠìĥĿê°ģíķ©ëĭĪëĭ¤&#34;:3999,&#34;ìĿ´ëĿ¼ìĦľ&#34;:4000,&#34;ĠëģĿëĤĺê³ł&#34;:4001,&#34;ìĹŃìĤ¬&#34;:4002,&#34;íķľëĭ¤ë©´&#34;:4003,&#34;ìĤ´ëĭ¤&#34;:4004,&#34;ë¨¹ê³ł&#34;:4005,&#34;ì¾Įíķľ&#34;:4006,&#34;ìķĦëĭĪëĿ¼&#34;:4007,&#34;ĠìŀĲìĭłìĿĺ&#34;:4008,&#34;Ġì²łíķĻ&#34;:4009,&#34;bb&#34;:4010,&#34;ê¸°ë¶Ħ&#34;:4011,&#34;Ġìłķì¹ĺ&#34;:4012,&#34;ĠìĭľìĦł&#34;:4013,&#34;Ġë´¤ìĹĪëĬĶëį°&#34;:4014,&#34;Ġê°Ģì§Ħ&#34;:4015,&#34;ìĿ¼ëĭ¨&#34;:4016,&#34;Ġìŀ¬ë°Įìĸ´&#34;:4017,&#34;ĠìłĦëĭ¬&#34;:4018,&#34;ĠìķĪíķĺê³ł&#34;:4019,&#34;ë¥¸ëĭ¤&#34;:4020,&#34;Ġë³´ê¸°ìĹĶ&#34;:4021,&#34;Ġìľłì¹ĺíķĺê³ł&#34;:4022,&#34;ì§ĢìķĬìĿĢ&#34;:4023,&#34;íĳľíĺĦ&#34;:4024,&#34;ë©ĺíĦ°&#34;:4025,&#34;ìĹ¬ìļ´ìĿ´&#34;:4026,&#34;íīģ&#34;:4027,&#34;an&#34;:4028,&#34;ĵ¨&#34;:4029,&#34;Ġë¥ĺ&#34;:4030,&#34;ìĿ´ìŀĲ&#34;:4031,&#34;ëłī&#34;:4032,&#34;ìĹĪìĸ´&#34;:4033,&#34;ì£¼ìĸ¼&#34;:4034,&#34;íĨ¤&#34;:4035,&#34;ê±¸ë¡ľ&#34;:4036,&#34;ìĽĲìĿ´&#34;:4037,&#34;ìĶ¨ê°Ģ&#34;:4038,&#34;ĠëĪĦêµ¬&#34;:4039,&#34;Ġê´ľíŀĪ&#34;:4040,&#34;**&#34;:4041,&#34;100&#34;:4042,&#34;30&#34;:4043,&#34;ou&#34;:4044,&#34;įëĭĪëĭ¤&#34;:4045,&#34;ìĿ´ë¥¼&#34;:4046,&#34;íķľë§ĪëĶĶë¡ľ&#34;:4047,&#34;ë²¤&#34;:4048,&#34;ĠëĦĪë¬´ëĦĪë¬´&#34;:4049,&#34;ë¯¸ì¹ľ&#34;:4050,&#34;Ġìŀĺë´¤ìĬµëĭĪëĭ¤&#34;:4051,&#34;ëłĪìĬ¤&#34;:4052,&#34;ëŃĺ&#34;:4053,&#34;Ġë³Ħë£¨&#34;:4054,&#34;Ġì§ľì¦ĿëĤĺ&#34;:4055,&#34;ĠíĴĢ&#34;:4056,&#34;ĠëĮĢëĭ¨íķĺëĭ¤&#34;:4057,&#34;ĠìķĪëĲ¨&#34;:4058,&#34;Ġcg&#34;:4059,&#34;ëĤĺìĿĺ&#34;:4060,&#34;ì£¼ìĹ°&#34;:4061,&#34;ëĤ´ìĿ¸ìĥĿ&#34;:4062,&#34;ìĹĲìĦľìĿĺ&#34;:4063,&#34;ĠëĮĢì¶©&#34;:4064,&#34;ëĶĶìĸ´&#34;:4065,&#34;íĬ¸ê°Ģ&#34;:4066,&#34;ĠëĵľëĿ¼ë§ĪëĬĶ&#34;:4067,&#34;ĠëĲĺìĹĪëĭ¤&#34;:4068,&#34;ĠìĹ¬ìŀĲê°Ģ&#34;:4069,&#34;ëĤ´ìļ©ìĿĢ&#34;:4070,&#34;ê¶ģ&#34;:4071,&#34;íĹĪìłĳ&#34;:4072,&#34;15&#34;:4073,&#34;ģìĵ¸&#34;:4074,&#34;íķĺëł¤ëĬĶ&#34;:4075,&#34;ĠìĹĨì§Ģë§Į&#34;:4076,&#34;Ġì°¬&#34;:4077,&#34;Ġì¤ĳë°ĺ&#34;:4078,&#34;ì¶ľìĹ°&#34;:4079,&#34;ëĨ¨&#34;:4080,&#34;Ġìŀ¬ë¯¸ìĹĨìĸ´&#34;:4081,&#34;ĠìłĦê¸°ìĦ¸ê°Ģ&#34;:4082,&#34;ê¸°ìĿĺ&#34;:4083,&#34;ìĭľìķĦ&#34;:4084,&#34;ê¹Įì§Ħ&#34;:4085,&#34;êµ¬íķĺê³ł&#34;:4086,&#34;Ġëª¨ìŀĲ&#34;:4087,&#34;ìĭłìĦł&#34;:4088,&#34;ì¡°ê¸Ī&#34;:4089,&#34;Ġë°Ķê¿&#34;:4090,&#34;Ġê¼´&#34;:4091,&#34;ì´ĪëĶ©&#34;:4092,&#34;íıīë¡łê°Ģ&#34;:4093,&#34;ĠíĻ©ëĭ¹&#34;:4094,&#34;íĿ¥ë¯¸&#34;:4095,&#34;ì§Īëģ&#34;:4096,&#34;ãħģ&#34;:4097,&#34;ĠìķĦìłĢìĶ¨&#34;:4098,&#34;ĠëĤĺìĹĲê²Į&#34;:4099,&#34;ìłĦíĺĢ&#34;:4100,&#34;Ġìŀ¬ë¯¸ë¥¼&#34;:4101,&#34;íİ¸ë³´ëĭ¤&#34;:4102,&#34;ë²Ħëł¸ëĭ¤&#34;:4103,&#34;ê»Ħ&#34;:4104,&#34;ĠìĺĪìģľ&#34;:4105,&#34;ì©Ķ&#34;:4106,&#34;Ġì§Ģê¸Īê¹Įì§Ģ&#34;:4107,&#34;ìĽĥê¸°&#34;:4108,&#34;ìŀĬ&#34;:4109,&#34;Ġë³´ìĭľê¸¸&#34;:4110,&#34;ëĮĢëĬĶ&#34;:4111,&#34;Ġëĭ¤ë§Į&#34;:4112,&#34;ìŀĪìĸ´&#34;:4113,&#34;ĠìĥĪë¡&#34;:4114,&#34;Ġë³´ê³łëĤĺìĦľ&#34;:4115,&#34;ĠìĤ¬ëĬĶ&#34;:4116,&#34;ê²°ë§ĲìĿ´&#34;:4117,&#34;ĠíĿ¥ë¯¸ë¡Ń&#34;:4118,&#34;Ġê·¸ëŁ¼&#34;:4119,&#34;ìĭľëĤĺë¦¬ìĺ¤&#34;:4120,&#34;ĠìŀĪìĬµëĭĪëĭ¤&#34;:4121,&#34;ì°Ŀ&#34;:4122,&#34;ĠìĺģíĻĺ&#34;:4123,&#34;ĠìµľìķħìĿ´ëĭ¤&#34;:4124,&#34;Ġëª°ìŀħìĿ´&#34;:4125,&#34;ĠìĹ°ê¸°ëł¥ìĿ´&#34;:4126,&#34;¬ëł&#34;:4127,&#34;!!!!!&#34;:4128,&#34;ĠëĤĺë¥¼&#34;:4129,&#34;ĠëĤĺíĥĢ&#34;:4130,&#34;ìĪĺëĬĶ&#34;:4131,&#34;ĠëĦĪë¬´ëĤĺëıĦ&#34;:4132,&#34;ëĵľëĿ¼&#34;:4133,&#34;Ġìŀ¬ë°ĮìĹĪìĸ´ìļĶ&#34;:4134,&#34;ĠìĹ¬ìĦ±&#34;:4135,&#34;ëįĶë§Į&#34;:4136,&#34;ë§¤ëł¥&#34;:4137,&#34;Ġê¸°ë¶ĦìĿ´&#34;:4138,&#34;Ġìĸ´ìĥīíķľ&#34;:4139,&#34;ì§Ģì»¬&#34;:4140,&#34;Ġê·¸ëĵ¤ìĿĺ&#34;:4141,&#34;ìĹĪì§Ģ&#34;:4142,&#34;ë²¼&#34;:4143,&#34;ĠìĹ°ê¸°ìĻĢ&#34;:4144,&#34;ĠìĿ¼ëĭ¨&#34;:4145,&#34;ëĲĺì§Ģ&#34;:4146,&#34;ì¦ĪëĭĪ&#34;:4147,&#34;ĠíķĦìļĶìĹĨëĬĶ&#34;:4148,&#34;Ġìłľìŀĳì§Ħ&#34;:4149,&#34;Ġê·ĢìĹ¬ìļ´&#34;:4150,&#34;ĠíķĻêµĲ&#34;:4151,&#34;ĠìłĦì²´ìłģìľ¼ë¡ľ&#34;:4152,&#34;Ġì§ł&#34;:4153,&#34;Ġëĭ¤ìĨĮ&#34;:4154,&#34;ëŀĺê¸°&#34;:4155,&#34;ë¬´ìĦľ&#34;:4156,&#34;ìĤ¬ëŀĮìĿĢ&#34;:4157,&#34;ĠìĻ¸êµŃ&#34;:4158,&#34;ìŀĶìŀĶíķľ&#34;:4159,&#34;ê°ĢëĬ¥&#34;:4160,&#34;ë³´ìĿ´&#34;:4161,&#34;Ġë°Ŀ&#34;:4162,&#34;ë´ĩ&#34;:4163,&#34;íĸĪëĭ¤ëĬĶ&#34;:4164,&#34;ê°ĻìĿĮ&#34;:4165,&#34;Ġë§Įëĵ¤ìĸ´ì§Ħ&#34;:4166,&#34;ĠìĪĺì¤ĢìĿ´&#34;:4167,&#34;Ġì©Ķ&#34;:4168,&#34;Ġê¾¸&#34;:4169,&#34;ĠìĺĪë»&#34;:4170,&#34;ìĿ´ê²ĥëıĦ&#34;:4171,&#34;ìĸ´ì§Ħ&#34;:4172,&#34;ë¡ľëĬĶ&#34;:4173,&#34;ë¡ľë§¨&#34;:4174,&#34;ìķĦëĨĶ&#34;:4175,&#34;ê±°ìļ´&#34;:4176,&#34;Ġëĭ¤ìĭľë´ĲëıĦ&#34;:4177,&#34;ìķĪë³´&#34;:4178,&#34;Ġíı¬ìŀ¥&#34;:4179,&#34;ëıĮìķĦ&#34;:4180,&#34;ĳ¹&#34;:4181,&#34;ĠìĿ´ìłł&#34;:4182,&#34;ìłĲì£¼ëĬĶ&#34;:4183,&#34;ê±°ë¦¬ëĬĶ&#34;:4184,&#34;ë§ĪìłĢ&#34;:4185,&#34;ìĥģìĿ´&#34;:4186,&#34;Ġëı¼&#34;:4187,&#34;Ġëįľ&#34;:4188,&#34;Ġê¸°ë³¸&#34;:4189,&#34;ĠìĪĺëıĦ&#34;:4190,&#34;ĠìłĦìĹĲ&#34;:4191,&#34;Ġê°ľíĮĲ&#34;:4192,&#34;Ġìļ°ìĹ°íŀĪ&#34;:4193,&#34;Ġê¼½&#34;:4194,&#34;Ġë³´ì§Ģë§Ī&#34;:4195,&#34;Ġë³´ì§Ģë§ĪìĦ¸ìļĶ&#34;:4196,&#34;Ġë¦¬ë·°&#34;:4197,&#34;ĠíĿĲë¦Ħ&#34;:4198,&#34;µĿìĺ¤&#34;:4199,&#34;ë¢&#34;:4200,&#34;ë¡¯&#34;:4201,&#34;ìĿ¸ëıĦ&#34;:4202,&#34;ìĭľíĤ¨&#34;:4203,&#34;ĠìŀĪëĤĺ&#34;:4204,&#34;ê³µê°Ĳ&#34;:4205,&#34;ĠìĤ¬ìĿ´&#34;:4206,&#34;ĠìĤ¬ê·¹&#34;:4207,&#34;ĠìłĢëłĩê²Į&#34;:4208,&#34;ì½Ķë¯¹&#34;:4209,&#34;Ġìĭ¬ìĭ¬&#34;:4210,&#34;ìķĦê¹Įìļ´&#34;:4211,&#34;Ġëª¸ë§¤&#34;:4212,&#34;ĠìĨĮìŀ¬ë¡ľ&#34;:4213,&#34;ë§ĺ&#34;:4214,&#34;ì§ĢìĿĺ&#34;:4215,&#34;Ġìŀĩ&#34;:4216,&#34;Ġì¢ĭìĿĦ&#34;:4217,&#34;ìľ¼ë¡ľìĦľ&#34;:4218,&#34;Ġìĸ´ìĿ´ê°Ģ&#34;:4219,&#34;ĠëŃī&#34;:4220,&#34;ëĵ¯ìĿ´&#34;:4221,&#34;Ġìĺ¤ëĿ½&#34;:4222,&#34;ĠìľłìĿ¼&#34;:4223,&#34;ëĦĪë¬´ëĤĺ&#34;:4224,&#34;ĠìłĢëıĦ&#34;:4225,&#34;ĠíĹĽ&#34;:4226,&#34;ê´Ģê³Ħ&#34;:4227,&#34;ĠìķĦëĭĮëĵ¯&#34;:4228,&#34;ìĽłìĿĮ&#34;:4229,&#34;Ġë°ĺìłĦìĿ´&#34;:4230,&#34;Ġê·¸ëłĩëĭ¤&#34;:4231,&#34;ĠíĹĪìłĳíķľ&#34;:4232,&#34;ĠìķĦë¦Ħëĭµê³ł&#34;:4233,&#34;?!&#34;:4234,&#34;ìĿ´ë¦¬&#34;:4235,&#34;ë§ĮìłĲ&#34;:4236,&#34;Ġë°¤&#34;:4237,&#34;ëĮĢìĿĺ&#34;:4238,&#34;ĠíķĺëĦ¤ìļĶ&#34;:4239,&#34;ëª¸&#34;:4240,&#34;Ġìĺ¤ê·¸ëĿ¼&#34;:4241,&#34;Ġë¶ĢíĦ°&#34;:4242,&#34;ĠëĲĺê³ł&#34;:4243,&#34;Ġê³łìĥĿ&#34;:4244,&#34;ëĳĲê³ł&#34;:4245,&#34;¬ë¦Ħ&#34;:4246,&#34;ìķĪëĲ&#34;:4247,&#34;ëĶ°ëĿ¼&#34;:4248,&#34;Ġíı¬ê¸°&#34;:4249,&#34;Ġì±Ļ&#34;:4250,&#34;Ġê³µê°ĲìĿ´&#34;:4251,&#34;Ġì¹´ë©ĶëĿ¼&#34;:4252,&#34;Ġtv&#34;:4253,&#34;Ġì§Ħë¶Ģíķľ&#34;:4254,&#34;ìĺ¬ëķĮ&#34;:4255,&#34;ĪëķĮ&#34;:4256,&#34;ë¡±&#34;:4257,&#34;¬ëŀĢ&#34;:4258,&#34;Ġíķľë§ĪëĶĶë¡ľ&#34;:4259,&#34;Ġë´¤ìľ¼ë©´&#34;:4260,&#34;Ġê°ĢëģĶ&#34;:4261,&#34;Ġ15&#34;:4262,&#34;Ġê°ĻìķĦ&#34;:4263,&#34;ĠëĶ´&#34;:4264,&#34;íĤ¬ë§ģíĥĢìŀĦìļ©&#34;:4265,&#34;ĠíĻľ&#34;:4266,&#34;ĠíĥĪ&#34;:4267,&#34;ĠëĳĲë²Ī&#34;:4268,&#34;Ġë§¤ëł¥ìłģìĿ¸&#34;:4269,&#34;êµ¬ë¥¼&#34;:4270,&#34;ĠìĨĮë¦Ħëıĭ&#34;:4271,&#34;Ġìļ©ìĦľ&#34;:4272,&#34;Ġê´´ë¬¼&#34;:4273,&#34;íķľê²ĥ&#34;:4274,&#34;ĠìĿ´ê¸°&#34;:4275,&#34;íķ´ì¤Ģ&#34;:4276,&#34;Ġë³´ìĭľ&#34;:4277,&#34;ë²Īë³´&#34;:4278,&#34;ĠìĽĶ&#34;:4279,&#34;Ġë¶ĢëģĦ&#34;:4280,&#34;ìĨįìĹĲìĦľ&#34;:4281,&#34;ëĬĲëĿ¼&#34;:4282,&#34;ë¥ĺìĿĺ&#34;:4283,&#34;Ġì§ľì¦ĿëĤĺëĬĶ&#34;:4284,&#34;ĠìĿ´ìľłëĬĶ&#34;:4285,&#34;Ġìĸ´ìĿ´ìĹĨëĬĶ&#34;:4286,&#34;ĠëĪĪë¹Ľ&#34;:4287,&#34;ë¢°&#34;:4288,&#34;Ġë§¡&#34;:4289,&#34;ëĦ£&#34;:4290,&#34;ĠìĹĨëĤĺ&#34;:4291,&#34;ë£¬&#34;:4292,&#34;ìĦ±ìĹĲ&#34;:4293,&#34;ĠìĨĮëħĢ&#34;:4294,&#34;ë´¤ìĿĮ&#34;:4295,&#34;ìŀ¬ë°ĮëĬĶëį°&#34;:4296,&#34;ĠíıĲ&#34;:4297,&#34;ë°°ìļ°ê°Ģ&#34;:4298,&#34;ê¼½&#34;:4299,&#34;ì§Ģë£¨íķ¨&#34;:4300,&#34;Ġì¶Ķì²ľíķ©ëĭĪëĭ¤&#34;:4301,&#34;ê´ľì°®ìĿĢ&#34;:4302,&#34;ê²¹ëĭ¤&#34;:4303,&#34;ĠOST&#34;:4304,&#34;ìĿ´ëŀĺ&#34;:4305,&#34;ìķĦëĭĺ&#34;:4306,&#34;ê¹Įì§ĢëĬĶ&#34;:4307,&#34;ì§ĢìķĬê³ł&#34;:4308,&#34;ê¾¼&#34;:4309,&#34;íķĺìĭľëĬĶ&#34;:4310,&#34;ĠìĬ¬íĶĦëĭ¤&#34;:4311,&#34;ĠìłĬìĿĢ&#34;:4312,&#34;ìŀĪëįĺ&#34;:4313,&#34;ãħĪ&#34;:4314,&#34;ëįľ&#34;:4315,&#34;ìĺ¹&#34;:4316,&#34;Ġë°¥&#34;:4317,&#34;ìŀĲëĭ¨&#34;:4318,&#34;ĠëģĿëĤĺëĬĶ&#34;:4319,&#34;ìĹ¬ë°°ìļ°&#34;:4320,&#34;ëĪĦê°Ģ&#34;:4321,&#34;ì¤ĺìĦľ&#34;:4322,&#34;ĠíĿ¬ìĥĿ&#34;:4323,&#34;ĠìĻłì§Ģ&#34;:4324,&#34;ëıĦìĹĨê³ł&#34;:4325,&#34;ìŀĲê³ł&#34;:4326,&#34;Ġíķĺë£¨&#34;:4327,&#34;ìĻĢëĬĶ&#34;:4328,&#34;ìĭłìĿĺ&#34;:4329,&#34;íķĺëĭ¤ê°Ģ&#34;:4330,&#34;ĠìĥĿê°ģëĤĺëĬĶ&#34;:4331,&#34;ë²Ħëł¸&#34;:4332,&#34;Ġì¹¼&#34;:4333,&#34;ĠìĤ´ì§Ŀ&#34;:4334,&#34;ĠíĻķìĭ¤íŀĪ&#34;:4335,&#34;ì¤ĳê°ĦìĹĲ&#34;:4336,&#34;ĠìķĦë¦Ħëĭµëĭ¤&#34;:4337,&#34;ĠìĪľìĪĺíķľ&#34;:4338,&#34;ì§Ģë§Ī&#34;:4339,&#34;Ġë³´ìĿ´&#34;:4340,&#34;ìĺģíĻĶìŀĦ&#34;:4341,&#34;ë³´ìĹ¬&#34;:4342,&#34;ìŀ¥ë¥´&#34;:4343,&#34;ìĤ¬ìĭ¤&#34;:4344,&#34;Ġë§Īì¹ĺ&#34;:4345,&#34;ëħĦìłĦìĹĲ&#34;:4346,&#34;ìķĪìĹĲ&#34;:4347,&#34;Ġë§Įëĵ¤ê³ł&#34;:4348,&#34;Ġìĥģì²ĺ&#34;:4349,&#34;Ġì¢ĭìķĺëįĺ&#34;:4350,&#34;ë³ĦìłĲ&#34;:4351,&#34;Ġíİĳ&#34;:4352,&#34;Ġíĳľìłķ&#34;:4353,&#34;Ġê±´ì§Ģ&#34;:4354,&#34;Ġë´Ĳìķ¼íķł&#34;:4355,&#34;ĠìĶ¬&#34;:4356,&#34;ê°Ģê°Ģ&#34;:4357,&#34;ê¸°ëįķ&#34;:4358,&#34;ìķĦìĺ¤&#34;:4359,&#34;ĠìŀĪì§Ģ&#34;:4360,&#34;íŀĪëĬĶ&#34;:4361,&#34;Ġë§ĲìĿĦ&#34;:4362,&#34;Ġìĭ¶ìĸ´&#34;:4363,&#34;Ġì¹¨&#34;:4364,&#34;ë°°ìļ°ëĵ¤ìĿ´&#34;:4365,&#34;ĠíıīìĥĿ&#34;:4366,&#34;ĠíķĦìļĶìĹĨëĭ¤&#34;:4367,&#34;ìŀ¥ë©´ìĿ´&#34;:4368,&#34;ĠëĨĢëŀį&#34;:4369,&#34;ĠëĸłëĤĺ&#34;:4370,&#34;ĠìĦ¹ìĭľ&#34;:4371,&#34;°©&#34;:4372,&#34;ĠìĺģíĻĶê´Ģ&#34;:4373,&#34;ëĵ¤ìĹĲ&#34;:4374,&#34;Ġê²©&#34;:4375,&#34;ĠìŀĪê²Į&#34;:4376,&#34;ëįĺì§Ģ&#34;:4377,&#34;Ġë¹Ħê·¹&#34;:4378,&#34;Ġê°ĲëıĻìłģ&#34;:4379,&#34;Ġìŀ¬ë¯¸ìĹĨëĦ¤&#34;:4380,&#34;ìĺĪìĪł&#34;:4381,&#34;ìĺĪìłĦìĹĲ&#34;:4382,&#34;Ġì¡¸ëĿ¼&#34;:4383,&#34;ëĭ¤ìĭľë´ĲëıĦ&#34;:4384,&#34;Ġìĭ¸ìĿ´ì½Ķ&#34;:4385,&#34;Ġìĭ«ëĭ¤&#34;:4386,&#34;ê²¼ëĭ¤&#34;:4387,&#34;Ġìŀ¼ìŀĪê²Į&#34;:4388,&#34;Ġíģ¬ê²Į&#34;:4389,&#34;ĠìĿ´ëŁ¬&#34;:4390,&#34;Ġì§Ĳ&#34;:4391,&#34;ìĺģíĻĶë³´ëĭ¤&#34;:4392,&#34;ĠëĤĺìĿĢ&#34;:4393,&#34;ĠìĺĢ&#34;:4394,&#34;Ġìĺ¤ëŀľ&#34;:4395,&#34;ĠíıīìłĲìĹĲ&#34;:4396,&#34;Ġì§Ģë£¨íķĺì§Ģ&#34;:4397,&#34;ëģ¼ë¦¬&#34;:4398,&#34;ĠìĹŃìĭľëĤĺ&#34;:4399,&#34;Ġìŀ¬ë°ĭê²Į&#34;:4400,&#34;19&#34;:4401,&#34;Ġìº&#34;:4402,&#34;ìĿ´íĽĦ&#34;:4403,&#34;ãħı&#34;:4404,&#34;ëłģ&#34;:4405,&#34;íķ´ì§Ħ&#34;:4406,&#34;ì²«&#34;:4407,&#34;ìĪĺìĹĨëĬĶ&#34;:4408,&#34;íĬ¸ì½¤&#34;:4409,&#34;ĠìĤ¬ê¸°&#34;:4410,&#34;ìķłëĵ¤ìĿ´&#34;:4411,&#34;ìĦ¤ìłķ&#34;:4412,&#34;Ġë¶Ħëħ¸&#34;:4413,&#34;Ġê¸´ìŀ¥&#34;:4414,&#34;ì²ĺìĿĮë¶ĢíĦ°&#34;:4415,&#34;ìĽĲìŀĳìĿĦ&#34;:4416,&#34;ĠìĤ°ë§Į&#34;:4417,&#34;Ġíļ¨&#34;:4418,&#34;ìĨĮìŀ¬ëĬĶ&#34;:4419,&#34;Ġê¹ĶëģĶ&#34;:4420,&#34;ëĬĶê±´&#34;:4421,&#34;ĠìĺģíĻĶë³´ê³ł&#34;:4422,&#34;ìĺģíĻĶê´ĢìĹĲìĦľ&#34;:4423,&#34;Ġê·¸ê²ĥ&#34;:4424,&#34;Ġê·¸ë¦°&#34;:4425,&#34;ìŀĲìĹ°&#34;:4426,&#34;ìĪĺìĿĺ&#34;:4427,&#34;ĠëĵľëŁ¬&#34;:4428,&#34;ëł¥ìĿĦ&#34;:4429,&#34;ĠíĽĦìĨį&#34;:4430,&#34;ĠíķĦìļĶíķľ&#34;:4431,&#34;ĠëĿ¼ê³ł&#34;:4432,&#34;ĠíĻįë³´&#34;:4433,&#34;Ġê·ĢìĹ½ê³ł&#34;:4434,&#34;on&#34;:4435,&#34;ĥ¥&#34;:4436,&#34;ëĤļ&#34;:4437,&#34;ìĭľìĹĲ&#34;:4438,&#34;ê°ĦìĿĺ&#34;:4439,&#34;êµ¬ëĭĪ&#34;:4440,&#34;ì¤ĳìĿĺ&#34;:4441,&#34;ĠìķĬê²Į&#34;:4442,&#34;Ġêµ¬ë&#34;:4443,&#34;Ġìĺ¤ë²Ħ&#34;:4444,&#34;Ġìķłëĵ¤ìĿ´&#34;:4445,&#34;ìŀĶìĿ¸&#34;:4446,&#34;ê°Ĳëıħëĭĺ&#34;:4447,&#34;ìĿ¸ê°ĢìļĶ&#34;:4448,&#34;Ġíĺķíİ¸&#34;:4449,&#34;ĠìĨĮë¦Ħëģ¼&#34;:4450,&#34;Ġê¹Įì§Ģ&#34;:4451,&#34;ad&#34;:4452,&#34;Ġë±&#34;:4453,&#34;Ġë¿&#34;:4454,&#34;ìĿ´ë©°&#34;:4455,&#34;íķĺëł¤&#34;:4456,&#34;ìĦ¯&#34;:4457,&#34;ĠìĿ´ë£¨&#34;:4458,&#34;ìĬ¤íĨł&#34;:4459,&#34;ĠìĹ°ìķł&#34;:4460,&#34;ëªħìĿĺ&#34;:4461,&#34;Ġìĭľê°ĦìĿĦ&#34;:4462,&#34;ìĬ¤íĨłë¦¬ëĬĶ&#34;:4463,&#34;íķĺê¸°ëıĦ&#34;:4464,&#34;ëįĶëĿ¼êµ¬ìļĶ&#34;:4465,&#34;ëıħêµĲ&#34;:4466,&#34;Ġì£Ħëĭ¤&#34;:4467,&#34;ĠíĻĶëł¤íķľ&#34;:4468,&#34;ëĭ¤ìĿĮ&#34;:4469,&#34;Ġìŀ¤&#34;:4470,&#34;ìĿĦê±°&#34;:4471,&#34;Ġê·¸ë¦½&#34;:4472,&#34;ë°ĳìĹĲ&#34;:4473,&#34;Ġíķĺë©´ìĦľ&#34;:4474,&#34;ĠìĹ°ìĺĪ&#34;:4475,&#34;ìĭ¤íĻĶ&#34;:4476,&#34;Ġë³´ê³łìĭ¶ëĭ¤&#34;:4477,&#34;Ġë°ĺìĦ±&#34;:4478,&#34;ĠìĿĺë¬¸&#34;:4479,&#34;Ġëª°ëĿ¼ëıĦ&#34;:4480,&#34;ĠíĬ¹ë³Ħ&#34;:4481,&#34;Ġì£¼ìĿ¸ê³µìĿĺ&#34;:4482,&#34;ë¶Īê°Ģ&#34;:4483,&#34;ĠãħħãħĤ&#34;:4484,&#34;re&#34;:4485,&#34;ĠìĭŃ&#34;:4486,&#34;Ġê·¸ì§Ģ&#34;:4487,&#34;ìĭĿìĿĦ&#34;:4488,&#34;ĠíĺĦìŀ¬&#34;:4489,&#34;íĶ¼ìĨĮ&#34;:4490,&#34;ì£¼ìĿ¸ê³µìĿ´&#34;:4491,&#34;ìŀĲì²´ê°Ģ&#34;:4492,&#34;Ġw&#34;:4493,&#34;ìĿ´ëĭĪ&#34;:4494,&#34;ê²Ģ&#34;:4495,&#34;ìķĦëĭĪëĭ¤&#34;:4496,&#34;ĠìłķìĦľ&#34;:4497,&#34;ĠìŀĪìĸ´ìļĶ&#34;:4498,&#34;ê·¸ìĿ¸&#34;:4499,&#34;Ġì§Ħìłķ&#34;:4500,&#34;Ġê°Ģê¹Į&#34;:4501,&#34;ĠìĬ¤íĬ¸&#34;:4502,&#34;ë¶Ģì¡±&#34;:4503,&#34;Ġìŀ¬ë°ĮëĬĶëį°&#34;:4504,&#34;Ġì¶ķ&#34;:4505,&#34;Ġì¡°íıŃ&#34;:4506,&#34;ĠìĤ¬ëŀĳìĹĲ&#34;:4507,&#34;Ġë¶Īêµ¬íķĺê³ł&#34;:4508,&#34;ì¹ľëĭ¤&#34;:4509,&#34;ĠìĦłìĥĿ&#34;:4510,&#34;Ġê³¼ìĹ°&#34;:4511,&#34;ĠíĢĦë¦¬íĭ°&#34;:4512,&#34;íķĺìĭł&#34;:4513,&#34;ê°ĢëĿ½&#34;:4514,&#34;ìĹĲë§Į&#34;:4515,&#34;Ġëĭ¬ëĿ¼&#34;:4516,&#34;ĠìĭľìĽĲ&#34;:4517,&#34;Ġë¬´ìĭľ&#34;:4518,&#34;ĠìĽ¬&#34;:4519,&#34;Ġë¯¸ìĬ¤&#34;:4520,&#34;ĠìĤ¬ëŀĳíķĺëĬĶ&#34;:4521,&#34;Ġì¢ĭìķĦìĦľ&#34;:4522,&#34;Ġë¶Ħëĵ¤&#34;:4523,&#34;Ġë°ĽìķĦ&#34;:4524,&#34;ĠìķħìĹŃ&#34;:4525,&#34;ì¤ĺìķ¼&#34;:4526,&#34;Ġê¹¨ëĭ«&#34;:4527,&#34;ê°ĢìĬ´ìĿ´&#34;:4528,&#34;Ġë¸ĶëŀĻ&#34;:4529,&#34;ë¿Ķ&#34;:4530,&#34;Ġìī½ê²Į&#34;:4531,&#34;Ġíķ´íĶ¼ìĹĶëĶ©&#34;:4532,&#34;ë§ĪìĬ¤&#34;:4533,&#34;ĠëĤĺìĺ´&#34;:4534,&#34;ì§Ħë¶Ģ&#34;:4535,&#34;ìĤ¬ìĿ´&#34;:4536,&#34;ĠëģĦ&#34;:4537,&#34;Ġíı¬ë&#34;:4538,&#34;ë§ĲìĿ´íķĦìļĶ&#34;:4539,&#34;êµ¬ë¡ľ&#34;:4540,&#34;Ġê²ģëĤĺ&#34;:4541,&#34;ë§Ļ&#34;:4542,&#34;Ġê°ľìĿ¸&#34;:4543,&#34;íİ¸ìĹĲ&#34;:4544,&#34;ë¦¬ëĦ¤&#34;:4545,&#34;ĠìĹ°ì¶ľëıĦ&#34;:4546,&#34;ë¸Ĳ&#34;:4547,&#34;ĠìĦ¤ëłĪ&#34;:4548,&#34;ĠëĤ®ìķĦìĦľ&#34;:4549,&#34;ĠìĹ´ìĭ¬íŀĪ&#34;:4550,&#34;ĠëĸłëĤĺìĦľ&#34;:4551,&#34;ĠOOOê¸°&#34;:4552,&#34;Ġê·¸ê±¸&#34;:4553,&#34;ìłĲì£¼&#34;:4554,&#34;Ġìĸ´ëł¸&#34;:4555,&#34;Ġìŀ¬ë°ĮìĹĪëĬĶëį°&#34;:4556,&#34;Ġìŀ¬ë°ĮìĹĪìĿĮ&#34;:4557,&#34;ĠìķĬìķĦ&#34;:4558,&#34;ĠëĤ¨ìĿĦ&#34;:4559,&#34;ĠìĿ´ëŁ°ê±¸&#34;:4560,&#34;Ġìķ¡ìħĺìĿ´&#34;:4561,&#34;ìł¸ìļĶ&#34;:4562,&#34;Ġê¸°ëĮĢë¥¼&#34;:4563,&#34;íķĻëħĦ&#34;:4564,&#34;ĠëĳĲê³ł&#34;:4565,&#34;ĠíĺĦìĭ¤ìĿĦ&#34;:4566,&#34;ê¿Ī&#34;:4567,&#34;Ġëľ»&#34;:4568,&#34;ìķĦê¹ĮìĽĮ&#34;:4569,&#34;Ġëĳĺëĭ¤&#34;:4570,&#34;Ġìľłì¾Įíķľ&#34;:4571,&#34;ìĸ´ëĸ¤&#34;:4572,&#34;¥´ëħ¸&#34;:4573,&#34;Ġêµ³ìĿ´&#34;:4574,&#34;Ġìħ&#34;:4575,&#34;ìĿ´ë¯¸&#34;:4576,&#34;ì§Ģë§ĪëĿ¼&#34;:4577,&#34;íķĺìħ¨&#34;:4578,&#34;ĠìĿ´ê²ĥëıĦ&#34;:4579,&#34;ĠìĿ´ìģľ&#34;:4580,&#34;ìĿ¸ëĵ¤&#34;:4581,&#34;ìĭľëĤĺ&#34;:4582,&#34;ëŀµ&#34;:4583,&#34;Ġì°¡&#34;:4584,&#34;ìħī&#34;:4585,&#34;Ġëª»íĸĪëĭ¤&#34;:4586,&#34;ĠìŀĲë§ī&#34;:4587,&#34;ë´¤ëįĺ&#34;:4588,&#34;íĿĶ&#34;:4589,&#34;Ġê²°ë¡ł&#34;:4590,&#34;ĠëĬĲëĤĢ&#34;:4591,&#34;Ġë°ľìłĦ&#34;:4592,&#34;ĠëĬĲëĤĮìĿĦ&#34;:4593,&#34;ì»¨&#34;:4594,&#34;Ġãħĭãħĭãħĭãħĭãħĭ&#34;:4595,&#34;Ġìį©&#34;:4596,&#34;CG&#34;:4597,&#34;íĵ¨&#34;:4598,&#34;íķľëĭ¤ê³ł&#34;:4599,&#34;ĠìĿ´ë»Ĳ&#34;:4600,&#34;ëł·&#34;:4601,&#34;...?&#34;:4602,&#34;ĠìķĦìĺ¤&#34;:4603,&#34;ĠëĤĺê°Ģ&#34;:4604,&#34;ìļ°ê³ł&#34;:4605,&#34;Ġìµľê·¼&#34;:4606,&#34;Ġë¬´ì§Ģ&#34;:4607,&#34;ë¬´ë¹Ħ&#34;:4608,&#34;Ġê°ĲëıĻìłģìĿ´ê³ł&#34;:4609,&#34;Ġê±°ì§ĵ&#34;:4610,&#34;ê²¨ìļ´&#34;:4611,&#34;ĠìĿ´íķ´íķł&#34;:4612,&#34;ìŀ¡íķľ&#34;:4613,&#34;ë¶Īìĸ´&#34;:4614,&#34;ëįĶëĿ¼ëıĦ&#34;:4615,&#34;Ġê²°ë§ĲëıĦ&#34;:4616,&#34;ĠìĺģíĻĶìĹĲìļĶ&#34;:4617,&#34;ëŀįëĭĪëĭ¤&#34;:4618,&#34;ĠìĬ¤ì¼ĢìĿ¼&#34;:4619,&#34;ê°Ģì§Ģê³ł&#34;:4620,&#34;ëĤ«&#34;:4621,&#34;ëĤ¼&#34;:4622,&#34;ìķĦìī½&#34;:4623,&#34;Ġìĭ¬ë¦¬&#34;:4624,&#34;Ġê·¸ëŀ¬&#34;:4625,&#34;ìŀĳìĿ´&#34;:4626,&#34;ì°®&#34;:4627,&#34;íĸĪëĬĶì§Ģ&#34;:4628,&#34;ìĭłìĿĢ&#34;:4629,&#34;ê²łìĿĮ&#34;:4630,&#34;Ġë§ĪìĦ¸ìļĶ&#34;:4631,&#34;ĠëĲĺì§Ģ&#34;:4632,&#34;Ġê°Ĳëªħ&#34;:4633,&#34;íĮĲìĹĲ&#34;:4634,&#34;ĠëıĻìĥĿ&#34;:4635,&#34;Ġë³Ħë¡ľëĭ¤&#34;:4636,&#34;ìĤ¬ëŀĮëĵ¤ìĿ´&#34;:4637,&#34;ì§Ģë£¨íķĺëĭ¤&#34;:4638,&#34;ĠíĴĭ&#34;:4639,&#34;Ġê¹ĬìĿ´&#34;:4640,&#34;ì¤Įë§Ī&#34;:4641,&#34;is&#34;:4642,&#34;íķĺëĿ¼&#34;:4643,&#34;íķĺëł¤ê³ł&#34;:4644,&#34;ĠìĹĳ&#34;:4645,&#34;ĠìĿ´ìĺģíĻĶê°Ģ&#34;:4646,&#34;ë§Įëĵľ&#34;:4647,&#34;ìĹĪëĬĶì§Ģ&#34;:4648,&#34;ê²łëĦ¤ìļĶ&#34;:4649,&#34;Ġë¹Ħì£¼ìĸ¼&#34;:4650,&#34;ëĭ¨ìĪľ&#34;:4651,&#34;Ġë°°ìļ°ìĿĺ&#34;:4652,&#34;Ġì¢ĭìķĦíķł&#34;:4653,&#34;íıīìłĲìĹĲ&#34;:4654,&#34;¬ë¦¼&#34;:4655,&#34;Ġìĭłê²½&#34;:4656,&#34;ĠëķĮë¬¸&#34;:4657,&#34;Ġë³¼ë§Įíķ¨&#34;:4658,&#34;ìĵ°ëłĪê¸°ìĺģíĻĶ&#34;:4659,&#34;ì¢ĭìĿĢìĺģíĻĶ&#34;:4660,&#34;ĠìĬ¬íĶĦê³ł&#34;:4661,&#34;ë±&#34;:4662,&#34;Ġìĩ¼&#34;:4663,&#34;Ġëĭ¬ë¦¬&#34;:4664,&#34;Ġìĥ¤&#34;:4665,&#34;Ġê²ĮìĿ´&#34;:4666,&#34;ĠìŀĪìĸ´ìķ¼&#34;:4667,&#34;ê³¼ìĿĺ&#34;:4668,&#34;Ġíķľëį°&#34;:4669,&#34;Ġì¤Į&#34;:4670,&#34;íİ¸ëıĦ&#34;:4671,&#34;Ġë§İëĭ¤&#34;:4672,&#34;ĠìłĢìĺĪìĤ°&#34;:4673,&#34;ë´ĲìļĶ&#34;:4674,&#34;ì¢ĭìķĦíķĺëĬĶ&#34;:4675,&#34;Ġíıīë²Ķíķľ&#34;:4676,&#34;. &#34; &#34; &#34;&#34;:4677,&#34;¦ê²Į&#34;:4678,&#34;ìĿ´ìħĺ&#34;:4679,&#34;ìķ¤&#34;:4680,&#34;ì§ĢëĤĺ&#34;:4681,&#34;ĠìŀĪëĦ¤ìļĶ&#34;:4682,&#34;Ġíĳ¹&#34;:4683,&#34;ĠìĹĨëĬĶëį°&#34;:4684,&#34;ìķĺê³ł&#34;:4685,&#34;ì¤ĳë°ĺ&#34;:4686,&#34;ĠëįĶìĿ´ìĥģ&#34;:4687,&#34;íķĺëĭ¤ëĭĪ&#34;:4688,&#34;ĠìĽĢ&#34;:4689,&#34;ĠëĤ¨ì£¼&#34;:4690,&#34;ĠìĿ¼ìĥģ&#34;:4691,&#34;ĠëĲĺê²Į&#34;:4692,&#34;ì²ĺêµ¬ëĭĪ&#34;:4693,&#34;ĠíŀĲë§ģ&#34;:4694,&#34;007&#34;:4695,&#34;ëŃĲëĥĲ&#34;:4696,&#34;Ġê·¸ëłĩëĭ¤ê³ł&#34;:4697,&#34;Ġìķħëĭ¹&#34;:4698,&#34;Ġìī¬&#34;:4699,&#34;ë§ĪìĿĮìĿ´&#34;:4700,&#34;Ġ&lt;&#34;:4701,&#34;Ġíĩ´&#34;:4702,&#34;ĠìĹĨëĭ¤ëĬĶ&#34;:4703,&#34;ĠëĤĺì¤ĳìĹĲ&#34;:4704,&#34;íĸĪëĦ¤&#34;:4705,&#34;ĠìĹ°ê²°&#34;:4706,&#34;Ġë³¼ìĪĺë¡Ŀ&#34;:4707,&#34;Ġë³¼ëķĮë§Īëĭ¤&#34;:4708,&#34;ê³ĦìĿĺ&#34;:4709,&#34;Ġìŀ¬ë¯¸ìŀĪìĿĮ&#34;:4710,&#34;Ġìĭ¶ëĦ¤ìļĶ&#34;:4711,&#34;íĽĮë¥Ń&#34;:4712,&#34;ë©ĭì§Ħ&#34;:4713,&#34;ìķĦê¹ĮìĽĢ&#34;:4714,&#34;ëĤĺìĻĢìĦľ&#34;:4715,&#34;Bê¸ī&#34;:4716,&#34;at&#34;:4717,&#34;ŀĳ&#34;:4718,&#34;Ġëº&#34;:4719,&#34;ëĬĶìĺģíĻĶ&#34;:4720,&#34;¬ë°&#34;:4721,&#34;Ġì§ķ&#34;:4722,&#34;ìľ¼ë¡ľìį¨&#34;:4723,&#34;íķ¨ìĹĲ&#34;:4724,&#34;ìĤ¬ìĿĺ&#34;:4725,&#34;ĠìłĦíĺķìłģìĿ¸&#34;:4726,&#34;Ġë§Ĳíķł&#34;:4727,&#34;ĠëĿ¼ìĿ´&#34;:4728,&#34;Ġëª©ìĨĮ&#34;:4729,&#34;ê½¤&#34;:4730,&#34;Īëł&#34;:4731,&#34;ë¡ľëıĦ&#34;:4732,&#34;ìļ°ìĻĢ&#34;:4733,&#34;Ġìĭľê°ģ&#34;:4734,&#34;Ġì°Ŀ&#34;:4735,&#34;ĠìĥĿê°ģíķĺê³ł&#34;:4736,&#34;ë¬´ì§Ģ&#34;:4737,&#34;ìŀ¬ë¯¸ê°Ģ&#34;:4738,&#34;ĠìĤ¬ëŀĮìĿĺ&#34;:4739,&#34;ëª¨ëĳĲ&#34;:4740,&#34;ĠíķĺëĬĶì§Ģ&#34;:4741,&#34;ìĺ¨ëĭ¤&#34;:4742,&#34;íĭ°ë¸Į&#34;:4743,&#34;ĠìĬ¬íĶĶ&#34;:4744,&#34;ĠìĤ°ìľ¼ë¡ľ&#34;:4745,&#34;Ġë°ĶëĢĮ&#34;:4746,&#34;Ġíİĳíİĳ&#34;:4747,&#34;ì§Ħìłķíķľ&#34;:4748,&#34;ìłĦì²´&#34;:4749,&#34;ìĦ±ìļ°&#34;:4750,&#34;ĠëĤ¨ëħĢ&#34;:4751,&#34;íĿ¡&#34;:4752,&#34;ê´ĢëŀĮ&#34;:4753,&#34;ĠìĥĿìĥĿ&#34;:4754,&#34;Ġë°ĺìłĦëıĦ&#34;:4755,&#34;ìķĦìĿ´ëĵ¤ìĿ´&#34;:4756,&#34;¬ëįĺ&#34;:4757,&#34;BS&#34;:4758,&#34;ĠëĩĮ&#34;:4759,&#34;ê²ĮìŀĦ&#34;:4760,&#34;Ġë³´ìķĺëĭ¤&#34;:4761,&#34;ë°¤&#34;:4762,&#34;Ġì¢ĭìĬµëĭĪëĭ¤&#34;:4763,&#34;Ġëª»íķł&#34;:4764,&#34;íļį&#34;:4765,&#34;ëŀĢëĭ¤&#34;:4766,&#34;Ġìķ¡ìħĺìĿĢ&#34;:4767,&#34;Ġë§Įëĵłëĭ¤&#34;:4768,&#34;Ġì§±ì§±&#34;:4769,&#34;Ġìŀ¬ëĤľ&#34;:4770,&#34;ĠìĿĮìķħëıĦ&#34;:4771,&#34;Ġì©Į&#34;:4772,&#34;Ġê´ĳê³ł&#34;:4773,&#34;ĠT&#34;:4774,&#34;ì§Ģë§Ĳ&#34;:4775,&#34;íķĺêµ¬&#34;:4776,&#34;ëį©&#34;:4777,&#34;ëĤĺë§Į&#34;:4778,&#34;ê±°ë©´&#34;:4779,&#34;ëĮĢë¥¼&#34;:4780,&#34;ĠìŀĪìľ¼ë©´&#34;:4781,&#34;ê·¸ë¦¬&#34;:4782,&#34;ìĦ±ìĿĺ&#34;:4783,&#34;ĠëĮĢíĳľ&#34;:4784,&#34;ĠìķĬì§Ģë§Į&#34;:4785,&#34;ĠíĿ¡&#34;:4786,&#34;ìĪŃ&#34;:4787,&#34;ĠëĨį&#34;:4788,&#34;ëŁ½ê³ł&#34;:4789,&#34;Ġê°ķëł¬&#34;:4790,&#34;ì§ĳëĭĪëĭ¤&#34;:4791,&#34;ìĶ¬ìĿĢ&#34;:4792,&#34;Ġì¡´ê²½&#34;:4793,&#34;ĠëĪĪë¬¼ìĿĦ&#34;:4794,&#34;ĠìĿ´ìłľìķ¼&#34;:4795,&#34;Ġë¹¼ê³ł&#34;:4796,&#34;âĻ¡âĻ¡&#34;:4797,&#34;ìĬ¤íĥĢìĿ¼&#34;:4798,&#34;ìħĶìĦľ&#34;:4799,&#34;ë´£ëĬĶëį°&#34;:4800,&#34;Ġë´£ëĬĶëį°&#34;:4801,&#34;ĠA&#34;:4802,&#34;Ġìª½&#34;:4803,&#34;ĠìĺģíĻĶëĿ¼ëĬĶ&#34;:4804,&#34;ë¡ľìĦľ&#34;:4805,&#34;ĠìķĦì¹¨&#34;:4806,&#34;íģ¬ë¦¬ìĬ¤&#34;:4807,&#34;Ġì²´&#34;:4808,&#34;ĠìĤ´ê³ł&#34;:4809,&#34;ĠìĺĪìłĦ&#34;:4810,&#34;Ġìĭ¬ê°ģ&#34;:4811,&#34;ĠìĬ¬íİ&#34;:4812,&#34;ĠëĨĴëĭ¤&#34;:4813,&#34;ĠìĥĿìķł&#34;:4814,&#34;ìĸ¼êµ´&#34;:4815,&#34;Ġì»¨&#34;:4816,&#34;ì§Ģê¸Īê¹Įì§Ģ&#34;:4817,&#34;Ġì¢ħêµĲ&#34;:4818,&#34;ĠìĿ´ìģĺê³ł&#34;:4819,&#34;ĠìĮ&#34;:4820,&#34;ìĿ´ê¸°&#34;:4821,&#34;ìĿ¸íĬ¸&#34;:4822,&#34;ì£¼ìłľ&#34;:4823,&#34;íŀĲ&#34;:4824,&#34;ë¬´ìĹĩ&#34;:4825,&#34;ëıĻìĥĿ&#34;:4826,&#34;Ġì¢ĢëįĶ&#34;:4827,&#34;Ġìķ¡ìħĺìĺģíĻĶ&#34;:4828,&#34;ĠëıĻë¬¼&#34;:4829,&#34;ar&#34;:4830,&#34;ëĭ¬ëĿ¼&#34;:4831,&#34;íķµ&#34;:4832,&#34;ê°ĸ&#34;:4833,&#34;ìķķ&#34;:4834,&#34;ì§Ģìĸ´&#34;:4835,&#34;ĠìķĦëł¨&#34;:4836,&#34;ìľ¼ëĭĪê¹Į&#34;:4837,&#34;ê±°ìŀĦ&#34;:4838,&#34;ë²¨&#34;:4839,&#34;ĠìĬ¤íı¬&#34;:4840,&#34;ë¯¸ê°Ģ&#34;:4841,&#34;ĠìĹ°ê¸°ìŀĲ&#34;:4842,&#34;Ġìŀ¬ë°ĮìĬµëĭĪëĭ¤&#34;:4843,&#34;Ġë¬´íĺĳ&#34;:4844,&#34;ë¶ĦìľĦ&#34;:4845,&#34;íģ¬ë¦°&#34;:4846,&#34;ĠìĿ¼ë¶Ģ&#34;:4847,&#34;ìµľê·¼&#34;:4848,&#34;ìĹŃëĮĢ&#34;:4849,&#34;ìĿ´ëŁ°ìĺģíĻĶ&#34;:4850,&#34;Ġê·¹ì¹ĺ&#34;:4851,&#34;íĺ¸ê°Ģ&#34;:4852,&#34;Ġëĭ¨ìĹ°&#34;:4853,&#34;ìĦĿìĿ´&#34;:4854,&#34;Ġëªĩë²Ī&#34;:4855,&#34;Ġê½Ŀ&#34;:4856,&#34;Ġì§Ħìĭ¬ìľ¼ë¡ľ&#34;:4857,&#34;ĠìłĲìĪĺë¥¼&#34;:4858,&#34;ĠëĽ°ìĸ´ëĤľ&#34;:4859,&#34;Ġíĥľìĸ´&#34;:4860,&#34;ê½ĥ&#34;:4861,&#34;Ġìĵ¸ëį°&#34;:4862,&#34;Ġë½ĳ&#34;:4863,&#34;Ġë§Īë¬´ë¦¬&#34;:4864,&#34;ìĿ´ìłķëıĦ&#34;:4865,&#34;ĠìĺģíĻĶìĿ¸ëĵ¯&#34;:4866,&#34;Ġëĭ®&#34;:4867,&#34;ĠìĹ°ìĨį&#34;:4868,&#34;Ġì§Ģê¸Īë´ĲëıĦ&#34;:4869,&#34;ê·¸ëłĩê²Į&#34;:4870,&#34;Ġìĭľë¦¬&#34;:4871,&#34;ìķĺì§Ģë§Į&#34;:4872,&#34;Ġê°Ģìł¸&#34;:4873,&#34;ĠìľĮ&#34;:4874,&#34;Ġë¬´ë¹Ħ&#34;:4875,&#34;ĠëĤ¨ê²¨&#34;:4876,&#34;íĬ¸ë§¨&#34;:4877,&#34;Ġì§Ģë£¨íķ´ìĦľ&#34;:4878,&#34;ëĤłëķĮ&#34;:4879,&#34;ì©¡&#34;:4880,&#34;ĠíĳľìłĪ&#34;:4881,&#34;ê¼´&#34;:4882,&#34;ìĸĳìĿ´&#34;:4883,&#34;ĠìĿ¸ìĥĿìĿĦ&#34;:4884,&#34;ĠìķĦìī¬ìĽĢ&#34;:4885,&#34;Ġìĭ¸êµ¬ëł¤&#34;:4886,&#34;ì¡¸ìŀĳ&#34;:4887,&#34;ê³µíı¬ìĺģíĻĶ&#34;:4888,&#34;ìıĺ&#34;:4889,&#34;ver&#34;:4890,&#34;ìĿ´ìĺģíĻĶë¥¼&#34;:4891,&#34;ëĵ£&#34;:4892,&#34;ìĹĲëĮĢíķľ&#34;:4893,&#34;ëĤĺëĦ¤&#34;:4894,&#34;Ġë³´ëĭĪê¹Į&#34;:4895,&#34;ë§ĲìĿĦ&#34;:4896,&#34;ìĻĵ&#34;:4897,&#34;Ġê²ī&#34;:4898,&#34;íĮ©&#34;:4899,&#34;ìĨĮëħĢ&#34;:4900,&#34;Ġê°ĻìķĦìĦľ&#34;:4901,&#34;Ġë§ĲíķĺëĬĶ&#34;:4902,&#34;Ġë³¸ëĭ¤ë©´&#34;:4903,&#34;ĠìĨĮìŀ¥&#34;:4904,&#34;Ġë¯¸ì¹ĺ&#34;:4905,&#34;ë¦¬ë©°&#34;:4906,&#34;Ġê³łìłĦ&#34;:4907,&#34;Ġê³łíĨµ&#34;:4908,&#34;Ġê±°ê¸°&#34;:4909,&#34;ĠìŀĳíĴĪìĿ´ëĭ¤&#34;:4910,&#34;ìĶ¨ìĿĺ&#34;:4911,&#34;ĠìĨįìĹĲ&#34;:4912,&#34;ĠìĿĮìķħìĿ´&#34;:4913,&#34;Ġëĸłìĺ¤&#34;:4914,&#34;ĠìĤ¶ìĿĺ&#34;:4915,&#34;ĠìĶģìĵ¸&#34;:4916,&#34;~~~~~~~~&#34;:4917,&#34;ĠìĿĺë¯¸ë¥¼&#34;:4918,&#34;it&#34;:4919,&#34;Ġ^&#34;:4920,&#34;Ġgood&#34;:4921,&#34;ê°Ĵ&#34;:4922,&#34;ë§ĮìĿĦ&#34;:4923,&#34;ëĦ·&#34;:4924,&#34;ĠìĦŀ&#34;:4925,&#34;ìŀ¬ë¯¸ëĬĶ&#34;:4926,&#34;ĠìĤ¬ëŀĳê³¼&#34;:4927,&#34;ĠìķĦê¹Ŀì§Ģ&#34;:4928,&#34;Ġë©ĭì§Ģëĭ¤&#34;:4929,&#34;ê°ĢëĬĶì¤Ħ&#34;:4930,&#34;Ġì§Ģê¸ĪìĿĢ&#34;:4931,&#34;ëĲ¬&#34;:4932,&#34;ĠìķĦìĿ´ëĵ¤ìĿ´&#34;:4933,&#34;ìĬ¤ëŁ¬ìĽĢ&#34;:4934,&#34;ĠíĳľíĺĦíķľ&#34;:4935,&#34;ĠìĺģíĻĶìĺĢìĸ´ìļĶ&#34;:4936,&#34;ìĻĦë²½&#34;:4937,&#34;Ġëĵ±ìŀ¥ìĿ¸ë¬¼&#34;:4938,&#34;ing&#34;:4939,&#34;Ġì¥Ĳ&#34;:4940,&#34;ĠìĬĪíį¼&#34;:4941,&#34;ll&#34;:4942,&#34;ħ¸&#34;:4943,&#34;ê°Ģë¥¼&#34;:4944,&#34;ĠëĤ´ëł¤&#34;:4945,&#34;ê²łìĸ´ìļĶ&#34;:4946,&#34;ĠìķĪëı¼&#34;:4947,&#34;Ġë³¸ìĺģíĻĶ&#34;:4948,&#34;Ġë¹¡&#34;:4949,&#34;ĠëģĿëĤľ&#34;:4950,&#34;Ġìŀ¬ë¯¸ìŀĪìĹĪëĭ¤&#34;:4951,&#34;Ġë°ĺë³µ&#34;:4952,&#34;ĠìŀĳíĴĪìĿĦ&#34;:4953,&#34;ê´ĢìĿ´&#34;:4954,&#34;Ġìŀ¥ë©´ìĹĲìĦľ&#34;:4955,&#34;ê°ĲëıħìĿĢ&#34;:4956,&#34;ë³Ħë£¨&#34;:4957,&#34;ĠìĹĲíĶ¼ìĨĮ&#34;:4958,&#34;ìĥĿê°ģìĹĨìĿ´&#34;:4959,&#34;ĠìķĦìĿ´ëĵ¤&#34;:4960,&#34;Ġëª¨ëĵłê²Į&#34;:4961,&#34;Ġì¹ľêµ¬ëĵ¤&#34;:4962,&#34;Ġìķķê¶Į&#34;:4963,&#34;ì¥Ĳ&#34;:4964,&#34;Ġìĸ´ëł¤ìļ´&#34;:4965,&#34;ie&#34;:4966,&#34;¨¸&#34;:4967,&#34;ĠìĮį&#34;:4968,&#34;ĠìĺģíĻĶëĵ¤&#34;:4969,&#34;ê±°ê°Ļëĭ¤&#34;:4970,&#34;ìĨĶ&#34;:4971,&#34;Ġì§Ģì¼ľ&#34;:4972,&#34;ĠëįĶë¶Īìĸ´&#34;:4973,&#34;Ġë³¼ê²Į&#34;:4974,&#34;ìĺģìĿ´&#34;:4975,&#34;íĿ¬ë&#34;:4976,&#34;Ġê±°ìĬ&#34;:4977,&#34;Ġëĭ¤ìĭľíķľë²Ī&#34;:4978,&#34;ìĭľê°ĦìĹĲ&#34;:4979,&#34;Ġìļ¸ê³ł&#34;:4980,&#34;Ġìļ¸ìĹĪëĭ¤&#34;:4981,&#34;ĠìĻ¸ëª¨&#34;:4982,&#34;Ġë¨¹ê³ł&#34;:4983,&#34;Ġê²½íĹĺ&#34;:4984,&#34;ĠêµŃë¯¼&#34;:4985,&#34;Ġìĸ¸ìłľëĤĺ&#34;:4986,&#34;¬ëįĶ&#34;:4987,&#34;ĠëĬ¥ëł¥&#34;:4988,&#34;ĠëıħíĬ¹íķľ&#34;:4989,&#34;Ġê²Ģìĥī&#34;:4990,&#34;44&#34;:4991,&#34;bs&#34;:4992,&#34;ë¤&#34;:4993,&#34;ìĿ´ìĺģíĻĶëĬĶ&#34;:4994,&#34;ëĭ¤ëĵ¤&#34;:4995,&#34;íķĺì§Ħ&#34;:4996,&#34;ĠìŀĪëįĺ&#34;:4997,&#34;ëĤĺëĭ¤&#34;:4998,&#34;ìķĦë¹ł&#34;:4999,&#34;ìĥģíĻ©&#34;:5000,&#34;ĠëĮĢë¶Ģë¶Ħ&#34;:5001,&#34;ĠìłĦíĪ¬&#34;:5002,&#34;ê°ľê·¸&#34;:5003,&#34;ê°ĲëıĦ&#34;:5004,&#34;ĠìĿ´ëŁ°ê²Į&#34;:5005,&#34;ĠíĿī&#34;:5006,&#34;ìĽĲëŀĺ&#34;:5007,&#34;ëĲĺìĦľ&#34;:5008,&#34;Ġì¡°íķ©&#34;:5009,&#34;ìĹ°ê¸°ëĬĶ&#34;:5010,&#34;Ġë°ľê²¬&#34;:5011,&#34;Ġãħłãħłãħł&#34;:5012,&#34;Ġë§Ŀì³Ĳ&#34;:5013,&#34;ĠìĬ¤ë¦´ëŁ¬ë&#34;:5014,&#34;íĺ¼ìŀĲ&#34;:5015,&#34;Ġëª¨ë¥´ê²łê³ł&#34;:5016,&#34;ĠíıŃëł¥&#34;:5017,&#34;ĠëģĮìĸ´&#34;:5018,&#34;Ġë°Ķê¿Ķ&#34;:5019,&#34;Ġì°Ŀì°Ŀ&#34;:5020,&#34;ĠìĿµ&#34;:5021,&#34;ìļ°ê¸°&#34;:5022,&#34;Ġìŀ¬ë¯¸ìŀĪëĦ¤ìļĶ&#34;:5023,&#34;Ġíķľì°¸&#34;:5024,&#34;ĠìĬ¤ìĬ¤ë¡ľ&#34;:5025,&#34;ë¯¸ìķĪ&#34;:5026,&#34;ìĨĮë¦Ħ&#34;:5027,&#34;ìĺĢì§Ģë§Į&#34;:5028,&#34;Ġê°ĲëıĻê³¼&#34;:5029,&#34;Ġë¯¸ëª¨&#34;:5030,&#34;Ġì§Ģë£¨íķł&#34;:5031,&#34;ê¸´ëĭ¤&#34;:5032,&#34;ĠìĿĺìĭ¬&#34;:5033,&#34;ĠìĬ¬íį¼&#34;:5034,&#34;ĠëĨĴìķĦ&#34;:5035,&#34;Ġê²Įëĭ¤ê°Ģ&#34;:5036,&#34;ĠìķĦìī½ëĦ¤ìļĶ&#34;:5037,&#34;ĠëĬĲëģ¼ëĬĶ&#34;:5038,&#34;âĻ¥âĻ¥âĻ¥âĻ¥&#34;:5039,&#34;Ġë¹łìł¸ëĵ¤&#34;:5040,&#34;ĠìĦ¬ìĦ¸&#34;:5041,&#34;ìĸ´ë¥¸&#34;:5042,&#34;ìłĦìŀĳ&#34;:5043,&#34;ìĤ¬ê±´&#34;:5044,&#34;ĠìĻľì¼Ģ&#34;:5045,&#34;ë²Ħë¦¬ê³ł&#34;:5046,&#34;ĠìĿ¼ë°ĺ&#34;:5047,&#34;ìĺģíĻĺ&#34;:5048,&#34;ĠíĹĲ&#34;:5049,&#34;íĿĺ&#34;:5050,&#34;Ġì²ĺëŁ¼&#34;:5051,&#34;ĠíĺĦëĮĢ&#34;:5052,&#34;ë°©ìĤ¬&#34;:5053,&#34;Ġë°ķìĪĺë¥¼&#34;:5054,&#34;ĠìĻ¸ê³Ħ&#34;:5055,&#34;ĠìĽĥê¸°ê³ł&#34;:5056,&#34;Ġë¹¼ê³łëĬĶ&#34;:5057,&#34;ĠëĶ°ëľ»íķ´ì§ĢëĬĶ&#34;:5058,&#34;Ġëĭ¤íģĲë©ĺíĦ°&#34;:5059,&#34;ìŀ¬ë¯¸ìĹĨìĸ´&#34;:5060,&#34;ì³¤ëĭ¤&#34;:5061,&#34;ĠìĿ´íĽĦë¡ľ&#34;:5062,&#34;ĠíĴĭíĴĭ&#34;:5063,&#34;ë®¤&#34;:5064,&#34;íĻĶëł¤&#34;:5065,&#34;íķĺê²łëĭ¤&#34;:5066,&#34;ĠìķĦë¥ĺ&#34;:5067,&#34;ê±°ëĿ¼&#34;:5068,&#34;ìĹĪìĿĦê¹Į&#34;:5069,&#34;Ġëĭ¤ë£¬&#34;:5070,&#34;Ġê²¬&#34;:5071,&#34;ëĵľìĿĺ&#34;:5072,&#34;ìĦ±ì¹ĺ&#34;:5073,&#34;ê²ĥë§Į&#34;:5074,&#34;ĠìĿ¸íĦ°&#34;:5075,&#34;ìľłì¾Į&#34;:5076,&#34;Ġíķłê¹Į&#34;:5077,&#34;ĠëıĻìķĪ&#34;:5078,&#34;ĠëĤľíķ´&#34;:5079,&#34;ë§¤ìļ°&#34;:5080,&#34;íķĺëĤĺëıĦ&#34;:5081,&#34;ĠëĲ¨&#34;:5082,&#34;ĠìĿ¸ìĥĿìĿĺ&#34;:5083,&#34;Ġ40&#34;:5084,&#34;ìłĦê°ľê°Ģ&#34;:5085,&#34;Ġë¯¼ë§Ŀ&#34;:5086,&#34;Ġëĺĳê°Ļ&#34;:5087,&#34;ìĸ´ìĦ¤íĶĪ&#34;:5088,&#34;ĠëŃīíģ´&#34;:5089,&#34;íĮĢ&#34;:5090,&#34;ë¡Ģ&#34;:5091,&#34;Ġìĭ±&#34;:5092,&#34;ìłķìĿĢ&#34;:5093,&#34;íĸĪëĦ¤ìļĶ&#34;:5094,&#34;ëĤ´ìĥĿ&#34;:5095,&#34;ê·¸ë§Į&#34;:5096,&#34;ëĥĪ&#34;:5097,&#34;ãħĭãħĭãħĭãħĭãħĭãħĭ&#34;:5098,&#34;Ġë§Ĳë¡ľ&#34;:5099,&#34;Ġëª»íķ´&#34;:5100,&#34;Ġìłľë¡ľ&#34;:5101,&#34;ĠëģĶ&#34;:5102,&#34;ë²ĦíĬ¸&#34;:5103,&#34;ë¬¸ìłľ&#34;:5104,&#34;ìŀ¬ë°Įìĸ´&#34;:5105,&#34;ĠìĤ¬ëŀĳìĿ´ìķ¼ê¸°&#34;:5106,&#34;íĶĦëŀĳìĬ¤&#34;:5107,&#34;Ġì¢ĭìķĺìĿĦ&#34;:5108,&#34;ìĪľìĪĺ&#34;:5109,&#34;ĠëĪĪìĹĲ&#34;:5110,&#34;ì³ĲìĦľ&#34;:5111,&#34;ĠíĭĢìĸ´&#34;:5112,&#34;ĠìķĦì§ģê¹Įì§Ģ&#34;:5113,&#34;Ġì¤ĳê°Ħì¤ĳê°Ħ&#34;:5114,&#34;ĠìĦ¸ìĥģìĹĲ&#34;:5115,&#34;ìĭľíĤ¤ëĬĶ&#34;:5116,&#34;ì«&#34;:5117,&#34;ìĿ¸ëĵ¤ìĿ´&#34;:5118,&#34;êµ¬ëŀĳ&#34;:5119,&#34;Ġê·¸ëŁ¬ë&#34;:5120,&#34;Ġê·¸ëŁŃìłĢëŁŃ&#34;:5121,&#34;ì¹¸&#34;:5122,&#34;ì¹¼&#34;:5123,&#34;Ġì¢ĭì§Ģë§Į&#34;:5124,&#34;Ġìĺ¬ëł¤&#34;:5125,&#34;Ġì£¼ë³Ģ&#34;:5126,&#34;ë¹Į&#34;:5127,&#34;Ġê³µë¶Ģ&#34;:5128,&#34;ëĸł&#34;:5129,&#34;ë¨¸ë¦¬&#34;:5130,&#34;ëľ©&#34;:5131,&#34;ĠìĨįíİ¸&#34;:5132,&#34;Ġê°Īëĵ±&#34;:5133,&#34;Ġë¯¿ìĿĦ&#34;:5134,&#34;Ġë¶ģíķľ&#34;:5135,&#34;Ġë»&#34;:5136,&#34;íķŃ&#34;:5137,&#34;ê°ĵ&#34;:5138,&#34;ìĿ´ëŁ¬&#34;:5139,&#34;ìł¼&#34;:5140,&#34;ë¦¬ê¸°&#34;:5141,&#34;ìľĦë¡ľ&#34;:5142,&#34;Ġë³´ê¸¸&#34;:5143,&#34;Ġë°ĭ&#34;:5144,&#34;ìŀ¥ìĹĲìĦľ&#34;:5145,&#34;Ġë´¤ëįĶëĭĪ&#34;:5146,&#34;ê²ĥëĵ¤&#34;:5147,&#34;íĮį&#34;:5148,&#34;íİĻ&#34;:5149,&#34;ê°ľìĹ°&#34;:5150,&#34;ëįĶëŁ½ê²Į&#34;:5151,&#34;Ġë§İìķĦ&#34;:5152,&#34;Ġë°°ìļ°ëĵ¤ëıĦ&#34;:5153,&#34;Ġì¢ĭìķĦíķĺëĬĶëį°&#34;:5154,&#34;ìĭĿìĿĺ&#34;:5155,&#34;íĤ¤ëĬĶ&#34;:5156,&#34;íħĮìĿ¼&#34;:5157,&#34;Ġê²°ë§ĲìĿĢ&#34;:5158,&#34;ĠëĴ¤ë¡ľ&#34;:5159,&#34;ì¯§&#34;:5160,&#34;ãħłãħłãħłãħłãħłãħłãħłãħł&#34;:5161,&#34;Ġì¦Ĳê²ģê²Į&#34;:5162,&#34;ãĢ&#34;:5163,&#34;ĠìķĪë¬´&#34;:5164,&#34;ëĤĺëĦ¤ìļĶ&#34;:5165,&#34;ĠëĤ³&#34;:5166,&#34;ìŀĲëĤĺ&#34;:5167,&#34;ĠìĭľíĬ¸ì½¤&#34;:5168,&#34;Ġìłķë§Ĳë¡ľ&#34;:5169,&#34;ìĭłìĿĦ&#34;:5170,&#34;ĠìķĬëĤĺ&#34;:5171,&#34;Ġë¹ĦíĺĦìĭ¤&#34;:5172,&#34;ìŀ¬ë°Įê³ł&#34;:5173,&#34;ĠëĤĺìĺ¤ë©´&#34;:5174,&#34;Ġëĵ¤ìĹĪëĭ¤&#34;:5175,&#34;ê°ĲëıĻìłģìĿ´&#34;:5176,&#34;ĠíĺĦìĭ¤ìłģìĿ¸&#34;:5177,&#34;ì§Ģë£¨íķľ&#34;:5178,&#34;ĠìķĪë³´ê³ł&#34;:5179,&#34;!!!!!!!!!!!!!!!!&#34;:5180,&#34;Ńī&#34;:5181,&#34;ê°±&#34;:5182,&#34;ìĦ¹&#34;:5183,&#34;ìĸ´ìłľ&#34;:5184,&#34;ëĭĪê¹Ĳ&#34;:5185,&#34;Ġëª½&#34;:5186,&#34;ìłĦíĺķìłģìĿ¸&#34;:5187,&#34;ìĻĢìļ°&#34;:5188,&#34;ĠìĥĿê°ģíķĺëĬĶ&#34;:5189,&#34;ê¸´íķľëį°&#34;:5190,&#34;Ġëª°ìŀħíķ´ìĦľ&#34;:5191,&#34;Ġë°©ë²ķ&#34;:5192,&#34;Ġë»Ķíķĺê³ł&#34;:5193,&#34;Ġë¬¸íĻĶ&#34;:5194,&#34;Ġìĥģìĥģëł¥&#34;:5195,&#34;ĠëĬĺìĸ´&#34;:5196,&#34;13&#34;:5197,&#34;ov&#34;:5198,&#34;Ġf&#34;:5199,&#34;ĠìĹĺ&#34;:5200,&#34;êµ¬ëĿ¼&#34;:5201,&#34;Ġì¢Į&#34;:5202,&#34;ĠìĹĨìĹĪëįĺ&#34;:5203,&#34;ì¹Ļ&#34;:5204,&#34;ìłĦëĵľ&#34;:5205,&#34;ê·¸ëĮĢë¡ľ&#34;:5206,&#34;Ġì¢ĭìķĺì§Ģë§Į&#34;:5207,&#34;ĠìĺĪìłĦìĹĲ&#34;:5208,&#34;ĠìĺĪê³łíİ¸&#34;:5209,&#34;Ġìļ°ë¦¬ê°Ģ&#34;:5210,&#34;Ġëª¨ë¥´ê²łì§Ģë§Į&#34;:5211,&#34;ìĤ¼ë¥ĺ&#34;:5212,&#34;Ġíŀĺëĵ¤ëĭ¤&#34;:5213,&#34;ê°Ķëĭ¤&#34;:5214,&#34;ĠìķĶíĬ¼&#34;:5215,&#34;Ġì±ĦëĦĲ&#34;:5216,&#34;Ġë°ĭë°ĭ&#34;:5217,&#34;Ġ!!!&#34;:5218,&#34;ĠìĹħ&#34;:5219,&#34;ìķĦìī¬&#34;:5220,&#34;ĠìķĦëĵ¤&#34;:5221,&#34;íķ´ì§Ģ&#34;:5222,&#34;Ġë³´ê¸´&#34;:5223,&#34;Ġë³´ìĿ¸ëĭ¤&#34;:5224,&#34;ìłĲìĪĺ&#34;:5225,&#34;ìłķìĿĺ&#34;:5226,&#34;ìłģìĿĢ&#34;:5227,&#34;Ġìĭľìĭľ&#34;:5228,&#34;íķ¨ìĿĢ&#34;:5229,&#34;ĠìłĦìŀĳ&#34;:5230,&#34;ĠìķĬìĿĦê¹Į&#34;:5231,&#34;Ġë¬´ì²Ļ&#34;:5232,&#34;ìĭ¤íķľ&#34;:5233,&#34;Ġë§İê³ł&#34;:5234,&#34;Īëį°&#34;:5235,&#34;Ġì§Ģë£¨íķĺê²Į&#34;:5236,&#34;ë³´ê³łìĭ¶ìĿĢ&#34;:5237,&#34;ãħİãħİãħİãħİ&#34;:5238,&#34;ë¬¼ìĿ´&#34;:5239,&#34;Ġì¢ĭìķĺìľ¼ëĤĺ&#34;:5240,&#34;Ġê¸°ëĮĢíĸĪëĬĶëį°&#34;:5241,&#34;ìĤ¬ëŀĮëĵ¤ìĿĢ&#34;:5242,&#34;ĠíĬ¹ìĪĺ&#34;:5243,&#34;Ġíİ¸ê²¬&#34;:5244,&#34;ĠíĥĢìŀĦ&#34;:5245,&#34;ĠìĽĥìĿĮìĿ´&#34;:5246,&#34;Ġê°ĲìłķìĿĦ&#34;:5247,&#34;VD&#34;:5248,&#34;ìĩ&#34;:5249,&#34;Ġìį¼&#34;:5250,&#34;ìŀŃ&#34;:5251,&#34;ìļĶìĿ¼&#34;:5252,&#34;Ġë³´ë©°&#34;:5253,&#34;ìļ©ìľ¼ë¡ľ&#34;:5254,&#34;íĸĪëĤĺ&#34;:5255,&#34;íĸĪìĸ´&#34;:5256,&#34;Ġëª¨ë¥¼&#34;:5257,&#34;ìħĢ&#34;:5258,&#34;ê²łìĬµëĭĪëĭ¤&#34;:5259,&#34;Ġëª»íķľëĭ¤&#34;:5260,&#34;Ġë©ĺ&#34;:5261,&#34;Ġìļ°ì£¼&#34;:5262,&#34;ìŀ¬ë°ĮëĦ¤ìļĶ&#34;:5263,&#34;ĠìĽĥê¹Ģ&#34;:5264,&#34;ìĹĩëĭ¤&#34;:5265,&#34;ĠíĨ°&#34;:5266,&#34;ë°ĽìĿĢ&#34;:5267,&#34;ëĺĳ&#34;:5268,&#34;ëıħíĬ¹&#34;:5269,&#34;ĠìŀĬìĿĦ&#34;:5270,&#34;ĠìĿ´ìľłë¥¼&#34;:5271,&#34;ì¸µ&#34;:5272,&#34;ĠëłĪìĿ´&#34;:5273,&#34;ĪëįĶëĭĪ&#34;:5274,&#34;Ġì¼ĢìĿ´ë¸Ķ&#34;:5275,&#34;Ġìĸ´ë¦°ìĿ´&#34;:5276,&#34;Ġë²Įìį¨&#34;:5277,&#34;ì¥¬&#34;:5278,&#34;Ġëįķë¶ĦìĹĲ&#34;:5279,&#34;ĠíĹĲë¦¬ìļ°ëĵľ&#34;:5280,&#34;Ġëī´&#34;:5281,&#34;ãħ£&#34;:5282,&#34;.........&#34;:5283,&#34;ĠìĭľëıĦ&#34;:5284,&#34;ë²Ħê·¸&#34;:5285,&#34;ë²Ħë¦¬ëĬĶ&#34;:5286,&#34;ë²ĦìĬ¤íĦ°&#34;:5287,&#34;ë³´ê³łìĭ¶ëĭ¤&#34;:5288,&#34;ĠìĭłíĮĮ&#34;:5289,&#34;Ġì£½ìĿĦ&#34;:5290,&#34;Ġê´Ģíķľ&#34;:5291,&#34;ë¶ĪìĮį&#34;:5292,&#34;Ġìłķìĭłë³ĳ&#34;:5293,&#34;ĠìŀĬíĺĢì§Ģì§Ģ&#34;:5294,&#34;Ġì±Ļê²¨&#34;:5295,&#34;ĠìĽĢì§ģ&#34;:5296,&#34;ĻëĭĪëĭ¤&#34;:5297,&#34;ìĿ¸ê³¼&#34;:5298,&#34;Ġëĭ¤ìĸĳ&#34;:5299,&#34;íķĺê³łìŀĲ&#34;:5300,&#34;ĠëĮĢíķ´ìĦľ&#34;:5301,&#34;ĠëĬĲìĻĢë¥´&#34;:5302,&#34;ì¢ĭìĿĮ&#34;:5303,&#34;Ġëĸ¡&#34;:5304,&#34;ëĬĲëĭĪ&#34;:5305,&#34;0000&#34;:5306,&#34;Ġë¡ľê·¸ìĿ¸&#34;:5307,&#34;ìŀ¬ë¯¸ìŀĪëĭ¤&#34;:5308,&#34;ëŁ¬ëĶĶ&#34;:5309,&#34;ìĸ´ë¦´ìłģ&#34;:5310,&#34;ëİĢ&#34;:5311,&#34;Ġë§¨ëĤł&#34;:5312,&#34;ìĸĺê¸°&#34;:5313,&#34;ë¯¿ê³ł&#34;:5314,&#34;ĠëŁ&#34;:5315,&#34;ìĿ´ë¡ľ&#34;:5316,&#34;ìĹĲë¡ľ&#34;:5317,&#34;ìĸ´ì©Į&#34;:5318,&#34;ìĹĨëĦ¤ìļĶ&#34;:5319,&#34;ìĥģìĺģ&#34;:5320,&#34;ìĺ¤ìĺ¤&#34;:5321,&#34;ĠìĦ¼&#34;:5322,&#34;Ġë´¤ìĿĦëķĮ&#34;:5323,&#34;Ġìŀ¬ë°Įëĭ¤ê³ł&#34;:5324,&#34;ë£¨ìĬ¤&#34;:5325,&#34;Ġë¬´ìĸ¸&#34;:5326,&#34;Ġì²Ļ&#34;:5327,&#34;ì²´ê°Ģ&#34;:5328,&#34;Ġë¹ĦíĮĲ&#34;:5329,&#34;ìķĪíĥĢ&#34;:5330,&#34;Ġì¢ĭìķĦíķ´ìĦľ&#34;:5331,&#34;ĠìŀĳíĴĪìĿĢ&#34;:5332,&#34;ĠëĦĺì¹ĺëĬĶ&#34;:5333,&#34;íĸīë³µ&#34;:5334,&#34;Ġë³´ìĹ¬ì£¼ê³ł&#34;:5335,&#34;ìĸ¸ëĭĪ&#34;:5336,&#34;Ġë³¼ë§Įíķĺëĭ¤&#34;:5337,&#34;ĠëĮĢìĤ¬ê°Ģ&#34;:5338,&#34;ë¦¬ìĬ¤ë§Ī&#34;:5339,&#34;Ġì¢ĭê²łìĸ´ìļĶ&#34;:5340,&#34;Ġì§ģìłĳ&#34;:5341,&#34;ĠìĥĪë¡Ń&#34;:5342,&#34;om&#34;:5343,&#34;ªħ&#34;:5344,&#34;ìĿ´íģ¬&#34;:5345,&#34;¬ëŁ¬&#34;:5346,&#34;ë¦¬íı¬&#34;:5347,&#34;ìĺ¬ë¦¬&#34;:5348,&#34;ìķ¼ë§Ĳë¡ľ&#34;:5349,&#34;Ġì¢ĭê²Į&#34;:5350,&#34;ìŀĪëĤĺ&#34;:5351,&#34;¬ëŀĺ&#34;:5352,&#34;ëħ¼&#34;:5353,&#34;ë£©&#34;:5354,&#34;ìĻĢìĿĺ&#34;:5355,&#34;ëł¤ìļĶ&#34;:5356,&#34;ìĺĢê³ł&#34;:5357,&#34;ĠìĿ¼íĴĪ&#34;:5358,&#34;ĠìĤ¬ëŀĳìĿĺ&#34;:5359,&#34;ĠìĥģìĹħ&#34;:5360,&#34;ëĸĦ&#34;:5361,&#34;Ġê²°ê³¼&#34;:5362,&#34;ëĭĪë¡ľ&#34;:5363,&#34;Ġì§ĳìĹĲìĦľ&#34;:5364,&#34;ĠìĭłìĦłíķľ&#34;:5365,&#34;ĠìĹīìĦ±íķľ&#34;:5366,&#34;,.,.&#34;:5367,&#34;ĠìķĪíĥĢê¹Ŀëĭ¤&#34;:5368,&#34;ĠëĿ&#34;:5369,&#34;¬ëĵľ&#34;:5370,&#34;ĠìĿ´ìļ©&#34;:5371,&#34;ìļĶìĨĮ&#34;:5372,&#34;ìķĦëĤ´&#34;:5373,&#34;ìłĲìĿ´ëĭ¤&#34;:5374,&#34;ìłķìļ°&#34;:5375,&#34;ëĶĺ&#34;:5376,&#34;ìłľëĮĢë¡ľ&#34;:5377,&#34;Ġìĺ¤ë°Ķ&#34;:5378,&#34;Ġìĵ°ëłĪê¸°ëĭ¤&#34;:5379,&#34;ì¢Ģë¹Ħ&#34;:5380,&#34;ĠëĬĲê»´ì§Ħëĭ¤&#34;:5381,&#34;ì¸¡&#34;:5382,&#34;ëĳĳ&#34;:5383,&#34;Ġì«Į&#34;:5384,&#34;Ġíĭ°ë¹ĦìĹĲìĦľ&#34;:5385,&#34;Ġë¹Įëł¤&#34;:5386,&#34;ĠëŁ¬ëĭĿíĥĢìŀĦ&#34;:5387,&#34;Ġë®¤ì§Ģì»¬&#34;:5388,&#34;ì¦Īë¥¼&#34;:5389,&#34;ĠI&#34;:5390,&#34;ìĿ´ë¦Ħ&#34;:5391,&#34;ê¸°ìĹĲëĬĶ&#34;:5392,&#34;ĠìķĦíĶĶ&#34;:5393,&#34;Ġ12&#34;:5394,&#34;ĠìĨĶì§ģ&#34;:5395,&#34;Ġëª¨ë¥´ê²Į&#34;:5396,&#34;ĠëĶ°ë¡ľ&#34;:5397,&#34;ë¨¹ëĬĶ&#34;:5398,&#34;ĠìĹ°ê¸°ëł¥ëıĦ&#34;:5399,&#34;Ġê·¸ëłĩì§Ģ&#34;:5400,&#34;ëĦĪìĬ¤&#34;:5401,&#34;ĠìŀĪìĹĪì§Ģë§Į&#34;:5402,&#34;Ġthe&#34;:5403,&#34;Ġëĥī&#34;:5404,&#34;¨¼&#34;:5405,&#34;..^^&#34;:5406,&#34;ãħĹ&#34;:5407,&#34;íķĺëįĺëį°&#34;:5408,&#34;ìĦľëıĦ&#34;:5409,&#34;ìłĲìłķëıĦ&#34;:5410,&#34;ìĤ¬ëĿ¼&#34;:5411,&#34;ĠìĹĨì§Ģ&#34;:5412,&#34;ĠëĤĺë§Į&#34;:5413,&#34;ì§ĦìĿ´&#34;:5414,&#34;Ġíķľë§ĪëĶĶ&#34;:5415,&#34;Ġê¸°ìĪł&#34;:5416,&#34;ëł¤ëĤĺ&#34;:5417,&#34;íĸĪëĭ¤ê³ł&#34;:5418,&#34;ĠëįĶëŁ¬ìļ´&#34;:5419,&#34;ĠëĵľëŁ½ê²Į&#34;:5420,&#34;Ġëĵľë¦½ëĭĪëĭ¤&#34;:5421,&#34;ìĥĿíĻľ&#34;:5422,&#34;ĠìĹ¬íĸī&#34;:5423,&#34;ĠìŀĳìĿĢ&#34;:5424,&#34;ë°Ķë¡ľ&#34;:5425,&#34;Ġì£½ìĿ´ê³ł&#34;:5426,&#34;ĠíıīìĿ´&#34;:5427,&#34;ĠëĪĦêµ¬ëĤĺ&#34;:5428,&#34;ĠíĤ¬ë§ģíĥĢìŀĦ&#34;:5429,&#34;ĠãħĪ&#34;:5430,&#34;Ġì§Īì§Īëģ&#34;:5431,&#34;Ġë²łìĬ¤íĬ¸&#34;:5432,&#34;Ġë¬´ìĦŃëĭ¤&#34;:5433,&#34;Ġê¹¨ëĭ¬&#34;:5434,&#34;Ġë¶ĪëŁ¬&#34;:5435,&#34;Ġì¦Ĳê±°ìļ´&#34;:5436,&#34;íķ´ì§Ħëĭ¤&#34;:5437,&#34;ĠìĹĨìĸ´ìļĶ&#34;:5438,&#34;ìļ´ëĵľ&#34;:5439,&#34;Ġ18&#34;:5440,&#34;Ġìŀĺíķĺê³ł&#34;:5441,&#34;ìŀĦìĿĦ&#34;:5442,&#34;ë³¸ìĺģíĻĶ&#34;:5443,&#34;íı´&#34;:5444,&#34;ĠìĿ¼ìĿ´&#34;:5445,&#34;ëªħìĿĦ&#34;:5446,&#34;Ġì£½ìĿĢ&#34;:5447,&#34;íĽĦíļĮ&#34;:5448,&#34;ì»¥&#34;:5449,&#34;ĠëĤ¨ìŀĲê°Ģ&#34;:5450,&#34;Ġíĺ¸ëŁ¬&#34;:5451,&#34;ëĨĪëĵ¤&#34;:5452,&#34;Īë²ķ&#34;:5453,&#34;Ġë¬ĺìĤ¬&#34;:5454,&#34;zz&#34;:5455,&#34;ĠìĿ´ëķĮ&#34;:5456,&#34;ìĸ´ëĬĲ&#34;:5457,&#34;ìķĦëĬĶ&#34;:5458,&#34;ë³´ëĦ¤&#34;:5459,&#34;íĨłë¡Ŀ&#34;:5460,&#34;ĠìĿ¸íķ´&#34;:5461,&#34;ĠìŀĲì£¼&#34;:5462,&#34;ĠìĤ¬ëŀĮëĵ¤ìĿĺ&#34;:5463,&#34;ì¼ĵ&#34;:5464,&#34;Ġë¶Īì¾Į&#34;:5465,&#34;ĠìĻĦìłĦíŀĪ&#34;:5466,&#34;Ġë°ľë¡ľ&#34;:5467,&#34;Ġìĵ°ëŀĺê¸°&#34;:5468,&#34;Ġìŀĳê°Ģê°Ģ&#34;:5469,&#34;ĠìĿ´ìģĺëĭ¤&#34;:5470,&#34;ì·¨íĸ¥&#34;:5471,&#34;ë½ķ&#34;:5472,&#34;22&#34;:5473,&#34;©ĺ&#34;:5474,&#34;Ġãħĩãħĩ&#34;:5475,&#34;İģ&#34;:5476,&#34;ìĹĳ&#34;:5477,&#34;ê¸ĭ&#34;:5478,&#34;ìĸ´ìĥī&#34;:5479,&#34;ë©ľë¡ľ&#34;:5480,&#34;ìŀĪìĸ´ìĦľ&#34;:5481,&#34;ĠìĺĨ&#34;:5482,&#34;ë´ħëĭĪëĭ¤&#34;:5483,&#34;ìłľë¡ľ&#34;:5484,&#34;Ġê¸°ê°Ģ&#34;:5485,&#34;ìŀĦìĬ¤&#34;:5486,&#34;ê°ĲìĿĢ&#34;:5487,&#34;Ġë³¼ìĪĺìŀĪ&#34;:5488,&#34;Ġìĭ¶ìĿĦ&#34;:5489,&#34;ìķłê°Ģ&#34;:5490,&#34;ĠìĤ¬ëŀĳìĬ¤ëŁ¬ìļ´&#34;:5491,&#34;ìĨįìĿĺ&#34;:5492,&#34;Ġê³łë§Ī&#34;:5493,&#34;Ġë°Ķê¾¸&#34;:5494,&#34;ĠíŀĺìĿ´&#34;:5495,&#34;Ġê°ĢìĬ´ìķĦ&#34;:5496,&#34;ìŀ¥ë©´ìĿĢ&#34;:5497,&#34;Ġê°Ħëĭ¤&#34;:5498,&#34;ĠìĭłìĦłíķĺê³ł&#34;:5499,&#34;Ġì¶ĶìĸµìĿĺ&#34;:5500,&#34;Ġë³´ìķĺìĬµëĭĪëĭ¤&#34;:5501,&#34;Ġê°Ģì¹ĺê°Ģ&#34;:5502,&#34;ĠìĺĪë»Ĳ&#34;:5503,&#34;ë°©ìĤ¬ìĪĺ&#34;:5504,&#34;Ġëł&#34;:5505,&#34;ëĭī&#34;:5506,&#34;ìĿ´ë²Ī&#34;:5507,&#34;ìĹĪëĥĲ&#34;:5508,&#34;ĠìĺģíĻĶëĦ¤&#34;:5509,&#34;ĠìķĦíĶĦ&#34;:5510,&#34;Ġê·¸ëĭ¤ì§Ģ&#34;:5511,&#34;Ġìĸ´ì²ĺêµ¬ëĭĪ&#34;:5512,&#34;Ġë§ĮëĤĺ&#34;:5513,&#34;íİľ&#34;:5514,&#34;ìĦ¸ê¸°&#34;:5515,&#34;Ġëª»ìĥĿ&#34;:5516,&#34;ëħĦë§ĮìĹĲ&#34;:5517,&#34;ëĲĺëĦ¤ìļĶ&#34;:5518,&#34;ë³´ê³łëĤĺìĦľ&#34;:5519,&#34;íħĿ&#34;:5520,&#34;ëĤ¨ëĬĶ&#34;:5521,&#34;ê²¨ì§Ħ&#34;:5522,&#34;ĠìĦ±ìĿ¸&#34;:5523,&#34;ëĲ©ëĭĪëĭ¤&#34;:5524,&#34;Ġê³¼ìŀ¥&#34;:5525,&#34;ĠëĶ±íŀĪ&#34;:5526,&#34;ì²ĺìĿĮìĹĶ&#34;:5527,&#34;Ġë¶Ģì¡±íķĺëĭ¤&#34;:5528,&#34;Ġìĭ¶ìĿĢëį°&#34;:5529,&#34;Ġë¬¸ìłľê°Ģ&#34;:5530,&#34;Ġë¿ĲìĿ´ëĭ¤&#34;:5531,&#34;ĠìĻľìĿ´ëŀĺ&#34;:5532,&#34;ĠìĦ¹ìĬ¤&#34;:5533,&#34;ìĸ´ëł¸ìĿĦ&#34;:5534,&#34;ĠëĬĲê¼Ī&#34;:5535,&#34;ì§ĢëıĦìķĬê³ł&#34;:5536,&#34;íľĺ&#34;:5537,&#34;ĦìĥĪ&#34;:5538,&#34;ŃëĭĪëĭ¤&#34;:5539,&#34;ìĹĲíľ´&#34;:5540,&#34;Ġê·¸ê±°&#34;:5541,&#34;ìłĲì¤Į&#34;:5542,&#34;ìĬ¤íĭ°&#34;:5543,&#34;ìĬ¤ì¼Ģ&#34;:5544,&#34;Ġë´¤ìĿĦ&#34;:5545,&#34;íķ¨ìĿĺ&#34;:5546,&#34;Ġì¤¬&#34;:5547,&#34;ìĭłë¶Ħ&#34;:5548,&#34;Ġëª»íķ¨&#34;:5549,&#34;Ġê°ľë¿Ķ&#34;:5550,&#34;Ġë©Ī&#34;:5551,&#34;ìĽĲìĿĺ&#34;:5552,&#34;ëĲĺìĹĪëĭ¤&#34;:5553,&#34;ë¦¬ëį&#34;:5554,&#34;ìķłëĭĪë©ĶìĿ´ìħĺ&#34;:5555,&#34;ĠëªħíĴĪ&#34;:5556,&#34;ĠíķĺëĤĺìĿĺ&#34;:5557,&#34;ë³¼ë§Įíķľ&#34;:5558,&#34;Ġë³´ìĹ¬ì¤Ģëĭ¤&#34;:5559,&#34;Ġëĭ¨ì§Ģ&#34;:5560,&#34;ëĬ¥ëł¥&#34;:5561,&#34;ë§Įëĵ¤ìĸ´&#34;:5562,&#34;ëıħë¦½&#34;:5563,&#34;ĠìĨĮìŀ¬ê°Ģ&#34;:5564,&#34;Ġê¸´ìŀ¥ê°ĲëıĦ&#34;:5565,&#34;ĪëĶ§&#34;:5566,&#34;Ġë¬´ìĹĩìĿĦ&#34;:5567,&#34;ì¶©ê²©&#34;:5568,&#34;ê¹Ĭê²Į&#34;:5569,&#34;ĠíķĻìĥĿ&#34;:5570,&#34;ĠíŀĪìĸ´ë¡ľ&#34;:5571,&#34;Ġë©įì²Ńíķľ&#34;:5572,&#34;ìĿ½&#34;:5573,&#34;íĻĢ&#34;:5574,&#34;ëĤĻ&#34;:5575,&#34;ëį¤&#34;:5576,&#34;ĠìĿ´ëģĮ&#34;:5577,&#34;ë¡ľëĵľ&#34;:5578,&#34;ëĦ¹&#34;:5579,&#34;ë°ĸ&#34;:5580,&#34;ë¶ķ&#34;:5581,&#34;ĠìĹĨìĬµëĭĪëĭ¤&#34;:5582,&#34;ĠìĥĪëģ¼&#34;:5583,&#34;Ġìĺ·&#34;:5584,&#34;ìĦ±ê³¼&#34;:5585,&#34;Ġìŀ¬ë°ĮëĦ¤&#34;:5586,&#34;ĠìĥĿê°ģìĹĨìĿ´&#34;:5587,&#34;ê´ľ&#34;:5588,&#34;Ġë¯¸ëĵľ&#34;:5589,&#34;ë²Ħë¦¼&#34;:5590,&#34;ĠìŀĪëĬĶì§Ģ&#34;:5591,&#34;ĠíķĺëĬĶê±°&#34;:5592,&#34;ì´Į&#34;:5593,&#34;ĠìľĦíķ´ìĦľ&#34;:5594,&#34;ĠìĨįìĹĲìĦľ&#34;:5595,&#34;ĠìłķëıĦìĿĺ&#34;:5596,&#34;ëıĪì£¼ê³ł&#34;:5597,&#34;ĠìĿ¸ìĥģìłģìĿ´&#34;:5598,&#34;Ġê¿ĪìĿĦ&#34;:5599,&#34;ĠëĽ°ìĸ´ëĦĺ&#34;:5600,&#34;ĠìĿ´ìłķëıĦë©´&#34;:5601,&#34;ĠìķĮê²łëĬĶëį°&#34;:5602,&#34;Ġë°ĳ&#34;:5603,&#34;ìĹ°ìĿ´&#34;:5604,&#34;ĠìĥĿê°ģíķ¨&#34;:5605,&#34;ëħĦìĿĺ&#34;:5606,&#34;Ġë¹Ħíķĺë©´&#34;:5607,&#34;ĠìķĪë´Ĳ&#34;:5608,&#34;Ġìĥģê´Ģ&#34;:5609,&#34;ì¶Ķê¸°&#34;:5610,&#34;ê²¨ìĦľ&#34;:5611,&#34;ĠìĿ´íķ´íķĺê¸°&#34;:5612,&#34;ĠëĨĴê²Į&#34;:5613,&#34;ë²Ķì£Ħ&#34;:5614,&#34;ê²ģëĭĪëĭ¤&#34;:5615,&#34;ĠëĶĶì¦ĪëĭĪ&#34;:5616,&#34;Ġì²ŃìĨĮëħĦ&#34;:5617,&#34;ê²ĥê°ĻìķĦìļĶ&#34;:5618,&#34;ĠíĴįê²½&#34;:5619,&#34;ĠíĪ¬ìŀĲ&#34;:5620,&#34;Ġì§ĿìĿ´&#34;:5621,&#34;Ġì°Įì§Ī&#34;:5622,&#34;Ġìĸ´ë¦´ëķĮ&#34;:5623,&#34;ĠìĿĳìĽĲ&#34;:5624,&#34;.,&#34;:5625,&#34;¬ĺ&#34;:5626,&#34;ëĮĵê¸Ģ&#34;:5627,&#34;Ġì¯&#34;:5628,&#34;ĠìµĿìĺ¤&#34;:5629,&#34;ëĭĮ&#34;:5630,&#34;ëĤĺìĺ¬&#34;:5631,&#34;ĠíķĺìĿ´&#34;:5632,&#34;ĠìŀĪêµ¬ëĤĺ&#34;:5633,&#34;ê·¸ëĤĺë§Ī&#34;:5634,&#34;Ġê°Ģë³įê²Į&#34;:5635,&#34;íĮĶìĿ´&#34;:5636,&#34;ëŁ¬ìĽĮ&#34;:5637,&#34;ãħĭãħĭãħĭãħĭãħĭãħĭãħĭ&#34;:5638,&#34;Ġë§ĲìķĦë¨¹&#34;:5639,&#34;Ġíķ´ëĿ¼&#34;:5640,&#34;ĠìķĦê¹Įìļ¸&#34;:5641,&#34;ì¼ĢìĿ´ë¸Ķ&#34;:5642,&#34;ìĶ¬ìĿ´&#34;:5643,&#34;Ġëª¨ë¥´ê²łìĿĮ&#34;:5644,&#34;ĠìıŁ&#34;:5645,&#34;Ġì¤ĳìļĶíķľ&#34;:5646,&#34;ĠíĥĦíĥĦíķľ&#34;:5647,&#34;Ġê¹ľì§Ŀ&#34;:5648,&#34;ìĿ´ëıĦ&#34;:5649,&#34;ëĭĪëĭ¹&#34;:5650,&#34;ìĭľìĽĲ&#34;:5651,&#34;ìĿĮìĿ´&#34;:5652,&#34;ëª¬&#34;:5653,&#34;ĠìłĦë°ĺ&#34;:5654,&#34;Ġìļ°ëł¤&#34;:5655,&#34;Ġìŀ¬ë¯¸ìĹĨê²Į&#34;:5656,&#34;ë°ľìĹ°ê¸°&#34;:5657,&#34;ĠìĦ±ê²©&#34;:5658,&#34;Ġë©ĭìŀĪëĭ¤&#34;:5659,&#34;000&#34;:5660,&#34;ëĵľëĿ¼ë§Īê°Ģ&#34;:5661,&#34;Ġì§ľì¦ĿëĤľëĭ¤&#34;:5662,&#34;ĠìĪĺì¤ĢìĿĺ&#34;:5663,&#34;Ġì¹ĺê³ł&#34;:5664,&#34;ëķħ&#34;:5665,&#34;ĠêµĲìľ¡&#34;:5666,&#34;ĠíĥĢìĿ´&#34;:5667,&#34;Ġìłľìŀĳë¹Ħ&#34;:5668,&#34;ìĿ¸ê°ĦìĿĺ&#34;:5669,&#34;âĺĨ&#34;:5670,&#34;¬¸&#34;:5671,&#34;Ńìłľ&#34;:5672,&#34;ĠëĮ&#34;:5673,&#34;ìĿ´ìģĺ&#34;:5674,&#34;Ġìķ¤&#34;:5675,&#34;ê¸°ì§Ģ&#34;:5676,&#34;ë§ĮìĿĢ&#34;:5677,&#34;Ġë³´ëł¤ê³ł&#34;:5678,&#34;ì£¼ê°Ģ&#34;:5679,&#34;ĠìłķìĿĺ&#34;:5680,&#34;Ġìĸ´ìļ°&#34;:5681,&#34;ĠëĤ´ë©´&#34;:5682,&#34;ìķĺìĿĦ&#34;:5683,&#34;ìŀĦìĥĪ&#34;:5684,&#34;Ġë³¼ê±°&#34;:5685,&#34;Ġíķ´ê²°&#34;:5686,&#34;Ġíķłë§ĲìĿ´&#34;:5687,&#34;Ġê´Ģìĭ¬&#34;:5688,&#34;ìĤ´ìĿ¸&#34;:5689,&#34;íĪ¬ë&#34;:5690,&#34;ĠëĤ¨ìŀĲìĿĺ&#34;:5691,&#34;Ġë°ĽìĿĦ&#34;:5692,&#34;ĠìºĲë¦ŃíĦ°ê°Ģ&#34;:5693,&#34;ìĹ¬ëŁ¬ë&#34;:5694,&#34;ê·ĢìĹ½&#34;:5695,&#34;ĠìĨĮë¦ĦìĿ´&#34;:5696,&#34;ëĮĢíķľë¯¼êµŃ&#34;:5697,&#34;Ġê²¨ìļ°&#34;:5698,&#34;Ġê¹¨ëĭ«ê²Į&#34;:5699,&#34;ë·&#34;:5700,&#34;ĪĦ&#34;:5701,&#34;ìĿ´ëĵ¤&#34;:5702,&#34;ê°Ģë©´&#34;:5703,&#34;ìĿ¸ê²ĥ&#34;:5704,&#34;ê¹ģ&#34;:5705,&#34;ê±°ìĿĺ&#34;:5706,&#34;ìŀĲëĵ¤ìĿ´&#34;:5707,&#34;ë¶Ģìŀĳ&#34;:5708,&#34;ĠìŀĲìĤ´&#34;:5709,&#34;Ġìļ°ìłķ&#34;:5710,&#34;Ġëħ¸ëĭµ&#34;:5711,&#34;ê°ķíĺ¸&#34;:5712,&#34;Ġë°©ìĺģ&#34;:5713,&#34;Ġì°įìĸ´&#34;:5714,&#34;Ġ50&#34;:5715,&#34;ìŀ¬ë°ĭëĭ¤&#34;:5716,&#34;Ġíĸīë³µíķľ&#34;:5717,&#34;Ġê°ľìĹ°ìĦ±ìĿ´&#34;:5718,&#34;Ġê°ľìĹ°ìĦ±ëıĦ&#34;:5719,&#34;ìĺģìĥģë¯¸&#34;:5720,&#34;Ġëĺĳê°ĻìĿĢ&#34;:5721,&#34;Īë²½ìĹĲ&#34;:5722,&#34;.^^&#34;:5723,&#34;ĠìĹ¿&#34;:5724,&#34;ë¦¬ì¹´&#34;:5725,&#34;ëłĲ&#34;:5726,&#34;Ġë³´ìŀĲ&#34;:5727,&#34;ĠìŀĪìĹĪëĬĶëį°&#34;:5728,&#34;íĸĪìľ¼ëĤĺ&#34;:5729,&#34;ĠìķĬëĦ¤ìļĶ&#34;:5730,&#34;ĠìĿ´ëŁ°ìĺģíĻĶê°Ģ&#34;:5731,&#34;ëĲĺê²Į&#34;:5732,&#34;Ġëĭ¹ìĹ°&#34;:5733,&#34;ĠíĹĪìĦ¸&#34;:5734,&#34;ì»·&#34;:5735,&#34;ĠëĤ®ê²Į&#34;:5736,&#34;Ġë¹łì§Ħ&#34;:5737,&#34;ìķĦìĿ´ê°Ģ&#34;:5738,&#34;ìķ½íķľ&#34;:5739,&#34;Ġìķŀìľ¼ë¡ľëıĦ&#34;:5740,&#34;ë³´ì§Ģë§Ī&#34;:5741,&#34;Ġêµ°ëĮĢ&#34;:5742,&#34;ĠìķĦë¦Ħëĭ¤ìĽĢ&#34;:5743,&#34;Ġì§Ŀíīģ&#34;:5744,&#34;Ġíı¬ë¥´ëħ¸&#34;:5745,&#34;40&#34;:5746,&#34;ĠãĦ±&#34;:5747,&#34;..;;&#34;:5748,&#34;Ġíĳ¸&#34;:5749,&#34;ë¡ľë§Į&#34;:5750,&#34;ìķĦìłĢìĶ¨&#34;:5751,&#34;Ġê·¸ê±´&#34;:5752,&#34;Ġëĭ¥&#34;:5753,&#34;ë³´ìŀĲ&#34;:5754,&#34;Ġë°ĳìĹĲ&#34;:5755,&#34;Ġë§Įíķľ&#34;:5756,&#34;ê·¸ë¦¼&#34;:5757,&#34;ì¹ĺê°Ģ&#34;:5758,&#34;íķĺëĬĶê±´&#34;:5759,&#34;ĠìķĪìĵ°&#34;:5760,&#34;ĠìķĮìĪĺ&#34;:5761,&#34;Ġì§Ģë£¨íĸĪëĭ¤&#34;:5762,&#34;ëħ¸ëĭµ&#34;:5763,&#34;ìĹĨëĬĶìĺģíĻĶ&#34;:5764,&#34;ĠëĤĺìĺ¤ì§Ģ&#34;:5765,&#34;Ġë¶Ħëĵ¤ìĿĢ&#34;:5766,&#34;ĠëªħìŀĳìĿ´&#34;:5767,&#34;Ġë¡ľë´ĩ&#34;:5768,&#34;Ġìľłì¹ĺíķĺëĭ¤&#34;:5769,&#34;ĠìĿĮìķħê³¼&#34;:5770,&#34;Ġíķľë²Īì¯¤&#34;:5771,&#34;Ġëĳĺì§¸&#34;:5772,&#34;Ġì©Ĳëĭ¤&#34;:5773,&#34;ĠëĭĪì½ľ&#34;:5774,&#34;ìĦ¸ìĥģìĹĲ&#34;:5775,&#34;ĠMì°½&#34;:5776,&#34;OOOê¸°&#34;:5777,&#34;Ġì£½ëĬĶì¤Ħ&#34;:5778,&#34;³¸&#34;:5779,&#34;¬ëłĪ&#34;:5780,&#34;ìĸ´ë¦¬&#34;:5781,&#34;ĠëĤ©&#34;:5782,&#34;ìĺģíĻĶìĿ¸ëį°&#34;:5783,&#34;ìĿĮìĿĦ&#34;:5784,&#34;Ġëĭ¤ëĭĪ&#34;:5785,&#34;Ġìĸ´ë¨¸ëĭĪ&#34;:5786,&#34;Ġìĺ¬ë¦¬&#34;:5787,&#34;ĠìĿ¸ëĤ´&#34;:5788,&#34;ë¬¼ìĿĦ&#34;:5789,&#34;Ġìĺģíĺ¼&#34;:5790,&#34;ĠíĥĲ&#34;:5791,&#34;Ġê°ķëł¥&#34;:5792,&#34;Ġë§Įëĵ¤ìĸ´ëıĦ&#34;:5793,&#34;Ġëĸ¨ìĸ´ì§Ħëĭ¤&#34;:5794,&#34;Ġìķ¼ëıĻ&#34;:5795,&#34;Ġìłľëª©ìĿ´&#34;:5796,&#34;Ġê¸°ëĭ¤ëł¤&#34;:5797,&#34;ĠìķĪë³¼&#34;:5798,&#34;ëłĪë©ĺ&#34;:5799,&#34;ìĺĽëĤłìĹĲ&#34;:5800,&#34;ìĭľì²Ńë¥ł&#34;:5801,&#34;Ġìĺ¤ëŀľë§Į&#34;:5802,&#34;ìĹł&#34;:5803,&#34;ĠíĦ&#34;:5804,&#34;ĠìķĦìĺĪ&#34;:5805,&#34;Ġë³´ëĭ¤ëĬĶ&#34;:5806,&#34;ë³´ëĭĪê¹Į&#34;:5807,&#34;ìłķìłģìĿ¸&#34;:5808,&#34;ìŀ¥ìĿĦ&#34;:5809,&#34;Ġì§Ģêµ¬&#34;:5810,&#34;íĨ±&#34;:5811,&#34;ë¯¸ëĦ¤&#34;:5812,&#34;Ġê¸°íļĮ&#34;:5813,&#34;ëł¤ëĭ¤ê°Ģ&#34;:5814,&#34;ë¬µ&#34;:5815,&#34;êµ¬ìĦ±&#34;:5816,&#34;Ġìŀĺìĸ´ìļ¸&#34;:5817,&#34;ĠìĥĿê°ģëĤĺìĦľ&#34;:5818,&#34;Ġìĺ¤ëŀ«&#34;:5819,&#34;Ġê¹İ&#34;:5820,&#34;ëĭ¤ëĬĶê±°&#34;:5821,&#34;ëĭ¤ëĬĶê±¸&#34;:5822,&#34;ë´¤ëĦ¤ìļĶ&#34;:5823,&#34;ĠíķĺëĬĶê²Į&#34;:5824,&#34;ìĹĲê²ĮëĬĶ&#34;:5825,&#34;ë¡Ŀë²ĦìĬ¤íĦ°&#34;:5826,&#34;ĠìľĦëĮĢíķľ&#34;:5827,&#34;ĠíķľêµŃìĺģíĻĶëĬĶ&#34;:5828,&#34;ì§Ģë£¨íķ´&#34;:5829,&#34;íĨµëł¹&#34;:5830,&#34;ĠìĹ¬ìļ´ìĿĦ&#34;:5831,&#34;ìķ½ê°Ħ&#34;:5832,&#34;ĠíĨµì¾Į&#34;:5833,&#34;ĠëĬĲëĤĦìĪĺ&#34;:5834,&#34;ĠíĿĶíķľ&#34;:5835,&#34;ĠíķĦë¦Ħ&#34;:5836,&#34;70&#34;:5837,&#34;~!!!&#34;:5838,&#34;ëĽ°&#34;:5839,&#34;Ġ/&#34;:5840,&#34;Ġl&#34;:5841,&#34;ĠìŀŃ&#34;:5842,&#34;ë¦¬íķľ&#34;:5843,&#34;Ġì§Īë&#34;:5844,&#34;ìľ¼ë¡ľëĬĶ&#34;:5845,&#34;íĺĪ&#34;:5846,&#34;ì¶¤&#34;:5847,&#34;ĠëĮĢë³¸&#34;:5848,&#34;ì¢Į&#34;:5849,&#34;Ġìµľê³łìŀħëĭĪëĭ¤&#34;:5850,&#34;ë¬¸íĻĶ&#34;:5851,&#34;íĤ¬&#34;:5852,&#34;Ġê°ĲíĿ¥&#34;:5853,&#34;ĠíĮĮìĿ´&#34;:5854,&#34;ìĿ´ëŁ°ê²Į&#34;:5855,&#34;ĠìĹ°ì¶ľê³¼&#34;:5856,&#34;ĠìĦ¸ëł¨&#34;:5857,&#34;íĺķëĭĺ&#34;:5858,&#34;ëĭĪë¥¼&#34;:5859,&#34;ê°ĲëıĻìłģìĿ¸&#34;:5860,&#34;Ġê°ĢìĬ´ìĹĲ&#34;:5861,&#34;Ġ70&#34;:5862,&#34;ë³ĳë§Ľ&#34;:5863,&#34;Ġê½ĥ&#34;:5864,&#34;Ġë¬´ìĹĩìĿ¸ì§Ģ&#34;:5865,&#34;ĠëĳĺìĿ´&#34;:5866,&#34;Ġì»¤íĶĮ&#34;:5867,&#34;Ġê°ĸê³ł&#34;:5868,&#34;ëħĦëıĦìĹĲ&#34;:5869,&#34;ĠìĺĪìģĺê³ł&#34;:5870,&#34;íĭ°ë¹ĦìĹĲìĦľ&#34;:5871,&#34;¸Ķ&#34;:5872,&#34;íĻĶë©´&#34;:5873,&#34;ì§Ģë©´&#34;:5874,&#34;ìĭ¬ë&#34;:5875,&#34;ê²ĮìļĶ&#34;:5876,&#34;íķ´ì£¼ìĦ¸ìļĶ&#34;:5877,&#34;Ġê·¸ê²ĥëıĦ&#34;:5878,&#34;ĠíķĺëĬĺ&#34;:5879,&#34;Ġë´ħëĭĪëĭ¤&#34;:5880,&#34;ì§Ħìĭ¤&#34;:5881,&#34;ìŀĪìĹĪëĭ¤&#34;:5882,&#34;ìłĦë¬¸&#34;:5883,&#34;Ġì§ĢëĤĺëıĦ&#34;:5884,&#34;ëĵľìĭľ&#34;:5885,&#34;ĠëıĦìłĦ&#34;:5886,&#34;ĠìĪĺê³ł&#34;:5887,&#34;ĠìĥĿê°ģíķĺë©´&#34;:5888,&#34;ĠìķĦëĭĻëĭĪëĭ¤&#34;:5889,&#34;Ġë§Įëĵ¤ëĭ¤ëĭĪ&#34;:5890,&#34;ìĦłìĥĿ&#34;:5891,&#34;Ġìĵ°ëłĪê¸°ê°ĻìĿĢ&#34;:5892,&#34;Ġíĥģ&#34;:5893,&#34;ì¢ħìĿ¼&#34;:5894,&#34;ĠìĹ´ë°Ľ&#34;:5895,&#34;ĠìŀĲì²´ëĬĶ&#34;:5896,&#34;Ġì¹´ë¦¬ìĬ¤ë§Ī&#34;:5897,&#34;íĻįì½©&#34;:5898,&#34;ĠìĹ¬ê¸°ìĦľ&#34;:5899,&#34;Ġì°©íķľ&#34;:5900,&#34;ĠíĹĲë¦¬ìĽĥ&#34;:5901,&#34;ìķĪëĲ¨&#34;:5902,&#34;ëłĪë©ĺíĥĢ&#34;:5903,&#34;°ľ&#34;:5904,&#34;ëĿ&#34;:5905,&#34;ë©į&#34;:5906,&#34;ìľĮ&#34;:5907,&#34;ì¤¬ëĭ¤&#34;:5908,&#34;íĺĲ&#34;:5909,&#34;ìĹ¬íĸī&#34;:5910,&#34;Ġê¸°ëıħêµĲ&#34;:5911,&#34;ëķĮëĬĶ&#34;:5912,&#34;ĠìĿ¸ê¸°&#34;:5913,&#34;ĠìłľìĻ¸&#34;:5914,&#34;ëĥĲê³ł&#34;:5915,&#34;ë²ĪìĿĢ&#34;:5916,&#34;Ġë°°ìļ°ë¥¼&#34;:5917,&#34;Ġì¡°ìŀĳ&#34;:5918,&#34;Ġë°ĺê°ľëıĦ&#34;:5919,&#34;ĠíķłìĪĺ&#34;:5920,&#34;Ġìļ¸ì»¥&#34;:5921,&#34;ĠíĬ¹ìĿ´&#34;:5922,&#34;ìĿ´ê±´ëŃĲ&#34;:5923,&#34;Ġìļ°ë¦¬ìĿĺ&#34;:5924,&#34;ĠìłĦê°ľëıĦ&#34;:5925,&#34;ìŀ¡ê³ł&#34;:5926,&#34;ê¸°ëĮĢìķĪíķĺê³ł&#34;:5927,&#34;Ġìŀłê¹Ĳ&#34;:5928,&#34;Ġê¸´ìŀ¥ê°ĲìĿ´&#34;:5929,&#34;ĠêµŃëĤ´&#34;:5930,&#34;????????&#34;:5931,&#34;Ġëĵ£ê³ł&#34;:5932,&#34;en&#34;:5933,&#34;ª¼&#34;:5934,&#34;ëĬĶëĮĢ&#34;:5935,&#34;ĠìĿ´ëıĦ&#34;:5936,&#34;ë§Įëĭ¤&#34;:5937,&#34;ìŀĲëĵ¤ìĿĺ&#34;:5938,&#34;ĠëĤ´ìĿ¸ìĥĿ&#34;:5939,&#34;Ġê¸°ì¤Ģ&#34;:5940,&#34;ë¥´ê²Į&#34;:5941,&#34;Ġë§Įëĵ¤ë©´&#34;:5942,&#34;ë´¤ì§Ģë§Į&#34;:5943,&#34;Ġë°ĶëŀįëĭĪëĭ¤&#34;:5944,&#34;ëĸ¡&#34;:5945,&#34;ĠìĤ´ëł¤&#34;:5946,&#34;Ġíı´&#34;:5947,&#34;ìĶ¨ëĬĶ&#34;:5948,&#34;ĠíĸĪìľ¼ë©´&#34;:5949,&#34;ê¸ĢìİĦ&#34;:5950,&#34;íĺķëŀĺ&#34;:5951,&#34;ĠëĬĲëĤĮìĿĺ&#34;:5952,&#34;ëĶ°ìľĦ&#34;:5953,&#34;ê·¸ëŀĺíĶ½&#34;:5954,&#34;âĻ¥âĻ¥âĻ¥&#34;:5955,&#34;Ġì¶ľìĹ°ì§Ħ&#34;:5956,&#34;ìłĲëĮĢëĬĶ&#34;:5957,&#34;ĠìŀĲìĭłìĿ´&#34;:5958,&#34;ĠëĬĲê¼Īëĭ¤&#34;:5959,&#34;ë¦¬íı¬íĦ°&#34;:5960,&#34;ĠG&#34;:5961,&#34;Ġ~~&#34;:5962,&#34;ķëĭĪëĭ¤&#34;:5963,&#34;ì§ĢìļĶ&#34;:5964,&#34;ĠëĤĻ&#34;:5965,&#34;ĠìķĦíĶĪ&#34;:5966,&#34;ìĭľìĤ¬íļĮ&#34;:5967,&#34;ĠíķĺëĦ¤&#34;:5968,&#34;Ġëĭ¤ë¥¼&#34;:5969,&#34;ê±´ë§Į&#34;:5970,&#34;ĠìĬ¤íģ¬ë¦°&#34;:5971,&#34;ë¯¸ìĬ¤&#34;:5972,&#34;ê²ĥê°ĻìĿĢ&#34;:5973,&#34;ë¶ĦìĿĢ&#34;:5974,&#34;ĠìķĪìĹĲ&#34;:5975,&#34;ĠëĤ¨ìĿĢ&#34;:5976,&#34;íĬ¸ìĿĺ&#34;:5977,&#34;ì¢ĭìķĺëĭ¤&#34;:5978,&#34;ĠëģĿìĿ´&#34;:5979,&#34;Ġë´Ĳì¤Ħ&#34;:5980,&#34;ĠëħĦ&#34;:5981,&#34;íħĮìĿ´&#34;:5982,&#34;ĠìŀĳíĴĪìĦ±&#34;:5983,&#34;Ġíĥĳ&#34;:5984,&#34;Ġëĸ¨&#34;:5985,&#34;Ġíİ¼&#34;:5986,&#34;ĠìķĦìĿ´ëıĮ&#34;:5987,&#34;ĠìŀĶëľ©&#34;:5988,&#34;Ġë°ķì§Ħ&#34;:5989,&#34;ĠìĿ¼ë³¸ìĺģíĻĶ&#34;:5990,&#34;ĠìĿ´ìłľìĦľìķ¼&#34;:5991,&#34;ë³Ħë¡ľëĭ¤&#34;:5992,&#34;ĠìŀĬì§Ģ&#34;:5993,&#34;Ġë¹¼ë©´&#34;:5994,&#34;ëłĪìĿ´ìħĺ&#34;:5995,&#34;Ġëĭ¨ìĪľíķľ&#34;:5996,&#34;ë¶Īë¥ľ&#34;:5997,&#34;ost&#34;:5998,&#34;¥ë¯¸&#34;:5999,&#34;ãģ&#34;:6000,&#34;ìĿ´ìĬ¨&#34;:6001,&#34;íķĺêµ°&#34;:6002,&#34;Ġìĭ¬ë¦¬ë&#34;:6003,&#34;ìłĲìĿ´ìĥģ&#34;:6004,&#34;Ġìŀ¬ë°©&#34;:6005,&#34;ì²©&#34;:6006,&#34;Ġëĭ¤ë£¨&#34;:6007,&#34;ìŀ¥ìķł&#34;:6008,&#34;ëĵľë¥¼&#34;:6009,&#34;ëĵľë¦½ëĭĪëĭ¤&#34;:6010,&#34;Ġìµľê°ķ&#34;:6011,&#34;ĠëĮĢíĻĶ&#34;:6012,&#34;ì¤ĳìĿ´&#34;:6013,&#34;ê°Ļê³ł&#34;:6014,&#34;íıīìłĲìĿĦ&#34;:6015,&#34;ĠíķĺëĤĺê°ĻìĿ´&#34;:6016,&#34;ìĿ´ëŁ°ê±¸&#34;:6017,&#34;ìĻĶëĭ¤&#34;:6018,&#34;ëĭĪëİģ&#34;:6019,&#34;ĠìĦ¤ëĵĿ&#34;:6020,&#34;ĠìĿ¸ê°ĦìĿ´&#34;:6021,&#34;Ġë¶ĦìľĦê¸°ê°Ģ&#34;:6022,&#34;ĠìĭľëĮĢë¥¼&#34;:6023,&#34;ĠíĥĦìĥĿ&#34;:6024,&#34;íĦ¸&#34;:6025,&#34;ëĤ®ìĿĢ&#34;:6026,&#34;íĮĮìĿ´ìĸ´&#34;:6027,&#34;ĠìķĪíĥĢê¹Įìļ´&#34;:6028,&#34;íĵ¨íĦ°&#34;:6029,&#34;ĠëŁ°&#34;:6030,&#34;Ġg&#34;:6031,&#34;ìĸ´ì§Ģ&#34;:6032,&#34;ìĸ´ìĹ¬&#34;:6033,&#34;ëĿ¼ê°Ģ&#34;:6034,&#34;ìķĦëĭĪë&#34;:6035,&#34;íķ´ì£¼ê³ł&#34;:6036,&#34;ë¶Ļ&#34;:6037,&#34;ìĥģìĿĺ&#34;:6038,&#34;ìľ¼ë¡ľë§Į&#34;:6039,&#34;Ġìĸ´ì§Ģ&#34;:6040,&#34;ê°ģë³¸&#34;:6041,&#34;ìłľìĿ¼&#34;:6042,&#34;ĠìĹ°ê¸°ìŀĺ&#34;:6043,&#34;ĠìľĦë¡ľ&#34;:6044,&#34;ê°ľëĬĶ&#34;:6045,&#34;ĠìĥĿê°ģíĸĪëĬĶëį°&#34;:6046,&#34;ĠìĿ¸ëıĦ&#34;:6047,&#34;ìĹĪëĭ¤ëĬĶ&#34;:6048,&#34;ë²Ħëł¤&#34;:6049,&#34;ĠìĤ¬ê³ł&#34;:6050,&#34;Ġìŀ¬ë¯¸ìŀĪìĹĪìĸ´ìļĶ&#34;:6051,&#34;ĠìĤ¬ëŀĳìĿĢ&#34;:6052,&#34;ê²½ì°°&#34;:6053,&#34;ìĿ´ëŁ°ê±°&#34;:6054,&#34;Ġìĸ¼ë§Ī&#34;:6055,&#34;ëĤĺìĺ¤ê³ł&#34;:6056,&#34;Ġìļķë§Ŀ&#34;:6057,&#34;Ġëĭ¬ëĭ¬&#34;:6058,&#34;ë¯¸ëĦ¤ìĿ´íĦ°&#34;:6059,&#34;´íĵ¨íĦ°&#34;:6060,&#34;Ġãħĩ&#34;:6061,&#34;ì§Ģë§Ĳê³ł&#34;:6062,&#34;ê°ĢìĿĺ&#34;:6063,&#34;ê¸°ìłĦìĹĲ&#34;:6064,&#34;ëĤĺìģľ&#34;:6065,&#34;ë¦¬ìļ°ëĵľ&#34;:6066,&#34;ìłĲìĹĲìĦľ&#34;:6067,&#34;ìłĲë§ĮìłĲ&#34;:6068,&#34;ìļ°ìĹ°íŀĪ&#34;:6069,&#34;ìķ¼íķł&#34;:6070,&#34;ê³¼ìĦľ&#34;:6071,&#34;Ġê°Ģë©´&#34;:6072,&#34;Ġê°Ģë²¼&#34;:6073,&#34;ìĨĮë£¡&#34;:6074,&#34;Ġëĵľë¦¼&#34;:6075,&#34;ëħĦìŀĳ&#34;:6076,&#34;Ġë§İìķĦìĦľ&#34;:6077,&#34;Ġìĭłë¹Ħ&#34;:6078,&#34;ĠëĦĺê²Į&#34;:6079,&#34;ĠíĶ½&#34;:6080,&#34;Ġì½ĶëĤľ&#34;:6081,&#34;Ġë°°ìĹŃ&#34;:6082,&#34;Ġë§¤ëł¥ìĿĦ&#34;:6083,&#34;Ġì§ĳì°©&#34;:6084,&#34;Ġëª¨ëĳĲê°Ģ&#34;:6085,&#34;ëıĪìĿ´&#34;:6086,&#34;Ġëĵ±ëĵ±&#34;:6087,&#34;ë§Įíģ¼ìĿĢ&#34;:6088,&#34;Ġì§Īë¦¬ì§Ģ&#34;:6089,&#34;ê·ĢìĹ¬&#34;:6090,&#34;ĠëłĪìłĦëĵľ&#34;:6091,&#34;ĠëĨĵê³ł&#34;:6092,&#34;Ġì´Īë°ĺìĹĲ&#34;:6093,&#34;ìĹīìĦ±&#34;:6094,&#34;ì§§&#34;:6095,&#34;ëį°ìĿ´&#34;:6096,&#34;ëĦĪë&#34;:6097,&#34;ĠìķĦì¤Įë§Ī&#34;:6098,&#34;ìĺĪë&#34;:6099,&#34;ìĥĪë¡&#34;:6100,&#34;ìĺģíĻĶìŀħëĭĪëĭ¤&#34;:6101,&#34;ë²Ĺ&#34;:6102,&#34;ìŀ¥íķľ&#34;:6103,&#34;Ġê²ª&#34;:6104,&#34;ëĵľë¡ľ&#34;:6105,&#34;íĨ°&#34;:6106,&#34;ë¶Ģê°Ģ&#34;:6107,&#34;ìłĢìĺĪìĤ°&#34;:6108,&#34;ë¹Ĺ&#34;:6109,&#34;ì¡°ìłĪ&#34;:6110,&#34;Ġì¹Ń&#34;:6111,&#34;Ġê±°ê¸°ìĹĲ&#34;:6112,&#34;ì¤ĦìĿ´ìķ¼&#34;:6113,&#34;ëĭĺëĵ¤&#34;:6114,&#34;ĠìĤ´ë¦°&#34;:6115,&#34;ê²°íĺ¼&#34;:6116,&#34;ìĽłì§Ģë§Į&#34;:6117,&#34;ĠìĨĲë°ľìĿ´&#34;:6118,&#34;Ġëį°ë¦¬ê³ł&#34;:6119,&#34;ëįķíĻĶ&#34;:6120,&#34;ìĿ¸ì¤ĦìķĮ&#34;:6121,&#34;íģ¬ë¡ľ&#34;:6122,&#34;ĠìŀĶìĿ¸íķľ&#34;:6123,&#34;ë¹¨ë¦¬&#34;:6124,&#34;Ġê·¸ëħĢìĿĺ&#34;:6125,&#34;ëª°ìŀħëıĦ&#34;:6126,&#34;ìĸ´ëĶĶìĦľ&#34;:6127,&#34;Ġë±Ģ&#34;:6128,&#34;Ġp&#34;:6129,&#34;Ġì¸&#34;:6130,&#34;ìĹĲëĮĢ&#34;:6131,&#34;ìĭľë©´&#34;:6132,&#34;ìľ¼ë¦¬&#34;:6133,&#34;ë²ĪëįĶ&#34;:6134,&#34;ìŀĪìĬµëĭĪëĭ¤&#34;:6135,&#34;Ġíķľëªħ&#34;:6136,&#34;ëĵľë¦¼&#34;:6137,&#34;ĠìłĦìľ¨&#34;:6138,&#34;ëłĪìĿ¸&#34;:6139,&#34;Ġì£¼ê¸°ëıĦ&#34;:6140,&#34;ë¹ĦìĬ·&#34;:6141,&#34;Ġë¹Ħë°Ģ&#34;:6142,&#34;íĭ¸&#34;:6143,&#34;ìłģìĿ´ì§Ģ&#34;:6144,&#34;ìµľê³łìµľê³ł&#34;:6145,&#34;ĠìĿĺìĻ¸ë¡ľ&#34;:6146,&#34;ìĺĪê³łíİ¸&#34;:6147,&#34;Ġëĵ¤ê³ł&#34;:6148,&#34;ë°°ìļ°ìĿĺ&#34;:6149,&#34;ì©Ŀ&#34;:6150,&#34;ĠìĹ¬ìŀĲìĿĺ&#34;:6151,&#34;ãħľãħľãħľãħľ&#34;:6152,&#34;Ġìĵ°ê³ł&#34;:6153,&#34;Ġë¶Ģë¶ĦëıĦ&#34;:6154,&#34;Ġëĭµëĭµíķĺê³ł&#34;:6155,&#34;íķĺíķĺíķĺ&#34;:6156,&#34;Ġìĸ´ìļ¸ë¦¬ëĬĶ&#34;:6157,&#34;Ġìıĺ&#34;:6158,&#34;ìĿ´ìĺĢëĭ¤&#34;:6159,&#34;ìĿ´ìĹĪìĿĮ&#34;:6160,&#34;íķĺë£¨&#34;:6161,&#34;íķĺê¸¸&#34;:6162,&#34;Ġìķī&#34;:6163,&#34;ĠìĿ´ìĹ°ê±¸&#34;:6164,&#34;ëĭĪíį¼&#34;:6165,&#34;Ġë³´ëĭ¤ëĭĪ&#34;:6166,&#34;ìĥĪë¡ľ&#34;:6167,&#34;Ġê·¸ìŀĲì²´&#34;:6168,&#34;ê±°ëĵł&#34;:6169,&#34;ìŀĲë¡ľ&#34;:6170,&#34;ì§ľë¡ľ&#34;:6171,&#34;Ġë§ĮëĤ¨&#34;:6172,&#34;ìŀ¬ë¥¼&#34;:6173,&#34;ê²łëĭ¤ëĬĶ&#34;:6174,&#34;Ġë³´ê³łëĤĺë©´&#34;:6175,&#34;ĠìĿ¼ê¹¨&#34;:6176,&#34;ĠëŃĲëĿ¼&#34;:6177,&#34;ë°ĶìĿ´&#34;:6178,&#34;ìĿ¸ëį°ëıĦ&#34;:6179,&#34;ĠìķĦëĭĪìķ¼&#34;:6180,&#34;ì½Ķë©ĶëĶĶ&#34;:6181,&#34;ì©Ĳëĭ¤&#34;:6182,&#34;ìĽłìĸ´ìļĶ&#34;:6183,&#34;..........&#34;:6184,&#34;Ġì£¼ìĿ¸ê³µìĿĢ&#34;:6185,&#34;Ġë³´ê¸°ìĹĲëĬĶ&#34;:6186,&#34;Ġë§İìĿĢëį°&#34;:6187,&#34;Ġëĸ¨ìĸ´ì§Ģê³ł&#34;:6188,&#34;ĠíĿ¥ë¯¸ë¡ľ&#34;:6189,&#34;ĠìĤ´ìķĦê°ĢëĬĶ&#34;:6190,&#34;Ġìĭľë¦¬ì¦ĪëĬĶ&#34;:6191,&#34;Ġë§Įëĵ¤ìĹĪëĬĶì§Ģ&#34;:6192,&#34;ìķĦë¦Ħëĭµ&#34;:6193,&#34;Ġìĸ´ì©ĶìĪĺ&#34;:6194,&#34;Ġê³µíı¬ë¬¼&#34;:6195,&#34;Ġíļ¨ê³¼&#34;:6196,&#34;íĻĶëł¤íķľ&#34;:6197,&#34;vd&#34;:6198,&#34;ĪìĿ´&#34;:6199,&#34;ľ©&#34;:6200,&#34;ìĿ´ìĺģíĻĶê°Ģ&#34;:6201,&#34;ĠìĺģíĻĶíĻĶ&#34;:6202,&#34;ĠìĺģíĻĶë³´ëĬĶ&#34;:6203,&#34;ëį´&#34;:6204,&#34;ëĬĶëį°ëıĦ&#34;:6205,&#34;Ġë´ī&#34;:6206,&#34;ìłģìŀĦ&#34;:6207,&#34;ê·¸ëħĢ&#34;:6208,&#34;Ġë´¤ìĿĦê¹Į&#34;:6209,&#34;Ġê°Ģì§Ģ&#34;:6210,&#34;ë¶Ģë¡ľ&#34;:6211,&#34;Ġìľ¡&#34;:6212,&#34;Ġë¬´ìĪł&#34;:6213,&#34;ĠìĥĿê°ģíķł&#34;:6214,&#34;ìĺĢìĸ´&#34;:6215,&#34;ë¹Ľ&#34;:6216,&#34;Ġíķ´ìĦĿ&#34;:6217,&#34;ĠìĽĥê²¼&#34;:6218,&#34;Ġì°¸ìľ¼ë¡ľ&#34;:6219,&#34;ëŃĲê°Ģ&#34;:6220,&#34;ĠíĺĦìĭ¤ìĦ±&#34;:6221,&#34;íıīë²Ķ&#34;:6222,&#34;Ġëª°ìŀħê°Ĳ&#34;:6223,&#34;Ġìľłì¹ĺíķ¨&#34;:6224,&#34;ë°Ľê³ł&#34;:6225,&#34;Ġê¸¸ê²Į&#34;:6226,&#34;ĠìĦ¸ìĥģìĿĦ&#34;:6227,&#34;ĠìķĦë¦Ħëĭµê²Į&#34;:6228,&#34;ìĭ¸ìĽĢ&#34;:6229,&#34;Ġì§Ħë¶Ģíķĺê³ł&#34;:6230,&#34;ĠíĮ¨ëŁ¬ëĶĶ&#34;:6231,&#34;Ġì¢ĭê²łëĦ¤ìļĶ&#34;:6232,&#34;Ġì¿ł&#34;:6233,&#34;Ġê°ĲìłķìĿ´ìŀħ&#34;:6234,&#34;as&#34;:6235,&#34;cg&#34;:6236,&#34;Ĩĵ&#34;:6237,&#34;Ġëĳ&#34;:6238,&#34;ãħĬ&#34;:6239,&#34;ì§Ģê¸Īë´ĲëıĦ&#34;:6240,&#34;ĠìŀĪëĦ¤&#34;:6241,&#34;ĠìĿ´ëŁ´&#34;:6242,&#34;ìĸ´ë²Ħë¦°&#34;:6243,&#34;ëĭĪê°Ģ&#34;:6244,&#34;ìķĦëĵ¤&#34;:6245,&#34;ìĿ¸ëĵ¤ìĿĺ&#34;:6246,&#34;êµīìŀ¥íŀĪ&#34;:6247,&#34;íķ´ì§Ģê³ł&#34;:6248,&#34;Ġê·¸ë§Įíģ¼&#34;:6249,&#34;ìĬ¤íĤ¤&#34;:6250,&#34;ìłķíĻĶ&#34;:6251,&#34;ìļ°ê°Ģ&#34;:6252,&#34;ìĥģëĭ¹íŀĪ&#34;:6253,&#34;ĠìĭľíĤ¤&#34;:6254,&#34;Ġê¸°ë°ľ&#34;:6255,&#34;êµŃìĺģ&#34;:6256,&#34;ĠìĥĿê°ģìľ¼ë¡ľ&#34;:6257,&#34;Ġê°ľë§īìŀ¥&#34;:6258,&#34;ëĲĺë©´&#34;:6259,&#34;Ġì¡°ìŀ¡&#34;:6260,&#34;Ġë´¤ëĬĶëį°ëıĦ&#34;:6261,&#34;Ġíķłë¨¸ëĭĪ&#34;:6262,&#34;Ġì£½ìĿ´ëĬĶ&#34;:6263,&#34;ìĺĪìłĦ&#34;:6264,&#34;íĮĲíĥĢì§Ģ&#34;:6265,&#34;Ġë¬µ&#34;:6266,&#34;ĠìĪł&#34;:6267,&#34;ĠëıĻìĭľìĹĲ&#34;:6268,&#34;ĠìĿ´ê±°ë³´ê³ł&#34;:6269,&#34;ĠëıĪìĿĦ&#34;:6270,&#34;ìĽłìĬµëĭĪëĭ¤&#34;:6271,&#34;ĠìĿ´ìĥģìĿĺ&#34;:6272,&#34;íĽĪíĽĪ&#34;:6273,&#34;Ġíķľë²ĪëıĦ&#34;:6274,&#34;íķľêµŃìĺģíĻĶ&#34;:6275,&#34;Ġëħ¸ëŀĺëıĦ&#34;:6276,&#34;íķ´ìķ¼ì§Ģ&#34;:6277,&#34;Ġë³Ģíĥľ&#34;:6278,&#34;ĠëŃĺê¹Į&#34;:6279,&#34;ĠìŀĲìĭłìĿĦ&#34;:6280,&#34;ĠëĵľëĿ¼ë§ĪëĿ¼&#34;:6281,&#34;ĠíĮ¬ìĿ´&#34;:6282,&#34;ëĮĦ&#34;:6283,&#34;Ġìľłëªħíķľ&#34;:6284,&#34;¤ì¼Ģ&#34;:6285,&#34;Ġ=&#34;:6286,&#34;Ġy&#34;:6287,&#34;ëĬĶëĵ¯&#34;:6288,&#34;ê°ĢëĦ¤&#34;:6289,&#34;ĠìĺģíĻĶìĿ¸ê°Ģ&#34;:6290,&#34;ìĸ´ê°ĢëĬĶ&#34;:6291,&#34;ĠìķĦëıĻ&#34;:6292,&#34;ìłĲì£¼ê³ł&#34;:6293,&#34;Ġëĭĺ&#34;:6294,&#34;ìĥģíķľ&#34;:6295,&#34;ìĺ¤ë¸Į&#34;:6296,&#34;ëħķ&#34;:6297,&#34;Ġìĸ´ëĳĲ&#34;:6298,&#34;Ġì§ĢëĤ¬&#34;:6299,&#34;ëĥĪëĭ¤&#34;:6300,&#34;Ġìĭľê±¸&#34;:6301,&#34;ĠìĬ¤íĮĮìĿ´&#34;:6302,&#34;ì¹ĺëħ¸&#34;:6303,&#34;íĸĪì§Ģ&#34;:6304,&#34;Ġëª¨íĹĺ&#34;:6305,&#34;Ġë³¸ê²Į&#34;:6306,&#34;ë¹¡&#34;:6307,&#34;Ġê°ĲëıĻìĿĺ&#34;:6308,&#34;ë¦¬ëĦ¤ìļĶ&#34;:6309,&#34;Ġì¡°ìłĪ&#34;:6310,&#34;Ġëĭ¤ìĭľëĬĶ&#34;:6311,&#34;ĠìĤ´ëĭ¤&#34;:6312,&#34;ĠíķĺëĤĺë¡ľ&#34;:6313,&#34;ĠìĺĪê³ł&#34;:6314,&#34;ê²¨ìļ¸&#34;:6315,&#34;íĶ¼ìĬ¤&#34;:6316,&#34;ĠìĿ´ê±´ëŃĲ&#34;:6317,&#34;ĠìķĦê¹ĮìĽłëĭ¤&#34;:6318,&#34;Ġê¹Ģê¸°ëįķ&#34;:6319,&#34;Ġìĭ¬ì§Ģìĸ´&#34;:6320,&#34;ìĹĩëĬĶëį°&#34;:6321,&#34;ìŀ¬ë¯¸ìŀĪê³ł&#34;:6322,&#34;Ġëªĩë²ĪìĿĦ&#34;:6323,&#34;ĠìĹ°ê¸°ëł¥ìĿĢ&#34;:6324,&#34;Ġì¹ĺë°Ģ&#34;:6325,&#34;ìĵ°ê³ł&#34;:6326,&#34;ĠìĿĺë¯¸ê°Ģ&#34;:6327,&#34;Ġëĭµëĭµíķľ&#34;:6328,&#34;ì¡¸ëĿ¼&#34;:6329,&#34;ê°ĳëĭĪëĭ¤&#34;:6330,&#34;ê±°ê°ĻìķĦìļĶ&#34;:6331,&#34;ĠìĿĢê·¼&#34;:6332,&#34;ëļĿ&#34;:6333,&#34;Ġëıĭë³´ìĿ´ëĬĶ&#34;:6334,&#34;Ġê²¨ìļ¸&#34;:6335,&#34;ë¬ĺíķľ&#34;:6336,&#34;ĠëĤĺë¨¸ì§Ģ&#34;:6337,&#34;ĠìłĦë¬¸ê°Ģ&#34;:6338,&#34;ë¢°ë§¤&#34;:6339,&#34;ë·Ķ&#34;:6340,&#34;ut&#34;:6341,&#34;Ġ;&#34;:6342,&#34;Ġë¥¼&#34;:6343,&#34;íĻĶìĿ´íĮħ&#34;:6344,&#34;Ġíľĺ&#34;:6345,&#34;ìłĲìľ¼ë¡ľ&#34;:6346,&#34;ìĭľìĺ¤&#34;:6347,&#34;ìŀĲìĻĢ&#34;:6348,&#34;ìĹĨê²Į&#34;:6349,&#34;Ġíķĺê¸¸ëŀĺ&#34;:6350,&#34;ì¹Ń&#34;:6351,&#34;ìŀĳìĿĢ&#34;:6352,&#34;íĥĳ&#34;:6353,&#34;Ġìŀ¬ë¯¸ìĻĢ&#34;:6354,&#34;Ġê°Ģê³ł&#34;:6355,&#34;Ġê°Ģë¥´&#34;:6356,&#34;íķĺëĬĶê²ĥ&#34;:6357,&#34;ëŀĺê³¤&#34;:6358,&#34;ì¤ĳìĹĲìĦľ&#34;:6359,&#34;Ġì£¼ê¸°&#34;:6360,&#34;ëķĮë¬¸&#34;:6361,&#34;ëĵłì§Ģ&#34;:6362,&#34;Ġë³¸ê±°&#34;:6363,&#34;ĠìĿ´ëŁ°ìĺģíĻĶë¥¼&#34;:6364,&#34;ìĭ¬ìľ¼ë¡ľ&#34;:6365,&#34;ĠìĬ¤íĨłë¦¬ìĿĺ&#34;:6366,&#34;Ġì¤ĳìĹĲìĦľ&#34;:6367,&#34;Ġê±°ë¶Ģ&#34;:6368,&#34;ĠìĺģêµŃ&#34;:6369,&#34;ìľĦìĹĲ&#34;:6370,&#34;ë´Ĳì£¼&#34;:6371,&#34;Ġë¶Ħëĵ¤ìĿ´&#34;:6372,&#34;ĠëıĦë§Ŀ&#34;:6373,&#34;Ġìŀ¥ë©´ëıĦ&#34;:6374,&#34;ĠëªħìŀĳìĿĦ&#34;:6375,&#34;ë³µìĿĦ&#34;:6376,&#34;Ġêµ¬ìĦ±ìĿ´&#34;:6377,&#34;ĠëĲ©ëĭĪëĭ¤&#34;:6378,&#34;ĠëĤ®ëĦ¤&#34;:6379,&#34;íıīìĿ´&#34;:6380,&#34;ëĬĶê±°ìķ¼&#34;:6381,&#34;Ġë³´ì§Ģë§ĪëĿ¼&#34;:6382,&#34;ĠìĨĲìĹĲ&#34;:6383,&#34;ĠëĶĶíħĮìĿ¼&#34;:6384,&#34;ê±´ê°ĢìļĶ&#34;:6385,&#34;Ġê´ľì°®ìĿĢëį°&#34;:6386,&#34;ĠìĿ½ìĸ´&#34;:6387,&#34;Ġì§ĢëĤĺì¹ĺê²Į&#34;:6388,&#34;łìłģìľ¼ë¡ľ&#34;:6389,&#34;ëĬ¦ê²Į&#34;:6390,&#34;ì§ĢëĦ¤&#34;:6391,&#34;ëıĦë¥¼&#34;:6392,&#34;ĠìĹł&#34;:6393,&#34;ëĤĺëĭĪ&#34;:6394,&#34;ë³´ìĺģ&#34;:6395,&#34;ìĽĶìĿ´&#34;:6396,&#34;íķĺê³łìĭ¶&#34;:6397,&#34;ê·¸ëŁ¼&#34;:6398,&#34;ê²łì£ł&#34;:6399,&#34;ìķħíķľ&#34;:6400,&#34;ĠìŀĲìĭĿ&#34;:6401,&#34;Ġìľłì§Ģ&#34;:6402,&#34;ì¢ĭëĦ¤ìļĶ&#34;:6403,&#34;Ġê°ĲìķĪ&#34;:6404,&#34;Ġìĺģìĸ´&#34;:6405,&#34;Ġìĺģíĸ¥&#34;:6406,&#34;!!!!!!&#34;:6407,&#34;íĭ°ì¦Į&#34;:6408,&#34;ĠìĿ´ìķ¼ê¸°ëĬĶ&#34;:6409,&#34;Ġë³Ħë¡ľê³ł&#34;:6410,&#34;Ġìĭ¬íķĺê²Į&#34;:6411,&#34;ëĵ±ìŀ¥&#34;:6412,&#34;ë°ĽëĬĶ&#34;:6413,&#34;ìĤ¬ë¡ľ&#34;:6414,&#34;ĠìĥĿíĻľ&#34;:6415,&#34;Ġë°ĺìłĦìĿĢ&#34;:6416,&#34;Ġë°ĽìĿĢ&#34;:6417,&#34;Ġìĵ°ëĬĶ&#34;:6418,&#34;ĠìĶ¹&#34;:6419,&#34;ëĪĦëĤĺ&#34;:6420,&#34;Ġëį°ìĿ´&#34;:6421,&#34;ĠíĽĮë¥Ńíķĺëĭ¤&#34;:6422,&#34;Ġë¬´ìĦľìĽĮ&#34;:6423,&#34;ë¶Ģë¶ĦìĿ´&#34;:6424,&#34;ĠíĻķìĭ¤&#34;:6425,&#34;ìłľëª©ìĿ´&#34;:6426,&#34;ĠêµĲíĽĪìĿĦ&#34;:6427,&#34;Ġë³¼ìĪĺìŀĪëĬĶ&#34;:6428,&#34;ìĭ«ìĸ´&#34;:6429,&#34;ëĵľëĿ¼ë§Īë¥¼&#34;:6430,&#34;ĠìĺģìĽĲíŀĪ&#34;:6431,&#34;ĠDVD&#34;:6432,&#34;ĹĦ&#34;:6433,&#34;ê¸°ê¹Įì§Ģ&#34;:6434,&#34;ìłĲìłĲ&#34;:6435,&#34;ìĭľë¦¬&#34;:6436,&#34;ë³´ìĿ´ëĬĶ&#34;:6437,&#34;Ġ13&#34;:6438,&#34;íķĺëĬĶìĺģíĻĶ&#34;:6439,&#34;ĠëĮĢì¤ĳ&#34;:6440,&#34;íĸĪìĹĪëĬĶëį°&#34;:6441,&#34;ĠìķĪìĬµ&#34;:6442,&#34;ê°ľê°Ģ&#34;:6443,&#34;Ġëª»íķĺëĭ¤&#34;:6444,&#34;Ġìķłëĵ¤ìĿĢ&#34;:6445,&#34;ê¸´íķĺì§Ģë§Į&#34;:6446,&#34;ĠìĽĥê³ł&#34;:6447,&#34;Ġìŀ¬ë¯¸ìĹĨìĹĪëĭ¤&#34;:6448,&#34;ë°ĶëŀĮ&#34;:6449,&#34;íĹĪë¬´&#34;:6450,&#34;ĠëķĮëł¤&#34;:6451,&#34;ëĬĲê»´&#34;:6452,&#34;ĠëªħìŀĳìŀħëĭĪëĭ¤&#34;:6453,&#34;ì©ľ&#34;:6454,&#34;Ġìŀ¼ëĤĺê²Į&#34;:6455,&#34;ìĥĿê°ģìĿ´&#34;:6456,&#34;ĠìŀĪëĭ¤ëĭĪ&#34;:6457,&#34;Ġì§ľì¦ĿëĤĺìĦľ&#34;:6458,&#34;íĪ¬ë¦¬&#34;:6459,&#34;Ġì§ĳìĹĲ&#34;:6460,&#34;Ġê²°ë§ĲìĿĦ&#34;:6461,&#34;Ġëĭ´ìķĦ&#34;:6462,&#34;ĠìĤ¶ìĹĲ&#34;:6463,&#34;ìĺ¬íķ´&#34;:6464,&#34;ìŀĸìķĦìļĶ&#34;:6465,&#34;Ġë²ĶìĿ¸&#34;:6466,&#34;Ġì£¼ìłľë¥¼&#34;:6467,&#34;Ġìĥīëĭ¤ë¥¸&#34;:6468,&#34;ãħħãħĤ&#34;:6469,&#34;Ġíĺ¹ìĿĢ&#34;:6470,&#34;íĢ´&#34;:6471,&#34;ĠìĨĮì¤ĳíķľ&#34;:6472,&#34;ĠëĤĺìģĺì§Ģ&#34;:6473,&#34;íĮ©íĬ¸&#34;:6474,&#34;ëī´&#34;:6475,&#34;ìĿ´ìĸ´&#34;:6476,&#34;ìĸ´íľ´&#34;:6477,&#34;ĠëĤŃ&#34;:6478,&#34;ë§ĮëıĦ&#34;:6479,&#34;ëĿ¼ìĿĺ&#34;:6480,&#34;Ġë³´ëįĺ&#34;:6481,&#34;ìĭľì¹´&#34;:6482,&#34;ĲëıĻ&#34;:6483,&#34;Ġì°°&#34;:6484,&#34;ĠëĮĢìĤ¬ëĵ¤&#34;:6485,&#34;íĸĪìĿĦëķĮ&#34;:6486,&#34;íĮł&#34;:6487,&#34;ì¤ĳíĽĪ&#34;:6488,&#34;Ġë¬´ë¦¬&#34;:6489,&#34;ë¶ĦìĿĺ&#34;:6490,&#34;ĠëĤ¨ëĦ¤ìļĶ&#34;:6491,&#34;Ġìľłë°ľ&#34;:6492,&#34;ĠìĤ¬ì§Ħ&#34;:6493,&#34;íĶĦëĭĿ&#34;:6494,&#34;Ġìĭľê°Ħê°ĢëĬĶì¤Ħ&#34;:6495,&#34;íĽĦìĿĺ&#34;:6496,&#34;Ġê°ķíķľ&#34;:6497,&#34;ìĽĥê¹Ģ&#34;:6498,&#34;Ġìĭ¬ìĺ¤&#34;:6499,&#34;ëĵľëĿ¼ë§ĪëĬĶ&#34;:6500,&#34;ĠëĤ®ì§Ģ&#34;:6501,&#34;ĠìłģìłĪ&#34;:6502,&#34;ĠìķĦìī½ì§Ģë§Į&#34;:6503,&#34;ĠíĿ¥ë¯¸ë¡ľìļ´&#34;:6504,&#34;ĠìĽĥê¸°ì§ĢëıĦ&#34;:6505,&#34;Ġìĸ´ìĥīíķĺê³ł&#34;:6506,&#34;ì»¤íĶĮ&#34;:6507,&#34;ê¹ĬìĿĢ&#34;:6508,&#34;Ġì¶ĶìĸµìĿ´&#34;:6509,&#34;ê°ĳìŀĲê¸°&#34;:6510,&#34;Ġì§ĳì¤ĳìĿ´&#34;:6511,&#34;íķĺìŀĲëĬĶ&#34;:6512,&#34;ë¿Į&#34;:6513,&#34;50&#34;:6514,&#34;Ġ007&#34;:6515,&#34;ìĿ´ìĹ°ê±¸&#34;:6516,&#34;íķĺëŁ¬&#34;:6517,&#34;ê°ĢìĹĲ&#34;:6518,&#34;ĠìĹ½&#34;:6519,&#34;Ġë§¹&#34;:6520,&#34;ìĸ´ëĤľ&#34;:6521,&#34;ìķĦì¹ĺ&#34;:6522,&#34;ĠìķĦìĹŃ&#34;:6523,&#34;ĮĢìĿĺ&#34;:6524,&#34;ìĭľê±¸&#34;:6525,&#34;ìļ°ìļ¸&#34;:6526,&#34;ìĪĺë¡ľ&#34;:6527,&#34;ìĪĺìŀĳ&#34;:6528,&#34;ìĥģìĪĺ&#34;:6529,&#34;ãħłãħľ&#34;:6530,&#34;Ġìĸ´ëĳ&#34;:6531,&#34;Ġë´¤ëĦ¤&#34;:6532,&#34;ë¶Ģë¥¼&#34;:6533,&#34;ĠìĪĺìŀħ&#34;:6534,&#34;ë¶Ħíķľ&#34;:6535,&#34;ìĦ¸íı¬&#34;:6536,&#34;ê°ĲìĤ¬&#34;:6537,&#34;Ġê°Ļê³ł&#34;:6538,&#34;Ġìµľê³łìĺĢëĭ¤&#34;:6539,&#34;íİ¸ì§ĳ&#34;:6540,&#34;ìĺĢëĦ¤&#34;:6541,&#34;ìĺĢìľ¼ë©´&#34;:6542,&#34;Ġë³¼ê±°ë¦¬&#34;:6543,&#34;ìłĢëŁ°&#34;:6544,&#34;ìĦłìĿĦ&#34;:6545,&#34;Ġìĭ¶ìĸ´ìļĶ&#34;:6546,&#34;íĺĦìŀ¬&#34;:6547,&#34;íıīìłĲìĿĢ&#34;:6548,&#34;ê°ĻìĿĢìĺģíĻĶ&#34;:6549,&#34;ĠìķĦëĭĪì§Ģ&#34;:6550,&#34;ì¦ĪìĿĺ&#34;:6551,&#34;Ġë§ĮëĵłìĺģíĻĶ&#34;:6552,&#34;ĠìĿ´ìĥģíķĺê²Į&#34;:6553,&#34;ë¹łì§Ħ&#34;:6554,&#34;ìŁģìĿ´&#34;:6555,&#34;Ġëĭ´ê²¨&#34;:6556,&#34;Ġë²łëĵľ&#34;:6557,&#34;Ġê°ĳëĭĪëĭ¤&#34;:6558,&#34;Ġìĸĳìĭ¬&#34;:6559,&#34;ëĬĲëĤĮìĿ´&#34;:6560,&#34;íĸĩëĭ¤&#34;:6561,&#34;Ġìĸ´ëĬĲìłķëıĦ&#34;:6562,&#34;Ġì²«ìĤ¬ëŀĳ&#34;:6563,&#34;Ġì°©ê°ģ&#34;:6564,&#34;Ġìĭľì²Ńë¥łìĿ´&#34;:6565,&#34;Ġë¿Į&#34;:6566,&#34;-^&#34;:6567,&#34;°Ķ&#34;:6568,&#34;ìĮ&#34;:6569,&#34;ãħĵ&#34;:6570,&#34;ìĦ¬&#34;:6571,&#34;ëıĦìķĦëĭĪê³ł&#34;:6572,&#34;ĠìĺģíĻĶìĻĢ&#34;:6573,&#34;ĠìķĦê¸°&#34;:6574,&#34;ê¹ľ&#34;:6575,&#34;ë§Īì¹ĺ&#34;:6576,&#34;Ġíķĺëĭ¤ê°Ģ&#34;:6577,&#34;ìŀĪìĿĦ&#34;:6578,&#34;ì°¡&#34;:6579,&#34;ìĦ±ê¸°&#34;:6580,&#34;Ġìŀ¬ë°Įëĭ¤ëĬĶ&#34;:6581,&#34;Ġê°ĲëıĻìĿĢ&#34;:6582,&#34;Ġê°ĲëıĻìłģìĿ´ëĭ¤&#34;:6583,&#34;ë°ķíķľ&#34;:6584,&#34;ëĤ¨ì£¼&#34;:6585,&#34;íĹĲë¦¬&#34;:6586,&#34;ĠìĺĪëĬ¥&#34;:6587,&#34;ëĬĲëģ¼&#34;:6588,&#34;ĠëĳĲë²Īì§¸&#34;:6589,&#34;ĠíĻĶëģĪ&#34;:6590,&#34;ĠìłĲìĪĺê°Ģ&#34;:6591,&#34;ĠëĤ®ìķĦ&#34;:6592,&#34;Ġë§¤ëł¥ìłģìĿ´&#34;:6593,&#34;ìĬ¤ëŁ½ì§Ģ&#34;:6594,&#34;ìŀ¬ë¯¸ìŀĪìĿĮ&#34;:6595,&#34;ĠìķĦëĭĪëĿ¼ê³ł&#34;:6596,&#34;Ġìŀ¬ëĬ¥&#34;:6597,&#34;Ġë³´ì§Ģë§Ĳ&#34;:6598,&#34;ì´ĪìĹĲ&#34;:6599,&#34;ĠìĨĲìĥī&#34;:6600,&#34;ìĹ¬ìŀĲê°Ģ&#34;:6601,&#34;ìĬ¬íĶĦ&#34;:6602,&#34;Ġìĸ´ìĦ¤íĶĦê³ł&#34;:6603,&#34;ëĿ¼ìĿ´ìĸ¸&#34;:6604,&#34;Ġê´Ģê°ĿìĿĦ&#34;:6605,&#34;Ġê¶ģê¸Īíķĺëĭ¤&#34;:6606,&#34;ë°ĺìłĦìĿ´&#34;:6607,&#34;ĠìĹīìĦ±íķĺê³ł&#34;:6608,&#34;Ġsf&#34;:6609,&#34;Ġì½ľ&#34;:6610,&#34;Ġìĭ¤ìłľë¡ľ&#34;:6611,&#34;ĠíĹ¤ìĸ´&#34;:6612,&#34;ìĻłì§Ģ&#34;:6613,&#34;ĠìĹŃëĮĢê¸ī&#34;:6614,&#34;?...&#34;:6615,&#34;es&#34;:6616,&#34;±ìłķ&#34;:6617,&#34;ĠE&#34;:6618,&#34;ì§ĢíĺĦ&#34;:6619,&#34;ìľĪ&#34;:6620,&#34;ìĬ¤ìĹĲ&#34;:6621,&#34;Ġìĺ¥&#34;:6622,&#34;ĠìĺĽ&#34;:6623,&#34;ìĹ¬ì§Ħ&#34;:6624,&#34;ìĿ¼ìĿĦ&#34;:6625,&#34;ìĿ¼ëĵ¯&#34;:6626,&#34;íķ¨ëıĦ&#34;:6627,&#34;ĠìķĬìķĦìĦľ&#34;:6628,&#34;Ġë¬´íķľ&#34;:6629,&#34;ĠëĤ´ìļ©ê³¼&#34;:6630,&#34;ì¡°ìĹ°&#34;:6631,&#34;ĠìľĦëĮĢ&#34;:6632,&#34;ë°©ê¸Ī&#34;:6633,&#34;ĠìĹĲíľ´&#34;:6634,&#34;Ġë³´ê¸°ìĹĲ&#34;:6635,&#34;ĠëĨĴìķĦìĦľ&#34;:6636,&#34;ì£¼ìĿ¸ê³µìĿĺ&#34;:6637,&#34;ìĸ¼ë§ĪëĤĺ&#34;:6638,&#34;Ġëªĩëªĩ&#34;:6639,&#34;ìĸ´ìķ¼ì§Ģ&#34;:6640,&#34;Ġì¦Ĳê²¨&#34;:6641,&#34;ĠêµĲê³¼ìĦľ&#34;:6642,&#34;Ġëª©ìĪ¨&#34;:6643,&#34;Ġíĺķëĭĺ&#34;:6644,&#34;ĠìĽĥê¸°ëĭ¤&#34;:6645,&#34;Ġë¬´ìĦŃì§ĢëıĦ&#34;:6646,&#34;ĠíĻķìĿ¸&#34;:6647,&#34;Ġì°¾ìķĦë³¼&#34;:6648,&#34;Ġì§ĳì¤ĳíķ´ìĦľ&#34;:6649,&#34;Ġë¸Ķë¡Ŀë²ĦìĬ¤íĦ°&#34;:6650,&#34;ëĨĴìĿĢ&#34;:6651,&#34;ĠìĺģíĻĺëį°&#34;:6652,&#34;Ġëĭ¤ìĸĳíķľ&#34;:6653,&#34;²Ī&#34;:6654,&#34;íĩ´&#34;:6655,&#34;ëĭ¬ë&#34;:6656,&#34;ìłĬ&#34;:6657,&#34;ëıĮìĿ´&#34;:6658,&#34;íķĺëįĶëĿ¼&#34;:6659,&#34;ĠëĤ¬&#34;:6660,&#34;Ġë³´ìķĺëĬĶëį°&#34;:6661,&#34;ë©´ìĹĲìĦľ&#34;:6662,&#34;ë°į&#34;:6663,&#34;ìłĦìĦ¤&#34;:6664,&#34;ĠìŀĪëĭ¤ê³ł&#34;:6665,&#34;Ġì§Ģê¸Īë³´&#34;:6666,&#34;Ġíķľëĭ¤ëĬĶ&#34;:6667,&#34;ì¹ĺê³¤&#34;:6668,&#34;Ġì£¼ë§Ĳ&#34;:6669,&#34;ê°ĻìķĦ&#34;:6670,&#34;Ġë§Ĳìķĺ&#34;:6671,&#34;Ġë³¼ëķĮ&#34;:6672,&#34;Ġì¡°ìļ©&#34;:6673,&#34;ëĨį&#34;:6674,&#34;íķĺì§Ģë§ĪëĿ¼&#34;:6675,&#34;Ġê²°ì½Ķ&#34;:6676,&#34;ĠëĤĺìĺ¤ëĦ¤&#34;:6677,&#34;ĠìķĦê¹Ŀê³ł&#34;:6678,&#34;ì¼°&#34;:6679,&#34;Ġì§ľì§ĳ&#34;:6680,&#34;ĠëĳĲëł¤&#34;:6681,&#34;ĠìĿ´ìĥģíķĺê³ł&#34;:6682,&#34;ĠëĤ®ëĭ¤&#34;:6683,&#34;ĠìĦłëıĻ&#34;:6684,&#34;ĠìŀĶíĺ¹&#34;:6685,&#34;Ġê°ĢìĬ´ìĿĦ&#34;:6686,&#34;ì¢ĭìĿĢëį°&#34;:6687,&#34;ìŀĩëĬĶ&#34;:6688,&#34;Ġìĭ¸ìļ°ëĬĶ&#34;:6689,&#34;ìĹ¬ëŁ¬&#34;:6690,&#34;ëĤ¸ëĭ¤&#34;:6691,&#34;Ġìĸ´ìĦ¤íĶĦ&#34;:6692,&#34;ëĺĲíķľ&#34;:6693,&#34;Ġëª°ìŀħëıĦê°Ģ&#34;:6694,&#34;ĠìķĪëĲł&#34;:6695,&#34;ìķŀìľ¼ë¡ľ&#34;:6696,&#34;ë¹¼ê³ł&#34;:6697,&#34;ĠìĬ¤íĬ¸ëłĪìĬ¤&#34;:6698,&#34;ĠìĿ¼ê¹¨ìĽĮ&#34;:6699,&#34;ìĿ´ìłł&#34;:6700,&#34;ë§Īë¬´&#34;:6701,&#34;ê³łìĥĿ&#34;:6702,&#34;ĠíĮĢ&#34;:6703,&#34;ë¡¤&#34;:6704,&#34;ìĺ¬ëĿ¼&#34;:6705,&#34;ë§Īê°Ģ&#34;:6706,&#34;ìĹĪêµ¬ëĤĺ&#34;:6707,&#34;Ġëĭ¤ìĦ¯&#34;:6708,&#34;ìĪĺíĺĦ&#34;:6709,&#34;ìŀ¥ìĿĺ&#34;:6710,&#34;ëĵľë¦¬&#34;:6711,&#34;Ġ11&#34;:6712,&#34;Ġìŀ¬ë°Įìĸ´ìĦľ&#34;:6713,&#34;ê°ĻìķĦìļĶ&#34;:6714,&#34;ìŀ¬ë¯¸ìĹĨê³ł&#34;:6715,&#34;ëıĻíĻĶ&#34;:6716,&#34;ĠëŃĲíķĺëĤĺ&#34;:6717,&#34;ìĨįìľ¼ë¡ľ&#34;:6718,&#34;ë§Īë¥¼&#34;:6719,&#34;ìĹ°ê¸°ë¥¼&#34;:6720,&#34;Ġëª°ëŀĲëĭ¤&#34;:6721,&#34;ĠìĿ´íķ´ë¥¼&#34;:6722,&#34;ĠëĺĲëĭ¤ë¥¸&#34;:6723,&#34;Ġê´Ģëł¨&#34;:6724,&#34;ĠìľĦíĹĺ&#34;:6725,&#34;Ġì§ľì¦Ŀë§Į&#34;:6726,&#34;ì£½ëĬĶ&#34;:6727,&#34;Ġìĸµì§ĢìĬ¤ëŁ¬ìļ´&#34;:6728,&#34;ĠëĤĺìĻĶëĭ¤&#34;:6729,&#34;ìŀ¬ë°ĭê²Į&#34;:6730,&#34;ìŀ¬ë°ĭìĸ´ìļĶ&#34;:6731,&#34;Ġìĸ´ì©ľ&#34;:6732,&#34;ĠíĮĲëĭ¨&#34;:6733,&#34;ĠëıĮìķĦê°Ģ&#34;:6734,&#34;ëªĩë²ĪìĿĦ&#34;:6735,&#34;Ġë§ĲëıĦìķĪëĲĺëĬĶ&#34;:6736,&#34;ëİħ&#34;:6737,&#34;Ġë°Ģëł¤&#34;:6738,&#34;ë©ĶìĿ´ëĵľ&#34;:6739,&#34;ĠìĹ°ìĺĪìĿ¸&#34;:6740,&#34;Ġìĸ´ìļ°ëŁ¬&#34;:6741,&#34;est&#34;:6742,&#34;íķĺê±°ëĤĺ&#34;:6743,&#34;íķľìĭ¬&#34;:6744,&#34;íķľê°ľëıĦ&#34;:6745,&#34;ĠìĺģíĻĶë§Į&#34;:6746,&#34;ĠìĹ¬ë¦Ħ&#34;:6747,&#34;ìĿ¸ê±´&#34;:6748,&#34;ĠìķĦëĤĺ&#34;:6749,&#34;ĠìķĦëĤ´&#34;:6750,&#34;ìĭľê°Ģ&#34;:6751,&#34;ĠìłķíĻķ&#34;:6752,&#34;ê·¸ëĭ¥&#34;:6753,&#34;ĠìĭľëģĦ&#34;:6754,&#34;ìĿ¼ìĿĺ&#34;:6755,&#34;ìĤ¬ìĻĢ&#34;:6756,&#34;ìĭłê³ł&#34;:6757,&#34;ĠìŀĺíķĺëĬĶ&#34;:6758,&#34;íĬľ&#34;:6759,&#34;Ġë¶Ģë¥´&#34;:6760,&#34;Ġì¡°ìĦł&#34;:6761,&#34;ìķłëĵ¤ìĿĢ&#34;:6762,&#34;ĠëªħíĻĶ&#34;:6763,&#34;Ġìŀ¬ë¯¸ìĹĨìĸ´ìĦľ&#34;:6764,&#34;ê²½ìĿ´&#34;:6765,&#34;íĮĲìĿ´&#34;:6766,&#34;ĠíĸĪìĿĮ&#34;:6767,&#34;ìĤ´ìķĦ&#34;:6768,&#34;Ġë³Ħë¡ľìŀĦ&#34;:6769,&#34;ì°¸ê³ł&#34;:6770,&#34;Ġëª¨ëĵłê±¸&#34;:6771,&#34;ì¢ħêµĲ&#34;:6772,&#34;ì²ĺìĿĮìľ¼ë¡ľ&#34;:6773,&#34;íĮ¨ìĬ¤&#34;:6774,&#34;Ġìŀ¬ë°ĭëĭ¤&#34;:6775,&#34;Ġëħ¸ëŀĺê°Ģ&#34;:6776,&#34;Ġìŀĳê°Ģëĭĺ&#34;:6777,&#34;Ġì©Ŀ&#34;:6778,&#34;Ġë¹µë¹µ&#34;:6779,&#34;ĠìĺĪìģĺëĭ¤&#34;:6780,&#34;íŀĺëĵ¤&#34;:6781,&#34;Ġíķľìĭ¬íķľ&#34;:6782,&#34;ª¨ë¡ľ&#34;:6783,&#34;ĠíĽĪíĽĪíķľ&#34;:6784,&#34;Ġëıħë¦½ìĺģíĻĶ&#34;:6785,&#34;ì¨Į&#34;:6786,&#34;Ġê·¸ë¦½ëĭ¤&#34;:6787,&#34;ĠìĹĲíĶ¼ìĨĮëĵľ&#34;:6788,&#34;Ġe&#34;:6789,&#34;ìĿ´ê²ĥ&#34;:6790,&#34;ë©¸&#34;:6791,&#34;Ġê·¸ëŀ&#34;:6792,&#34;ìľ¼ëł¤ê³ł&#34;:6793,&#34;ìŀĲê¾¸&#34;:6794,&#34;ĠìĹĨê²Į&#34;:6795,&#34;ĠìĹĨìĹĪìĿĮ&#34;:6796,&#34;ĠëĮĢëĨĵê³ł&#34;:6797,&#34;êµ¬ê°Ģ&#34;:6798,&#34;Ġë¬´ë£Į&#34;:6799,&#34;ĠëĬĶ&#34;:6800,&#34;ĠíĺĲ&#34;:6801,&#34;Ġìĺ¤ë¹ł&#34;:6802,&#34;ĠìĤ¬ëŀĮëıĦ&#34;:6803,&#34;ĠëĲĺëĦ¤ìļĶ&#34;:6804,&#34;Ġìĭ¶ì§Ģ&#34;:6805,&#34;ì¤ĦìĿĢ&#34;:6806,&#34;Ġê²°ìłķ&#34;:6807,&#34;ë¶ĢíĦ°ê°Ģ&#34;:6808,&#34;ìĭľê°ĦìĿĦ&#34;:6809,&#34;ĠìĹ°ì¶ľìĿĢ&#34;:6810,&#34;Ġì§ľìŀĦìĥĪ&#34;:6811,&#34;Ġìŀ¥ë©´ìĿĦ&#34;:6812,&#34;Ġê´ľì°®ìķĺëĭ¤&#34;:6813,&#34;ìĻĶëĬĶëį°&#34;:6814,&#34;Ġë§ĪìĿĮìľ¼ë¡ľ&#34;:6815,&#34;ëĤ´ê°Ģë³¸&#34;:6816,&#34;Ġì§ľì¦ĿëĤ¨&#34;:6817,&#34;íĪ°&#34;:6818,&#34;Ġë´¤ëĭ¤ë©´&#34;:6819,&#34;Ġëĸ¨ìĸ´ì§Ĳ&#34;:6820,&#34;ìµľê³łìĿĺìĺģíĻĶ&#34;:6821,&#34;ĠíĥĢê³ł&#34;:6822,&#34;ìĿĮìķħìĿ´&#34;:6823,&#34;íģ¬ëł&#34;:6824,&#34;ĠëķľìĹĲ&#34;:6825,&#34;Ġëĭ¤ë¥´ê²Į&#34;:6826,&#34;Ġë¹µíĦ°&#34;:6827,&#34;Ġë§ĪìĿ´íģ´&#34;:6828,&#34;Ġëģ¼ìĽĮ&#34;:6829,&#34;ìį¼&#34;:6830,&#34;ĠP&#34;:6831,&#34;ëĭ·&#34;:6832,&#34;íķĢ&#34;:6833,&#34;ê°ĪëķĮ&#34;:6834,&#34;ìĹĲìĿ´&#34;:6835,&#34;ĠìĺģíĻĶìĿ¸ì§Ģ&#34;:6836,&#34;ĠìĿ´ìłķ&#34;:6837,&#34;ìĸ´ìļ©&#34;:6838,&#34;ëĿ¼ëħ¸&#34;:6839,&#34;ëł´&#34;:6840,&#34;ĠìķĦëĥĲ&#34;:6841,&#34;Ġìłķìŀĳ&#34;:6842,&#34;ë¶ĢìĿĺ&#34;:6843,&#34;ĠìĥĿê°ģëıĦ&#34;:6844,&#34;Ġêµ´&#34;:6845,&#34;ëĵ¤ìĿ´ëĤĺ&#34;:6846,&#34;ĠìŀĲëŀĳ&#34;:6847,&#34;ĠìķĮê²łëĭ¤&#34;:6848,&#34;ìĺģìĽħ&#34;:6849,&#34;Ġë°°ìļ°ëıĦ&#34;:6850,&#34;ì§ģíķľ&#34;:6851,&#34;Ġê°ĲíŀĪ&#34;:6852,&#34;ìŀ¬ë°ĮëĬĶ&#34;:6853,&#34;Ġìŀ¬ë¯¸ìĹĨìĸ´ìļĶ&#34;:6854,&#34;ë¯¼ìĿ´&#34;:6855,&#34;ê·¹ìĿĦ&#34;:6856,&#34;ë³¼ëķĮë§Īëĭ¤&#34;:6857,&#34;ìĽĥê²¨&#34;:6858,&#34;Ġë§ŀì¶°&#34;:6859,&#34;íĹĪíĹĪ&#34;:6860,&#34;Ġãħĭãħĭãħĭãħĭãħĭãħĭ&#34;:6861,&#34;ĠìķĦê¹Įìļ´ìĺģíĻĶ&#34;:6862,&#34;Ġì¶ľìĹ°íķľ&#34;:6863,&#34;ĠìĿ½ê³ł&#34;:6864,&#34;ãħĭãħĭãħĭãħĭãħĭãħĭãħĭãħĭãħĭãħĭãħĭãħĭãħĭãħĭãħĭãħĭãħĭãħĭãħĭãħĭãħĭãħĭãħĭãħĭãħĭãħĭãħĭãħĭãħĭãħĭãħĭãħĭ&#34;:6865,&#34;ëĪĪë¬¼ìĿ´&#34;:6866,&#34;ìĭ«ëĭ¤&#34;:6867,&#34;ê¸°ìĸµìĹĲ&#34;:6868,&#34;ìº¬&#34;:6869,&#34;ê·¸ëŁ¬ëĤĺ&#34;:6870,&#34;ĠìĿ´ëĶ°ìľĦ&#34;:6871,&#34;ĠíĶĮë¡¯&#34;:6872,&#34;ë¡ľë§¨ìĬ¤&#34;:6873,&#34;ĠìķĦë¥ĺìŀĳ&#34;:6874,&#34;ì·&#34;:6875,&#34;ëĭĪëĿ¼&#34;:6876,&#34;ìĿ´ìĹ¬&#34;:6877,&#34;ë§Įíķĺëĭ¤&#34;:6878,&#34;ë¦¬ìĻĢ&#34;:6879,&#34;Ġìłł&#34;:6880,&#34;ë©ľ&#34;:6881,&#34;íķ´ìĦł&#34;:6882,&#34;Ġë³´íĨµ&#34;:6883,&#34;Ġëª¬&#34;:6884,&#34;ìľ¼ìĭł&#34;:6885,&#34;ĠëĦĮ&#34;:6886,&#34;ì¹ĺì§Ģ&#34;:6887,&#34;ë¶Ģëª¨&#34;:6888,&#34;Ġë³¸ê±´ëį°&#34;:6889,&#34;ĠëĤ¨ê¸°&#34;:6890,&#34;Ġê²ĥìĹĲ&#34;:6891,&#34;ìĹĪëĭ¤ê³ł&#34;:6892,&#34;Ġë¹ħ&#34;:6893,&#34;ìŀ¬ë¯¸ìŀĪëĬĶ&#34;:6894,&#34;ĠìŀĳìľĦ&#34;:6895,&#34;Ġë¶Ģíĥģ&#34;:6896,&#34;ĠìķĪë´&#34;:6897,&#34;ĠíĹĮ&#34;:6898,&#34;Ġê³łë§Ļ&#34;:6899,&#34;Ġë§¤ìĿ¼&#34;:6900,&#34;ìĭĿìĿĢ&#34;:6901,&#34;Ġìķ¡ìħĺìĿĦ&#34;:6902,&#34;Ġì¶Ķê²©&#34;:6903,&#34;ì°¨ë³Ħ&#34;:6904,&#34;Ġê´ľì°®ìĿĮ&#34;:6905,&#34;íĺķìłľ&#34;:6906,&#34;ìŀĺë´¤ìĬµëĭĪëĭ¤&#34;:6907,&#34;ìĹĩìĿĮ&#34;:6908,&#34;ìķĪëĲľ&#34;:6909,&#34;ìĥĿê°ģìĿĦ&#34;:6910,&#34;ĠìķĦìĿ´ê°Ģ&#34;:6911,&#34;Ġë°ĽëĬĶ&#34;:6912,&#34;Ġë³µìŀ¡&#34;:6913,&#34;ĠìĺģíĻĶëĿ¼ëĭĪ&#34;:6914,&#34;ìĭľëĮĢë¥¼&#34;:6915,&#34;ë³´ì§Ģë§ĪìĦ¸ìļĶ&#34;:6916,&#34;íķĺì§ĢìķĬê³ł&#34;:6917,&#34;ëĶ°ëľ»íķľ&#34;:6918,&#34;ĠìľłìĿ¼íķľ&#34;:6919,&#34;Ġê²¬ìŀĲëĭ¨&#34;:6920,&#34;ìĩĦ&#34;:6921,&#34;Ġn&#34;:6922,&#34;ħĢ&#34;:6923,&#34;ëį¸&#34;:6924,&#34;ë¡ľì§Ģ&#34;:6925,&#34;...^^&#34;:6926,&#34;ìĿ¸ì§ĢëıĦ&#34;:6927,&#34;Ġëĭ¬ëł¤&#34;:6928,&#34;ìĽ¬&#34;:6929,&#34;ë§ĪìŀĲ&#34;:6930,&#34;ĠìĹĨëĤĺìļĶ&#34;:6931,&#34;ì£¼ê¸°&#34;:6932,&#34;ìĥģìĿĢ&#34;:6933,&#34;ĠìķĪê°Ħëĭ¤&#34;:6934,&#34;ê¹Įì§ĢëıĦ&#34;:6935,&#34;Ġë¯¸ìĬ¤íĦ°&#34;:6936,&#34;ĠìĤ¬ëŀĮëĵ¤ìĹĲê²Į&#34;:6937,&#34;ì¢ĭê²Į&#34;:6938,&#34;Ġê³µê°Ħ&#34;:6939,&#34;ĠëĤ´ìļ©ìĿ¸ì§Ģ&#34;:6940,&#34;ì¤Ħê±°ë¦¬&#34;:6941,&#34;ĠìĤ´ë©´ìĦľ&#34;:6942,&#34;Ġìŀ¼ìŀĪëĭ¤&#34;:6943,&#34;ì½§&#34;:6944,&#34;ĠìĦľë¶Ģ&#34;:6945,&#34;ìŀ¡ìĿĦ&#34;:6946,&#34;ëĬĶê±°ì§Ģ&#34;:6947,&#34;Ġê·¹ìŀ¥ê°ĢìĦľ&#34;:6948,&#34;ìķ¡ìħĺìĿĢ&#34;:6949,&#34;Ġëĭ´ë°°&#34;:6950,&#34;ĠìķĦìī¬ìĽĢìĿ´&#34;:6951,&#34;ĠìĺģíĻĶìĺĢìĿĮ&#34;:6952,&#34;ĠëĤļìĭľ&#34;:6953,&#34;Ġê¿Īê¾¸&#34;:6954,&#34;ëª¨ë¥´ê³ł&#34;:6955,&#34;Ġë¹ĦëĶĶìĺ¤ë¡ľ&#34;:6956,&#34;ĠìķķëıĦ&#34;:6957,&#34;ì¤¬ìľ¼ë©´&#34;:6958,&#34;ìĻłë§Įíķĺë©´&#34;:6959,&#34;Ġì¤ĺìķ¼&#34;:6960,&#34;Ġëĭ¤ìļ´ë°ĽìķĦ&#34;:6961,&#34;ĠíķĺëĤĺíķĺëĤĺê°Ģ&#34;:6962,&#34;Ġë¥ĺìĬ¹&#34;:6963,&#34;ĠìĬ¬íİĲ&#34;:6964,&#34;ht&#34;:6965,&#34;¡íĮ¨&#34;:6966,&#34;ĠL&#34;:6967,&#34;ëĭ¼&#34;:6968,&#34;ìĸ´ìĿĺ&#34;:6969,&#34;ë¡ľìį¨&#34;:6970,&#34;ëĿ¼ëĿ¼&#34;:6971,&#34;ë¦¬ëĤĺ&#34;:6972,&#34;Ġë³´ëĤ´&#34;:6973,&#34;ìłķê³¼&#34;:6974,&#34;ìłĦìĿĦ&#34;:6975,&#34;ê·¸ëķĮ&#34;:6976,&#34;ìĬµëĭĪê¹Į&#34;:6977,&#34;ëŀĺëıĦ&#34;:6978,&#34;Ġìŀ¬ë°ĮìĿĦ&#34;:6979,&#34;Ġì¤įëĭĪëĭ¤&#34;:6980,&#34;ë¶ĦìĿĦ&#34;:6981,&#34;ìĦ¸ìĹ¬&#34;:6982,&#34;ê°Ĳìłķ&#34;:6983,&#34;Ġë³¸ë°©ìĤ¬ìĪĺ&#34;:6984,&#34;ĠëģĿëĤ¬&#34;:6985,&#34;ë§Ŀìŀĳ&#34;:6986,&#34;Ġê±°ë¶ģ&#34;:6987,&#34;ì§ĪìĿ´&#34;:6988,&#34;Ġìĭľê°ĦìĹĲ&#34;:6989,&#34;Ġëĸ¼&#34;:6990,&#34;Ġê·¹ë³µ&#34;:6991,&#34;Ġìļ¸ë¦¬ëĬĶ&#34;:6992,&#34;Ġëĭ¨íİ¸&#34;:6993,&#34;Ġì§ľì¦ĿëĤĺê³ł&#34;:6994,&#34;íĿ¬ê°Ģ&#34;:6995,&#34;ìķ¡ìħĺìĿ´&#34;:6996,&#34;ĠëłĪìķĮ&#34;:6997,&#34;Ġê·ĢìĹ¬ìĽĮ&#34;:6998,&#34;Ġìľłì¾Įíķĺê³ł&#34;:6999,&#34;Ġë¶ĪìĮįíķĺëĭ¤&#34;:7000,&#34;Ġë§ĽìĿ´&#34;:7001,&#34;Ġof&#34;:7002,&#34;Ġìĺ¬íķ´&#34;:7003,&#34;Ġë§Ĳíķĺê³łìŀĲ&#34;:7004,&#34;ĠëĨĢëŀįëĭ¤&#34;:7005,&#34;ĠìĿ´ë»ĲìĦľ&#34;:7006,&#34;Ġ&gt;&#34;:7007,&#34;ìĿ´ìļĶ&#34;:7008,&#34;ëĤĢ&#34;:7009,&#34;ë¦ĩ&#34;:7010,&#34;ìĥĺ&#34;:7011,&#34;ë³´ëĤ´&#34;:7012,&#34;ìļ°ìĿĺ&#34;:7013,&#34;ìłĦìĿ´&#34;:7014,&#34;Ġìłķì²´&#34;:7015,&#34;ĠìĬ¤íİĺ&#34;:7016,&#34;ĠìĽ°&#34;:7017,&#34;ĠìŀĲìĦ¸&#34;:7018,&#34;ĠëĤ¨íİ¸&#34;:7019,&#34;Ġìĺ¤ë¸Į&#34;:7020,&#34;ë²Ħì§Ģê°Ģ&#34;:7021,&#34;Ġë¶Ģìĭ¤&#34;:7022,&#34;Ġ21&#34;:7023,&#34;Ġê°Ĳê°ģ&#34;:7024,&#34;Ġë°ĺëĵľìĭľ&#34;:7025,&#34;ë°Ķë³´&#34;:7026,&#34;ĠìŀĳíĴĪìŀħëĭĪëĭ¤&#34;:7027,&#34;ĠëķĮë§Īëĭ¤&#34;:7028,&#34;ì²ľìŀ¬&#34;:7029,&#34;íĸĪëĭ¤ë©´&#34;:7030,&#34;ìĭľê°ĦëĤŃë¹Ħ&#34;:7031,&#34;Ġë°°ìĭł&#34;:7032,&#34;ì§ĳìĹĲ&#34;:7033,&#34;ê°ĲëıĻìłģìĿ´ê³ł&#34;:7034,&#34;ĠìłķëıĦë©´&#34;:7035,&#34;ì¡ĮìĿĮ&#34;:7036,&#34;Ġë°Ľê³ł&#34;:7037,&#34;Ġìĺģìĥģê³¼&#34;:7038,&#34;Ġë¨¸ë¦¬ê°Ģ&#34;:7039,&#34;ĠìĨĮìŀ¬ëĬĶ&#34;:7040,&#34;Ġëª¨ë¥´ê²łëĦ¤ìļĶ&#34;:7041,&#34;ì¿¡&#34;:7042,&#34;ìľ¤ë°ľ&#34;:7043,&#34;ĠíĿĲë¥´ëĬĶ&#34;:7044,&#34;ĠëģĮê³ł&#34;:7045,&#34;ĠìĿ´ë¦ĦìĿĦ&#34;:7046,&#34;Ġì±ħìŀĦ&#34;:7047,&#34;ĠíĥĪì¶ľ&#34;:7048,&#34;íķŃìĥģ&#34;:7049,&#34;ìĿ´ìĹĲ&#34;:7050,&#34;íķĺê·ł&#34;:7051,&#34;ëĤ©&#34;:7052,&#34;ëĵŃ&#34;:7053,&#34;ìķĦë§Ī&#34;:7054,&#34;ìĹĨìĿĦ&#34;:7055,&#34;ĠëĤĺëĦ¤ìļĶ&#34;:7056,&#34;Ġëĭ¤ìĿ´&#34;:7057,&#34;ìŀ¥ìĭ¤&#34;:7058,&#34;ĠëĵŃëĭĪëĭ¤&#34;:7059,&#34;Ġì§Ģê²¹&#34;:7060,&#34;íķłë§Įíķľ&#34;:7061,&#34;Ġëį¤&#34;:7062,&#34;ìĤ¬ìĹĲ&#34;:7063,&#34;Ġìŀĺë´¤ìĸ´ìļĶ&#34;:7064,&#34;íĬĢ&#34;:7065,&#34;ĠëĬ¦&#34;:7066,&#34;ĠìĿ¸íĺķ&#34;:7067,&#34;Ġê°ľëħĲ&#34;:7068,&#34;ì¤Ģíĺ¸&#34;:7069,&#34;ë³´ëĭ¤ëıĦ&#34;:7070,&#34;ëįĶëįĶ&#34;:7071,&#34;Ġìļ°ë¦¬ëĬĶ&#34;:7072,&#34;ĠìĽĥìľ¼ë©´ìĦľ&#34;:7073,&#34;Ġìĭ¤ëł¥&#34;:7074,&#34;ĠëıĻìĦ±ìķł&#34;:7075,&#34;ëª»íķ´&#34;:7076,&#34;Ġë§īíĮĲìĹĲ&#34;:7077,&#34;ĠìĦ¤ìłķìĿ´&#34;:7078,&#34;Ġë§Ŀíķľ&#34;:7079,&#34;Ġë§ŀì§Ģ&#34;:7080,&#34;ĠìĦłë¬¼&#34;:7081,&#34;Ġì§ĳìĸ´&#34;:7082,&#34;ê¸°ëıĦíķĺê³ł&#34;:7083,&#34;ĠìĹ´ìĹ°&#34;:7084,&#34;ê¸°ëĮĢíķĺê³ł&#34;:7085,&#34;Ġëĭ´ìĿĢ&#34;:7086,&#34;Ġì´Īëĵ±íķĻìĥĿ&#34;:7087,&#34;ê´ĳê³ł&#34;:7088,&#34;ĠëĤļìĺĢëĭ¤&#34;:7089,&#34;Ġìĺ¤ëŀĺëĲľ&#34;:7090,&#34;Ġëĭ¤ë¥´ëĭ¤&#34;:7091,&#34;Ġëĭ¹ìĭłìĿĢ&#34;:7092,&#34;Ġì§§ìĿĢ&#34;:7093,&#34;ĠìŀĬíĺĢì§Ģ&#34;:7094,&#34;Ġê°ĢëĵĿíķľ&#34;:7095,&#34;ĠëģĶì°į&#34;:7096,&#34;ĠëĿĦ&#34;:7097,&#34;ĠF&#34;:7098,&#34;ĠN&#34;:7099,&#34;..!&#34;:7100,&#34;¬ëĦ¤&#34;:7101,&#34;ĠìĿ´ë¯¼&#34;:7102,&#34;ìķĦì¹¨&#34;:7103,&#34;Ġê·¸ëĵ¤&#34;:7104,&#34;ìłĲë¶ĢíĦ°&#34;:7105,&#34;Ġë°ĸ&#34;:7106,&#34;ĠìĹĨìľ¼ë©´&#34;:7107,&#34;Ġì¢ĭëĭ¤ê³ł&#34;:7108,&#34;ì£¼ë©´&#34;:7109,&#34;ìŀĪì§Ģë§Į&#34;:7110,&#34;ĠëĦĪë¬´ëıĦ&#34;:7111,&#34;ĠëĮĢìĭł&#34;:7112,&#34;Ġìŀ¬ë°Įëįĺëį°&#34;:7113,&#34;ĠìķĪëĤĺ&#34;:7114,&#34;Ġìµľê³łë´ī&#34;:7115,&#34;ĠëģĪ&#34;:7116,&#34;Ġë³¸ëĵ¯&#34;:7117,&#34;Ġê°ĲëıĻë°Ľ&#34;:7118,&#34;Ġê¹į&#34;:7119,&#34;ĠíĿ¬ë&#34;:7120,&#34;Ġíĸĩ&#34;:7121,&#34;Ġì¤ĳëıħ&#34;:7122,&#34;ĠìķłêµŃ&#34;:7123,&#34;ë¬¼ë¡ł&#34;:7124,&#34;ìŀ¬ë°ĮìĹĪìĸ´ìļĶ&#34;:7125,&#34;Ġìŀ¬ë¯¸ìĹĨëĭ¤ê³ł&#34;:7126,&#34;ãĦ²&#34;:7127,&#34;ëĤ¨ê¸°&#34;:7128,&#34;ìĦ¤ë§Ī&#34;:7129,&#34;ì¦Īê°Ģ&#34;:7130,&#34;ĠìķĦê¹ĿëĦ¤ìļĶ&#34;:7131,&#34;Ġë§Īì§Ģë§īê¹Įì§Ģ&#34;:7132,&#34;ĠìĦ¤ë§Ī&#34;:7133,&#34;ĠìłĦê°ľìĻĢ&#34;:7134,&#34;Ġë°ĺìłĦìĿĦ&#34;:7135,&#34;ê¶ĮìĿ´&#34;:7136,&#34;Ġì¦Ĳê¸¸&#34;:7137,&#34;ìĵ°ëĬĶ&#34;:7138,&#34;ìŀ¬ë°ĭìĿĮ&#34;:7139,&#34;Ġìŀłìĭľ&#34;:7140,&#34;ê²¬ìŀĲëĭ¨&#34;:7141,&#34;Ġì¼Ģë¦ŃíĦ°&#34;:7142,&#34;Ġìĸ¼êµ´ìĿ´&#34;:7143,&#34;Ġê½¤ëĤĺ&#34;:7144,&#34;ìķĦëĭĮê°Ģ&#34;:7145,&#34;ìĪĻíķľ&#34;:7146,&#34;Ġì½©&#34;:7147,&#34;Ġë¬»ìĸ´&#34;:7148,&#34;âĢ¦&#34;:7149,&#34;ĠëĨĢëĿ¼ìļ´&#34;:7150,&#34;ĠíĶ¼íķ´ìŀĲ&#34;:7151,&#34;ĠìĿ¼ë¶ĢëŁ¬&#34;:7152,&#34;ìĿ´ìłķëıĦë©´&#34;:7153,&#34;Ġëĭ¤íģĲë©ĺíĦ°ë¦¬&#34;:7154,&#34;Ġyou&#34;:7155,&#34;ĳëĮĢ&#34;:7156,&#34;ĠëĹĦ&#34;:7157,&#34;ìĿ´ì£ł&#34;:7158,&#34;ìŀĪëĥĲ&#34;:7159,&#34;ì§ĢìĹĲ&#34;:7160,&#34;ëĤ©ëĭĪëĭ¤&#34;:7161,&#34;¬ëĦ¤ìļĶ&#34;:7162,&#34;ëıĦë¡ľ&#34;:7163,&#34;ëłĽ&#34;:7164,&#34;ĠìĹĨëĭ¤ê³ł&#34;:7165,&#34;ĠëĤ´ê²Į&#34;:7166,&#34;ķĮë¬¸ìĹĲ&#34;:7167,&#34;ë¯¸ì¹ĺ&#34;:7168,&#34;íŀĪê³ł&#34;:7169,&#34;íĸĪìĿĦê¹Į&#34;:7170,&#34;ĠìĪĺë§İìĿĢ&#34;:7171,&#34;ë£¨íĨł&#34;:7172,&#34;Ġë¬´ê²Į&#34;:7173,&#34;ë¶Ħëĵ¤ìĿĢ&#34;:7174,&#34;ê°ľìĿ¸&#34;:7175,&#34;ĠìĿ¸ëĶĶ&#34;:7176,&#34;Ġìµľê³łë¡ľ&#34;:7177,&#34;Ġêµ¬ë¦¬&#34;:7178,&#34;ìłĢê¸°&#34;:7179,&#34;ìķĪëı¼&#34;:7180,&#34;Ġìķłë§¤&#34;:7181,&#34;ĠìłĢê¸ī&#34;:7182,&#34;ë°ĶëĿ¼&#34;:7183,&#34;ĠìĹŃìĤ¬ë¥¼&#34;:7184,&#34;Ġë°Ķíĥķ&#34;:7185,&#34;ĠëıĻìĸĳ&#34;:7186,&#34;ë³¼ìĪĺë¡Ŀ&#34;:7187,&#34;ë³´ëĬĶê²Į&#34;:7188,&#34;Ġê´ľì°®ê³ł&#34;:7189,&#34;Ġì¤Ħê±°&#34;:7190,&#34;Ġë§¤ëł¥ìĹĲ&#34;:7191,&#34;ĠìłķëıĦê°Ģ&#34;:7192,&#34;ĠìĥĿê¸´&#34;:7193,&#34;ĠìķĦë¬´ëŁ°&#34;:7194,&#34;ĠíĮĮìĽĮ&#34;:7195,&#34;Ġê³§&#34;:7196,&#34;ìµľìķħìĿ´ëĭ¤&#34;:7197,&#34;ìĬ¬íĶĦëĭ¤&#34;:7198,&#34;ĠìķĮë°Ķëĵ¤&#34;:7199,&#34;ĠìĤ¬ìĭ¤ìĿĦ&#34;:7200,&#34;ì±ħìĿĦ&#34;:7201,&#34;ĠìķĬìķĺëįĺ&#34;:7202,&#34;ë¡Ńê³ł&#34;:7203,&#34;ê±°ê°ĻìĿĮ&#34;:7204,&#34;ìĿ´íķ´ê°Ģ&#34;:7205,&#34;Ġë¹ĽìĿĦ&#34;:7206,&#34;ĠìłĦìĦ¤ìĿĺ&#34;:7207,&#34;ìĬĪíį¼&#34;:7208,&#34;ëĳ¥ìĿ´&#34;:7209,&#34;Ġìĸ´ëł¸ìĿĦëķĮ&#34;:7210,&#34;¬ë°ķ&#34;:7211,&#34;ĠíĬ¹ìĪĺíļ¨ê³¼&#34;:7212,&#34;ĠëĮĦ&#34;:7213,&#34;ow&#34;:7214,&#34;¨¹&#34;:7215,&#34;ĠX&#34;:7216,&#34;ľ¨&#34;:7217,&#34;ìĿ´ëĵł&#34;:7218,&#34;ê°Ģë³įê²Į&#34;:7219,&#34;ëıĦìĿĺ&#34;:7220,&#34;ê²ĮíķĺëĬĶ&#34;:7221,&#34;ëĭĪì½ľ&#34;:7222,&#34;ëį°ì²´&#34;:7223,&#34;ìĺµ&#34;:7224,&#34;ìĬ¤íĨ¤&#34;:7225,&#34;ê¹ĮìļĶ&#34;:7226,&#34;Ġíķĺìĭľ&#34;:7227,&#34;ìļ°ìĬ¤&#34;:7228,&#34;Ġìĺ¹&#34;:7229,&#34;íĥĲ&#34;:7230,&#34;ĠíķľìĪ¨&#34;:7231,&#34;íķ¨ê»ĺ&#34;:7232,&#34;ë¶Ħë§ĮìĹĲ&#34;:7233,&#34;ĠìķĪëĵ¤&#34;:7234,&#34;ê°ĻìķĦìĦľ&#34;:7235,&#34;ĠìĽ¨&#34;:7236,&#34;ìŀĦìĹĲëıĦ&#34;:7237,&#34;ĠìĥĿê°ģëĤľëĭ¤&#34;:7238,&#34;ìľłë¦¬&#34;:7239,&#34;ìŀ¬ë¯¸ìŀĩ&#34;:7240,&#34;ĠëŃĲëĭĪ&#34;:7241,&#34;Ġìķłê¸°&#34;:7242,&#34;Ġê³łëĩĮ&#34;:7243,&#34;ìľĦìĽĲ&#34;:7244,&#34;ĠíĥĿ&#34;:7245,&#34;ì´¬ìĺģ&#34;:7246,&#34;Ġë©ĭì§Ģê³ł&#34;:7247,&#34;Ġê´ľì°®ëĭ¤&#34;:7248,&#34;ìĤ¬ëŀĮìĿĺ&#34;:7249,&#34;ë¨¹ìĿĢ&#34;:7250,&#34;ê·¼ëŀĺ&#34;:7251,&#34;ĠíĺĦìĭ¤ìĿ´&#34;:7252,&#34;Ġì§ľì¦ĿìĿ´&#34;:7253,&#34;ìĬ¤ëŁ¬ìĽĮ&#34;:7254,&#34;ë¶ĪíĹĪ&#34;:7255,&#34;ë³ĳíĹĮ&#34;:7256,&#34;ĠãħĤ&#34;:7257,&#34;ìĹ¬ë²Ħ&#34;:7258,&#34;Ġêµ¿êµ¿&#34;:7259,&#34;ìĿĮìķħëıĦ&#34;:7260,&#34;íĥĪì¶ľ&#34;:7261,&#34;ìŀ¬ë¯¸ìĹĨìĸ´ìļĶ&#34;:7262,&#34;Ġê¶ģê¸Īíķ´ìĦľ&#34;:7263,&#34;ìĭľëĮĢìĹĲ&#34;:7264,&#34;Ġìŀ¥ë¥´ê°Ģ&#34;:7265,&#34;Ġbê¸ī&#34;:7266,&#34;¶ĢíĦ°&#34;:7267,&#34;ê¸°ìĸµìĿ´&#34;:7268,&#34;Ġdvd&#34;:7269,&#34;ì§Ħë¶Ģíķľ&#34;:7270,&#34;ìĥĪë¡ľìļ´&#34;:7271,&#34;al&#34;:7272,&#34;ic&#34;:7273,&#34;Ġk&#34;:7274,&#34;ĠìŃī&#34;:7275,&#34;ëĬĶê±¸&#34;:7276,&#34;ìłĪë¡ľ&#34;:7277,&#34;ĠìŀĲëıĻ&#34;:7278,&#34;ĠìĺģíĻĶë³´ë©´ìĦľ&#34;:7279,&#34;ëĤĺê°Ħ&#34;:7280,&#34;ë§Įì¡±&#34;:7281,&#34;ë¦¬ìĹĦ&#34;:7282,&#34;ìķĦëħ¸&#34;:7283,&#34;ìĺģíĻĶìĹĲìĦľ&#34;:7284,&#34;ìĹĨì§Ģ&#34;:7285,&#34;ĠëĤĺìĺ¬ë&#34;:7286,&#34;ì§ĦìķĬ&#34;:7287,&#34;Ġìŀ¬ë¯¸ë¡ľ&#34;:7288,&#34;ĠëĤ´ìĥĿ&#34;:7289,&#34;íķłë¿Ĳ&#34;:7290,&#34;ìĹ°ìķł&#34;:7291,&#34;Ġê°Ģë³į&#34;:7292,&#34;ë¯¸ëĬĶ&#34;:7293,&#34;Ġ199&#34;:7294,&#34;ëĵłê°Ģ&#34;:7295,&#34;Ġì²©&#34;:7296,&#34;Ġë§ĲìŀĲ&#34;:7297,&#34;ë¬´ìĭľ&#34;:7298,&#34;ĠìĤ¬ìļ©&#34;:7299,&#34;Ġì¡°íĻĶ&#34;:7300,&#34;ĠíĮĿ&#34;:7301,&#34;íķĺì§Ģë§Ī&#34;:7302,&#34;ëĭµëĭĪëĭ¤&#34;:7303,&#34;Ġë©ĭìŀĪëĬĶ&#34;:7304,&#34;íĺ¸ê°Ĳ&#34;:7305,&#34;ìĽłê³ł&#34;:7306,&#34;ì¹´íĶĦ&#34;:7307,&#34;ì¹´ë©ĶëĿ¼&#34;:7308,&#34;Ġë§Ŀì¹ľ&#34;:7309,&#34;ì°¸ìĭł&#34;:7310,&#34;ê»ĺìļĶ&#34;:7311,&#34;Ġì°įê³ł&#34;:7312,&#34;ĠëĨĢëŀĲ&#34;:7313,&#34;Ġë´Ĳìķ¼ì§Ģ&#34;:7314,&#34;Ġìĭ¸ìĽĢ&#34;:7315,&#34;©´ìĦľ&#34;:7316,&#34;Ġê°ģìĥī&#34;:7317,&#34;ĠìĪĺìŀĳìĿ´ëĭ¤&#34;:7318,&#34;ĠëĶ°ëľ»íķĺê³ł&#34;:7319,&#34;ĠCê¸ī&#34;:7320,&#34;ĠìŀĶìŀĶíķĺê³ł&#34;:7321,&#34;íķĻêµĲìĹĲìĦľ&#34;:7322,&#34;ìŀĶìŀĶíķĺê³ł&#34;:7323,&#34;;;;;;;;;&#34;:7324,&#34;Ġë¦¬ìĸ¼ë¦¬íĭ°&#34;:7325,&#34;ĠìĨĮìĦ¤ìĿĦ&#34;:7326,&#34;ĠìĭĿìĥģíķľ&#34;:7327,&#34;ĠíĿ¬ë§ĿìĿĦ&#34;:7328,&#34;íĽĮë¥Ńíķľ&#34;:7329,&#34;199&#34;:7330,&#34;60&#34;:7331,&#34;½ķ&#34;:7332,&#34;ëĭ¤ë¥´&#34;:7333,&#34;íķĺìĿ´&#34;:7334,&#34;ĠìĺģíĻĶëĤĺ&#34;:7335,&#34;ĠìĺģíĻĶìķ¼&#34;:7336,&#34;ìĿĢëį°&#34;:7337,&#34;ëĵ¤ë¡ľ&#34;:7338,&#34;ë¥ľ&#34;:7339,&#34;ë³´ê¸´&#34;:7340,&#34;ìĬ¤ë§¨&#34;:7341,&#34;ëŀŃ&#34;:7342,&#34;ìĹĨëĤĺ&#34;:7343,&#34;ì£¼ê¸°ëıĦ&#34;:7344,&#34;ìĥģìłģìĿ¸&#34;:7345,&#34;Ġì§Ģê²¨&#34;:7346,&#34;Ġíķľë°©&#34;:7347,&#34;íķłì§Ģ&#34;:7348,&#34;ĠëĮĢíĨµëł¹&#34;:7349,&#34;ë¶ĢëĬĶ&#34;:7350,&#34;êµ¬ìĿĺ&#34;:7351,&#34;ë¶ĦëıĻìķĪ&#34;:7352,&#34;Ġì£¼ì§Ģ&#34;:7353,&#34;ê°Ĳê³¼&#34;:7354,&#34;íĬ¸ë¡ľ&#34;:7355,&#34;ĠìĿ¼ìľ¼&#34;:7356,&#34;íĤ¬ë§ģíĥĢìŀĦ&#34;:7357,&#34;Ġê°ĲëıħìĿĦ&#34;:7358,&#34;Ġìŀ¬ë¯¸ìŀĪìĬµëĭĪëĭ¤&#34;:7359,&#34;Ġë°ĺëĮĢ&#34;:7360,&#34;ë°ķì£½&#34;:7361,&#34;Ġë§¤ëĭĪìķĦ&#34;:7362,&#34;ĠëĤĺìĺ¤ëĬĶëį°&#34;:7363,&#34;ëĿ¼ëĬĶê²Į&#34;:7364,&#34;Ġë¡ľì½Ķ&#34;:7365,&#34;Ġìĸ´ëĸ¨&#34;:7366,&#34;ĠëĬĲëĤĮìĿĢ&#34;:7367,&#34;ĠíŀĺëĤ´&#34;:7368,&#34;Ġì£¼ìĿ¸ê³µëĵ¤&#34;:7369,&#34;ê°ĲëıĻëıĦ&#34;:7370,&#34;ĠëĭµìĿ´&#34;:7371,&#34;ëĤ¬ìĿĮ&#34;:7372,&#34;Ġê¹Ĭê²Į&#34;:7373,&#34;ĠìłĲìĪĺëĬĶ&#34;:7374,&#34;ĠìłĲìĪĺì¤Ģ&#34;:7375,&#34;ĪëįĶëĿ¼ë©´&#34;:7376,&#34;ìľłì¹ĺíķľ&#34;:7377,&#34;ìľłì¹ĺíķĺê³ł&#34;:7378,&#34;Ġë§Įëĵ¤ìĹĪìĿĦê¹Į&#34;:7379,&#34;Ġê·ĢìĹ½ëĭ¤&#34;:7380,&#34;Ġãħīãħīãħī&#34;:7381,&#34;ĠíĥĦíĥĦíķĺê³ł&#34;:7382,&#34;ì¶ĶìĸµìĿĺ&#34;:7383,&#34;21&#34;:7384,&#34;od&#34;:7385,&#34;ot&#34;:7386,&#34;¤ëĭ¤&#34;:7387,&#34;ìĿĺë¥¼&#34;:7388,&#34;ìķĦì§Ģ&#34;:7389,&#34;Ġê·¸ê²ĥìĿĦ&#34;:7390,&#34;ê¹ĥ&#34;:7391,&#34;Ġì¢ĭìĿĦëĵ¯&#34;:7392,&#34;Ġëĭ¤ìĭł&#34;:7393,&#34;ìŀĪì§Ģ&#34;:7394,&#34;Ġìĥĺ&#34;:7395,&#34;ìķĺìľ¼ë©´&#34;:7396,&#34;êµŃìĿĺ&#34;:7397,&#34;ĠìķĪìĸ´ìļ¸&#34;:7398,&#34;Ġìµľê³łìŀĦ&#34;:7399,&#34;ë¬´íĺĳ&#34;:7400,&#34;ë¹Ħì¶Ķ&#34;:7401,&#34;ìĺĢëĤĺ&#34;:7402,&#34;ê±¸ìŀĳ&#34;:7403,&#34;Ġë¹Ħíĸī&#34;:7404,&#34;ëıĻìĽĲ&#34;:7405,&#34;Ġìĭ¤íĹĺ&#34;:7406,&#34;ì§ĪìķĬ&#34;:7407,&#34;ìĬ¨ìĿ´&#34;:7408,&#34;ëŀĢíĭ°&#34;:7409,&#34;ĠìķĦê¹ĿëĦ¤&#34;:7410,&#34;Ġë¶Īê°ĢëĬ¥&#34;:7411,&#34;Ġì²ĺìĿĮìĹĶ&#34;:7412,&#34;Ġê·¹ëĭ¨&#34;:7413,&#34;ì©į&#34;:7414,&#34;Ġëĭ¹ìĹ°íŀĪ&#34;:7415,&#34;ĠëĬĲëĤĮìĿ´ëĭ¤&#34;:7416,&#34;ê°ĲëıĻìĿ´&#34;:7417,&#34;Īë°©&#34;:7418,&#34;ì£½ë°ķì£½&#34;:7419,&#34;Ġì»¸&#34;:7420,&#34;ĠíĮĮê´´&#34;:7421,&#34;Ġëĭ´ê¸´&#34;:7422,&#34;ĠìŀĬê³ł&#34;:7423,&#34;Ġìķ¼íķľ&#34;:7424,&#34;Ġë¬´ìĹĩìĿ¸ê°Ģ&#34;:7425,&#34;ĠíıŃë°ľ&#34;:7426,&#34;ĠíıŃíĴį&#34;:7427,&#34;ì²łíķĻ&#34;:7428,&#34;ë§ĪìĿĮìĹĲ&#34;:7429,&#34;Ġëª»ë³´ê²łëĭ¤&#34;:7430,&#34;Ġìŀ¤ëĭ¤&#34;:7431,&#34;Ġìĭľë¦¬ì¦&#34;:7432,&#34;íķĺëĶĶ&#34;:7433,&#34;íķĺëĭĪê¹Į&#34;:7434,&#34;ê°ĢëģĶ&#34;:7435,&#34;ëĤĺê°ĢëĬĶ&#34;:7436,&#34;ëĿ¼ìĿ¸&#34;:7437,&#34;ëŁ¬ëĿ¼&#34;:7438,&#34;ìŀĲë§ī&#34;:7439,&#34;ìĽŁ&#34;:7440,&#34;ĠìĹĨëĥĲ&#34;:7441,&#34;ìłģìľ¼ë¡ł&#34;:7442,&#34;Ġë§ĮëĤľ&#34;:7443,&#34;Ġìŀ¬ë¯¸ìŀĩ&#34;:7444,&#34;ìĤ¬ê·¹&#34;:7445,&#34;ê²łëĬĶëį°&#34;:7446,&#34;ê°ľëħĲ&#34;:7447,&#34;~~^^&#34;:7448,&#34;ìĹĪëĭ¤ë©´&#34;:7449,&#34;ìĶ¹&#34;:7450,&#34;ìŀ¬ë¯¸ìĹĨëĬĶ&#34;:7451,&#34;Ġë§Įëĵ¤ìĸ´ìĦľ&#34;:7452,&#34;ĠëĤ´ìļ©ìĹĲ&#34;:7453,&#34;ĠìĤ¬ëŀĳíķ´ìļĶ&#34;:7454,&#34;ìľĦê°Ģ&#34;:7455,&#34;ìľĦíķľ&#34;:7456,&#34;Ġëĭ¤ìĭľë³´ëĭĪ&#34;:7457,&#34;ìĬ¨ìĿĺ&#34;:7458,&#34;íļĮê°Ģ&#34;:7459,&#34;Ġíĥĵ&#34;:7460,&#34;ĠìĿ´íķ´ìķĪ&#34;:7461,&#34;ĠìĪĻ&#34;:7462,&#34;Ġê´ľì°®ìķĺëĬĶëį°&#34;:7463,&#34;ìŀĺëª»&#34;:7464,&#34;Ġê¹Ģë¯¼&#34;:7465,&#34;ëĤ´ìļ©ìĿ¸ì§Ģ&#34;:7466,&#34;ĠëĲ¬&#34;:7467,&#34;Ġê³¼íķĻ&#34;:7468,&#34;ì¡Įëįĺ&#34;:7469,&#34;Ġë§İìĿĢê±¸&#34;:7470,&#34;ĠíĴĪ&#34;:7471,&#34;ĠìķĬìĿĢëį°&#34;:7472,&#34;ìķ¡ìħĺëıĦ&#34;:7473,&#34;ì´Īëĵ±íķĻêµĲ&#34;:7474,&#34;ĠìĨĮìŀ¬ìĻĢ&#34;:7475,&#34;Ġìĭľìŀĳíķ´ìĦľ&#34;:7476,&#34;Ġìŀ¬ë¯¸ëıĦìĹĨê³ł&#34;:7477,&#34;ëłĪìĿ´ëĵľ&#34;:7478,&#34;ìķĹëĭ¤&#34;:7479,&#34;Ġëķ¡&#34;:7480,&#34;ĠëķĲ&#34;:7481,&#34;Ġìķ½ê°ĦìĿĺ&#34;:7482,&#34;êµ³êµ³&#34;:7483,&#34;ì´Īë°ĺìĹĲ&#34;:7484,&#34;ĠìĨĮì¤ĳíķ¨ìĿĦ&#34;:7485,&#34;Ġìĸ´ë¦´ìłģ&#34;:7486,&#34;ìĽ¨ìĿ´&#34;:7487,&#34;ĠìĹ¬ëŁ¬ê°Ģì§Ģ&#34;:7488,&#34;ê¶ģê¸Ī&#34;:7489,&#34;ĠíĬ¹ë³Ħíķľ&#34;:7490,&#34;Ġëĳĺì§¸ì¹ĺê³ł&#34;:7491,&#34;ë·°&#34;:7492,&#34;ëĭ¤ë§Į&#34;:7493,&#34;ê¸°ìĻĢ&#34;:7494,&#34;ëĤĺë¥¼&#34;:7495,&#34;ìķĦìĹŃ&#34;:7496,&#34;Ġê°Ŀ&#34;:7497,&#34;ëį°ë¯¸&#34;:7498,&#34;ĠìķĦëŀĺ&#34;:7499,&#34;ĠìķĦíĮĮ&#34;:7500,&#34;ìĭľê¸°&#34;:7501,&#34;ë³´ìĭľê¸¸&#34;:7502,&#34;ëĮĢìĹĲ&#34;:7503,&#34;ìŀĪìľ¼ë©´&#34;:7504,&#34;ìĥģìĹĲ&#34;:7505,&#34;Ġìĸ´íľ´&#34;:7506,&#34;ìĭłëıĦ&#34;:7507,&#34;Ġê±±ìłķ&#34;:7508,&#34;ëķĮë§¤&#34;:7509,&#34;ìĨĮê°Ģ&#34;:7510,&#34;ëĵ¤ìĿ´ëŀĳ&#34;:7511,&#34;ìłķë§Ĳë¡ľ&#34;:7512,&#34;Ġë¯¸ì³¤&#34;:7513,&#34;ëĲĺëĤĺ&#34;:7514,&#34;ìĦłìĿ´&#34;:7515,&#34;ìĦłíĥĿ&#34;:7516,&#34;íĭĭ&#34;:7517,&#34;ëıĻë¬¼&#34;:7518,&#34;ĠëŃĲê³ł&#34;:7519,&#34;ĠëŃĲíķĺëĬĶ&#34;:7520,&#34;ĠìĹŃëŁī&#34;:7521,&#34;Ġë°Ķëĭ¤&#34;:7522,&#34;ĠìĹĨëĬĶê²Į&#34;:7523,&#34;ì²Ńì¶ĺ&#34;:7524,&#34;ĠìĭłìĿĺ&#34;:7525,&#34;Ġì£½ìĹ¬&#34;:7526,&#34;ĠìĿ´íķ´íķłìĪĺ&#34;:7527,&#34;Ġë°°íĬ¸ë§¨&#34;:7528,&#34;ìŀĺë§Įëĵ¤&#34;:7529,&#34;...........&#34;:7530,&#34;íĮĮì¹ĺëħ¸&#34;:7531,&#34;ĠìłĲìĿ´&#34;:7532,&#34;ë¹łìł¸&#34;:7533,&#34;íıīìĥĿ&#34;:7534,&#34;ì§ĢìķĬëĬĶëĭ¤&#34;:7535,&#34;ĠìĥĿìĹĲ&#34;:7536,&#34;Ġë´Ĳìķ¼íķĺëĬĶ&#34;:7537,&#34;ëĪĦêµ°&#34;:7538,&#34;ìĽĶíķľ&#34;:7539,&#34;ĠìĭľëĮĢìĹĲ&#34;:7540,&#34;ĠìĿ´ë¦ĦìĿ´&#34;:7541,&#34;Ġê°ĸëĭ¤&#34;:7542,&#34;ìķĮë°Ķëĵ¤&#34;:7543,&#34;Ġìŀĺëª»ëĲľ&#34;:7544,&#34;Ġì«ĵ&#34;:7545,&#34;Ġì¹ľêµ¬ê°Ģ&#34;:7546,&#34;Ġë§ĮìłĲìĹĲ&#34;:7547,&#34;âĺħâĺħ&#34;:7548,&#34;ë¦¬ë©´ìĦľ&#34;:7549,&#34;ĠíĿ¡ìŀħ&#34;:7550,&#34;Ġê°Ģë²¼ìļ´&#34;:7551,&#34;ìĹĲëĮĢíķ´&#34;:7552,&#34;?..&#34;:7553,&#34;ĳ¼&#34;:7554,&#34;íķĺìĭ¤&#34;:7555,&#34;¬ë½ķ&#34;:7556,&#34;Ġíĺģ&#34;:7557,&#34;ìĭ¼&#34;:7558,&#34;ëĤĺìģĺ&#34;:7559,&#34;ĠëĤ¯&#34;:7560,&#34;ëĵ¤íķľíħĮ&#34;:7561,&#34;ìĿ¸ê²Į&#34;:7562,&#34;Ġë³´ëĿ¼ê³ł&#34;:7563,&#34;Ġê·¸ê²ĥìĿ´&#34;:7564,&#34;ĠëĤĺìĺ¬ëķĮ&#34;:7565,&#34;ĠíķĺìĹ¬&#34;:7566,&#34;ìķ¼íķľëĭ¤&#34;:7567,&#34;ì£¼ì§Ģ&#34;:7568,&#34;ì£¼ìĿ¼&#34;:7569,&#34;ìłģìĿ´ëĿ¼&#34;:7570,&#34;ĠìĻ¤ì¼Ģ&#34;:7571,&#34;ê³¼ê±°&#34;:7572,&#34;ìķĺëĦ¤&#34;:7573,&#34;íĶĶìĿ´&#34;:7574,&#34;ì¹ĺìĿĺ&#34;:7575,&#34;ĠìĨĶ&#34;:7576,&#34;Ġìŀ¬ë°ĮìĹĪëįĺ&#34;:7577,&#34;ĠìķĪê°Ģ&#34;:7578,&#34;ĠëŃ£&#34;:7579,&#34;ĠìĻľê³¡&#34;:7580,&#34;íĬ¸ë¥¼&#34;:7581,&#34;ìłĢì§Ī&#34;:7582,&#34;ëįĶë§¨&#34;:7583,&#34;ë²Ħë¦´&#34;:7584,&#34;Ġìľłíĸī&#34;:7585,&#34;Ġìŀ¥ìķł&#34;:7586,&#34;ĠìĤ¬ëŀĮìĿ´ëĿ¼ë©´&#34;:7587,&#34;ĠëĤ´ìļ©ìĿĺ&#34;:7588,&#34;ëĭĺìĿĢ&#34;:7589,&#34;Ġë§¤ë¯¸&#34;:7590,&#34;Ġë§¤ëģĦ&#34;:7591,&#34;ë§Īë¥´&#34;:7592,&#34;Ġìĭľê°Ħë§Į&#34;:7593,&#34;Ġì£½ê³ł&#34;:7594,&#34;ĠëıĦë¬´ì§Ģ&#34;:7595,&#34;ĠíķľêµŃìĹĲìĦľ&#34;:7596,&#34;Ġëĭ¹íĻ©&#34;:7597,&#34;Ġìļ¸ë©´ìĦľ&#34;:7598,&#34;Ġë§Ŀê°Ģ&#34;:7599,&#34;Ġë§ŀìķĦ&#34;:7600,&#34;ĠìłķëıĦëĬĶ&#34;:7601,&#34;ìĤ¬ëŀĳìĿĦ&#34;:7602,&#34;Ġíİ¸ìķĪ&#34;:7603,&#34;Ġê³µê°Ĳíķł&#34;:7604,&#34;Ġë²Ħë¦¬ê³ł&#34;:7605,&#34;Ġíĺ¸ê¸°&#34;:7606,&#34;ìŀĸìĿĢ&#34;:7607,&#34;ĪëįĶëĿ¼&#34;:7608,&#34;Īë³´ëĭ¤&#34;:7609,&#34;ĠìĬ¤íĨłë¦¬ëĿ¼&#34;:7610,&#34;ê·¸ëŁ°ëį°&#34;:7611,&#34;Ġë¨¼ê°Ģ&#34;:7612,&#34;ìľ¼ë©´ìĦľëıĦ&#34;:7613,&#34;ìĸ´ë¦°ìĭľìłĪ&#34;:7614,&#34;Ġë¶Īíİ¸íķľ&#34;:7615,&#34;ĠãĦ·ãĦ·ãĦ·&#34;:7616,&#34;ĠìļĶìĨĮê°Ģ&#34;:7617,&#34;Ġë£¨ì¦Ī&#34;:7618,&#34;ĠìľłìĿ¼íķĺê²Į&#34;:7619,&#34;Ġì»¨ìħī&#34;:7620,&#34;ëıħíĬ¹íķľ&#34;:7621,&#34;Ġìłłìŀ¥&#34;:7622,&#34;ì¹´íĶĦë¦¬ìĺ¤&#34;:7623,&#34;ĠK&#34;:7624,&#34;ĠìĺģíĻĶìĺĪìļĶ&#34;:7625,&#34;ĠìĹ¼&#34;:7626,&#34;ëĤĺìĿ´íĬ¸&#34;:7627,&#34;ĠìłĪë¡ľ&#34;:7628,&#34;ëĵ¤ëģ¼ë¦¬&#34;:7629,&#34;ìłķìĹĲ&#34;:7630,&#34;ìłķì©¡&#34;:7631,&#34;ë§ĪìĿĺ&#34;:7632,&#34;ê¹Įì§Ģë§Į&#34;:7633,&#34;ìļ°ë¦¬ê°Ģ&#34;:7634,&#34;ìĥģê³¼&#34;:7635,&#34;ê°ĦìĹĲ&#34;:7636,&#34;Ġìĸ´ëĶ&#34;:7637,&#34;Ġìĸ´ëķ&#34;:7638,&#34;ëĵľëŁ½ê²Į&#34;:7639,&#34;ì¹ĺë¥¼&#34;:7640,&#34;Ġë¬´ëĤľ&#34;:7641,&#34;ë¶Ħëªħ&#34;:7642,&#34;ĠìĥĿê°ģëĤĺ&#34;:7643,&#34;Ġë§ĲìķĦìķ¼&#34;:7644,&#34;Ġë§Ĳê³łëĬĶ&#34;:7645,&#34;Ġëª»ë´Ĳì£¼&#34;:7646,&#34;íı¼&#34;:7647,&#34;ĠìľłìķĦ&#34;:7648,&#34;ëĲĺëĬĶëį°&#34;:7649,&#34;ì¡°ìĦł&#34;:7650,&#34;Ġëªħìŀ¥ë©´&#34;:7651,&#34;Ġëªħë³µìĿĦ&#34;:7652,&#34;ìĹŃíķł&#34;:7653,&#34;ë°ĺê°ľëıĦ&#34;:7654,&#34;Ġíķłë§Ĳ&#34;:7655,&#34;ëĭµê²Į&#34;:7656,&#34;Ġê¸°ìĸµëĤĺëĬĶ&#34;:7657,&#34;ìķĮê³ł&#34;:7658,&#34;ìĤ¬ëŀĮìĿĦ&#34;:7659,&#34;ë¨¹ìĿĦ&#34;:7660,&#34;íħĮëŁ¬&#34;:7661,&#34;ë¦¼ìĿ´&#34;:7662,&#34;ĠíŀĺìĿĦ&#34;:7663,&#34;Ġì¤ĦìĪĺ&#34;:7664,&#34;Ġë§Įëĵ¤ìĸ´ëĿ¼&#34;:7665,&#34;ĠìĦľìļ¸&#34;:7666,&#34;ì¡Įìĸ´ìļĶ&#34;:7667,&#34;ĠìĿ¸ìĥĿìĹĲ&#34;:7668,&#34;ĠìĪĺì¤ĢìĿĦ&#34;:7669,&#34;Ġì¶Ķì²ľíķĺê³ł&#34;:7670,&#34;ëģĿëĤĺ&#34;:7671,&#34;Ġì¦Ĳê¸°&#34;:7672,&#34;Ġë³´ê²ĮëĲľ&#34;:7673,&#34;Ġëį°ë·Ķ&#34;:7674,&#34;Ġì«Ħ&#34;:7675,&#34;Ġë¹ĽëĤĺëĬĶ&#34;:7676,&#34;ëļ±ë§ŀ&#34;:7677,&#34;ĠëļĿ&#34;:7678,&#34;Ġìĵ¸ëį°ìĹĨìĿ´&#34;:7679,&#34;ãĢĤ&#34;:7680,&#34;ovie&#34;:7681,&#34;ìķĪíĥĢê¹Ŀ&#34;:7682,&#34;Ġì§ľì§ĳê¸°&#34;:7683,&#34;ĠíĺĲìĺ¤&#34;:7684,&#34;ëŀĢíĭ°ëħ¸&#34;:7685,&#34;^-^&#34;:7686,&#34;im&#34;:7687,&#34;êº&#34;:7688,&#34;ĨĴ&#34;:7689,&#34;ê°Ģìļ´&#34;:7690,&#34;ê¸°ë²ķ&#34;:7691,&#34;ìķĦíĶĦ&#34;:7692,&#34;ìĬ¤ìĻĢ&#34;:7693,&#34;ìĬ¤íİĺ&#34;:7694,&#34;ì§Ħì§Ģ&#34;:7695,&#34;ìĺ¤ëŀ«&#34;:7696,&#34;ê·¸ëŁŃìłĢëŁŃ&#34;:7697,&#34;ì°¬ëŀĢ&#34;:7698,&#34;ë¶ĢìĹĲ&#34;:7699,&#34;ê°ľë¥¼&#34;:7700,&#34;ìłĢë¦¬&#34;:7701,&#34;ĠìĨĮìĨĮíķľ&#34;:7702,&#34;ìĽĲìĿĢ&#34;:7703,&#34;ĠëĵľëĿ¼ë§ĪìŀħëĭĪëĭ¤&#34;:7704,&#34;Ġë°°ìļ°ëĬĶ&#34;:7705,&#34;ì¡°ìķĦ&#34;:7706,&#34;ĠìĤ¬ëŀĳíķ´&#34;:7707,&#34;ìļ¸ë¿Ĳ&#34;:7708,&#34;Ġì¢ĭìķĺìĿĦíħĲëį°&#34;:7709,&#34;ìĺĪìģĺ&#34;:7710,&#34;Ġìķ¡ìħĺê³¼&#34;:7711,&#34;êµĲíĽĪ&#34;:7712,&#34;Ġëª°ëĿ¼&#34;:7713,&#34;ìĭľê°ĦëıĻìķĪ&#34;:7714,&#34;ĠëĳĲê·¼&#34;:7715,&#34;ëª»íķĺëĬĶ&#34;:7716,&#34;ê²°ë¡ł&#34;:7717,&#34;ĠìĹ¬ìŀĲëĬĶ&#34;:7718,&#34;ëĤ´ìļ©ìĿĦ&#34;:7719,&#34;Ġë³¼ë§ĮíĸĪëĭ¤&#34;:7720,&#34;Ġê±´ê°Ģ&#34;:7721,&#34;Ġì°¾ìķĦìĦľ&#34;:7722,&#34;ĠìĻ¸ë¡ľ&#34;:7723,&#34;Ġë¨¹ëĬĶ&#34;:7724,&#34;Ġë§ĲìĿ´íķĦìļĶ&#34;:7725,&#34;ëģĿëĤĺê³ł&#34;:7726,&#34;Ġëĸ¨ìĸ´ì§Ģ&#34;:7727,&#34;Ġê³±&#34;:7728,&#34;ĠìĤ¶ìĿ´&#34;:7729,&#34;Ġìŀłëĵ¤&#34;:7730,&#34;ìĹ¬ëħ&#34;:7731,&#34;ìĽĲìŀĳìĿĺ&#34;:7732,&#34;Ġë¬´ìĦŃê³ł&#34;:7733,&#34;Ġëĵ¤ìĸ´ê°Ģ&#34;:7734,&#34;ì¿µ&#34;:7735,&#34;ĠìķĬìķĺì§Ģë§Į&#34;:7736,&#34;ìķĪëĲĺê³ł&#34;:7737,&#34;ĠìķĶê±¸&#34;:7738,&#34;ìŀĲì²´ëĬĶ&#34;:7739,&#34;ìħĶìķ¼&#34;:7740,&#34;Ġíģ´ëŀĺ&#34;:7741,&#34;Ġë³´ìķĺëįĺ&#34;:7742,&#34;Ġëĭ¬ì½¤&#34;:7743,&#34;ĠìĿ´ê²ĥë³´ëĭ¨&#34;:7744,&#34;ìĸ´ë¦°ìĿ´&#34;:7745,&#34;ĠìĥĿê°ģíķ´ë³´ê²Į&#34;:7746,&#34;ĠíĿĳìĿ¸&#34;:7747,&#34;Ġê°ĢëĬ¥íķľ&#34;:7748,&#34;ĠíĿĺëŁ¬ê°ĢëĬĶ&#34;:7749,&#34;Ġ:)&#34;:7750,&#34;ìĭłìĦłíķľ&#34;:7751,&#34;ë§ĺìĹĲ&#34;:7752,&#34;Ġê°Ģê¹Įìļ´&#34;:7753,&#34;Ġê±°ì§ĵë§Ĳ&#34;:7754,&#34;OST&#34;:7755,&#34;nd&#34;:7756,&#34;£Į&#34;:7757,&#34;íķĳ&#34;:7758,&#34;ê³łëıĦ&#34;:7759,&#34;íķĺìķĦ&#34;:7760,&#34;íķĺëĬĺ&#34;:7761,&#34;ìĿĢê±°&#34;:7762,&#34;ìĸ´ë¥¼&#34;:7763,&#34;ìĿ¸ìĹĲ&#34;:7764,&#34;ĠìķĦëĨĶ&#34;:7765,&#34;íķ´íĶ¼&#34;:7766,&#34;ìĺģíĻĶë³´ê³ł&#34;:7767,&#34;ë³´êµ¬&#34;:7768,&#34;ìĬ¤íı¬&#34;:7769,&#34;ìŀĲë¦¬&#34;:7770,&#34;ĠëĤĺìĿĦëĵ¯&#34;:7771,&#34;ìĥģìĥģ&#34;:7772,&#34;íĺĶ&#34;:7773,&#34;ê·¸ìĿĺ&#34;:7774,&#34;ĠìĭľìĤ¬íļĮ&#34;:7775,&#34;Ġìµľë¯¼&#34;:7776,&#34;ìĭłê¸°&#34;:7777,&#34;Ġìŀĺíķľëĭ¤&#34;:7778,&#34;Ġì£¼ìĦ±ì¹ĺ&#34;:7779,&#34;íİ¸ìĹĲìĦľ&#34;:7780,&#34;íĥĢê³ł&#34;:7781,&#34;ë²Ħë¦¬&#34;:7782,&#34;Ġë²¨&#34;:7783,&#34;ĠìĤ¬ìļ´ëĵľ&#34;:7784,&#34;ëªħíķľ&#34;:7785,&#34;Ġì¡°ì°¨&#34;:7786,&#34;Ġìĭ¶ìĹĪëĭ¤&#34;:7787,&#34;Ġìĭ¶ìĹĪëįĺ&#34;:7788,&#34;Ġì¢ĭìķĦíķĺì§Ģë§Į&#34;:7789,&#34;íķĺì§Ģë§Ĳ&#34;:7790,&#34;ĠìĹŃê²¨&#34;:7791,&#34;ê»Ģ&#34;:7792,&#34;ëħ¸ì¶ľ&#34;:7793,&#34;íıīìłĲë³´ê³ł&#34;:7794,&#34;ĠíĻĢ&#34;:7795,&#34;Ġë¶ĦëŁī&#34;:7796,&#34;ì¹ľêµ¬ëĵ¤&#34;:7797,&#34;ìĤ´ìĿ´&#34;:7798,&#34;ë³¼ìĪĺ&#34;:7799,&#34;íķĺê¸°ìĹĶ&#34;:7800,&#34;Ġë§Įëĵ¤ìĸ´ëĤ¸&#34;:7801,&#34;Ġìłģìĸ´ëıĦ&#34;:7802,&#34;ĠìĿ¸ìĥĿìĿ´&#34;:7803,&#34;ìĤ¬ëŀĳê³¼&#34;:7804,&#34;Ġëª¨ìĬµìĿĢ&#34;:7805,&#34;Ġê³µê°ĲëıĦ&#34;:7806,&#34;ĠëĨĢëŀĲëĭ¤&#34;:7807,&#34;ëŁ¬ëĥĲ&#34;:7808,&#34;ĠìŀłìĿ´&#34;:7809,&#34;ĠëĬĲëģ¼ê³ł&#34;:7810,&#34;Ġë¹¼ê³¤&#34;:7811,&#34;íķĺìĭľê³ł&#34;:7812,&#34;Ġìŀ¼ìŀĪìĸ´ìļĶ&#34;:7813,&#34;Ġë°°ê²½ìľ¼ë¡ľ&#34;:7814,&#34;ĠëĵľëĿ¼ë§Īë¡ľ&#34;:7815,&#34;íıŃëł¥&#34;:7816,&#34;Ġì£¼ìłľê°Ģ&#34;:7817,&#34;ĠìķĮìķĺìĿĮ&#34;:7818,&#34;íķĦë²Ħê·¸&#34;:7819,&#34;ĠìŀĥìĿĢ&#34;:7820,&#34;ìĹĦì²ŃëĤľ&#34;:7821,&#34;Ġê°Ķëĭ¤&#34;:7822,&#34;ĠëĥĦìĥĪ&#34;:7823,&#34;Ġëĭ¤íĸīìĿ´ëĭ¤&#34;:7824,&#34;Ġìĸ´ëłµëĭ¤&#34;:7825,&#34;ĠìĿ´ëŀĺìĦľ&#34;:7826,&#34;ĠìķĪë³¸ëĭ¤&#34;:7827,&#34;ĠíĹĽìĽĥìĿĮ&#34;:7828,&#34;ê°ľìĹ°ìĦ±&#34;:7829,&#34;ì¢ħìĿ¼ê´Ģ&#34;:7830,&#34;ë¶ĪíĹĪìłĦ&#34;:7831,&#34;ª©&#34;:7832,&#34;³¼&#34;:7833,&#34;ê³±&#34;:7834,&#34;ìļ¤&#34;:7835,&#34;ì§Ģë¶Ģ&#34;:7836,&#34;ëĤŃ&#34;:7837,&#34;ĠìĺģíĻĶìĿ´&#34;:7838,&#34;ĠìĺģíĻĶìĿ¸ì¤Ħ&#34;:7839,&#34;ìĿĦìĪĺê°Ģ&#34;:7840,&#34;Ġë§´&#34;:7841,&#34;íķ´ìł¸&#34;:7842,&#34;Ġë³´ëĭ¨&#34;:7843,&#34;ìłĲìĹĲ&#34;:7844,&#34;ìŀĲëıĦ&#34;:7845,&#34;ì§Ħíĸī&#34;:7846,&#34;ĠìĹ°ê·¹&#34;:7847,&#34;ĲëıĮ&#34;:7848,&#34;ìķĺëĦ¤ìļĶ&#34;:7849,&#34;Ġëª¨ë¥¸ëĭ¤&#34;:7850,&#34;êµŃë¯¼&#34;:7851,&#34;ë¶Ħëĵ¤ìĿ´&#34;:7852,&#34;ìħ§&#34;:7853,&#34;ĠìķĪì¢ĭìķĦ&#34;:7854,&#34;~~!!&#34;:7855,&#34;Ġì§Ħì§ľë¡ľ&#34;:7856,&#34;Ġêµīìŀ¥&#34;:7857,&#34;Ġê°ľìĦ±&#34;:7858,&#34;ĠìĨĮíĻĶ&#34;:7859,&#34;ë¹ħ&#34;:7860,&#34;^^*&#34;:7861,&#34;Ġìĭ¶ìĸ´ìĦľ&#34;:7862,&#34;ĠíĮį&#34;:7863,&#34;ì¦ĿìĿ´&#34;:7864,&#34;ìĺĪì§Ħ&#34;:7865,&#34;Ġëª¨ë¥´ì§Ģë§Į&#34;:7866,&#34;ìŀĪëĬĶìĺģíĻĶ&#34;:7867,&#34;Ġë§Īì§Ģë§īìĹĶ&#34;:7868,&#34;Ġë§Ŀì¹ĺ&#34;:7869,&#34;Ġë³´ê¸°ê°Ģ&#34;:7870,&#34;ëĶ©ëķĮ&#34;:7871,&#34;Ġìłģëĭ¹íŀĪ&#34;:7872,&#34;ëįĶëĿ¼ë©´&#34;:7873,&#34;ìĬ¹ìłĦ&#34;:7874,&#34;ëŁ¬ë¸Į&#34;:7875,&#34;ì²ĺìĿĮìĹĲëĬĶ&#34;:7876,&#34;Ġìĸ´ëĶĶë¡ľ&#34;:7877,&#34;ĠìĨĮìŀ¬ëıĦ&#34;:7878,&#34;Ġì¹´ë©Ķ&#34;:7879,&#34;ëĪĦêµ¬&#34;:7880,&#34;ĠìķŀëĴ¤&#34;:7881,&#34;ĠëĶĶìĽĮ&#34;:7882,&#34;ĠìĺģíĻĶëĿ¼ìĦľ&#34;:7883,&#34;Ġê·¸ìłĢê·¸ëŁ°&#34;:7884,&#34;Ġì±ħìĿĦ&#34;:7885,&#34;Ġë§Įëĵ¤ìĹĪëĤĺ&#34;:7886,&#34;Ġëķħ&#34;:7887,&#34;ĠíĿĶëĵ¤&#34;:7888,&#34;ĠìĻĶìĬµëĭĪëĭ¤&#34;:7889,&#34;Ġíĸ¥ìĹ°&#34;:7890,&#34;ĠìĹ¬ì£¼ê°Ģ&#34;:7891,&#34;ĠìĹ¬ëŁ¬ë¶Ħ&#34;:7892,&#34;ĠíķĻêµĲìĹĲìĦľ&#34;:7893,&#34;Ġê°ķëł¬íķľ&#34;:7894,&#34;ë¤Ħ&#34;:7895,&#34;ìķĦëĭĪë©´&#34;:7896,&#34;íģ¬ëłĪëĶ§&#34;:7897,&#34;18&#34;:7898,&#34;SF&#34;:7899,&#34;ay&#34;:7900,&#34;et&#34;:7901,&#34;ê°Ģë¦¬&#34;:7902,&#34;ê²ī&#34;:7903,&#34;ëĿ¼ìĹĲ&#34;:7904,&#34;ëĦĮ&#34;:7905,&#34;ìĭľìĿĺ&#34;:7906,&#34;ë³´ëĦ¤ìļĶ&#34;:7907,&#34;ìĬ¤íĭ±&#34;:7908,&#34;Ġë°ı&#34;:7909,&#34;ìŀĲë©´&#34;:7910,&#34;íķĺê³łëĬĶ&#34;:7911,&#34;Ġìµľì´Ī&#34;:7912,&#34;ì¹ĺëıĦ&#34;:7913,&#34;êµ¬ìĹŃ&#34;:7914,&#34;Ġëª¨ìļķ&#34;:7915,&#34;Ġìłķë§ĲìĿ´ì§Ģ&#34;:7916,&#34;Ġë¬´ëĦĪ&#34;:7917,&#34;ĠìŀĲê¸°ê°Ģ&#34;:7918,&#34;íİ¸ê³¼&#34;:7919,&#34;ĠíıīìłĲë³´ê³ł&#34;:7920,&#34;Ġë©ĶìĿ´&#34;:7921,&#34;Ġë¹Ļ&#34;:7922,&#34;ĠëģĿëĤłëķĮ&#34;:7923,&#34;Ġìļ°ë¦¬ëĵ¤&#34;:7924,&#34;Ġê°ĲëıħëıĦ&#34;:7925,&#34;ĠìĤ¬ëŀĳíķ©ëĭĪëĭ¤&#34;:7926,&#34;Ġë°ĺìĺģ&#34;:7927,&#34;ëĳĲë²Ī&#34;:7928,&#34;ĠíĽĦìĹĲ&#34;:7929,&#34;ĠëĶ°ë¦Ħ&#34;:7930,&#34;ì§ĳìĸ´&#34;:7931,&#34;ì§ĢìķĬëĭ¤&#34;:7932,&#34;Ġì°¾ëĬĶ&#34;:7933,&#34;ĠìķĦë¬´ëıĦ&#34;:7934,&#34;íĥĦíĥĦ&#34;:7935,&#34;ì¢ħìĺģ&#34;:7936,&#34;Ġì¹ĺìľł&#34;:7937,&#34;ĠëĬĲê»´ì¡Įëĭ¤&#34;:7938,&#34;ĠëıħìĿ¼&#34;:7939,&#34;ì¸Ħ&#34;:7940,&#34;ê·ĢìĹ¬ìļ´&#34;:7941,&#34;ĠëĴ¤ìĹĲ&#34;:7942,&#34;Ġìĭľë¦¬ì¦Īì¤ĳ&#34;:7943,&#34;Ġê¸¸ìĿ´&#34;:7944,&#34;Ġ60&#34;:7945,&#34;ĠíĻ©ëĭ¹íķľ&#34;:7946,&#34;Ġê¸ĢìİĦ&#34;:7947,&#34;ì±ĦëĦĲ&#34;:7948,&#34;íĸĩëĬĶëį°&#34;:7949,&#34;ìĨĮìŀ¬ê°Ģ&#34;:7950,&#34;ë³´ì§Ģë§ĪëĿ¼&#34;:7951,&#34;íĿ¥íĸī&#34;:7952,&#34;ì§ľì¦ĿëĤĺ&#34;:7953,&#34;ĠëķĢ&#34;:7954,&#34;Ġì¢ĭê²łìĬµëĭĪëĭ¤&#34;:7955,&#34;ĠìĹĦë§Īê°Ģ&#34;:7956,&#34;ĠëŁ¬ìĭľìķĦ&#34;:7957,&#34;Ġëľ¬ê¸ĪìĹĨëĬĶ&#34;:7958,&#34;ì§Ģëª»íķł&#34;:7959,&#34;Ġëª©ìĨĮë¦¬ê°Ģ&#34;:7960,&#34;ĠìĿ¸íĦ°ëĦ·&#34;:7961,&#34;ì¥¬ìĸ¼&#34;:7962,&#34;Ġì§Īì§ĪëģĮ&#34;:7963,&#34;Ġ,,&#34;:7964,&#34;ĠìŁ&#34;:7965,&#34;ëĭĲ&#34;:7966,&#34;ìĿĺìĭĿ&#34;:7967,&#34;ê¸°ìľĦíķ´&#34;:7968,&#34;ĠìĹ®&#34;:7969,&#34;ìĺĽ&#34;:7970,&#34;ìĺģíĻĶìłľ&#34;:7971,&#34;Ġê·¸ëĭ¹ìĭľ&#34;:7972,&#34;ìĬ¤íħĶ&#34;:7973,&#34;ìŀĲê·¹&#34;:7974,&#34;ë§Īë¦¬&#34;:7975,&#34;ìĹĨìĸ´ìļĶ&#34;:7976,&#34;ìĹĨìĹĪëĭ¤&#34;:7977,&#34;ĠëĤĺìĿĮ&#34;:7978,&#34;ĠëĤĺì¤ĳ&#34;:7979,&#34;ĠëĤĺëŀĳ&#34;:7980,&#34;Ġíķĺë©°&#34;:7981,&#34;Ġìłķë³´&#34;:7982,&#34;Ġì§Ģê²¹ëĭ¤&#34;:7983,&#34;ĠìĦ¬ë&#34;:7984,&#34;ë¯¸íĻĶ&#34;:7985,&#34;ìĭłë¶Ħëĵ¤&#34;:7986,&#34;ĠìĽħ&#34;:7987,&#34;~~~~~&#34;:7988,&#34;ìĭ¤ìłľ&#34;:7989,&#34;Ġë§ĲìĶĢ&#34;:7990,&#34;ĠìĹ¬íĥľ&#34;:7991,&#34;ĠìŀĲê³ł&#34;:7992,&#34;ĠìłľìŀĦìĬ¤&#34;:7993,&#34;Ġë¹ķëĭĪëĭ¤&#34;:7994,&#34;ĠìĤ¬ëŀĮëĵ¤ìĿĦ&#34;:7995,&#34;Ġë¶Ģëĭ´&#34;:7996,&#34;ĠëģĿìĹĲ&#34;:7997,&#34;ĠíĮ¬ëĵ¤&#34;:7998,&#34;ĠìłĢíıīê°Ģ&#34;:7999,&#34;ë°ĶíĥĢ&#34;:8000,&#34;ìŀ¼ìŀĪ&#34;:8001,&#34;ì¶ĶëĬĶ&#34;:8002,&#34;íĽĦìĹĲ&#34;:8003,&#34;Ġìŀ¥ë©´ëĵ¤ìĿ´&#34;:8004,&#34;Ġíıīê·ł&#34;:8005,&#34;ĠëıĻëĦ¤&#34;:8006,&#34;ëª»íķľ&#34;:8007,&#34;Ġê´ľì°®ê²Į&#34;:8008,&#34;ë³µìĪĺ&#34;:8009,&#34;ĠìĹ¬ìŀĲëĵ¤&#34;:8010,&#34;ìĽĥê¸´&#34;:8011,&#34;Ġìĭ¬ìŀ¥&#34;:8012,&#34;ĠìĦłìĤ¬&#34;:8013,&#34;ë°ĽìĿĦ&#34;:8014,&#34;Ġìłģëĭ¹íķľ&#34;:8015,&#34;Ġë°ķìĪĺ&#34;:8016,&#34;ìĤ¬ëŀĳìĿĢ&#34;:8017,&#34;ìĻ¸êµŃ&#34;:8018,&#34;Ġê·¸ëłĩì§Ģë§Į&#34;:8019,&#34;Ġê¿Ģ&#34;:8020,&#34;ĠìĽĲìŀĳìĿĺ&#34;:8021,&#34;ëħĦëĮĢìĹĲ&#34;:8022,&#34;ë¸ĶëŀĻ&#34;:8023,&#34;ê·Ģìĭł&#34;:8024,&#34;Ġë³ĢíĻĶ&#34;:8025,&#34;íĺľìĦł&#34;:8026,&#34;ëĳĶ&#34;:8027,&#34;ĠìŀĪìĹĪìľ¼ë©´&#34;:8028,&#34;Ġê·ĢìĹ¬ìĽĢ&#34;:8029,&#34;ê·¸ëŁ°ì§Ģ&#34;:8030,&#34;ĠìķĮìķĺëĦ¤&#34;:8031,&#34;íģ¬ë£¨&#34;:8032,&#34;ĠìĻłë§Įíķĺë©´&#34;:8033,&#34;................................&#34;:8034,&#34;Ġíĺ¹ìĭľ&#34;:8035,&#34;ê³³ìĹĲ&#34;:8036,&#34;ìį©&#34;:8037,&#34;Ġì§Ħì§Ģíķĺê²Į&#34;:8038,&#34;ë¡ľë§¨íĭ±&#34;:8039,&#34;Ġë³´ìĭľë©´&#34;:8040,&#34;Ġë§¡ìĿĢ&#34;:8041,&#34;ìłĦì²´ìłģìľ¼ë¡ľ&#34;:8042,&#34;íķµëħ¸ìŀ¼&#34;:8043,&#34;ĠìķĪë¬´ìĦľ&#34;:8044,&#34;ê°±ìĿ´&#34;:8045,&#34;ĠìĿ´ëıĦìłĢëıĦ&#34;:8046,&#34;ck&#34;:8047,&#34;~âĻ¥&#34;:8048,&#34;Ġ&amp;&#34;:8049,&#34;ĠW&#34;:8050,&#34;ŃĪ&#34;:8051,&#34;ìĿ´íĶĦ&#34;:8052,&#34;ìķ¡&#34;:8053,&#34;Īë¹Ħ&#34;:8054,&#34;ĠìĿ´ëĭ¤&#34;:8055,&#34;ĠìĿ´ëłĩ&#34;:8056,&#34;ĠìĿ´ë³´ëĭ¤&#34;:8057,&#34;ë¦¬ìĸ¼&#34;:8058,&#34;ìķĦì§Ħì§ľ&#34;:8059,&#34;ìķĦëĪĦ&#34;:8060,&#34;ì²¼&#34;:8061,&#34;ĠëĤĺë¬´&#34;:8062,&#34;ĠëĤĺìĿ´ê°Ģ&#34;:8063,&#34;Ġëĭ¤íģ¬&#34;:8064,&#34;Ġìĸ´ìłľ&#34;:8065,&#34;Ġê¸°íļį&#34;:8066,&#34;ë¬»&#34;:8067,&#34;ĠìĪĺë¡Ŀ&#34;:8068,&#34;ë¶ĦíŀĪ&#34;:8069,&#34;ê²łìĸ´&#34;:8070,&#34;ê²łëĭ¤ê³ł&#34;:8071,&#34;Ġë§Īìĭľê¸¸&#34;:8072,&#34;ëĵ¯íķĺëĭ¤&#34;:8073,&#34;ìľłë°ľ&#34;:8074,&#34;ì²´ìłģ&#34;:8075,&#34;ëĦĪë¬´ëĤĺëıĦ&#34;:8076,&#34;ĠëĵľëĿ¼ë§ĪìĿĺ&#34;:8077,&#34;ĠìĤ¬ìĿ´ì½Ķ&#34;:8078,&#34;ìĺģìĿĺ&#34;:8079,&#34;Ġíķ¸&#34;:8080,&#34;ì¡°ìļ©&#34;:8081,&#34;ìŀ¬ë°ĮëĦ¤&#34;:8082,&#34;Ġë°Ķëĭ¥&#34;:8083,&#34;ëĸ¨&#34;:8084,&#34;Ġìĭ¤ê°Ĳ&#34;:8085,&#34;ìŀ¼ìŀĪìĸ´ìļĶ&#34;:8086,&#34;ëĿ¼ê³łìļĶ&#34;:8087,&#34;ĠìĤ´ë¦¬ì§Ģ&#34;:8088,&#34;Ġíķłë¦¬ìļ°ëĵľ&#34;:8089,&#34;ĠìķĦëĭĪìŀĸìķĦ&#34;:8090,&#34;ĠìĿ´íķ´ë¶Īê°Ģ&#34;:8091,&#34;Ġì§ľë¦¿&#34;:8092,&#34;ĠíķľêµŃìĿĺ&#34;:8093,&#34;ĠëĤľë¬´&#34;:8094,&#34;ìĿĦê¹ĮìļĶ&#34;:8095,&#34;Ġì§Ģê¸ĪìĿĺ&#34;:8096,&#34;íĥľíĺĦ&#34;:8097,&#34;Ġì§ľì¦ĿëĤĺê²Į&#34;:8098,&#34;ĠìĦľìĸĳ&#34;:8099,&#34;ĠìĥĿê²¼&#34;:8100,&#34;ĠìĬ¤ë¦´ëıĦ&#34;:8101,&#34;Ġë°©íķ´&#34;:8102,&#34;ëĭ¤ëĭĪëĬĶ&#34;:8103,&#34;ìĦĿê·ľ&#34;:8104,&#34;ĠìĹ°ê¸°ëł¥ìĹĲ&#34;:8105,&#34;íĳľìłķ&#34;:8106,&#34;ĠìĽĲìŀĳìĿ´&#34;:8107,&#34;ì§Ģê¸ĪëıĦ&#34;:8108,&#34;êº¼ë©´&#34;:8109,&#34;ìĻķêµŃ&#34;:8110,&#34;Ġë³´ê²ĮëĲĺ&#34;:8111,&#34;Ġë¦¬ì¦Ī&#34;:8112,&#34;ìĬ¬íĶĪ&#34;:8113,&#34;Ġë¬´ìĦŃê²Į&#34;:8114,&#34;Ġìŀ¼ìŀĪìĿĮ&#34;:8115,&#34;ĠíħĲ&#34;:8116,&#34;ë¡Ńê²Į&#34;:8117,&#34;Ġë¯¼íıĲ&#34;:8118,&#34;ì§Ħìĭ¬ìľ¼ë¡ľ&#34;:8119,&#34;ĠíĤ¤ìĬ¤&#34;:8120,&#34;Ġìĸ¸ìłł&#34;:8121,&#34;ë§ĪìĿ´íģ´&#34;:8122,&#34;Ġë¯¸ìĨĮê°Ģ&#34;:8123,&#34;Ġëħ¹ìķĦ&#34;:8124,&#34;ìłĲë§ĮìłĲìĹĲ&#34;:8125,&#34;Ġë±ĢíĮĮìĿ´ìĸ´&#34;:8126,&#34;Ġìĸ´ëĳ¡&#34;:8127,&#34;dd&#34;:8128,&#34;©į&#34;:8129,&#34;Ġìª¼&#34;:8130,&#34;ìĿ´ëķĮ&#34;:8131,&#34;Ġìķµ&#34;:8132,&#34;ĠìĿĦ&#34;:8133,&#34;ĠìĺģíĻĶê°Ļ&#34;:8134,&#34;Īë¥¼&#34;:8135,&#34;ìĿĦê²ĥ&#34;:8136,&#34;ìļĶíķľ&#34;:8137,&#34;ĠëĤ¬ëĭ¤&#34;:8138,&#34;ìĺ·&#34;:8139,&#34;ìĺģíĻĶê´Ģ&#34;:8140,&#34;ìłĲìĿ´ëĤĺ&#34;:8141,&#34;ê±°ê°ĻìĿĢëį°&#34;:8142,&#34;ìłķë¯¼&#34;:8143,&#34;ì§Ħì°½&#34;:8144,&#34;Ġëĭ¤ëħĢ&#34;:8145,&#34;ìłĦìĿĺ&#34;:8146,&#34;Ġìĸ´ì§¸&#34;:8147,&#34;ëĵľë§Į&#34;:8148,&#34;ĠìĬ¤íĥ&#34;:8149,&#34;ĠìĬ¤íĭ°&#34;:8150,&#34;ĠëıĪë²&#34;:8151,&#34;Ġì°¢&#34;:8152,&#34;íŀĪìĸ´ë¡ľ&#34;:8153,&#34;ëŁ¬ì§Ģ&#34;:8154,&#34;ìħ°&#34;:8155,&#34;ìĨĮìŀ¥&#34;:8156,&#34;Ġë§ĲìĿ¸ê°Ģ&#34;:8157,&#34;ìĭ¬ìĹĲ&#34;:8158,&#34;ĠëĵľëĿ¼ë§Īëĭ¤&#34;:8159,&#34;Ġë°°ìļ°ëĵ¤ìĿĢ&#34;:8160,&#34;ë¯Ģë¡ľ&#34;:8161,&#34;Ġìļ°ìĹ°&#34;:8162,&#34;ì¡°íĺĦ&#34;:8163,&#34;ë°Ķëĭ¥&#34;:8164,&#34;ĠìĹŃê²¨ìļ´&#34;:8165,&#34;Ġìĭľê°ĦìķĦê¹Ŀëĭ¤&#34;:8166,&#34;ëĬĲëĥĲ&#34;:8167,&#34;Ġë¶Īê³¼&#34;:8168,&#34;Ġë©ĭì§Ģê²Į&#34;:8169,&#34;ì£¤&#34;:8170,&#34;ìĿ´ê±°ë³´ê³ł&#34;:8171,&#34;Ġë°°ê¸ī&#34;:8172,&#34;íĺķìĿ´&#34;:8173,&#34;Ġì°¨ìĿ´&#34;:8174,&#34;Ġë¹łë¥¸&#34;:8175,&#34;ĠíķĦìļĶê°Ģ&#34;:8176,&#34;ĠìĺģìĥģìĿ´&#34;:8177,&#34;ìĻ¸ìĿĺ&#34;:8178,&#34;ê¸°ëĮĢë¥¼&#34;:8179,&#34;Ġë²Ħë¦°&#34;:8180,&#34;ãĦ·ãĦ·ãĦ·&#34;:8181,&#34;ĠëĤ«ê²łëĭ¤&#34;:8182,&#34;Ġë¹łìł¸ìĦľ&#34;:8183,&#34;ĠíĦ°ë¯¸ëĦ¤ìĿ´íĦ°&#34;:8184,&#34;ê·¹ìŀ¥íĮĲ&#34;:8185,&#34;ĠìĥģíĻ©ìĿĦ&#34;:8186,&#34;ĠìĪ¨ê²¨ì§Ħ&#34;:8187,&#34;ĠìĻĶëĭ¤&#34;:8188,&#34;ĠìĤ¬ë¬´&#34;:8189,&#34;ĠìĿĺëıĦê°Ģ&#34;:8190,&#34;íĶĦë¡ľê·¸ëŀ¨&#34;:8191,&#34;ë²Īë´¤&#34;:8192,&#34;Ġì¿µ&#34;:8193,&#34;Ġëľ¬ê¸ĪìĹĨìĿ´&#34;:8194,&#34;Ġë¶Ģëª¨ëĭĺ&#34;:8195,&#34;Ġêµ¬ë¶Ħ&#34;:8196,&#34;ë±ħ&#34;:8197,&#34;Ġìĵ¸ëį°ìĹĨëĬĶ&#34;:8198,&#34;ì«Į&#34;:8199,&#34;ĠíĦ¸&#34;:8200,&#34;am&#34;:8201,&#34;ig&#34;:8202,&#34;le&#34;:8203,&#34;ê°ĢìľĦ&#34;:8204,&#34;ëıĦìķĪ&#34;:8205,&#34;ĠìĿ´ìĿĢ&#34;:8206,&#34;ĠìĿ´íĨłë¡Ŀ&#34;:8207,&#34;ìĸ´ìĬ¤&#34;:8208,&#34;ëĵ¤ìĹ¬&#34;:8209,&#34;ìĬ¤ì¹´&#34;:8210,&#34;ĠìĤ½&#34;:8211,&#34;ĠìĤŃìłľ&#34;:8212,&#34;ìĤŃ&#34;:8213,&#34;ĠëĤĺëłĪìĿ´ìħĺ&#34;:8214,&#34;Ġíķĺê¸°&#34;:8215,&#34;Ġìłķëĭ¹&#34;:8216,&#34;Ġë¶ķ&#34;:8217,&#34;íķłìĪĺê°Ģ&#34;:8218,&#34;Ġì§Ħë¦¬&#34;:8219,&#34;ĠìµľìĨĮ&#34;:8220,&#34;ê²ĥìĹĲ&#34;:8221,&#34;íĸĪëĭ¤ê°Ģ&#34;:8222,&#34;ìĤ¬ëıĦ&#34;:8223,&#34;ĠëŃ¥ë¯¸&#34;:8224,&#34;ĠëĵľëĦ¤ìļĶ&#34;:8225,&#34;Ġê°Ļìķĺëĭ¤&#34;:8226,&#34;ë¹Ħíķ´&#34;:8227,&#34;Ġë³¼ëł¤ê³ł&#34;:8228,&#34;ĠìľłëŁ½&#34;:8229,&#34;ĠíĸĪëįĶëĭĪ&#34;:8230,&#34;ìĺģìĽĲ&#34;:8231,&#34;Ġìķłíĭĭ&#34;:8232,&#34;Ġìĭ¶ìĬµëĭĪëĭ¤&#34;:8233,&#34;ìŀ¬ë°ĮìĬµëĭĪëĭ¤&#34;:8234,&#34;íı¬ìĿ¸íĬ¸&#34;:8235,&#34;Ġë³´ëĬĶê±°&#34;:8236,&#34;Ġê¸°ëĮĢìĿ´ìĥģ&#34;:8237,&#34;Ġê°ķê°Ħ&#34;:8238,&#34;ĠëıĻìĺģìĥģ&#34;:8239,&#34;ĠìķĦê¹ĮìĽĮìĦľ&#34;:8240,&#34;Ġê´ľì°®ìķĺìĿĮ&#34;:8241,&#34;ê¹Ģê¸°ëįķ&#34;:8242,&#34;Ġëĭ¨ì²´&#34;:8243,&#34;Ġë¹łì§ĢëĬĶ&#34;:8244,&#34;ĠìĺģìĥģëıĦ&#34;:8245,&#34;íķľíħĮëĬĶ&#34;:8246,&#34;ì´Īëĵ±íķĻìĥĿ&#34;:8247,&#34;Ġê°ľë´īíķľ&#34;:8248,&#34;ĠìĨĲë°ľ&#34;:8249,&#34;ĠíĿ¥ë¯¸ë¥¼&#34;:8250,&#34;ĠãħĦ&#34;:8251,&#34;Ġë¶Ģë¶ĦìĿĢ&#34;:8252,&#34;ĠìĭľëĤĺë¦¬ìĺ¤ê°Ģ&#34;:8253,&#34;ĠìŀĪìĹĪê³ł&#34;:8254,&#34;ĠëıĮìķĦë³´ê²Į&#34;:8255,&#34;ê²ĥê°ĻëĦ¤ìļĶ&#34;:8256,&#34;Ġëĺĳê°ĻìĿ´&#34;:8257,&#34;ìŀĳê°Ģê°Ģ&#34;:8258,&#34;ĠëĬ¥ê°Ģ&#34;:8259,&#34;ì²¨ìĹĶ&#34;:8260,&#34;Ġë§ĪìĿ´ëĦĪìĬ¤&#34;:8261,&#34;ĠìŀĲê·¹ìłģìĿ¸&#34;:8262,&#34;Ġì§Ħì§Ģíķľ&#34;:8263,&#34;Ġíģ¬ë¦¬ìĬ¤ë§ĪìĬ¤&#34;:8264,&#34;ĠëĪĦêµ°ì§Ģ&#34;:8265,&#34;ìŀĪëįĺëį°&#34;:8266,&#34;ĠìĦłìĥĿëĭĺ&#34;:8267,&#34;Ġìĸ´ëł¸ìĿĦ&#34;:8268,&#34;ë¶ĦìľĦê¸°&#34;:8269,&#34;Ġíİ¼ì³Ĳ&#34;:8270,&#34;Ġë°Ķíĥķìľ¼ë¡ľ&#34;:8271,&#34;ed&#34;:8272,&#34;Ġis&#34;:8273,&#34;ì§Ģê¸Īë³´&#34;:8274,&#34;ĠìķĦíĶĦëĭ¤&#34;:8275,&#34;Ġë³´ìĿ´ì§Ģ&#34;:8276,&#34;Ġê·¸ìķ¼ë§Ĳë¡ľ&#34;:8277,&#34;ìĬ¤íĶ¼&#34;:8278,&#34;ìŀĲìĿ¸&#34;:8279,&#34;ìĹĨëĬĶëį°&#34;:8280,&#34;ĠíķĺíĴĪ&#34;:8281,&#34;ìĪĺìĦł&#34;:8282,&#34;ë²ħ&#34;:8283,&#34;ìĥģíĥľ&#34;:8284,&#34;Ġìłķìļ°&#34;:8285,&#34;Ġê²¬ë&#34;:8286,&#34;íķĺê³łìĭ¶ìĿĢ&#34;:8287,&#34;Ġìĸ´ê±°ì§Ģ&#34;:8288,&#34;ĠìĦŃ&#34;:8289,&#34;ê³µì£¼&#34;:8290,&#34;ìĹ¬íĥľ&#34;:8291,&#34;ĠìĹ°ê¸°íķĺëĬĶ&#34;:8292,&#34;ĠìĪĺë©´&#34;:8293,&#34;êµ¬ìĻĢ&#34;:8294,&#34;ìĭ¤íĮ¨&#34;:8295,&#34;Ġë§ĲíĪ¬&#34;:8296,&#34;íĥĢì¿ł&#34;:8297,&#34;ìĺĢì§Ģ&#34;:8298,&#34;Ġíĺĳ&#34;:8299,&#34;íĬ¸ëĬĶ&#34;:8300,&#34;Ġìĺ¤ëĬĶ&#34;:8301,&#34;Ġë¹Ħíĺ¸ê°Ĳ&#34;:8302,&#34;ëģĹ&#34;:8303,&#34;ìĭ¬ìĭ¬&#34;:8304,&#34;Ġë¶ĢìŀĲìĹ°&#34;:8305,&#34;Ġìŀ¬ë¯¸ìŀĪìĹĪìĬµëĭĪëĭ¤&#34;:8306,&#34;Ġê³łìĸĳìĿ´&#34;:8307,&#34;íħľ&#34;:8308,&#34;ë§Īëŀĳ&#34;:8309,&#34;ì¶Ķìĸ´&#34;:8310,&#34;ìĶ¨ëıĦ&#34;:8311,&#34;ĠíĻĶìŀ¥ìĭ¤&#34;:8312,&#34;íķĺëĤĺíķĺëĤĺ&#34;:8313,&#34;ìŀĺìĥĿ&#34;:8314,&#34;íķĺê¸°ìĹĲ&#34;:8315,&#34;Ġì¡¸ìĹħ&#34;:8316,&#34;Ġì¶©ìĭ¤&#34;:8317,&#34;ĠìłĦê°ľëĬĶ&#34;:8318,&#34;ì¡ĮìĬµëĭĪëĭ¤&#34;:8319,&#34;ëŀľìĬ¤&#34;:8320,&#34;Ġë¨¹ì¹ł&#34;:8321,&#34;Ġãħĭãħĭãħĭãħĭãħĭãħĭãħĭ&#34;:8322,&#34;Ġê°Ģì¡±ìĿĺ&#34;:8323,&#34;ĠêµŃê°Ģ&#34;:8324,&#34;ĠìĿ¸ìĥģìłģìĿ¸&#34;:8325,&#34;ĠìĦ¸ìĥģìĿ´&#34;:8326,&#34;ĠìĹĶëĶ©ìĿ´&#34;:8327,&#34;2014&#34;:8328,&#34;ê°ĶëĬĶëį°&#34;:8329,&#34;ĠìŀĦíĮ©íĬ¸&#34;:8330,&#34;ìĭľëĮĢìĿĺ&#34;:8331,&#34;ĠêµĲíĽĪëıĦ&#34;:8332,&#34;ĠìłĦì²´ìłģìĿ¸&#34;:8333,&#34;ìķŀìĹĲ&#34;:8334,&#34;Ġê°ľê·¸ë§¨&#34;:8335,&#34;ĠìŀĺìĥĿê²¼&#34;:8336,&#34;Ġë¹Īìķ½&#34;:8337,&#34;ĠìĺģìĽĲíķľ&#34;:8338,&#34;ëĮĢëĭ¨íķľ&#34;:8339,&#34;Ġëįĺìł¸&#34;:8340,&#34;Ġë°ĿíĺĢ&#34;:8341,&#34;ĠíĴĭíĴĭíķľ&#34;:8342,&#34;ìłĦë¬¸ê°Ģ&#34;:8343,&#34;op&#34;:8344,&#34;§íĮħ&#34;:8345,&#34;Ġãħĭãħĭãħĭãħĭãħĭãħĭãħĭãħĭãħĭãħĭãħĭãħĭãħĭãħĭãħĭãħĭ&#34;:8346,&#34;ħķ&#34;:8347,&#34;ĵ¯&#34;:8348,&#34;ëĭ¬ë¦¬&#34;:8349,&#34;ìĿ´ê²ĥìĿ´&#34;:8350,&#34;ëıĦíķľ&#34;:8351,&#34;ë¦¬ëŀĳ&#34;:8352,&#34;ĠìĺģíĻĶì§Ģ&#34;:8353,&#34;ĠìĺģíĻĶìĿ¼&#34;:8354,&#34;ëĦĲëıĮ&#34;:8355,&#34;Ġë³´ëł¤&#34;:8356,&#34;ìĭľì§Ģ&#34;:8357,&#34;ìĭľëĦ¤&#34;:8358,&#34;ìľ¼ìħ¨&#34;:8359,&#34;ĠëĤĺìĹĲê²Ĳ&#34;:8360,&#34;Ġíķĺëĭ¤ëĭĪ&#34;:8361,&#34;Ġì¢ĭëĦ¤&#34;:8362,&#34;ê°ĦíŀĪ&#34;:8363,&#34;Ġìĺ³&#34;:8364,&#34;Ġê°ĢìĪĺ&#34;:8365,&#34;Ġê°ĢíŀĪ&#34;:8366,&#34;ì¹ĺë©´&#34;:8367,&#34;ĠëĮĢê²°&#34;:8368,&#34;ìĿ¼ìĿĢ&#34;:8369,&#34;ëŀĺëĵľ&#34;:8370,&#34;ìĤ¬ê³ł&#34;:8371,&#34;Ġë¬´ê²ģ&#34;:8372,&#34;ìħľ&#34;:8373,&#34;ĠìķĪëĤĺìĺ¨ëĭ¤&#34;:8374,&#34;Ġë§Īì°¬&#34;:8375,&#34;Ġëª»ë§Įëĵ¤&#34;:8376,&#34;ëĤľíķ´&#34;:8377,&#34;ë³¸ì§Ģ&#34;:8378,&#34;Ġê²ĥìĿ¸ê°Ģ&#34;:8379,&#34;ĠìĿ´ëŁ°ê±´&#34;:8380,&#34;ĠëģĿëıĦ&#34;:8381,&#34;ëıĻê·¼&#34;:8382,&#34;ĠìĤ¬ëŀĳíķĺê³ł&#34;:8383,&#34;Ġë³´ëĬĶê²ĥ&#34;:8384,&#34;ëĸ¼&#34;:8385,&#34;ìŀ¼ìŀĩ&#34;:8386,&#34;êµ°ëĮĢ&#34;:8387,&#34;ĠíķłëķĮ&#34;:8388,&#34;Ġì£½ìĿ´&#34;:8389,&#34;ìĺĪìĥģ&#34;:8390,&#34;ê·¹íŀĪ&#34;:8391,&#34;ë¶ĢíĦ°ëĬĶ&#34;:8392,&#34;ĠìĽĲì¡°&#34;:8393,&#34;ĠíķľêµŃìĿ¸&#34;:8394,&#34;Ġë§Įëĵłê±°&#34;:8395,&#34;Ġìŀ¼ìŀĩ&#34;:8396,&#34;ì§ĳìĹĲìĦľ&#34;:8397,&#34;ĠìĿ´ìĥģìĿĢ&#34;:8398,&#34;ĠëĤ®ëĦ¤ìļĶ&#34;:8399,&#34;ĠìłģìłĪíķľ&#34;:8400,&#34;ìŀ¡ëĬĶ&#34;:8401,&#34;íĿ¬ìĿĺ&#34;:8402,&#34;Ġìŀ¬ê°ľë´ī&#34;:8403,&#34;ëķ¡&#34;:8404,&#34;Ġëĭ´ê³ł&#34;:8405,&#34;êº¼ìķ¼&#34;:8406,&#34;Ġë§īìŀ¥ëĵľëĿ¼ë§Ī&#34;:8407,&#34;ëįķë¶ĦìĹĲ&#34;:8408,&#34;Ġ2014&#34;:8409,&#34;ì¹ĺê³łëĬĶ&#34;:8410,&#34;ĠìķłëĭĪëĬĶ&#34;:8411,&#34;Ġì²¨ìĿ´ëĭ¤&#34;:8412,&#34;ĠíĻĺê²½&#34;:8413,&#34;ëĨĢëĵľ&#34;:8414,&#34;Ġìľłì¾Įíķĺê²Į&#34;:8415,&#34;ìĸµì§Ģë¡ľ&#34;:8416,&#34;ìłľìŀĳë¹Ħ&#34;:8417,&#34;ëĨ¨ëĦ¤&#34;:8418,&#34;ë¬´ìĦľìļ´&#34;:8419,&#34;Ġê²°ë¡łìĿĢ&#34;:8420,&#34;ĠìĮ©&#34;:8421,&#34;ĠìĬ¤íı¬ì¸ł&#34;:8422,&#34;.-&#34;:8423,&#34;Dë¡ľ&#34;:8424,&#34;²ł&#34;:8425,&#34;ìµĿìĺ¤&#34;:8426,&#34;ĠR&#34;:8427,&#34;ìŀĥ&#34;:8428,&#34;ìĹĲíļ¨&#34;:8429,&#34;ìĦľë¡ľ&#34;:8430,&#34;ìĸ´ìĸ´&#34;:8431,&#34;ë§Įíķĺê³ł&#34;:8432,&#34;ìĺ¬ë¦¬ë&#34;:8433,&#34;ìĭľìĬ¤&#34;:8434,&#34;ì£¼íĸī&#34;:8435,&#34;ĠìŀĪìľ¼ëĤĺ&#34;:8436,&#34;ĠìĹ°ìĥģ&#34;:8437,&#34;ê·¸ëĭ¤ì§Ģ&#34;:8438,&#34;Ġíķľë²ĪëįĶ&#34;:8439,&#34;ìĨĮë¦¬ê°Ģ&#34;:8440,&#34;Ġëª»ë³¸&#34;:8441,&#34;ë¬´ì¡°ê±´&#34;:8442,&#34;Ġê²ĥëĵ¤ìĿ´&#34;:8443,&#34;Ġë§Įëĵ¤ìĪĺ&#34;:8444,&#34;ĠëĵľëĿ¼ë§Īì¤ĳ&#34;:8445,&#34;ë¦¬ë³´&#34;:8446,&#34;ë¦¬ëĥĲ&#34;:8447,&#34;ĠëĲĺëĬĶëį°&#34;:8448,&#34;Ġì¡°ëĭĪëİģ&#34;:8449,&#34;Ġìļ°ë¢°ë§¤&#34;:8450,&#34;íĤ¥&#34;:8451,&#34;Ġìŀ¬ë¯¸ìŀĪìĸ´&#34;:8452,&#34;ëĤ¨ëħĢ&#34;:8453,&#34;ì½ĶëĤľ&#34;:8454,&#34;Ġì¶Ķë¦¬&#34;:8455,&#34;ĠíĸĪìľ¼ëĤĺ&#34;:8456,&#34;Ġë¶ĪìķĪ&#34;:8457,&#34;Ġë©ĭìŀĪê³ł&#34;:8458,&#34;ì¹ľêµ¬ëŀĳ&#34;:8459,&#34;ĠëıĦëĳĳ&#34;:8460,&#34;ĠíıīìĿĦ&#34;:8461,&#34;ëª»íķĺê³ł&#34;:8462,&#34;ĠìĿ´ê±°ë³´ëĭ¨&#34;:8463,&#34;Ġìŀ¼ìŀĪëĬĶ&#34;:8464,&#34;Ġìļ¸ìĹĪìĸ´ìļĶ&#34;:8465,&#34;ĠìĹĲìĦľ&#34;:8466,&#34;Ġê°Ģìŀ¥íķľ&#34;:8467,&#34;ìĤ¬ë¯¸&#34;:8468,&#34;Ġê³¼ëĮĢ&#34;:8469,&#34;ëĤĺìĺ¤ëĦ¤&#34;:8470,&#34;ëŀľëĵľ&#34;:8471,&#34;Ġíı¬ìĿ¸íĬ¸&#34;:8472,&#34;ĠìķĦë¬´íĬ¼&#34;:8473,&#34;ë§ŀëĬĶ&#34;:8474,&#34;Ġëĭ´ëĭ´&#34;:8475,&#34;ì°½ìłķ&#34;:8476,&#34;ìºĲë¦¬&#34;:8477,&#34;Ġì§Īë¦¬&#34;:8478,&#34;Ġíĺķìłľ&#34;:8479,&#34;Ġíĸīë³µíķĺê²Į&#34;:8480,&#34;ìĿ¼ë³¸ìĺģíĻĶ&#34;:8481,&#34;Ġëĭµëĭµíķĺëĭ¤&#34;:8482,&#34;Ġê¸Ģê³ł&#34;:8483,&#34;ĠìĺģíĻĶëĿ¼ì§Ģë§Į&#34;:8484,&#34;ĠìĸĳìķĦì¹ĺ&#34;:8485,&#34;ĠìĭľëĮĢìĿĺ&#34;:8486,&#34;Ġë¶ĪìĮįíķľ&#34;:8487,&#34;Ġëĭ¨ìĪľíŀĪ&#34;:8488,&#34;ìºħ&#34;:8489,&#34;Ġë©ĶìĦ¸ì§Ģ&#34;:8490,&#34;Ġì°¸ìĭłíķľ&#34;:8491,&#34;ĠëĤĺë¨¸ì§ĢëĬĶ&#34;:8492,&#34;Ġê³µíı¬ë¥¼&#34;:8493,&#34;ĠíıĲì§Ģ&#34;:8494,&#34;ĠìıŁìķĦ&#34;:8495,&#34;ìĥĪë¡Ŀ&#34;:8496,&#34;Ġìĸ´ëĳĲìļ´&#34;:8497,&#34;ì¨Įëĵł&#34;:8498,&#34;ĠìĽ°ë©ĶìĿ´ëĵľ&#34;:8499,&#34;ĠìŀĲëıĻì°¨&#34;:8500,&#34;ãĤ&#34;:8501,&#34;ķħ&#34;:8502,&#34;ìĹĲëĭ¤&#34;:8503,&#34;ìĹĲëĭ¤ê°Ģ&#34;:8504,&#34;ê¸°ìĪł&#34;:8505,&#34;ĠìĿ´ë»&#34;:8506,&#34;...!&#34;:8507,&#34;ë©Ģ&#34;:8508,&#34;ìĿ¸ìĺģíĻĶ&#34;:8509,&#34;ìĿ¸ê±¸&#34;:8510,&#34;ìľ¼ëŁ¬&#34;:8511,&#34;ëĮĢê³ł&#34;:8512,&#34;Ġì¢ĭìľ¼ëĤĺ&#34;:8513,&#34;ì£¼ìĦ±ì¹ĺ&#34;:8514,&#34;Ġíķľíİ¸ìĿĺ&#34;:8515,&#34;ëĵľëĦ¤ìļĶ&#34;:8516,&#34;ëĵľìĽĮ&#34;:8517,&#34;Ġìĭľì¼ľ&#34;:8518,&#34;ĠìĬ¤íħĿ&#34;:8519,&#34;ĠìµľìĨĮíķľ&#34;:8520,&#34;Ġëª¨ìķĦ&#34;:8521,&#34;Ġë§ĲìĿĢ&#34;:8522,&#34;ëħĦê°Ħ&#34;:8523,&#34;Ġê²ĥë§Į&#34;:8524,&#34;Ġë³¼ê¹Į&#34;:8525,&#34;Ġë¶ĢíĻľ&#34;:8526,&#34;ì¢ĭìķĺìĸ´ìļĶ&#34;:8527,&#34;ĠëĵľëĿ¼ë§ĪìĹĲ&#34;:8528,&#34;ĠëģĿëĤĺìĦľ&#34;:8529,&#34;ëıĻìĿ´&#34;:8530,&#34;ĠëŃĲìŀĦ&#34;:8531,&#34;Ġìŀ¬ë¯¸ìŀĪìĹĪìĿĮ&#34;:8532,&#34;Ġìĭ¶ëĭ¤ë©´&#34;:8533,&#34;Ġê³łë¬¸&#34;:8534,&#34;ëŁ½ì§Ģ&#34;:8535,&#34;ê´ĢìĿĦ&#34;:8536,&#34;Ġìĭľê°ĦëķĮ&#34;:8537,&#34;ĠëķĮëĬĶ&#34;:8538,&#34;ĠìĺĪì¸¡&#34;:8539,&#34;ì°¨íĶ¼&#34;:8540,&#34;íĭ°ê°Ģ&#34;:8541,&#34;ĠíĸĪìĬµëĭĪëĭ¤&#34;:8542,&#34;Ġë©ĭì§Ģ&#34;:8543,&#34;Ġê´Ģìĭ¬ìĿ´&#34;:8544,&#34;ìłķëıĦìĿĺ&#34;:8545,&#34;ĠëĶ°ìľĦ&#34;:8546,&#34;ë§¤ìĿ´ìħĺ&#34;:8547,&#34;Ġë¡ľë§Ŀ&#34;:8548,&#34;ìŀĺë§Įëĵł&#34;:8549,&#34;ëĭĪë²Ħ&#34;:8550,&#34;Ġëĭ¨ìĸ´&#34;:8551,&#34;ì°¸ëĤĺ&#34;:8552,&#34;ë°°ëĬĶ&#34;:8553,&#34;ĠëĤ¨ìŀĲì£¼ìĿ¸ê³µ&#34;:8554,&#34;ĠìĿ¸ê°ĦìĿĢ&#34;:8555,&#34;Ġìĭ¤ë§ĿìĿ´&#34;:8556,&#34;ĠíĤ¹&#34;:8557,&#34;Ġëª¨ìĬµìĹĲ&#34;:8558,&#34;ĠìºĲë¦ŃíĦ°ëĵ¤&#34;:8559,&#34;ĠìºĲë¦ŃíĦ°ë¥¼&#34;:8560,&#34;ãĦ·ãĦ·ãĦ·ãĦ·&#34;:8561,&#34;ĠìĨĲê°ĢëĿ½&#34;:8562,&#34;ĠëĴ¤ì£½ë°ķì£½&#34;:8563,&#34;Ġìŀĳê°ĢìĿĺ&#34;:8564,&#34;ëħ¸ìŀ¼ëħ¸ìŀ¼&#34;:8565,&#34;ëĪĪìĿ´&#34;:8566,&#34;ĠìłĪë§Ŀ&#34;:8567,&#34;íĮ¬ìĿ´&#34;:8568,&#34;íĻķìĭ¤íŀĪ&#34;:8569,&#34;ĠíĴĢìĸ´ëĤ¸&#34;:8570,&#34;ëĤĺìĻĶìľ¼ë©´&#34;:8571,&#34;Ġíķµëħ¸ìŀ¼&#34;:8572,&#34;íķĻëħĦëķĮ&#34;:8573,&#34;ĠìĻ¸ê³ĦìĿ¸&#34;:8574,&#34;ìĬ¤íĭ°ë¸Ĳ&#34;:8575,&#34;ê´ľíŀĪ&#34;:8576,&#34;ìłĬìĿĢ&#34;:8577,&#34;&gt;&gt;&#34;:8578,&#34;´ëĵľ&#34;:8579,&#34;Ġx&#34;:8580,&#34;ìĿ´ìłķ&#34;:8581,&#34;ê³½&#34;:8582,&#34;ê³łìĭ¶ëĭ¤&#34;:8583,&#34;íĻĶëĬĶ&#34;:8584,&#34;ĠìŀĪëĥĲ&#34;:8585,&#34;ëıĦìłĢíŀĪ&#34;:8586,&#34;íķľê°Ģ&#34;:8587,&#34;ê¸°ìŀĲ&#34;:8588,&#34;ê¸°ë³´ëĭ¨&#34;:8589,&#34;ĠìĿ´ë§Įíķľ&#34;:8590,&#34;ĠìĿ´ìģ¨&#34;:8591,&#34;ìĸ´ëĤĺìĦľ&#34;:8592,&#34;ë§Įëĵ¬&#34;:8593,&#34;Ġìłĸ&#34;:8594,&#34;ëĵ¤ëŁ¬&#34;:8595,&#34;ìķĦëĵ¤ìĿ´&#34;:8596,&#34;Ġë³´ìķĦëıĦ&#34;:8597,&#34;Ġê·¸ëĵ¤ìĿ´&#34;:8598,&#34;Ġê·¸ëıĻìķĪ&#34;:8599,&#34;ìĬ¤ëłĪ&#34;:8600,&#34;ìĬ¤íĦ´&#34;:8601,&#34;ë§Ĳíķł&#34;:8602,&#34;ì¤įëĭĪëĭ¤&#34;:8603,&#34;Ġëĭ¤ë³´ê³ł&#34;:8604,&#34;ìĪĺìłķ&#34;:8605,&#34;ìŀ¥ìĿĢ&#34;:8606,&#34;ĠìĬµ&#34;:8607,&#34;Ġì§ĢíĤ¤&#34;:8608,&#34;ĠëĤ´ëıĪ&#34;:8609,&#34;Ġê¸°íĥĢ&#34;:8610,&#34;ĠìķĬìĬµëĭĪëĭ¤&#34;:8611,&#34;Ġê±·&#34;:8612,&#34;ìĨĮìĭľ&#34;:8613,&#34;Ġìµľê³łëĿ¼ê³ł&#34;:8614,&#34;Ġê°ľëĤĺ&#34;:8615,&#34;ĠìŀĲë³¸&#34;:8616,&#34;Ġë³¸ê²ĥ&#34;:8617,&#34;ìľłë¨¸&#34;:8618,&#34;ìµľê°ķ&#34;:8619,&#34;Ġê³µì§ľë¡ľ&#34;:8620,&#34;ĠëģĿìĿĦ&#34;:8621,&#34;Ġì¡°ì¹´&#34;:8622,&#34;Ġíķ´ìķ¼ì§Ģ&#34;:8623,&#34;ë¬¼ë¡ľ&#34;:8624,&#34;Ġì¹ł&#34;:8625,&#34;ëª¨ë¥¼&#34;:8626,&#34;ĠìĽĥê¸°ëĬĶ&#34;:8627,&#34;Ġìĥģì§ķ&#34;:8628,&#34;íĶĦëłĪ&#34;:8629,&#34;ĠíķłìķĦë²Ħì§Ģ&#34;:8630,&#34;ì½Ķëĵľ&#34;:8631,&#34;Ġê¸°ëĮĢìķĪíķĺê³ł&#34;:8632,&#34;ì²ľìĽĲ&#34;:8633,&#34;ĠìĹ°ì¶ľëł¥ìĿ´&#34;:8634,&#34;ĠíĸĪìĿĦê¹Į&#34;:8635,&#34;ìĤ´ëķĮ&#34;:8636,&#34;Ġë³´ìĹ¬ì¤Ħ&#34;:8637,&#34;íĽ¨&#34;:8638,&#34;íķĺê¸°ê°Ģ&#34;:8639,&#34;Ġê¼Ńë³´ìĦ¸ìļĶ&#34;:8640,&#34;ìĺĢëĭ¤ë©´&#34;:8641,&#34;Ġêµ¬ìĦ±ëıĦ&#34;:8642,&#34;ê°ĲëıĻìłģ&#34;:8643,&#34;ê°ĲëıĻê³¼&#34;:8644,&#34;Ġê±¸ê¹Į&#34;:8645,&#34;ĠìĨįìķĺëĭ¤&#34;:8646,&#34;Ġìľłì¹ĺíķ´ìĦľ&#34;:8647,&#34;Ġãħİãħİãħİãħİ&#34;:8648,&#34;Ġë°ĺìłĦìĹĲ&#34;:8649,&#34;ĠìĿ¸ê°Ħëĵ¤&#34;:8650,&#34;ìŀ¥ë©´ìĹĲìĦľ&#34;:8651,&#34;ì£½ìĿĮ&#34;:8652,&#34;ìĹŃìĭľëĤĺ&#34;:8653,&#34;ìķĦìĿ´ëıĮ&#34;:8654,&#34;ë¸Įë¦¬&#34;:8655,&#34;Ġë²Ħëł¤&#34;:8656,&#34;ë»ĶíĸĪëĭ¤&#34;:8657,&#34;Ġê°Ģì¡±ìĺģíĻĶ&#34;:8658,&#34;Ġëª¨ë¥´ê²łëĦ¤&#34;:8659,&#34;ëıĮëł¤&#34;:8660,&#34;ĠìķŀìĹĲ&#34;:8661,&#34;ê²ģëĤĺ&#34;:8662,&#34;ëĨĪìĿ´&#34;:8663,&#34;ĠíĮĲíĥĢ&#34;:8664,&#34;ìłĲëĮĢê°Ģ&#34;:8665,&#34;Ġê¸¸ìĿĦ&#34;:8666,&#34;ĠìĿ´ëĶ´ê±¸&#34;:8667,&#34;íķĦë¦Ħ&#34;:8668,&#34;íķĺìŀĲë©´&#34;:8669,&#34;ĠëĤ®ìĿĢì§Ģ&#34;:8670,&#34;Ġë§ĮëĵľëĦ¤&#34;:8671,&#34;Ġìŀĺë§Įëĵ¤ìĹĪëĭ¤&#34;:8672,&#34;ë²Īë´Ĳ&#34;:8673,&#34;ĠíĭĢë¦¼&#34;:8674,&#34;Ġì°½íĶ¼&#34;:8675,&#34;ĠìķĪë§ŀëĬĶ&#34;:8676,&#34;ĠìĽĮëĤĻ&#34;:8677,&#34;ë§¤ëł¥ìłģìĿ¸&#34;:8678,&#34;Ġìī¬ìļ´&#34;:8679,&#34;Ġíĥľìĸ´ëĤĺìĦľ&#34;:8680,&#34;ìĻĦë²½íķľ&#34;:8681,&#34;ëĤ´ìĥĿìĹĲ&#34;:8682,&#34;ìķĪëĲľëĭ¤&#34;:8683,&#34;ĠìłĲìĪĺì¤Ģê²ĥëĵ¤&#34;:8684,&#34;Ġê°Ŀê´Ģ&#34;:8685,&#34;²ķ&#34;:8686,&#34;ıëĭ¤&#34;:8687,&#34;ìĿ´ë¯¼&#34;:8688,&#34;ìĿ´ìĹĪëįĺ&#34;:8689,&#34;ìĹ£&#34;:8690,&#34;ê°Ģë©°&#34;:8691,&#34;ĠìĿ´ëĿ¼ëĬĶ&#34;:8692,&#34;ìĸ´ë¨¸ëĭĪ&#34;:8693,&#34;...(&#34;:8694,&#34;Ġê°ĵ&#34;:8695,&#34;êµ¬ë¦¬&#34;:8696,&#34;Ġë³´ëĿ¼&#34;:8697,&#34;Ġì¢ĭì§Ģ&#34;:8698,&#34;ì£¼ëĬĶëį°&#34;:8699,&#34;ì§ĦìĿĺ&#34;:8700,&#34;Ġíķľëĭ¤ê³ł&#34;:8701,&#34;ìķĺëĤĺ&#34;:8702,&#34;íķłë§ĲìĿ´&#34;:8703,&#34;Ġëį®&#34;:8704,&#34;êµ¬ëĬĶ&#34;:8705,&#34;Ġë¬´ìĭĿ&#34;:8706,&#34;ë¶ĦëıĦ&#34;:8707,&#34;íİ¸ê¹Įì§Ģ&#34;:8708,&#34;íĬ¸ë¦Ń&#34;:8709,&#34;Ġìŀ¥êµŃìĺģ&#34;:8710,&#34;Ġë²ħ&#34;:8711,&#34;Ġë¶Ģìłķ&#34;:8712,&#34;ĠìķĪë´ĲëıĦ&#34;:8713,&#34;ëªħìĿĢ&#34;:8714,&#34;ĠëģĿëĤł&#34;:8715,&#34;ĠëĤ´ìļ©ìłĦê°ľ&#34;:8716,&#34;ĠëĲĺëıĮìķĦ&#34;:8717,&#34;ëıĻê±´&#34;:8718,&#34;ì¡°íıŃ&#34;:8719,&#34;ëª¨ìĸĳ&#34;:8720,&#34;Ġëĭ¤ìĭľê¸Ī&#34;:8721,&#34;ëŃī&#34;:8722,&#34;Ġëĵ¤ê²Į&#34;:8723,&#34;Ġë§Īì§Ģë§īìĿ´&#34;:8724,&#34;Ġë³´ìĹ¬ì¤¬&#34;:8725,&#34;Ġë°°ê¼½&#34;:8726,&#34;íķĺëĤĺìļĶ&#34;:8727,&#34;ìĽłëĬĶëį°&#34;:8728,&#34;ãħľãħľãħľ&#34;:8729,&#34;Ġë§ŀëĤĺ&#34;:8730,&#34;ĠëĪĦêµ¬ë&#34;:8731,&#34;ìĤ¬ëŀĳíķĺëĬĶ&#34;:8732,&#34;ĠìķĦëĭĪëĿ¼ë©´&#34;:8733,&#34;íĿ¬ìĦł&#34;:8734,&#34;íĻ©ëĭ¹&#34;:8735,&#34;Ġë¨¸ë¦¿&#34;:8736,&#34;ìĿ´ëĿ¼ëĬĶê²Į&#34;:8737,&#34;ì²ĺìĿĮìĹĲ&#34;:8738,&#34;Ġê°Ģì¡±ìĿ´&#34;:8739,&#34;Ġê³¤&#34;:8740,&#34;ĠìŀłìĿĦ&#34;:8741,&#34;ĠëĮĢìĤ¬ëıĦ&#34;:8742,&#34;ëįķìĹĲ&#34;:8743,&#34;Ġìłľëª©ìĿĦ&#34;:8744,&#34;ĠëĦ¤íĭ°ì¦Į&#34;:8745,&#34;Ġê¸ĢìĿĦ&#34;:8746,&#34;ì°¬ìļ±&#34;:8747,&#34;Ġê·ĢìĹ¬ìĽĮìļĶ&#34;:8748,&#34;Ġì¶©ë¶Ħíķľ&#34;:8749,&#34;Ġth&#34;:8750,&#34;ĠìĬ¤íĨłë¦¬ë¡ľ&#34;:8751,&#34;Ġì»¤ë²Ħ&#34;:8752,&#34;ìłłìŀ¥&#34;:8753,&#34;ëĴ¤ë¡ľ&#34;:8754,&#34;ĠìĿ´ë¯¸ì§Ģ&#34;:8755,&#34;ĠìłĪìłľ&#34;:8756,&#34;Ġì§ģìĹħ&#34;:8757,&#34;ĠíĹĪë¬´íķľ&#34;:8758,&#34;¬ë¦°ëĭ¤&#34;:8759,&#34;Ġìĺ¤ê¸Ģê±°ë¦¬ëĬĶ&#34;:8760,&#34;ì¹ľêµ¬ê°Ģ&#34;:8761,&#34;Ġë®¤ì§ģ&#34;:8762,&#34;Ġê·¸ëł¤ëĤ¸&#34;:8763,&#34;Ġê±°ì§Ģê°ĻìĿĢ&#34;:8764,&#34;Ġëĭ¤ìļ´ë°ĽìķĦìĦľ&#34;:8765,&#34;ĠìĿ´íķĺëıĦ&#34;:8766,&#34;ìĤ´ëĭ¤ìĤ´ëĭ¤&#34;:8767,&#34;ĠíĽĦìĨįìŀĳ&#34;:8768,&#34;Ġê°Ĳëªħê¹Ĭê²Į&#34;:8769,&#34;ëĭ¨ìĪľíķľ&#34;:8770,&#34;ĠëĽ°ìĸ´ëĦĺëĬĶ&#34;:8771,&#34;ĠìłĦë°ĺìłģìľ¼ë¡ľ&#34;:8772,&#34;ëłĪë©ĺíĥĢìĿ¸&#34;:8773,&#34;ĠìĦ¤ëĵĿëł¥&#34;:8774,&#34;Ġì²©ë³´&#34;:8775,&#34;.!&#34;:8776,&#34;bc&#34;:8777,&#34;įĶ&#34;:8778,&#34;ìĹ¬ë¦Ħ&#34;:8779,&#34;ì§ĢìĦŃ&#34;:8780,&#34;ê²»&#34;:8781,&#34;ìĿĢëĵ¯&#34;:8782,&#34;ìĿĢê·¼&#34;:8783,&#34;ìĿĦì§Ģ&#34;:8784,&#34;ĠìĿ´ì¤Ģ&#34;:8785,&#34;ĠìĿ´ìĨĮë£¡&#34;:8786,&#34;ìķĦìĿĺ&#34;:8787,&#34;ìķĦëĭ´&#34;:8788,&#34;ĠìķĦëĵ¤ìĿ´&#34;:8789,&#34;ëŁ¬ë¦¬&#34;:8790,&#34;ëĮĢìŀĳ&#34;:8791,&#34;ìļ°ë¦¬ëĬĶ&#34;:8792,&#34;ìŀ¥ìĹĲ&#34;:8793,&#34;Ġìłķìĥģ&#34;:8794,&#34;ê³¼ìĹ°&#34;:8795,&#34;Ġìĺ®&#34;:8796,&#34;íĥĵ&#34;:8797,&#34;ĠíķľìĪľê°Ħ&#34;:8798,&#34;ìŀ¬ë¡ľ&#34;:8799,&#34;Ġì§ĦìĪĺ&#34;:8800,&#34;Ġë´¤ëĤĺ&#34;:8801,&#34;ìĹ¬ìĦ±&#34;:8802,&#34;ĠìĪĺëĬĶ&#34;:8803,&#34;íĦ°ë¦¬&#34;:8804,&#34;ì¤ĳíķĻêµĲ&#34;:8805,&#34;ëŁ¬ìĬ¤&#34;:8806,&#34;ëķĮëıĦ&#34;:8807,&#34;Ġë§Īëĭ¤&#34;:8808,&#34;ìĭ¤ëł¥&#34;:8809,&#34;Ġëª»ë¯¸&#34;:8810,&#34;ëĶĶì¦ĪëĭĪ&#34;:8811,&#34;íĬ¸ëĿ¼&#34;:8812,&#34;ĠìĿ´ëŁ°ìĺģíĻĶëĬĶ&#34;:8813,&#34;ĠìĨĮíĨµ&#34;:8814,&#34;ëįĶìļ±&#34;:8815,&#34;ìŀ¬ë°ĮìĹĪëĭ¤&#34;:8816,&#34;ĠìĽĥìĹĪëĭ¤&#34;:8817,&#34;Ġë°ĶëĿ¼ëĬĶ&#34;:8818,&#34;Ġìĥģíĥľ&#34;:8819,&#34;ì§Īì§Īëģ&#34;:8820,&#34;ĠëķĮê°Ģ&#34;:8821,&#34;ĠëĦĺìĸ´ìĦľ&#34;:8822,&#34;ľì°¬&#34;:8823,&#34;ëł¸ëĦ¤&#34;:8824,&#34;Ġë¡ľëĵľ&#34;:8825,&#34;ãħĭãħĭãħĭãħĭãħĭãħĭãħĭãħĭãħĭ&#34;:8826,&#34;Ġìĸ´ëĸł&#34;:8827,&#34;ëª©ìĨĮë¦¬&#34;:8828,&#34;Ġê¹Ģì¹ĺ&#34;:8829,&#34;ìĽĥê¸°ê³ł&#34;:8830,&#34;Ġãħłãħłãħłãħł&#34;:8831,&#34;Ġì¤ĦìĿ´ìķ¼&#34;:8832,&#34;ìķĪë´¤&#34;:8833,&#34;ĠìķĦìĿ´ëĶĶìĸ´&#34;:8834,&#34;ìĬ¤ëŁ¬ìĽłëĭ¤&#34;:8835,&#34;ìĵ°ëłĪê¸°ìĵ°ëłĪê¸°&#34;:8836,&#34;íĿ¬ë§Ŀ&#34;:8837,&#34;ìķĦìĿ´ëĵ¤&#34;:8838,&#34;ë¿ĲìĿ´ëĭ¤&#34;:8839,&#34;Ġì¤Ģë¹Ħ&#34;:8840,&#34;ìĬ¹ìļ°&#34;:8841,&#34;ĠíĳľíĺĦìĿ´&#34;:8842,&#34;Ġëĵ±ë¡Ŀ&#34;:8843,&#34;íĹĪìĪł&#34;:8844,&#34;Ġëĸ¨ìĸ´ëľ¨&#34;:8845,&#34;ĠìķĦìī¬ìĽĮìļĶ&#34;:8846,&#34;ĠìŀĬìĿĦìĪĺ&#34;:8847,&#34;ĠìĨĮìŀ¬ìĿĺ&#34;:8848,&#34;Ġì¡°ê¸Īë§Į&#34;:8849,&#34;ĠìĤ´ìķĦìŀĪëĬĶ&#34;:8850,&#34;íļ¨ì£¼&#34;:8851,&#34;ĠìĿ¸ìĥģìłģ&#34;:8852,&#34;Ġìĭľì²ŃìŀĲ&#34;:8853,&#34;Ġê¹¨ìķĮ&#34;:8854,&#34;ì¤ĳê°Ħì¤ĳê°Ħ&#34;:8855,&#34;Ġíĺ¼ëŀĢ&#34;:8856,&#34;ìĭľíĤ¤ê³ł&#34;:8857,&#34;ìĭľíĤ¤ì§Ģ&#34;:8858,&#34;ãħĩãħĩãħĩãħĩ&#34;:8859,&#34;Ġì£ĦìĨ¡&#34;:8860,&#34;Ġìĺģìĥģë¯¸ê°Ģ&#34;:8861,&#34;ê·¸ëŀ¬&#34;:8862,&#34;Ġìĸ¸ëĭĪ&#34;:8863,&#34;ìĭľë¦¬ì¦Īì¤ĳ&#34;:8864,&#34;Ġê·¸ë¦¬ìĽĮ&#34;:8865,&#34;ĠìĺĽëĤłìĹĲ&#34;:8866,&#34;íŀĺëĵł&#34;:8867,&#34;ĠìĬ¹ë¦¬&#34;:8868,&#34;ãĦ¹ãħĩ&#34;:8869,&#34;ì°¾ìķĦ&#34;:8870,&#34;âĺħâĺĨ&#34;:8871,&#34;Ġì°¬ìĸĳ&#34;:8872,&#34;Ġíĺķíİ¸ìĹĨëĬĶ&#34;:8873,&#34;Īëł¨&#34;:8874,&#34;Ġëª½íĻĺ&#34;:8875,&#34;ìĺµëĭĪëĭ¤&#34;:8876,&#34;Ġìĸ´ëķł&#34;:8877,&#34;¤ë²Ħ&#34;:8878,&#34;Ġu&#34;:8879,&#34;Ġ;;;&#34;:8880,&#34;ģĿ&#34;:8881,&#34;..!!&#34;:8882,&#34;ì§ĢìĽĲ&#34;:8883,&#34;ê°Ģë©´ìĦľ&#34;:8884,&#34;Ġìķ¨&#34;:8885,&#34;ëĤĺëĿ¼ëĬĶ&#34;:8886,&#34;ĠìĿ´ìĦ±&#34;:8887,&#34;ĠìĿ´ë³Ħ&#34;:8888,&#34;Ġë§ģ&#34;:8889,&#34;ìĸ´ì°Į&#34;:8890,&#34;ìķĦëł¨&#34;:8891,&#34;ìĿ¸ìĥģ&#34;:8892,&#34;ìĿ¸ëĶĶ&#34;:8893,&#34;ĠìķĦìļ°&#34;:8894,&#34;Ġë³´êµ¬&#34;:8895,&#34;ë³´ëįĺ&#34;:8896,&#34;ìĬ¤ëŀĢ&#34;:8897,&#34;ëŀĮìĿ´&#34;:8898,&#34;ë§ĪëĬĶ&#34;:8899,&#34;ĠëĤĺê³ł&#34;:8900,&#34;ĠíķĺëıĦ&#34;:8901,&#34;Ġíķĺê¸°ìĹĶ&#34;:8902,&#34;ì£¼ìľ¨&#34;:8903,&#34;Ġê²ł&#34;:8904,&#34;ĠìŀĪê¸´&#34;:8905,&#34;ĠìŀĪê²łì§Ģë§Į&#34;:8906,&#34;ê°ĦëıĦ&#34;:8907,&#34;Ġê¸°ê´´&#34;:8908,&#34;íĮ¡&#34;:8909,&#34;Ġë¬´ê±°ìļ´&#34;:8910,&#34;ĠìķĪì¢ĭ&#34;:8911,&#34;ĠìķĪëĤĺìĺ´&#34;:8912,&#34;Ġëª»íķĺê²łëĭ¤&#34;:8913,&#34;Ġë³¸ì§Ī&#34;:8914,&#34;ìłĢê²ĥ&#34;:8915,&#34;ìĽĲìĹĲ&#34;:8916,&#34;ĠìĿ¼ìĿĦ&#34;:8917,&#34;ĠìĤ¬íĪ¬ë¦¬&#34;:8918,&#34;Ġë°°ìļ°ëĵ¤ìĿĦ&#34;:8919,&#34;Ġíķ´ë¦¬íı¬íĦ°&#34;:8920,&#34;Ġê°ĲìĿ´&#34;:8921,&#34;Ġê³łìĸ´&#34;:8922,&#34;íķĺì§Ģë§Ĳê³ł&#34;:8923,&#34;ĠìĹŃê²¹ëĭ¤&#34;:8924,&#34;ë¯¼ìĿĺ&#34;:8925,&#34;Ġíı°&#34;:8926,&#34;ëĬĲìĻĢë¥´&#34;:8927,&#34;ĠëĶ°ë¶Ħ&#34;:8928,&#34;ĠëĤľìŀ¡&#34;:8929,&#34;ë°©ìĭĿ&#34;:8930,&#34;ĠìºĲë¦Ń&#34;:8931,&#34;ëĪĪë&#34;:8932,&#34;Ġë³Ħê±°&#34;:8933,&#34;ê°ĲëıĻìĿĦ&#34;:8934,&#34;Ġë³¼ë§Įíķ©ëĭĪëĭ¤&#34;:8935,&#34;ìĤ¬ëĵľ&#34;:8936,&#34;ĠìłĦê°ľìĹĲ&#34;:8937,&#34;ì±Ļ&#34;:8938,&#34;ëĭ¤ìļ´ë°Ľ&#34;:8939,&#34;ìŀ¥ë©´ëıĦ&#34;:8940,&#34;ĠíĶ¼íĦ°&#34;:8941,&#34;ĠíĳľíĺĦíķł&#34;:8942,&#34;Ġëĭ´ë°±&#34;:8943,&#34;Ġìĭ¸ìļ°&#34;:8944,&#34;Ġ--&#34;:8945,&#34;íķłìĪĺìŀĪëĬĶ&#34;:8946,&#34;Ġë²łìĿ´&#34;:8947,&#34;ĠìķŀìĦľ&#34;:8948,&#34;oooo&#34;:8949,&#34;Ġìŀ¡ìķĦ&#34;:8950,&#34;ìħ¨ìľ¼ë©´&#34;:8951,&#34;íķĺìĭľê¸¸&#34;:8952,&#34;ĠìłĦìŁģìĿĺ&#34;:8953,&#34;ĠìłĦìŁģìĺģíĻĶ&#34;:8954,&#34;íı¬ë¨¸&#34;:8955,&#34;ĠíħĮìĿ´&#34;:8956,&#34;ĠìĹŃìĤ¬ìĥģ&#34;:8957,&#34;ëĴ¤ìĹĲ&#34;:8958,&#34;ëª¨ë¥´ê²Į&#34;:8959,&#34;ëª¨ë¥´ê²łëĭ¤&#34;:8960,&#34;Ġë²Ĺìĸ´ëĤĺ&#34;:8961,&#34;ĠìķĮëł¤ì£¼ëĬĶ&#34;:8962,&#34;ìĦ¼ìĬ¤&#34;:8963,&#34;ìĹ¬ê¸°ìĦľ&#34;:8964,&#34;Ġìĺ¤ê·¸ëĿ¼ëĵľëĬĶ&#34;:8965,&#34;ĠìĤ°ë§Įíķĺê³ł&#34;:8966,&#34;ĠíķĦìļĶíķľê°Ģ&#34;:8967,&#34;íİĻíĬ¸&#34;:8968,&#34;ì¼ĵëª¬&#34;:8969,&#34;Ġìļ°ëł¤ë¨¹&#34;:8970,&#34;ë©įì²Ń&#34;:8971,&#34;Ġì¹Ńì°¬&#34;:8972,&#34;ĠìĦ¬ëľ©&#34;:8973,&#34;Ġë§Īì°¬ê°Ģì§Ģ&#34;:8974,&#34;Good&#34;:8975,&#34;bad&#34;:8976,&#34;Ļíķ©&#34;:8977,&#34;ê³łíķľ&#34;:8978,&#34;ãħĲ&#34;:8979,&#34;Ġìķ¡&#34;:8980,&#34;ĠìĺģíĻĶëŀĳ&#34;:8981,&#34;ë¦¬ìĸ¸&#34;:8982,&#34;ëĭĪìĬ¤&#34;:8983,&#34;Ġì§¬ë½ķ&#34;:8984,&#34;ë©´ìĿĦ&#34;:8985,&#34;ìĭľëıĦ&#34;:8986,&#34;Ġëĭ¿&#34;:8987,&#34;ìŀĲìĭĿ&#34;:8988,&#34;ìĽį&#34;:8989,&#34;ĠëĦĲ&#34;:8990,&#34;ë§ĪìłĢëıĦ&#34;:8991,&#34;ĠìĹĨëįĺ&#34;:8992,&#34;ĠëĤĺìĹ´&#34;:8993,&#34;ìĺ¤ê³ł&#34;:8994,&#34;Ġìĸ´ìłķì©¡&#34;:8995,&#34;ì°Ĳ&#34;:8996,&#34;Ġíķľê±°&#34;:8997,&#34;Ġì§Ħíķľ&#34;:8998,&#34;íķĺëĬĶê²ĥëıĦ&#34;:8999,&#34;ê°ľìĿĺ&#34;:9000,&#34;ê°Ĳìĥģ&#34;:9001,&#34;Ġë§Īìķ½&#34;:9002,&#34;Ġìµľê³łëĦ¤ìļĶ&#34;:9003,&#34;Ġê°ľëĺ¥&#34;:9004,&#34;ë³¸ìĥī&#34;:9005,&#34;Ġë³´ê³łìŀĪëĬĶëį°&#34;:9006,&#34;ìłĢëĤĺ&#34;:9007,&#34;ë²ĪìĿ´ëĤĺ&#34;:9008,&#34;ĠìĤ¬ìĥģ&#34;:9009,&#34;ëĭ¤ëĬĶê±´&#34;:9010,&#34;ëıĻìļ±&#34;:9011,&#34;Ġìļ°ëĬĶ&#34;:9012,&#34;ĠëŃĲëĿ¼ê³ł&#34;:9013,&#34;Ġê°Ĳëıħê³¼&#34;:9014,&#34;Ġê³łëıħ&#34;:9015,&#34;Ġê±°ê¸°ëĭ¤&#34;:9016,&#34;Ġê±°ëĵŃ&#34;:9017,&#34;ĠìĥģëĮĢ&#34;:9018,&#34;Ġìĵ°ëłĪê¸°ë¥¼&#34;:9019,&#34;íıīìłĲì¡°ìłĪ&#34;:9020,&#34;Ġìĭłê³ł&#34;:9021,&#34;íļĮë¶ĢíĦ°&#34;:9022,&#34;ë´Ĳìķ¼ì§Ģ&#34;:9023,&#34;ìĿ´ëŁ°ìĺģíĻĶê°Ģ&#34;:9024,&#34;ĠìĿĺíķ´&#34;:9025,&#34;ìĺĪê³ł&#34;:9026,&#34;ìł¸ìķ¼&#34;:9027,&#34;Ġê¸°ëĮĢìĹĨìĿ´&#34;:9028,&#34;íĮĲìĿĦ&#34;:9029,&#34;ĠíĸĪìĸ´ìļĶ&#34;:9030,&#34;ĠíĸĪëĬĶì§Ģ&#34;:9031,&#34;Ġëĵ¤ìĸ´ìĦľ&#34;:9032,&#34;Ġë©ĭì§Ĳ&#34;:9033,&#34;ĠìĽĲíķĺëĬĶ&#34;:9034,&#34;íĺ¸ëŁ¬&#34;:9035,&#34;ĠëıĦìĻĢ&#34;:9036,&#34;ĠëĤľë¦¬&#34;:9037,&#34;Ġëĭ¹ìŀ¥&#34;:9038,&#34;ĠìĹ¬ìŀĲë¥¼&#34;:9039,&#34;Ġë§īíĮĲ&#34;:9040,&#34;ìĹĩìĸ´ìļĶ&#34;:9041,&#34;ìĪľìĿ´&#34;:9042,&#34;ĠëĨĴì§Ģ&#34;:9043,&#34;ì¼ĢìĿ´&#34;:9044,&#34;ì¡Įìľ¼ë©´&#34;:9045,&#34;ë¶Īíĺ¸ê°Ģ&#34;:9046,&#34;Ġì½Ķë¯¸ëĶĶìĺģíĻĶ&#34;:9047,&#34;ĠëĿ¼ìĬ¤íĬ¸&#34;:9048,&#34;ĠëĬĲê»´ì§Ģ&#34;:9049,&#34;ë§Įíģ¼ìĿ´ëĤĺ&#34;:9050,&#34;ĠíĮĮê²©&#34;:9051,&#34;ĠìĽĲìŀĳìĹĲ&#34;:9052,&#34;ê¿Ģ&#34;:9053,&#34;ĠìłĪëĮĢë¡ľ&#34;:9054,&#34;ĠêµŃìĸ´&#34;:9055,&#34;íĶĮë¦°&#34;:9056,&#34;ì¿¨&#34;:9057,&#34;Ġíļį&#34;:9058,&#34;ê²ĥê°ĻìĿĮ&#34;:9059,&#34;íķĺíķĺíķĺíķĺ&#34;:9060,&#34;Ġë¸Įë£¨ìĬ¤&#34;:9061,&#34;Ġë§Īëĥ¥&#34;:9062,&#34;Ġíı¬ìĬ¤íĦ°ê°Ģ&#34;:9063,&#34;ë¶ģíķľ&#34;:9064,&#34;ĠíĿĳë°±&#34;:9065,&#34;ĠíĤ¬ë§ģíĥĢìŀĦìļ©ìľ¼ë¡ľ&#34;:9066,&#34;ë²Įìį¨&#34;:9067,&#34;ìĨĮìĦ¤ìĿĦ&#34;:9068,&#34;ìĺ¤ê¸Ģê±°&#34;:9069,&#34;Ġë©Ķìĭľì§Ģ&#34;:9070,&#34;****&#34;:9071,&#34;ìķĦê¹Įìļ´ìĺģíĻĶ&#34;:9072,&#34;Ġë°¤ìĹĲ&#34;:9073,&#34;ìŀ¥ë¥´ê°Ģ&#34;:9074,&#34;Ġê²©íĪ¬&#34;:9075,&#34;Ġê¹ĶëģĶíķľ&#34;:9076,&#34;very&#34;:9077,&#34;Ġê±°ê¸°ìĦľ&#34;:9078,&#34;ĠíĿīëĤ´&#34;:9079,&#34;ĠìĬ¤ë¦´ëŁ¬ë¬¼&#34;:9080,&#34;ë®¤ì§Ģì»¬&#34;:9081,&#34;ìľłì¾Įíķĺê³ł&#34;:9082,&#34;ĠìĿ´ëģĮìĸ´&#34;:9083,&#34;ĠëĤ©ëĵĿ&#34;:9084,&#34;ĠëĳĶ&#34;:9085,&#34;ëĵ±ìŀ¥ìĿ¸ë¬¼&#34;:9086,&#34;ê°ĲìĤ¬íķ©ëĭĪëĭ¤&#34;:9087,&#34;BC&#34;:9088,&#34;íĳ¼&#34;:9089,&#34;Ġh&#34;:9090,&#34;Ġ??&#34;:9091,&#34;ĠâĢ&#34;:9092,&#34;ê³łëĵ±íķĻêµĲ&#34;:9093,&#34;Ġêº&#34;:9094,&#34;íķĺê¸¸ëŀĺ&#34;:9095,&#34;ê°Ģìķ¼&#34;:9096,&#34;ë§Įíķ´ìĦł&#34;:9097,&#34;Ġê°±&#34;:9098,&#34;ìĿ¸ì§ĢëĬĶ&#34;:9099,&#34;ìĬ¤ìĹĲìĦľ&#34;:9100,&#34;ìľ¼ëł¤&#34;:9101,&#34;!!âĻ¥&#34;:9102,&#34;ëĮĢê¸°&#34;:9103,&#34;ê¹Įë´Ĳ&#34;:9104,&#34;ìĹĨì§Ģë§Į&#34;:9105,&#34;Ġì¢ĭëįĶëĿ¼&#34;:9106,&#34;ì§Ħìłķ&#34;:9107,&#34;ĠìĥĪë²½ìĹĲ&#34;:9108,&#34;ìĨĶì§ģ&#34;:9109,&#34;ëĤ´ì§Ģ&#34;:9110,&#34;íĥ±&#34;:9111,&#34;íŀĲë§ģ&#34;:9112,&#34;ìĹ°ìĺĪ&#34;:9113,&#34;ê³µë¶Ģ&#34;:9114,&#34;ì¹ĺëĭ¤&#34;:9115,&#34;Ġëª¨ìĸĳ&#34;:9116,&#34;ĠìķĬìķĦìļĶ&#34;:9117,&#34;ëłĪìķĮ&#34;:9118,&#34;ĠìĥĿê°ģìĿĢ&#34;:9119,&#34;ĠìĥĿê°ģë§Į&#34;:9120,&#34;ìŀħëĭĪê¹Į&#34;:9121,&#34;Ġëª»íķ´ìĦľ&#34;:9122,&#34;ĠìĹ¬ì¹ľ&#34;:9123,&#34;ë¹ĦìĹĲ&#34;:9124,&#34;ĠëĤ¨ìĿĺ&#34;:9125,&#34;ĠëĤ¨ëĬĶê²Į&#34;:9126,&#34;ìłĢëĥ¥&#34;:9127,&#34;ĠìĨĮê°ľ&#34;:9128,&#34;ĠìĨĮëħĦ&#34;:9129,&#34;ëįĶêµ°&#34;:9130,&#34;Ġë¯¸íķĻ&#34;:9131,&#34;Ġë¯¸ëħĢ&#34;:9132,&#34;ê³Ħë¥¼&#34;:9133,&#34;íĭĪ&#34;:9134,&#34;Ġê³µë£¡&#34;:9135,&#34;ãħľãħł&#34;:9136,&#34;ĠëĲĺë©´&#34;:9137,&#34;Ġë°ĺìĿĳ&#34;:9138,&#34;ìĹŃìĿĦ&#34;:9139,&#34;ê²½ìĿĦ&#34;:9140,&#34;ìĹ°ê¸°ìĹĲ&#34;:9141,&#34;ĠìķĦëĭĪìĹĪëĭ¤&#34;:9142,&#34;ê·¹ìĿĺ&#34;:9143,&#34;Ġë§Īì§Ģë§īíļĮ&#34;:9144,&#34;ëł¸ëįĺ&#34;:9145,&#34;ĠëıĪëĤ´ê³ł&#34;:9146,&#34;ê¹Ģë¯¼&#34;:9147,&#34;íķĺê¸°ëĬĶ&#34;:9148,&#34;ĠìĿĮìĭĿ&#34;:9149,&#34;Ġë§Ŀíķł&#34;:9150,&#34;ĠìļĶìĥĪ&#34;:9151,&#34;íıīìĿĦ&#34;:9152,&#34;ëĬĶê±°ëĥĲ&#34;:9153,&#34;íĨµìĪĺ&#34;:9154,&#34;Ġì°įëĬĶ&#34;:9155,&#34;Ġìĭ¤ë§ĿìĿ´ëĭ¤&#34;:9156,&#34;ĠìºĲë¦ŃíĦ°ëıĦ&#34;:9157,&#34;ĠìºĲë¦ŃíĦ°ëĵ¤ìĿ´&#34;:9158,&#34;ĠëĨĢëŀĢ&#34;:9159,&#34;ëŁ¬ë©´&#34;:9160,&#34;ë¸ĮëĿ¼&#34;:9161,&#34;íĸ¥ìĿ´&#34;:9162,&#34;ĠëĤĺìĻĶëįĺ&#34;:9163,&#34;ĠëĤĺìĻĢìķ¼&#34;:9164,&#34;Ġê¸´ìŀ¥ê°ĲìĿĦ&#34;:9165,&#34;ĠìłķìĭłìĿ´&#34;:9166,&#34;ĠëĮĢìĤ¬ìĻĢ&#34;:9167,&#34;ìĭ¶ìĿĢëį°&#34;:9168,&#34;ëĤ¨ìŀĲìĿĺ&#34;:9169,&#34;ëĿ¼ìĿ´ì¦Ī&#34;:9170,&#34;ĠìļĶì¦ĺìĿĢ&#34;:9171,&#34;Ġê°ķì¶Ķíķ©ëĭĪëĭ¤&#34;:9172,&#34;Ġì¼Ģë¹Ī&#34;:9173,&#34;íĥĪë¦¬ìķĦ&#34;:9174,&#34;Ġì¶©ê²©ìłģìĿ¸&#34;:9175,&#34;Ġë¯¼ì¡±&#34;:9176,&#34;êµ³ìĿ´&#34;:9177,&#34;ĠìĹ¬ì£¼ìĿ¸ê³µìĿ´&#34;:9178,&#34;Ġëĵ£ê¸°&#34;:9179,&#34;Ġìĸ´ë¥¸ìĿ´&#34;:9180,&#34;ĠíħĮëŁ¬&#34;:9181,&#34;Ġíķľìĭ¬íķĺëĭ¤&#34;:9182,&#34;ë¹¼ê³¤&#34;:9183,&#34;ĠìĽĥê²¨ìĦľ&#34;:9184,&#34;ĠëĪĦêµ°ê°Ģ&#34;:9185,&#34;ë²Īë³´ê³ł&#34;:9186,&#34;ìĿ´ëŀĺìĦľ&#34;:9187,&#34;ìĿ´íĽĦë¡ľ&#34;:9188,&#34;!~&#34;:9189,&#34;ìª&#34;:9190,&#34;ŀĢ&#34;:9191,&#34;ìĿ´íķľ&#34;:9192,&#34;ìĿ´ìĻĢ&#34;:9193,&#34;ãħĮ&#34;:9194,&#34;íķľíİ¸&#34;:9195,&#34;ĠìĺģíĻĶê°Ļëĭ¤&#34;:9196,&#34;ìĸ´ì©Ķ&#34;:9197,&#34;Ġë³´ìĿ´ê³ł&#34;:9198,&#34;Ġê·¸ê°Ģ&#34;:9199,&#34;ìĭľë¥¼&#34;:9200,&#34;ë³´ëŁ¬&#34;:9201,&#34;ĠìĹĨìĹĪ&#34;:9202,&#34;ĠëĤĺë©´&#34;:9203,&#34;ĠíķĺìĦ¸ìļĶ&#34;:9204,&#34;ìĪĺëĭĺ&#34;:9205,&#34;ìĥģìļ°&#34;:9206,&#34;ĠìŀĪìĹĪìĿĮ&#34;:9207,&#34;íķĺê³łëıĦ&#34;:9208,&#34;¬ëŀĲ&#34;:9209,&#34;ëĤ´ìĦľ&#34;:9210,&#34;ìĹ°ìĿĺ&#34;:9211,&#34;Ġë´¤ê³ł&#34;:9212,&#34;ìĹ¬ëıĦ&#34;:9213,&#34;ìĿ¼ì§Ģ&#34;:9214,&#34;ìĿ¼ëŁ¬&#34;:9215,&#34;Ġëª¨ë¥¸&#34;:9216,&#34;ĠìłĦíĻĶ&#34;:9217,&#34;ë¶Ħì§ľë¦¬&#34;:9218,&#34;ê°Ĳíķľ&#34;:9219,&#34;ê·Ħ&#34;:9220,&#34;ĠìłľìĿ´ìĬ¨&#34;:9221,&#34;ëįĶìĿ´ìĥģ&#34;:9222,&#34;Ġë²¤&#34;:9223,&#34;Ġë¶Ģë¶Ģ&#34;:9224,&#34;ë²ĪìĹĲ&#34;:9225,&#34;Ġíķĳ&#34;:9226,&#34;ĠíķŃ&#34;:9227,&#34;Ġìŀ¬ë¯¸ìŀĪìĹĪëĬĶëį°&#34;:9228,&#34;ìŀ¬ë°ĮìĹĪëĬĶëį°&#34;:9229,&#34;ĠìĽĥìĿĦ&#34;:9230,&#34;ëĤ¨ìĿĦ&#34;:9231,&#34;Ġëĭ¤ìĭľë³´ê³ł&#34;:9232,&#34;ì²ŃìĨĮëħĦ&#34;:9233,&#34;ĠíķĺëĤĺëĬĶ&#34;:9234,&#34;ĠëĤĺìĺ¤ëĦ¤ìļĶ&#34;:9235,&#34;Ġìķ¡ìħĺìĶ¬&#34;:9236,&#34;Ġì½ĶìĬ¤&#34;:9237,&#34;êµĲìľ¡&#34;:9238,&#34;ĠìĿ´íķ´ëıĦ&#34;:9239,&#34;Ġë¶Īê°Ģ&#34;:9240,&#34;Ġì²ĺìĿĮìĿ´ëĦ¤&#34;:9241,&#34;Ġì²ĺìĿĮë³¸ëĭ¤&#34;:9242,&#34;Ġê·¹íĺĲ&#34;:9243,&#34;ìłķëıĦëĬĶ&#34;:9244,&#34;íĤ¤ëĵľ&#34;:9245,&#34;ë¥ĺìĺģíĻĶ&#34;:9246,&#34;ĠíıīíĻĶ&#34;:9247,&#34;ìĿ´ê±°ëĤĺ&#34;:9248,&#34;Ġê·¸ëŁ°ê±°&#34;:9249,&#34;ìķĮìķĦ&#34;:9250,&#34;Ġê´ľì°®ëĦ¤ìļĶ&#34;:9251,&#34;............&#34;:9252,&#34;íķĺê¸°ê¹Įì§Ģ&#34;:9253,&#34;Ġìĭ¬íĺķëŀĺ&#34;:9254,&#34;ĠíĹĪëĤĺ&#34;:9255,&#34;ĠíĺĦìĭ¤ê³¼&#34;:9256,&#34;ĠíĺĦìĭ¤ìłģìĿ´&#34;:9257,&#34;ê»ĺìĦľ&#34;:9258,&#34;ĠíĶ¼ìķĦëħ¸&#34;:9259,&#34;Ġìĸµì§ĢìĬ¤ëŁ½ê³ł&#34;:9260,&#34;ìĬ¹íĹĮ&#34;:9261,&#34;Ġìŀħìŀ¥ìĹĲìĦľ&#34;:9262,&#34;Ġíĺ¸íĿ¡&#34;:9263,&#34;ĠìĻĢìĦľ&#34;:9264,&#34;Ġì¹ľêµ¬ëŀĳ&#34;:9265,&#34;ì§Ģê¸ĪìĿĢ&#34;:9266,&#34;Ġìĸ´ëĶĶìĹĲ&#34;:9267,&#34;Ġì¡°ê¸ĪìĿĢ&#34;:9268,&#34;Ġë³´ê²ĮëĲĺëĬĶ&#34;:9269,&#34;ìĽĲìŀĳìĿ´&#34;:9270,&#34;Ġìĸ´ìĦ¤íĶĦëĭ¤&#34;:9271,&#34;Ġë¬¸ìłľë¥¼&#34;:9272,&#34;ĠìŀĶìŀĶíķĺê²Į&#34;:9273,&#34;Ġìĸĺê¸°ë¥¼&#34;:9274,&#34;Ġê°ĲëıĻìłģìĿ´ëĦ¤ìļĶ&#34;:9275,&#34;ìĨĲê°ĢëĿ½&#34;:9276,&#34;ĠíĴįìŀĲ&#34;:9277,&#34;Ġìĸ´ìļ¸ë¦¬ì§Ģ&#34;:9278,&#34;ìķĶíĬ¼&#34;:9279,&#34;Ġì½ĺ&#34;:9280,&#34;Ġíĺ¹ìĭľëĤĺ&#34;:9281,&#34;Ġìį°&#34;:9282,&#34;Ġë¬ĺíķľ&#34;:9283,&#34;Ġë²Ĺìĸ´&#34;:9284,&#34;Ġmovie&#34;:9285,&#34;ĠìĥĪìĤ¼&#34;:9286,&#34;ì§ĪëķĮ&#34;:9287,&#34;ì¤ĦìķĮìķĺëĭ¤&#34;:9288,&#34;ë½Ģ&#34;:9289,&#34;ĠìĹ¬ëŁ¬ë²Ī&#34;:9290,&#34;íĿ¥ë¯¸ì§Ħì§Ħ&#34;:9291,&#34;Ġìµľê·¼ìĹĲ&#34;:9292,&#34;ëĤ«ëĭ¤&#34;:9293,&#34;ĠëĿ¼ìĿ´ìĸ¸&#34;:9294,&#34;Ġì¸¡&#34;:9295,&#34;ìĺ¤ëŀ«ë§ĮìĹĲ&#34;:9296,&#34;ëĿ¼ìĹĲëª½&#34;:9297,&#34;25&#34;:9298,&#34;il&#34;:9299,&#34;vs&#34;:9300,&#34;ľìĭľ&#34;:9301,&#34;íķĺìĿĺ&#34;:9302,&#34;ê¸°ë°ľ&#34;:9303,&#34;ĠìĿ´ê²ĥìĿ´&#34;:9304,&#34;ìĸ´ëłµ&#34;:9305,&#34;ë¦¬ëĬĶëį°&#34;:9306,&#34;ĠìłĪë&#34;:9307,&#34;ìķĦëŀĺ&#34;:9308,&#34;ĠìķĦíĮł&#34;:9309,&#34;íķ´ê°ĢëĬĶ&#34;:9310,&#34;Ġë³´ê²łëĭ¤&#34;:9311,&#34;Ġë³´ìĦĿ&#34;:9312,&#34;ìĥĮ&#34;:9313,&#34;Ġê·¸ìĿ´ìĥģ&#34;:9314,&#34;ë°ĳ&#34;:9315,&#34;ëŀ´&#34;:9316,&#34;ĠìĤĲ&#34;:9317,&#34;ëĮĢì¤ĳ&#34;:9318,&#34;Ġì§Ģê²½&#34;:9319,&#34;ê·¸ëĭ¹ìĭľ&#34;:9320,&#34;Ġíķľê°ľëıĦ&#34;:9321,&#34;ìķĺìĸ´&#34;:9322,&#34;ë¯¸ë¥¼&#34;:9323,&#34;ë¯¸ëŀĺ&#34;:9324,&#34;ê²ĥê°ĻìĿĢëį°&#34;:9325,&#34;ìĿ¼ìĹĲ&#34;:9326,&#34;Ġìŀĺë³´ê³ł&#34;:9327,&#34;ĠëĬ¦ê²Į&#34;:9328,&#34;ê°ĲíŀĪ&#34;:9329,&#34;Ġê°Ļì§Ģë§Į&#34;:9330,&#34;ĠëĤ¨ê¸°ëĬĶ&#34;:9331,&#34;íĬ¸ìĻĢ&#34;:9332,&#34;Ġìĺ¤íķ´&#34;:9333,&#34;ĠìĬ¤íĨłë¦¬ìłĦê°ľ&#34;:9334,&#34;ìķĪìĹĲìĦľ&#34;:9335,&#34;ìĽĲìĹĲìĦľ&#34;:9336,&#34;Ġì§Ģë£¨íķ¨ìĿĦ&#34;:9337,&#34;ìĽĮì¦Ī&#34;:9338,&#34;ĠëĲĺìĦľ&#34;:9339,&#34;Ġíķ´ì¤Ģëĭ¤&#34;:9340,&#34;íĤ´&#34;:9341,&#34;Ġìĭ¶ìĹĪëĬĶëį°&#34;:9342,&#34;Ġê°ĲìĦ±ìĿĦ&#34;:9343,&#34;ĠìĤ¬ëŀĳìĬ¤ëŁ½ëĭ¤&#34;:9344,&#34;Ġìŀ¬ë¯¸ìĹĨëĦ¤ìļĶ&#34;:9345,&#34;Ġìĭľê°ĦëıĦ&#34;:9346,&#34;ĠíķĺëĤĺê°Ģ&#34;:9347,&#34;ìµľê³łìŀħëĭĪëĭ¤&#34;:9348,&#34;Ġì£½ìĸ´&#34;:9349,&#34;ì¦ĿìĿĦ&#34;:9350,&#34;ìĹĲê²ĮëıĦ&#34;:9351,&#34;ĠíĽĦíķĺê²Į&#34;:9352,&#34;ĠìĦ±ìĿ¸ìĿ´&#34;:9353,&#34;ĠíĸĪëĤĺ&#34;:9354,&#34;Ġì§ľë¦¬&#34;:9355,&#34;Ġíģ¬ë&#34;:9356,&#34;ì½ķ&#34;:9357,&#34;ĠìĿ´ìĥģíķ´&#34;:9358,&#34;ìĸ¸ë§¨&#34;:9359,&#34;ĠìłģìĿĢ&#34;:9360,&#34;ĠìłģëĤĺëĿ¼&#34;:9361,&#34;Ġê±´ì§Ī&#34;:9362,&#34;ìŀ¬ë¯¸ìŀĪìĹĪìĸ´ìļĶ&#34;:9363,&#34;ĠìķĦë¬´ëĤĺ&#34;:9364,&#34;Ġìĸµìļ¸&#34;:9365,&#34;ĠìĹ´ê´ĳ&#34;:9366,&#34;ĠìºĲë¦ŃíĦ°ëĬĶ&#34;:9367,&#34;ë§ŀê³ł&#34;:9368,&#34;ĠìĺģíĻĶìĺĢëĬĶëį°&#34;:9369,&#34;ĪëĶ°&#34;:9370,&#34;ìĬ¬íį¼&#34;:9371,&#34;ìķĦê¹Ŀê³ł&#34;:9372,&#34;Ġëĵ¤ìĸ´ê°Ħ&#34;:9373,&#34;ĠìķĪë³´ëĬĶê²Į&#34;:9374,&#34;ĠëĤļìĿ´ì§Ģ&#34;:9375,&#34;Ġë°°ê²½ìĿĮìķħ&#34;:9376,&#34;ìĻĦìĦ±ëıĦ&#34;:9377,&#34;ĠãħİãĦ·ãĦ·&#34;:9378,&#34;ĠìĽĥìĿĮìĿĦ&#34;:9379,&#34;Ġê²°êµŃìĿĢ&#34;:9380,&#34;íŀĪë´¤&#34;:9381,&#34;ë§ĪìĿĮìĿĦ&#34;:9382,&#34;Ġëĭ¹ìĭľìĹĲ&#34;:9383,&#34;ĠìłĪìłķ&#34;:9384,&#34;Ġê°Ģì¹ĺëıĦ&#34;:9385,&#34;,,,,,,,,&#34;:9386,&#34;ĠìĤ¼ë¥ĺìĺģíĻĶ&#34;:9387,&#34;Ġìĸ´ì©Įë©´&#34;:9388,&#34;ìŀ¬ë¯¸ëıĦìĹĨê³ł&#34;:9389,&#34;ìĿ´íķĺëĵľ&#34;:9390,&#34;Ġì¿¨&#34;:9391,&#34;ê¼¬ë§Ī&#34;:9392,&#34;Ġë©ĶìĦ¸ì§Ģë¥¼&#34;:9393,&#34;ì¤ĦìķĮìķĺëĬĶëį°&#34;:9394,&#34;íĹĪìłĳíķľ&#34;:9395,&#34;ĠìĥĪë¡Ŀ&#34;:9396,&#34;¬ëł¸&#34;:9397,&#34;ìµľê·¼ìĹĲ&#34;:9398,&#34;Ġê²īë©ĭ&#34;:9399,&#34;ĠìĿµìĪĻ&#34;:9400,&#34;ëıħë¦½ìĺģíĻĶ&#34;:9401,&#34;ëŀľìĬ¤íı¬ë¨¸&#34;:9402,&#34;_^&#34;:9403,&#34;id&#34;:9404,&#34;´£&#34;:9405,&#34;ëĩ&#34;:9406,&#34;Ġ!!!!&#34;:9407,&#34;Ġì¾Į&#34;:9408,&#34;ĠìĮĵ&#34;:9409,&#34;ê°Īë&#34;:9410,&#34;ëĭ¤ì½Ķ&#34;:9411,&#34;ê³°&#34;:9412,&#34;ëĬĶê²ĥëıĦ&#34;:9413,&#34;ê³łìłĦ&#34;:9414,&#34;Ġíī&#34;:9415,&#34;ĠìĺģíĻĶëĵ¤ìĿ´&#34;:9416,&#34;Ġë§Īë²ķ&#34;:9417,&#34;ìķĦë¦¬&#34;:9418,&#34;ìĿ¸íĦ°&#34;:9419,&#34;ë³´ëł¤ê³ł&#34;:9420,&#34;ìĬ¤íĭ´&#34;:9421,&#34;ëĮĢì¶©&#34;:9422,&#34;ĠìĹĨìĸ´ëıĦ&#34;:9423,&#34;ì§Ħíķľ&#34;:9424,&#34;ìŀĪìĿĦê¹Į&#34;:9425,&#34;ìłĦëĭ¬&#34;:9426,&#34;ĠìŀĪìĹĪìĬµëĭĪëĭ¤&#34;:9427,&#34;ĠìĹ°ê´Ģ&#34;:9428,&#34;Ġíķľê°Ģ&#34;:9429,&#34;ì¹ĺë§Į&#34;:9430,&#34;Ġìŀ¬ë°ĮìĹĪ&#34;:9431,&#34;ĠëĬĳëĮĢ&#34;:9432,&#34;Ġì£¼ìľ¤ë°ľ&#34;:9433,&#34;Ġë§ĪëĭĪ&#34;:9434,&#34;Ġëª»íķĺëĦ¤&#34;:9435,&#34;ĠìĹ¬ìĭł&#34;:9436,&#34;ĠìŀĲìķĦ&#34;:9437,&#34;Ġê²ĥëĵ¤&#34;:9438,&#34;Ġìĺ¤ì§Ģ&#34;:9439,&#34;Ġê¹¡íĮ¨&#34;:9440,&#34;ìŀ¬ë¯¸ìŀĪëĦ¤ìļĶ&#34;:9441,&#34;ë²ĦíĬ¼&#34;:9442,&#34;ëªħíĻĶ&#34;:9443,&#34;ĠìķłìŀĶ&#34;:9444,&#34;ĠìłĢì§Ģ&#34;:9445,&#34;ĠíĹ¬&#34;:9446,&#34;Ġê±°íĴĪ&#34;:9447,&#34;ĠìĹŃìŀĳ&#34;:9448,&#34;Ġëĭ¤ìĭľë³´ê¸°&#34;:9449,&#34;ëŃĩ&#34;:9450,&#34;Ġëª°ìķĦ&#34;:9451,&#34;Ġê¸°ëĮĢê°Ģ&#34;:9452,&#34;Ġê°ķìļĶ&#34;:9453,&#34;ìĻľìĿ´ëłĩê²Į&#34;:9454,&#34;ëĲĲëĭ¤&#34;:9455,&#34;ĠíĺĦìĭ¤ìĿĢ&#34;:9456,&#34;ìĥĿê°ģìľ¼ë¡ľ&#34;:9457,&#34;Ġë¦°&#34;:9458,&#34;ĠìĦłìłķ&#34;:9459,&#34;Ġê³¼ìłķìĿ´&#34;:9460,&#34;Ġë°©ê¸Ī&#34;:9461,&#34;êµ¬ë¨¼&#34;:9462,&#34;ĠìĿ¼ë³¸ìĿĺ&#34;:9463,&#34;ëĬĶê±°ëĭ¤&#34;:9464,&#34;Ġê¸´ë°ķ&#34;:9465,&#34;Īë°ľ&#34;:9466,&#34;ì£½ìĿ´ê³ł&#34;:9467,&#34;ĠëĨĢëŀĺ&#34;:9468,&#34;Ġì»¬&#34;:9469,&#34;Ġì»·&#34;:9470,&#34;Ġì»´íĵ¨íĦ°&#34;:9471,&#34;Ġìŀħìŀ¥&#34;:9472,&#34;Ġê³°&#34;:9473,&#34;íķłìĪĺëıĦ&#34;:9474,&#34;ĠëĤłìķĦ&#34;:9475,&#34;ĠíĺķìĤ¬&#34;:9476,&#34;ì¤ĺëıĦ&#34;:9477,&#34;Ġì´Īëĵ±íķĻêµĲ&#34;:9478,&#34;Ġìĭľë¦¬ì¦ĪìĿĺ&#34;:9479,&#34;ë²łìĬ¤íĬ¸&#34;:9480,&#34;ìĿ´ìķ¼ê¸°ê°Ģ&#34;:9481,&#34;Ġë°°ê²½ìĿ´&#34;:9482,&#34;Ġì£¼ê³łìĭ¶ëĭ¤&#34;:9483,&#34;Ġì¶©ë¶Ħíķĺëĭ¤&#34;:9484,&#34;Ġì»¤ìĦľ&#34;:9485,&#34;ìĹ°ì¶ľìĿ´&#34;:9486,&#34;ë»ĳ&#34;:9487,&#34;ê½Ŀ&#34;:9488,&#34;Ġìĵ¸ìĵ¸&#34;:9489,&#34;ĠìŀĲìĹ°ìĬ¤ëŁ½ê²Į&#34;:9490,&#34;íĭ°ë¹Ħë¡ľ&#34;:9491,&#34;ëłĪëĶĶ&#34;:9492,&#34;ĠìĺģíĻĶìĿ¸ê²ĥ&#34;:9493,&#34;ìµľìķħìĿĺìĺģíĻĶ&#34;:9494,&#34;Ġìĭ«ìĸ´íķĺëĬĶ&#34;:9495,&#34;ìłĲì¤Ģê²ĥ&#34;:9496,&#34;ì¶ľìĹ°ì§Ħ&#34;:9497,&#34;Ġì©Ķìĸ´&#34;:9498,&#34;Ġë¸ĶëŀĻì½Ķë¯¸ëĶĶ&#34;:9499,&#34;Ġìĭľë¦¬ì¦Īë¥¼&#34;:9500,&#34;ĠìĨĮìŀ¥íķĺê³ł&#34;:9501,&#34;Ġë»¥&#34;:9502,&#34;Ġì¯§&#34;:9503,&#34;ĠíķĺìĿ´íĭ´&#34;:9504,&#34;ëŀĺê³¤ë³¼&#34;:9505,&#34;!?&#34;:9506,&#34;ëĭ¤ìĨĮ&#34;:9507,&#34;ëĤĦ&#34;:9508,&#34;ĠìĺģíĻĶìĨį&#34;:9509,&#34;ĠìĺģíĻĶëŀĢ&#34;:9510,&#34;ìĭ¬ë¦¬&#34;:9511,&#34;ìĿĺëıĦ&#34;:9512,&#34;ìĿĢìĺģíĻĶ&#34;:9513,&#34;ëĤĺìĺ¬ëķĮ&#34;:9514,&#34;Ġë§Ļ&#34;:9515,&#34;ìĸ´ìĿ´ê°Ģ&#34;:9516,&#34;ë¡ľë´ĩ&#34;:9517,&#34;ë¡ľë²ĦíĬ¸&#34;:9518,&#34;ëłĢ&#34;:9519,&#34;ëį°ëłĲ&#34;:9520,&#34;íķ´ìĦĿ&#34;:9521,&#34;íķ´ì¤Ģëĭ¤&#34;:9522,&#34;ìĥĪë²½ìĹĲ&#34;:9523,&#34;ìĺģíĻĶë³´ë©´ìĦľ&#34;:9524,&#34;ìĬ¤íĮĮìĿ´&#34;:9525,&#34;ëŀ¬ëĭ¤&#34;:9526,&#34;ì¤į&#34;:9527,&#34;ìłķì¹ĺ&#34;:9528,&#34;Ġì¢ĭìķĹ&#34;:9529,&#34;ìŀĪìĹĪëĬĶëį°&#34;:9530,&#34;ìłĦìĿĢ&#34;:9531,&#34;ìĥģëıĦ&#34;:9532,&#34;ìĺ¤ìļ°&#34;:9533,&#34;Ġìĺ¬ëĵľ&#34;:9534,&#34;Ġë§Įìķ½&#34;:9535,&#34;ìĦ±íķľ&#34;:9536,&#34;ĠìĹ°ê¸°ë§Į&#34;:9537,&#34;Ġëª¨ë°©&#34;:9538,&#34;ĠìķĪê°ĢëĬĶ&#34;:9539,&#34;Ġì£¼ìĦ¸ìļĶ&#34;:9540,&#34;ĠëĵľëĶĶìĸ´&#34;:9541,&#34;ĠìĿ¸ì¢ħ&#34;:9542,&#34;Ġìµľê³łìĿ¸ëĵ¯&#34;:9543,&#34;ìľłì¾Įíķľ&#34;:9544,&#34;Ġë¹Ħíķ´ìĦľ&#34;:9545,&#34;Ġë¹Ħì¥¬ìĸ¼&#34;:9546,&#34;Ġë¯¸ì³Ĳ&#34;:9547,&#34;ë²Ħì¸ł&#34;:9548,&#34;Ġë§Įëĵ¤ìĹĪëĥĲ&#34;:9549,&#34;ëĲĺìļĶ&#34;:9550,&#34;ĠëģĿëĤ¨&#34;:9551,&#34;ìĺģêµŃ&#34;:9552,&#34;ë¦¬ëĵľ&#34;:9553,&#34;ë¦¬ë·°&#34;:9554,&#34;Ġìķłì´ĪìĹĲ&#34;:9555,&#34;OOOO&#34;:9556,&#34;ĠëĬĲëĤĢëĭ¤&#34;:9557,&#34;ĠìŀĪëĬĶê°Ģ&#34;:9558,&#34;ĠëĦĺì³Ĳ&#34;:9559,&#34;Ġë©ĭìł¸ìļĶ&#34;:9560,&#34;Ġê¸°ìĸµëĤľëĭ¤&#34;:9561,&#34;Ġìŀ¥ë©´ë§Į&#34;:9562,&#34;ĠíķľêµŃìĺģíĻĶìĿĺ&#34;:9563,&#34;Ġê´ľì°®ìķĺëįĺ&#34;:9564,&#34;Ġìĭ¬íķĺëĭ¤&#34;:9565,&#34;ê¼Ī&#34;:9566,&#34;ì§ĳì¤ĳ&#34;:9567,&#34;ĠìļĶë¦¬&#34;:9568,&#34;ĠìķĦìĿ´ëĶĶ&#34;:9569,&#34;Ġë§Įëĵ¤ìĸ´ì£¼&#34;:9570,&#34;Ġê³µíı¬ê°Ģ&#34;:9571,&#34;íĿ¬ëĬĶ&#34;:9572,&#34;Ġíİ¸ìĿ¸ëį°&#34;:9573,&#34;ìķĦìĿ´ëĵ¤ê³¼&#34;:9574,&#34;Ġê²ĮìĬ¤íĬ¸&#34;:9575,&#34;ë´ĲëıĦë´ĲëıĦ&#34;:9576,&#34;íĬ¹ìľłìĿĺ&#34;:9577,&#34;ê¸°ëĮĢìĿ´ìĥģ&#34;:9578,&#34;ëŁ¬ë¬¼&#34;:9579,&#34;ĠëĬĲê»´ì§Ģì§Ģ&#34;:9580,&#34;ì°½ìĭľìłĪ&#34;:9581,&#34;ĠìłľëĮĢë¡ľëĲľ&#34;:9582,&#34;ĠíĨµíķ´ìĦľ&#34;:9583,&#34;ĠìĿĺë¯¸ëıĦ&#34;:9584,&#34;ì¤ĺìķ¼ì§Ģ&#34;:9585,&#34;ë²ķíķľ&#34;:9586,&#34;ìĬ¬íĶĦê³ł&#34;:9587,&#34;ì§Ŀíīģ&#34;:9588,&#34;ì¶©ë¶ĦíŀĪ&#34;:9589,&#34;Ġíŀĺëĵ¤ìĹĪëĭ¤&#34;:9590,&#34;Ġì²¨ë¶ĢíĦ°&#34;:9591,&#34;ëªħìŀĳìĿ´ëĭ¤&#34;:9592,&#34;Ġìĸ´ë¦°ìĭľìłĪ&#34;:9593,&#34;Ġì£ł&#34;:9594,&#34;ìĺ¬ëł¤&#34;:9595,&#34;ĠìĦ¤ìłķìĿĢ&#34;:9596,&#34;Ġê°ĲëıĻìłģìĿ´ìĹĲìļĶ&#34;:9597,&#34;ĠìĿ¸ë¬¼ëĵ¤ìĿĺ&#34;:9598,&#34;ĠìĻłë§Įíķľ&#34;:9599,&#34;ìķĦëĭĮëį°&#34;:9600,&#34;ĠëĨĴìĿĢì§Ģ&#34;:9601,&#34;ĠëįĶìļ±ëįĶ&#34;:9602,&#34;ë¦¬ìĿĺë¦¬ìĿĺ&#34;:9603,&#34;ĠìĹĲë¡ľìĺģíĻĶ&#34;:9604,&#34;íĢĦ&#34;:9605,&#34;ë²Īë´ĲëıĦ&#34;:9606,&#34;Ġê¼¬ë§Ī&#34;:9607,&#34;Ġê»Ĳëĭ¤&#34;:9608,&#34;Ġë©´ìĿ´&#34;:9609,&#34;Ġê¹ľëĨĢ&#34;:9610,&#34;Ġëļľ&#34;:9611,&#34;Ġì°¬ìĤ¬ë¥¼&#34;:9612,&#34;Ġëºı&#34;:9613,&#34;ĠìķĪë¬´ìĦŃ&#34;:9614,&#34;ĠìĺĨìĹĲ&#34;:9615,&#34;ì¼ĢìĿ´ë¸ĶìĹĲìĦľ&#34;:9616,&#34;°ľê²¬&#34;:9617,&#34;íıīë²Ķíķľ&#34;:9618,&#34;ĠìĤ´ëĭ¤ìĤ´ëĭ¤&#34;:9619,&#34;ìĦ¸íı¬ìĨĮëħĢ&#34;:9620,&#34;ĠíĿ¬ëĮĢìĿĺ&#34;:9621,&#34;ì§Ģë¶Ģì§Ģ&#34;:9622,&#34;Ġíķ¸ëĵľ&#34;:9623,&#34;âĺħâĺĨâĺħâĺĨ&#34;:9624,&#34;el&#34;:9625,&#34;ff&#34;:9626,&#34;ĠH&#34;:9627,&#34;ģëĭĪëĭ¤&#34;:9628,&#34;ì§ĪëĿ¼&#34;:9629,&#34;ëĵ¦&#34;:9630,&#34;ë¦ħ&#34;:9631,&#34;ĠìĺģíĻĶìłģ&#34;:9632,&#34;ìĭ¹&#34;:9633,&#34;ëĤĺë³´ëĭ¤&#34;:9634,&#34;ĠìĿ´ìĸ´ì§ĢëĬĶ&#34;:9635,&#34;...;;&#34;:9636,&#34;Ġì§¤&#34;:9637,&#34;ìĺģíĻĶë³´ëĬĶ&#34;:9638,&#34;ìĺģíĻĶìĺĢëĭ¤&#34;:9639,&#34;ë³´ìĨĮ&#34;:9640,&#34;ìĬ¤íħĿ&#34;:9641,&#34;ëŀ¨&#34;:9642,&#34;ê±°ìĽĮ&#34;:9643,&#34;ìĤĲ&#34;:9644,&#34;ìŀĲëĵ¤ìĿĢ&#34;:9645,&#34;ìŀĲìĭłìĿĺ&#34;:9646,&#34;ìķ¼ìŀĲ&#34;:9647,&#34;ì£¼ë§Ĳ&#34;:9648,&#34;ìłģìĿĦ&#34;:9649,&#34;Ġì§Ģìĺ¥&#34;:9650,&#34;Ġíķľìĭľê°Ħ&#34;:9651,&#34;ëĵľë¦½&#34;:9652,&#34;ĠìĭľíĹĺ&#34;:9653,&#34;Ġì°Ķ&#34;:9654,&#34;ê²ĥìĿ¸ê°Ģ&#34;:9655,&#34;ì¹ĺê¸°&#34;:9656,&#34;Ġê¸°ì¡´&#34;:9657,&#34;Ġëª¨ëıħ&#34;:9658,&#34;ìĤ¬ê¸°&#34;:9659,&#34;ìĤ¬ì§Ħ&#34;:9660,&#34;Ġë¬´ìĿĺë¯¸&#34;:9661,&#34;ëŁ¬ìĽĢ&#34;:9662,&#34;ĠìķĪê²¨&#34;:9663,&#34;ĠìķĪì¢ĭìĿĢ&#34;:9664,&#34;Ġì¡±&#34;:9665,&#34;Ġê°ľì½ĺ&#34;:9666,&#34;Ġë³¸ì§Ģ&#34;:9667,&#34;ìĺĢëĦ¤ìļĶ&#34;:9668,&#34;Ġìĺ¤ë¡ľì§Ģ&#34;:9669,&#34;ĠìĤ¬ê³¼&#34;:9670,&#34;Ġì¤ĳìĿĺ&#34;:9671,&#34;ìĺģìĿĢ&#34;:9672,&#34;ëıĻìĿĦ&#34;:9673,&#34;Ġíķ´ìļĶ&#34;:9674,&#34;ì¡°íķľ&#34;:9675,&#34;íĤµ&#34;:9676,&#34;Ġìĭ¶ìĿĮ&#34;:9677,&#34;ìķłê¸°&#34;:9678,&#34;Ġì¢ĭìķĦíķĺìĭľëĬĶ&#34;:9679,&#34;ìľĦë¥¼&#34;:9680,&#34;¬ë¦½&#34;:9681,&#34;ĠìĭłìĿ¸&#34;:9682,&#34;ìĿ´ëŁ°ê±´&#34;:9683,&#34;ìķĬê³ł&#34;:9684,&#34;Ġëª¨ë¥´ê²Ł&#34;:9685,&#34;ĠìķĦê¹ĿìĬµëĭĪëĭ¤&#34;:9686,&#34;ĠíĬĢ&#34;:9687,&#34;Ġë§Īì§Ģë§īìĿĢ&#34;:9688,&#34;Ġì²ĺìĿĮìĹĲ&#34;:9689,&#34;ĠìĿ´ìķ¼ê¸°ìĿĺ&#34;:9690,&#34;ë¡łìĿĺ&#34;:9691,&#34;íĺĢìĦľ&#34;:9692,&#34;ĠìĦ¸ìĽĶ&#34;:9693,&#34;ĠíıīìĨĮ&#34;:9694,&#34;Ġë§Įëĵłê±´ì§Ģ&#34;:9695,&#34;Ġë³Ħë¡ľìĺĢëĭ¤&#34;:9696,&#34;ĠëĬĲëĤĮëıĦ&#34;:9697,&#34;ì¹´ëį°ë¯¸&#34;:9698,&#34;ìķĪë³¸&#34;:9699,&#34;ì§Ģë£¨íķ´ìĦľ&#34;:9700,&#34;ë©Ķë¦¬&#34;:9701,&#34;ĠëĤ¨ìŀĲëĬĶ&#34;:9702,&#34;Ġë»Ķíķĺëĭ¤&#34;:9703,&#34;Ġëª¨ëĵłê²ĥìĿ´&#34;:9704,&#34;ĠìĻ¸ë©´&#34;:9705,&#34;ĠìĹ´ìłķ&#34;:9706,&#34;ëıĪìľ¼ë¡ľ&#34;:9707,&#34;ë¸Įë£¨ìĬ¤&#34;:9708,&#34;Ġìŀ¬ë°ĭìĸ´ìļĶ&#34;:9709,&#34;ĠìĤ´ìķĦìķ¼&#34;:9710,&#34;ëĨĪìĿĺ&#34;:9711,&#34;ë¶Ģë¶ĦìĿĢ&#34;:9712,&#34;íĺľêµĲ&#34;:9713,&#34;Ġìĸ´ìĿ´ìĹĨìĿĮ&#34;:9714,&#34;Ġë¯¸êµŃìĿĺ&#34;:9715,&#34;ê²ĥê°ĻìķĦ&#34;:9716,&#34;ëĭĿë§¨&#34;:9717,&#34;Ġì»¤ëħķ&#34;:9718,&#34;Ġê°ĸê²Į&#34;:9719,&#34;Ġê°ĸì¶ĺ&#34;:9720,&#34;ĠìĹŃìĤ¬ìĹĲ&#34;:9721,&#34;Ġìĺ¤ê¸Ģìĺ¤ê¸Ģ&#34;:9722,&#34;Ġì¤ĺëıĦ&#34;:9723,&#34;Ġ2000&#34;:9724,&#34;Ġê·¸ëŁ´ëĵ¯&#34;:9725,&#34;ì´ĪëĶ©ëķĮ&#34;:9726,&#34;ĠìĨĮë¦Ħëģ¼ì¹ĺëĬĶ&#34;:9727,&#34;ë§ĲìĿ´íķĦìļĶìĹĨëĭ¤&#34;:9728,&#34;ìķĦìī½ëĭ¤&#34;:9729,&#34;ìĦ¹ìĬ¤&#34;:9730,&#34;Ġì¼ĢìĿ´ë¸ĶìĹĲìĦľ&#34;:9731,&#34;Ġë¬´ìĸ¸ê°Ģ&#34;:9732,&#34;ĠìķĪë´ĲìĦľ&#34;:9733,&#34;ê¹ģëĭĪëĭ¤&#34;:9734,&#34;cn&#34;:9735,&#34;¥¸&#34;:9736,&#34;ª»&#34;:9737,&#34;Ħĺ&#34;:9738,&#34;ìĿ´ë»Ĳ&#34;:9739,&#34;ìłĪë&#34;:9740,&#34;ì§ĢíĻĺ&#34;:9741,&#34;íķľíħĲ&#34;:9742,&#34;ëĤĺë¬´&#34;:9743,&#34;ëĤĺìłĢëĤĺ&#34;:9744,&#34;ê²ĮìĿ´&#34;:9745,&#34;ê²Įëĭ¤ê°Ģ&#34;:9746,&#34;ìĬ¬ë¦¬&#34;:9747,&#34;ë¦¬ìī¬&#34;:9748,&#34;ëłĺ&#34;:9749,&#34;ìĿ¸ìľ¼ë¡ľ&#34;:9750,&#34;ìĿ¸íĺľ&#34;:9751,&#34;ìĺģíĻĶëĦ¤ìļĶ&#34;:9752,&#34;ìĭľì¼°&#34;:9753,&#34;ìĹĨìĬµëĭĪëĭ¤&#34;:9754,&#34;ĠíķĺëĭĪ&#34;:9755,&#34;ì§Ħíĺ¸&#34;:9756,&#34;íĨ¡&#34;:9757,&#34;íķłìĪľ&#34;:9758,&#34;Ġë´¤ëĬĶì§Ģ&#34;:9759,&#34;ê²ĥëĵ¤ìĿ´&#34;:9760,&#34;ê²ĥì²ĺëŁ¼&#34;:9761,&#34;ìłľë¥¼&#34;:9762,&#34;Ġê¸°ìŀĲ&#34;:9763,&#34;ĠìĹ°ê¸°ìŀĲëĵ¤&#34;:9764,&#34;ëŀĺìļĶ&#34;:9765,&#34;ìĭłíĺľ&#34;:9766,&#34;ëŁ¬ëĭĪ&#34;:9767,&#34;ëŁ¬íĭ°ë¸Į&#34;:9768,&#34;ĠìķĪëĭ¤&#34;:9769,&#34;ĠìķĪê°Ĳ&#34;:9770,&#34;ĠìķĪëĤĺìĺ¤ëĬĶ&#34;:9771,&#34;~~!&#34;:9772,&#34;Ġë§Ĳìķĺëĭ¤&#34;:9773,&#34;ëħĦìĿĦ&#34;:9774,&#34;ĠìłľìĻķ&#34;:9775,&#34;íĥĢìĿ´&#34;:9776,&#34;Ġê²ĥê³¼&#34;:9777,&#34;Ġìĺ¤íĶĦëĭĿ&#34;:9778,&#34;ĠìĨĮíĴĪ&#34;:9779,&#34;ìĭ¬ìĿĢ&#34;:9780,&#34;Ġë§İëĦ¤&#34;:9781,&#34;ìĽĲëıĦ&#34;:9782,&#34;Ġê³µì¤ĳ&#34;:9783,&#34;ìŀ¬ë°ĮìĹĪìĿĮ&#34;:9784,&#34;ĠìĽĥê²¼ëĭ¤&#34;:9785,&#34;ëĳĲê·¼&#34;:9786,&#34;Ġê±°ìķ¼&#34;:9787,&#34;ë°Ķëĭ¤&#34;:9788,&#34;Ġë°ĶëŀĢëĭ¤&#34;:9789,&#34;êµ°ìĿ´&#34;:9790,&#34;!!!!!!!&#34;:9791,&#34;Ġíı¼&#34;:9792,&#34;íĮĲìľ¼ë¡ľ&#34;:9793,&#34;Ġìµľê³łìĿĺìĺģíĻĶ&#34;:9794,&#34;Ġì²ĺìĿĮìĿ´&#34;:9795,&#34;ĠëªħìŀĳìĿĢ&#34;:9796,&#34;Ġë¡ľë¹Ī&#34;:9797,&#34;Ġë¡ľë²ĦíĬ¸&#34;:9798,&#34;ìĻľìĿ´ë¦¬&#34;:9799,&#34;íħĮë¦¬&#34;:9800,&#34;ê²©ìĿ´&#34;:9801,&#34;Ġë§īìĥģ&#34;:9802,&#34;¬ëĿ¼ê¸°&#34;:9803,&#34;ĠìĿĮëª¨&#34;:9804,&#34;Ġêµ¬ì¡°&#34;:9805,&#34;Ġë§ŀì¶Ķ&#34;:9806,&#34;ì¼ĢíĮħ&#34;:9807,&#34;ĠìķĦìĿ´ëĵ¤ìĿĺ&#34;:9808,&#34;ĠìķĦìĿ´ëĵ¤ìĹĲê²Į&#34;:9809,&#34;Ġëª°ìŀħíķĺê²Į&#34;:9810,&#34;ì§ĢìķĬê²Į&#34;:9811,&#34;ì§ĢìķĬìķĦ&#34;:9812,&#34;ìĵ°ëłĪê¸°ëĭ¤&#34;:9813,&#34;ĠëĪĦëĤĺ&#34;:9814,&#34;ĠìĿ¸ìĥĿìĿĢ&#34;:9815,&#34;Ġë°ĽìķĦìķ¼&#34;:9816,&#34;Ġê·¹ìŀ¥ìĹĲ&#34;:9817,&#34;ëĦĺì¹ĺëĬĶ&#34;:9818,&#34;íĬ¹ë³Ħ&#34;:9819,&#34;Ġë²Ħë¬´&#34;:9820,&#34;ĠìĹĦì²ŃëĤĺê²Į&#34;:9821,&#34;ĠìĹīëļ±&#34;:9822,&#34;ĠìĨĲê¼½&#34;:9823,&#34;ĠíĮĮê³ł&#34;:9824,&#34;Ġë¬¼ìĸ´&#34;:9825,&#34;Ġê°Ģì¡±ìĿĦ&#34;:9826,&#34;Ġê°Ģì¡±ìķł&#34;:9827,&#34;Ġë¶Ģì¡±íķĺê³ł&#34;:9828,&#34;ĠìĤ¶ê³¼&#34;:9829,&#34;Ġìŀ¬ë°ĭìĿĮ&#34;:9830,&#34;ĠëĤĺë¦ĦëĮĢë¡ľ&#34;:9831,&#34;Ġê´Ģê°ĿìĿ´&#34;:9832,&#34;Ġì¶©ê²©ìłģìĿ´&#34;:9833,&#34;ë¡Ńëĭ¤&#34;:9834,&#34;Ġíģ´ë¦¬&#34;:9835,&#34;ĠìºĲìĬ¤íĮħìĿ´&#34;:9836,&#34;Ġë¹ĦêµĲíķĺë©´&#34;:9837,&#34;Ġì±ĦìĽĮ&#34;:9838,&#34;ĠìĪľìĪĺíķĺê³ł&#34;:9839,&#34;ìĵ¸ëį°&#34;:9840,&#34;ìŀĳê°Ģëĭĺ&#34;:9841,&#34;Ġìıł&#34;:9842,&#34;Ġë¹µìłĲ&#34;:9843,&#34;Ġì´ĪëĶ©ëķĮ&#34;:9844,&#34;Ġìī½ì§Ģ&#34;:9845,&#34;Ġë°ĶëĿ¼ë³´ëĬĶ&#34;:9846,&#34;ĠìĨĮë¦¬ë§Į&#34;:9847,&#34;Ġê·¸ëŁ´ìĭ¸&#34;:9848,&#34;íķĺê²łìĬµëĭĪëĭ¤&#34;:9849,&#34;ĠíĻįì½©ìĺģíĻĶ&#34;:9850,&#34;ë±Ģ&#34;:9851,&#34;ëĭ¬ëĿ¼ê³ł&#34;:9852,&#34;ìĹ¬ëŁ¬ë¶Ħ&#34;:9853,&#34;ĠìĦ¸ëł¨ëĲľ&#34;:9854,&#34;Ġìĺģíĸ¥ìĿĦ&#34;:9855,&#34;ĠíħĲëį°&#34;:9856,&#34;ëº&#34;:9857,&#34;ìĿ´ëŁ´&#34;:9858,&#34;ìķ¨&#34;:9859,&#34;ìĿĺìĻ¸ë¡ľ&#34;:9860,&#34;ë¡ľëĿ¼&#34;:9861,&#34;ë§Įìķ½&#34;:9862,&#34;ë¦¬ìĬ¨&#34;:9863,&#34;ĠìłĪë°ĺ&#34;:9864,&#34;ìķĦëĥĲ&#34;:9865,&#34;ìĿ¸íķ´&#34;:9866,&#34;ëį°ìļĶ&#34;:9867,&#34;Ġì§Ļ&#34;:9868,&#34;ĠëĭĪëĦ¤&#34;:9869,&#34;ĠëĤĺìķĦ&#34;:9870,&#34;Ġëĭ¤ë¦Ħ&#34;:9871,&#34;ìłĦíŀĪ&#34;:9872,&#34;Ġìłķì£¼íĸī&#34;:9873,&#34;ĠìŀĪìĸ´ëıĦ&#34;:9874,&#34;ìĺ¤ë²Ħ&#34;:9875,&#34;Ġëĵ¬&#34;:9876,&#34;Ġìĸ´ëĶĺ&#34;:9877,&#34;Ġìĺ¬ë¦¬ë&#34;:9878,&#34;Ġì§Ģê°Ģ&#34;:9879,&#34;ê·¸ëŁ´&#34;:9880,&#34;ì¡ĭ&#34;:9881,&#34;Ġê°Ģê¹Ŀ&#34;:9882,&#34;ìĦ±ê³µ&#34;:9883,&#34;íŀĪíŀĪ&#34;:9884,&#34;ìĸĢ&#34;:9885,&#34;Ġê¸°ë²ķ&#34;:9886,&#34;ìĿ¼ëķĮ&#34;:9887,&#34;ĠìĹ°ê¸°íķľ&#34;:9888,&#34;ĠìĹ°ê¸°ë¡ľ&#34;:9889,&#34;êµ¬êµ¬&#34;:9890,&#34;ĠìłĦëıĦ&#34;:9891,&#34;êµŃëĤ´&#34;:9892,&#34;ì¤ĳíķľ&#34;:9893,&#34;ë¶ĦìłķëıĦ&#34;:9894,&#34;ê²łê³ł&#34;:9895,&#34;ëł¥ìĹĲ&#34;:9896,&#34;ëħĦëıĻìķĪ&#34;:9897,&#34;ìĺĢêµ¬ëĤĺ&#34;:9898,&#34;ĠìĸĦ&#34;:9899,&#34;ĠëĤ¨ê¸´&#34;:9900,&#34;ĠìĿ´ëŁ°ìĭĿìľ¼ë¡ľ&#34;:9901,&#34;ìĽĲìĿĦ&#34;:9902,&#34;ìĪĢ&#34;:9903,&#34;Ġë²ĦìłĦ&#34;:9904,&#34;ĠëĵľëĿ¼ë§ĪëıĦ&#34;:9905,&#34;ë¦¬ëł¤&#34;:9906,&#34;ĠìĤ¬ëŀĳìĬ¤ëŁ½ê³ł&#34;:9907,&#34;íĹī&#34;:9908,&#34;ë°ĺëĭ´&#34;:9909,&#34;¬ë¦´&#34;:9910,&#34;ë°ľë¡ľ&#34;:9911,&#34;ìĿ´ëŁ°ìĺģíĻĶëĬĶ&#34;:9912,&#34;ĠìĿĺë¦¬&#34;:9913,&#34;Ġì¶Ķê°Ģ&#34;:9914,&#34;Ġê¸°ëĮĢíĸĪ&#34;:9915,&#34;ĠìĦ±íĺķ&#34;:9916,&#34;ë°°ìļ°ëĵ¤ëıĦ&#34;:9917,&#34;ìĤ¬ëŀĮëıĦ&#34;:9918,&#34;ĠìĹĲìĿ´&#34;:9919,&#34;ĠëĲĲëĭ¤&#34;:9920,&#34;íģ¬ê°Ģ&#34;:9921,&#34;Ġë§¤ëł¥ìłģ&#34;:9922,&#34;ì§ĢìķĬìĿĮ&#34;:9923,&#34;ĠìķĪëĲĺëĦ¤&#34;:9924,&#34;Ġìłģê·¹&#34;:9925,&#34;ĠìĥĿì¡´&#34;:9926,&#34;íĪŃ&#34;:9927,&#34;ĠëĪĪìľ¼ë¡ľ&#34;:9928,&#34;ĠìļķìĿĦ&#34;:9929,&#34;Ġìŀ¬ìķĻ&#34;:9930,&#34;ìłĲëıĦìķĦê¹Ŀëĭ¤&#34;:9931,&#34;Ġì¹ĺë£Į&#34;:9932,&#34;Ġê°Ħì§Ģ&#34;:9933,&#34;ëģĿëĤ´&#34;:9934,&#34;ĠìŀĲì²´ëıĦ&#34;:9935,&#34;Ġìķħë§Ī&#34;:9936,&#34;ĠëĤĺìĻĢëıĦ&#34;:9937,&#34;ê²ģê²Į&#34;:9938,&#34;ë¸Ķë£¨&#34;:9939,&#34;ìĽĲìŀĳìĹĲ&#34;:9940,&#34;ëŃĶì§Ģ&#34;:9941,&#34;Ġìĸ´ìĿ´ìĹĨëĭ¤&#34;:9942,&#34;ĠìĦ¸ìĥģìĹĲìĦľ&#34;:9943,&#34;ì±ħìŀĦ&#34;:9944,&#34;Ġì¶ĶìĸµìĿĦ&#34;:9945,&#34;ìĭ¸ìĿ´ì½Ķ&#34;:9946,&#34;ĠìĬ¤íĥĢëİĢ&#34;:9947,&#34;ĠìķĶìļ¸&#34;:9948,&#34;Ġëª°ìŀħëıĦëıĦ&#34;:9949,&#34;ìĹĶëĶ©ìĿ´&#34;:9950,&#34;íģ¬ë¥¼&#34;:9951,&#34;ĠìĥģíĻ©ìĿ´&#34;:9952,&#34;ìĭŃëĭĪëĭ¤&#34;:9953,&#34;Ġëĵ£ëĬĶ&#34;:9954,&#34;ëĤĺë¦ĦëĮĢë¡ľ&#34;:9955,&#34;ë³¼ë§Įíķ¨&#34;:9956,&#34;ĠìĹīë§Ŀì§Ħì°½&#34;:9957,&#34;ĠëĨĪëĵ¤&#34;:9958,&#34;ĠìĿ´ëĶ°ìľĦë¡ľ&#34;:9959,&#34;ĠíĹĪìĪłíķľ&#34;:9960,&#34;Ġìĥģì²ĺë¥¼&#34;:9961,&#34;ìłĲì£¼ê¸°ëıĦ&#34;:9962,&#34;íĿĶíķľ&#34;:9963,&#34;BSìĹĲìĦľ&#34;:9964,&#34;ĠíĿīëĤ´ëĤ´&#34;:9965,&#34;ĠìĦ¬ìĦ¸íķľ&#34;:9966,&#34;ĪĦëĿ¼&#34;:9967,&#34;ĠëĵľëĿ¼ë§ĪëĿ¼ê³ł&#34;:9968,&#34;ĠìĿĢê·¼íŀĪ&#34;:9969,&#34;ĠìĹ½ê¸°&#34;:9970,&#34;ê¹ľì§Ŀ&#34;:9971,&#34;Ġìĸ´ìĦ¤íĶĦê²Į&#34;:9972,&#34;ĠìķĪë´Ħ&#34;:9973,&#34;.(&#34;:9974,&#34;.?&#34;:9975,&#34;na&#34;:9976,&#34;ģìĹĲ&#34;:9977,&#34;..;&#34;:9978,&#34;ëĬĻ&#34;:9979,&#34;ìķµ&#34;:9980,&#34;ìķľ&#34;:9981,&#34;ìļ¬&#34;:9982,&#34;íķĺëįĶëĭĪ&#34;:9983,&#34;ê¸°ì¢ħìĺģ&#34;:9984,&#34;ìĿĦêº¼&#34;:9985,&#34;ĠìĿ´ì§Ģ&#34;:9986,&#34;ìĸ´ëł¤&#34;:9987,&#34;ë¡ľìĿĺ&#34;:9988,&#34;ë¦¬ì¦ĺ&#34;:9989,&#34;ëĵ¤ë¦°&#34;:9990,&#34;ìķĦì¤Įë§Ī&#34;:9991,&#34;ìĿ¸ëĵ¤ìĿĢ&#34;:9992,&#34;ìĺģíĻĶì¤ĳìĹĲ&#34;:9993,&#34;ë³´ìĿ¸ëĭ¤&#34;:9994,&#34;ìŀĲìľł&#34;:9995,&#34;ìĹĪìĿĦíħĲëį°&#34;:9996,&#34;Ġíķĺìłķìļ°&#34;:9997,&#34;ìķ¼ê²łëĭ¤&#34;:9998,&#34;ìĪĺê³ł&#34;:9999} . !head /gdrive/My Drive/nlpbook/bbpe/merges.txt . #version: 0.2 - Trained by `huggingface/tokenizers` Ġ ì Ġ ë ì Ŀ ë ĭ í ķ ê ° . . ìĿ ´ ëĭ ¤ . BPE 어휘집합과 바이그램 쌍/병합우선순위 일부를 출력했습니다. . BERT &#53664;&#53356;&#45208;&#51060;&#51200; &#44396;&#52629; . import os os.makedirs(&#39;/gdrive/My Drive/nlpbook/wordpiece&#39;, exist_ok= True) . from tokenizers import BertWordPieceTokenizer wordpiece_tokenizer = BertWordPieceTokenizer(lowercase = False) wordpiece_tokenizer.train( files=[&#39;/root/train.txt&#39;, &#39;/root/test.txt&#39;], vocab_size = 10000, ) wordpiece_tokenizer.save_model(&#39;/gdrive/My Drive/nlpbook/wordpiece&#39;) . [&#39;/gdrive/My Drive/nlpbook/wordpiece/vocab.txt&#39;] . 워드피스 방식입니다. BPE와 차이점은 단순히 빈도를 기준으로 병합하는 것이 아니라 병합했을 때 말뭉치의 우도를 높이는 쌍을 병합합니다. . !head /gdrive/My Drive/nlpbook/wordpiece/vocab.txt . [PAD] [UNK] [CLS] [SEP] [MASK] ! &#34; % &amp; &#39; . 워드피스 수행 결과의 일부 입니다. . &#53664;&#53360;&#54868;&#54616;&#44592; - GPT . from transformers import GPT2Tokenizer tokenizer_gpt = GPT2Tokenizer.from_pretrained(&#39;/gdrive/My Drive/nlpbook/bbpe&#39;) tokenizer_gpt.pad_token = &#39;[PAD]&#39; . file /gdrive/My Drive/nlpbook/bbpe/config.json not found . sentences = [ &quot;아 더빙.. 진짜 짜증나네요 목소리&quot;, &quot;흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나&quot;, &quot;별루 였다..&quot;, ] tokenized_sentences = [tokenizer_gpt.tokenize(sentence) for sentence in sentences] tokenized_sentences . [[&#39;ìķĦ&#39;, &#39;ĠëįĶë¹Ļ&#39;, &#39;..&#39;, &#39;Ġì§Ħì§ľ&#39;, &#39;Ġì§ľì¦ĿëĤĺ&#39;, &#39;ëĦ¤ìļĶ&#39;, &#39;Ġëª©ìĨĮë¦¬&#39;], [&#39;íĿł&#39;, &#39;...&#39;, &#39;íı¬ìĬ¤íĦ°&#39;, &#39;ë³´ê³ł&#39;, &#39;Ġì´ĪëĶ©&#39;, &#39;ìĺģíĻĶ&#39;, &#39;ì¤Ħ&#39;, &#39;....&#39;, &#39;ìĺ¤ë²Ħ&#39;, &#39;ìĹ°ê¸°&#39;, &#39;ì¡°ì°¨&#39;, &#39;Ġê°Ģë³į&#39;, &#39;ì§Ģ&#39;, &#39;ĠìķĬ&#39;, &#39;êµ¬ëĤĺ&#39;], [&#39;ë³Ħë£¨&#39;, &#39;Ġìĺ&#39;, &#39;Ģëĭ¤&#39;, &#39;..&#39;]] . GPT 토크나이저로 토큰화 해봤는데요. 알수 없는 언어들이 출력됩니다. . 이는 GPT 모델은 바이트 기준 BPE를 적용하기 때문입니다. . batch_inputs = tokenizer_gpt( sentences, padding = &#39;max_length&#39;, # 문장 최대 길이에 맞춰 패딩 max_length = 12, # 문장 토큰 기준 최대 길이 truncation = True, # 문장 잘림 허용 옵션 ) batch_inputs.keys() . dict_keys([&#39;input_ids&#39;, &#39;attention_mask&#39;]) . 실제 모델 입력값 입니다. 결과는 input_ids, attention_mask 두개로 나옵니다. . batch_inputs[&#39;input_ids&#39;] . [[334, 2338, 263, 581, 4055, 464, 3808, 0, 0, 0, 0, 0], [3693, 336, 2876, 758, 2883, 356, 806, 422, 9875, 875, 2960, 7292], [4957, 451, 3653, 263, 0, 0, 0, 0, 0, 0, 0, 0]] . input_ids는 토큰화 결과를 가지고 각 토큰을 인덱스로 바꾼 것 입니다. . 여기서 모든 문장의 길이가 12로 맞춰줬는데 앞선 max_length 인자에 12를 넣었기 때문입니다. . [PAD] 토큰은 인덱스 0이며 더미 토큰입니다. 즉 위 값 중 0이 있으면 문장이 짧아 토큰 길이를 맞춰준 것으로 생각할 수 있습니다. . 문장 잘림을 허용하는 옵션 때문에 문장2는 토큰길이가 원래 15였는데 12안에 들어왔습니다. . batch_inputs[&#39;attention_mask&#39;] . [[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]] . attention_mask는 일반 토큰이 자리한 곳(1)과 패딩 토큰이 자리한 곳(0)을 구분해주는 장치입니다. . &#53664;&#53360;&#54868;&#54616;&#44592; - BERT . from transformers import BertTokenizer tokenizer_bert = BertTokenizer.from_pretrained( &#39;/gdrive/My Drive/nlpbook/wordpiece&#39;, do_lower_case = False, ) . file /gdrive/My Drive/nlpbook/wordpiece/config.json not found . sentences = [ &quot;아 더빙.. 진짜 짜증나네요 목소리&quot;, &quot;흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나&quot;, &quot;별루 였다..&quot;, ] tokenized_sentences = [tokenizer_bert.tokenize(sentence) for sentence in sentences] tokenized_sentences . [[&#39;아&#39;, &#39;더빙&#39;, &#39;.&#39;, &#39;.&#39;, &#39;진짜&#39;, &#39;짜증나&#39;, &#39;##네요&#39;, &#39;목소리&#39;], [&#39;흠&#39;, &#39;.&#39;, &#39;.&#39;, &#39;.&#39;, &#39;포스터&#39;, &#39;##보고&#39;, &#39;초딩&#39;, &#39;##영화&#39;, &#39;##줄&#39;, &#39;.&#39;, &#39;.&#39;, &#39;.&#39;, &#39;.&#39;, &#39;오버&#39;, &#39;##연기&#39;, &#39;##조차&#39;, &#39;가볍&#39;, &#39;##지&#39;, &#39;않&#39;, &#39;##구나&#39;], [&#39;별루&#39;, &#39;였다&#39;, &#39;.&#39;, &#39;.&#39;]] . 토큰 일부에 있는 ##은 해당 토큰이 어절의 시작이 아님을 나타냅니다. . batch_inputs = tokenizer_bert( sentences, padding = &#39;max_length&#39;, max_length = 12, truncation = True, ) batch_inputs.keys() . dict_keys([&#39;input_ids&#39;, &#39;token_type_ids&#39;, &#39;attention_mask&#39;]) . 코드 적합시 input_ids, token_type_ids, attention_mask 총 3개의 출력물이 나옵니다. . batch_inputs[&#39;input_ids&#39;] . [[2, 621, 2631, 16, 16, 1993, 3678, 1990, 3323, 3, 0, 0], [2, 997, 16, 16, 16, 2609, 2045, 2796, 1981, 1040, 16, 3], [2, 3274, 9507, 16, 16, 3, 0, 0, 0, 0, 0, 0]] . 모든 문장 시작시 2, 끝날 때 3이 붙은 것을 알 수 있습니다. . 여기서 2는 [CLS], 3은 [SEP]라는 토큰에 대응하는 인덱스입니다. . batch_inputs[&#39;attention_mask&#39;] . [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]] . attention_mask은 GPT와 마찬가지로 일반 토큰이 차지한 부분을 구분하는 역할을 합니다. . batch_inputs[&#39;token_type_ids&#39;] . [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]] . token_type_ids는 세그먼트에 해당합니다. BERT 모델은 기본적으로 문서 2개를 입력받는데요. . 첫 번째 세그먼트(문서 혹은 문장)은 0, 두 번째 세그먼트는 1을 주어 둘을 구분합니다. . 이번 실습에서 문장을 하나씩 넣었으므로 모든 값이 0입니다. .",
            "url": "https://ksy1526.github.io/myblog//myblog/2021/12/20/Do_natural_language1.html",
            "relUrl": "/2021/12/20/Do_natural_language1.html",
            "date": " • Dec 20, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "SSUDA) 캐글 이용자 2021 설문조사 결과 분석",
            "content": ". &#52880;&#44544;&#44284; &#50672;&#46041;&#54616;&#44592; . !pip install kaggle !pip install --upgrade --force-reinstall --no-deps kaggle from google.colab import files files.upload() . Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12) Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2) Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2) Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.10.8) Requirement already satisfied: six&gt;=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0) Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.62.3) Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3) Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0) Requirement already satisfied: text-unidecode&gt;=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify-&gt;kaggle) (1.3) Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;kaggle) (2.10) Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;kaggle) (3.0.4) Collecting kaggle Downloading kaggle-1.5.12.tar.gz (58 kB) |████████████████████████████████| 58 kB 2.5 MB/s Building wheels for collected packages: kaggle Building wheel for kaggle (setup.py) ... done Created wheel for kaggle: filename=kaggle-1.5.12-py3-none-any.whl size=73051 sha256=540a3a7d36ae6106f20d1f7c29b1afe562ca44be8bd818181fa99f5c13aeecb8 Stored in directory: /root/.cache/pip/wheels/62/d6/58/5853130f941e75b2177d281eb7e44b4a98ed46dd155f556dc5 Successfully built kaggle Installing collected packages: kaggle Attempting uninstall: kaggle Found existing installation: kaggle 1.5.12 Uninstalling kaggle-1.5.12: Successfully uninstalled kaggle-1.5.12 Successfully installed kaggle-1.5.12 . Upload widget is only available when the cell has been executed in the current browser session. Please rerun this cell to enable. Saving kaggle.json to kaggle.json . {&#39;kaggle.json&#39;: b&#39;{&#34;username&#34;:&#34;ksy1998&#34;,&#34;key&#34;:&#34;ff1e945a67cd54bc7068e3afe4a03ad6&#34;}&#39;} . !mkdir -p ~/.kaggle !cp kaggle.json ~/.kaggle/ !chmod 600 ~/.kaggle/kaggle.json . !kaggle competitions download -c kaggle-survey-2021 . Downloading kaggle-survey-2021.zip to /content 0% 0.00/3.01M [00:00&lt;?, ?B/s] 100% 3.01M/3.01M [00:00&lt;00:00, 103MB/s] . !unzip kaggle-survey-2021.zip . Archive: kaggle-survey-2021.zip inflating: kaggle_survey_2021_responses.csv inflating: supplementary_data/kaggle_survey_2021_answer_choices.pdf inflating: supplementary_data/kaggle_survey_2021_methodology.pdf . &#45936;&#51060;&#53552; &#48520;&#47084;&#50724;&#44592; . import gc # For Memory Optimization import numpy as np import pandas as pd import matplotlib.pyplot as plt import seaborn as sns # Not sure if I used this from wordcloud import WordCloud from scipy.stats import norm # Some more necessary libraries (These are for drawing the image on the bar charts) import matplotlib.font_manager as fm from matplotlib.offsetbox import TextArea, DrawingArea, OffsetImage, AnnotationBbox import matplotlib.image as mpimg # To Avoid unnecessary warnings import warnings warnings.filterwarnings(&#39;ignore&#39;) # Since there are many columns, I would like to view them all pd.set_option(&#39;display.max_rows&#39;, 100) pd.set_option(&#39;display.max_columns&#39;, 400) . df = pd.read_csv(&#39;kaggle_survey_2021_responses.csv&#39;) df = df.iloc[1:,:] # The first row was describing the columns. Better to look at the description from the Metadata file provided df.head(3).style.set_properties(**{&quot;background-color&quot;: &quot;#76c5d6&quot;,&quot;color&quot;: &quot;black&quot;, &quot;border-color&quot;: &quot;black&quot;}) . Time from Start to Finish (seconds) Q1 Q2 Q3 Q4 Q5 Q6 Q7_Part_1 Q7_Part_2 Q7_Part_3 Q7_Part_4 Q7_Part_5 Q7_Part_6 Q7_Part_7 Q7_Part_8 Q7_Part_9 Q7_Part_10 Q7_Part_11 Q7_Part_12 Q7_OTHER Q8 Q9_Part_1 Q9_Part_2 Q9_Part_3 Q9_Part_4 Q9_Part_5 Q9_Part_6 Q9_Part_7 Q9_Part_8 Q9_Part_9 Q9_Part_10 Q9_Part_11 Q9_Part_12 Q9_OTHER Q10_Part_1 Q10_Part_2 Q10_Part_3 Q10_Part_4 Q10_Part_5 Q10_Part_6 Q10_Part_7 Q10_Part_8 Q10_Part_9 Q10_Part_10 Q10_Part_11 Q10_Part_12 Q10_Part_13 Q10_Part_14 Q10_Part_15 Q10_Part_16 Q10_OTHER Q11 Q12_Part_1 Q12_Part_2 Q12_Part_3 Q12_Part_4 Q12_Part_5 Q12_OTHER Q13 Q14_Part_1 Q14_Part_2 Q14_Part_3 Q14_Part_4 Q14_Part_5 Q14_Part_6 Q14_Part_7 Q14_Part_8 Q14_Part_9 Q14_Part_10 Q14_Part_11 Q14_OTHER Q15 Q16_Part_1 Q16_Part_2 Q16_Part_3 Q16_Part_4 Q16_Part_5 Q16_Part_6 Q16_Part_7 Q16_Part_8 Q16_Part_9 Q16_Part_10 Q16_Part_11 Q16_Part_12 Q16_Part_13 Q16_Part_14 Q16_Part_15 Q16_Part_16 Q16_Part_17 Q16_OTHER Q17_Part_1 Q17_Part_2 Q17_Part_3 Q17_Part_4 Q17_Part_5 Q17_Part_6 Q17_Part_7 Q17_Part_8 Q17_Part_9 Q17_Part_10 Q17_Part_11 Q17_OTHER Q18_Part_1 Q18_Part_2 Q18_Part_3 Q18_Part_4 Q18_Part_5 Q18_Part_6 Q18_OTHER Q19_Part_1 Q19_Part_2 Q19_Part_3 Q19_Part_4 Q19_Part_5 Q19_OTHER Q20 Q21 Q22 Q23 Q24_Part_1 Q24_Part_2 Q24_Part_3 Q24_Part_4 Q24_Part_5 Q24_Part_6 Q24_Part_7 Q24_OTHER Q25 Q26 Q27_A_Part_1 Q27_A_Part_2 Q27_A_Part_3 Q27_A_Part_4 Q27_A_Part_5 Q27_A_Part_6 Q27_A_Part_7 Q27_A_Part_8 Q27_A_Part_9 Q27_A_Part_10 Q27_A_Part_11 Q27_A_OTHER Q28 Q29_A_Part_1 Q29_A_Part_2 Q29_A_Part_3 Q29_A_Part_4 Q29_A_OTHER Q30_A_Part_1 Q30_A_Part_2 Q30_A_Part_3 Q30_A_Part_4 Q30_A_Part_5 Q30_A_Part_6 Q30_A_Part_7 Q30_A_OTHER Q31_A_Part_1 Q31_A_Part_2 Q31_A_Part_3 Q31_A_Part_4 Q31_A_Part_5 Q31_A_Part_6 Q31_A_Part_7 Q31_A_Part_8 Q31_A_Part_9 Q31_A_OTHER Q32_A_Part_1 Q32_A_Part_2 Q32_A_Part_3 Q32_A_Part_4 Q32_A_Part_5 Q32_A_Part_6 Q32_A_Part_7 Q32_A_Part_8 Q32_A_Part_9 Q32_A_Part_10 Q32_A_Part_11 Q32_A_Part_12 Q32_A_Part_13 Q32_A_Part_14 Q32_A_Part_15 Q32_A_Part_16 Q32_A_Part_17 Q32_A_Part_18 Q32_A_Part_19 Q32_A_Part_20 Q32_A_OTHER Q33 Q34_A_Part_1 Q34_A_Part_2 Q34_A_Part_3 Q34_A_Part_4 Q34_A_Part_5 Q34_A_Part_6 Q34_A_Part_7 Q34_A_Part_8 Q34_A_Part_9 Q34_A_Part_10 Q34_A_Part_11 Q34_A_Part_12 Q34_A_Part_13 Q34_A_Part_14 Q34_A_Part_15 Q34_A_Part_16 Q34_A_OTHER Q35 Q36_A_Part_1 Q36_A_Part_2 Q36_A_Part_3 Q36_A_Part_4 Q36_A_Part_5 Q36_A_Part_6 Q36_A_Part_7 Q36_A_OTHER Q37_A_Part_1 Q37_A_Part_2 Q37_A_Part_3 Q37_A_Part_4 Q37_A_Part_5 Q37_A_Part_6 Q37_A_Part_7 Q37_A_OTHER Q38_A_Part_1 Q38_A_Part_2 Q38_A_Part_3 Q38_A_Part_4 Q38_A_Part_5 Q38_A_Part_6 Q38_A_Part_7 Q38_A_Part_8 Q38_A_Part_9 Q38_A_Part_10 Q38_A_Part_11 Q38_A_OTHER Q39_Part_1 Q39_Part_2 Q39_Part_3 Q39_Part_4 Q39_Part_5 Q39_Part_6 Q39_Part_7 Q39_Part_8 Q39_Part_9 Q39_OTHER Q40_Part_1 Q40_Part_2 Q40_Part_3 Q40_Part_4 Q40_Part_5 Q40_Part_6 Q40_Part_7 Q40_Part_8 Q40_Part_9 Q40_Part_10 Q40_Part_11 Q40_OTHER Q41 Q42_Part_1 Q42_Part_2 Q42_Part_3 Q42_Part_4 Q42_Part_5 Q42_Part_6 Q42_Part_7 Q42_Part_8 Q42_Part_9 Q42_Part_10 Q42_Part_11 Q42_OTHER Q27_B_Part_1 Q27_B_Part_2 Q27_B_Part_3 Q27_B_Part_4 Q27_B_Part_5 Q27_B_Part_6 Q27_B_Part_7 Q27_B_Part_8 Q27_B_Part_9 Q27_B_Part_10 Q27_B_Part_11 Q27_B_OTHER Q29_B_Part_1 Q29_B_Part_2 Q29_B_Part_3 Q29_B_Part_4 Q29_B_OTHER Q30_B_Part_1 Q30_B_Part_2 Q30_B_Part_3 Q30_B_Part_4 Q30_B_Part_5 Q30_B_Part_6 Q30_B_Part_7 Q30_B_OTHER Q31_B_Part_1 Q31_B_Part_2 Q31_B_Part_3 Q31_B_Part_4 Q31_B_Part_5 Q31_B_Part_6 Q31_B_Part_7 Q31_B_Part_8 Q31_B_Part_9 Q31_B_OTHER Q32_B_Part_1 Q32_B_Part_2 Q32_B_Part_3 Q32_B_Part_4 Q32_B_Part_5 Q32_B_Part_6 Q32_B_Part_7 Q32_B_Part_8 Q32_B_Part_9 Q32_B_Part_10 Q32_B_Part_11 Q32_B_Part_12 Q32_B_Part_13 Q32_B_Part_14 Q32_B_Part_15 Q32_B_Part_16 Q32_B_Part_17 Q32_B_Part_18 Q32_B_Part_19 Q32_B_Part_20 Q32_B_OTHER Q34_B_Part_1 Q34_B_Part_2 Q34_B_Part_3 Q34_B_Part_4 Q34_B_Part_5 Q34_B_Part_6 Q34_B_Part_7 Q34_B_Part_8 Q34_B_Part_9 Q34_B_Part_10 Q34_B_Part_11 Q34_B_Part_12 Q34_B_Part_13 Q34_B_Part_14 Q34_B_Part_15 Q34_B_Part_16 Q34_B_OTHER Q36_B_Part_1 Q36_B_Part_2 Q36_B_Part_3 Q36_B_Part_4 Q36_B_Part_5 Q36_B_Part_6 Q36_B_Part_7 Q36_B_OTHER Q37_B_Part_1 Q37_B_Part_2 Q37_B_Part_3 Q37_B_Part_4 Q37_B_Part_5 Q37_B_Part_6 Q37_B_Part_7 Q37_B_OTHER Q38_B_Part_1 Q38_B_Part_2 Q38_B_Part_3 Q38_B_Part_4 Q38_B_Part_5 Q38_B_Part_6 Q38_B_Part_7 Q38_B_Part_8 Q38_B_Part_9 Q38_B_Part_10 Q38_B_Part_11 Q38_B_OTHER . 1 910 | 50-54 | Man | India | Bachelor’s degree | Other | 5-10 years | Python | R | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | Python | nan | nan | nan | nan | nan | nan | nan | nan | Vim / Emacs | nan | nan | nan | nan | nan | Colab Notebooks | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | A laptop | nan | Google Cloud TPUs | nan | nan | nan | nan | 2-5 times | Matplotlib | Seaborn | nan | Ggplot / ggplot2 | Shiny | nan | nan | nan | nan | Leaflet / Folium | nan | nan | 5-10 years | Scikit-learn | TensorFlow | nan | nan | nan | nan | nan | nan | nan | nan | nan | Caret | nan | nan | nan | nan | nan | nan | Linear or Logistic Regression | Decision Trees or Random Forests | Gradient Boosting Machines (xgboost, lightgbm, etc) | Bayesian Approaches | nan | Dense Neural Networks (MLPs, etc) | Convolutional Neural Networks | nan | Recurrent Neural Networks | nan | nan | nan | General purpose image/video tools (PIL, cv2, skimage, etc) | nan | nan | nan | nan | nan | nan | Word embeddings/vectors (GLoVe, fastText, word2vec) | nan | nan | nan | nan | nan | Manufacturing/Fabrication | 50-249 employees | 3-4 | No (we do not use ML methods) | nan | nan | nan | nan | nan | nan | None of these activities are an important part of my role at work | nan | 25,000-29,999 | $100-$999 | nan | nan | Google Cloud Platform (GCP) | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | Google Cloud Compute Engine | nan | nan | nan | nan | nan | nan | Google Cloud Storage (GCS) | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | No / None | nan | nan | PostgreSQL | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | None | nan | nan | nan | nan | nan | nan | nan | nan | No / None | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | No / None | nan | nan | nan | nan | GitHub | nan | Kaggle | nan | nan | nan | nan | Coursera | edX | Kaggle Learn Courses | DataCamp | nan | Udacity | Udemy | nan | nan | nan | nan | nan | Local development environments (RStudio, JupyterLab, etc.) | nan | Email newsletters (Data Elixir, O&#39;Reilly Data &amp; AI, etc) | nan | Kaggle (notebooks, forums, etc) | nan | YouTube (Kaggle YouTube, Cloud AI Adventures, etc) | Podcasts (Chai Time Data Science, O’Reilly Data Show, etc) | Blogs (Towards Data Science, Analytics Vidhya, etc) | Journal Publications (peer-reviewed journals, conference proceedings, etc) | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | . 2 784 | 50-54 | Man | Indonesia | Master’s degree | Program/Project Manager | 20+ years | nan | nan | SQL | C | C++ | Java | nan | nan | nan | nan | nan | nan | nan | Python | nan | nan | nan | nan | nan | nan | Notepad++ | nan | nan | nan | Jupyter Notebook | nan | nan | Kaggle Notebooks | Colab Notebooks | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | A cloud computing platform (AWS, Azure, GCP, hosted notebooks, etc) | nan | nan | nan | nan | None | nan | Never | Matplotlib | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | Under 1 year | Scikit-learn | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | Linear or Logistic Regression | Decision Trees or Random Forests | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | Manufacturing/Fabrication | 1000-9,999 employees | 1-2 | We are exploring ML methods (and may one day put a model into production) | nan | Build and/or run the data infrastructure that my business uses for storing, analyzing, and operationalizing data | nan | nan | nan | nan | nan | nan | 60,000-69,999 | $0 ($USD) | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | Kaggle Learn Courses | nan | nan | nan | nan | nan | Cloud-certification programs (direct from AWS, Azure, GCP, or similar) | University Courses (resulting in a university degree) | nan | nan | Advanced statistical software (SPSS, SAS, etc.) | nan | nan | nan | nan | nan | nan | nan | nan | Journal Publications (peer-reviewed journals, conference proceedings, etc) | nan | nan | nan | nan | nan | Google Cloud Platform (GCP) | nan | Oracle Cloud | nan | nan | nan | nan | nan | nan | nan | nan | nan | Google Cloud Compute Engine | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | None | nan | MySQL | nan | SQLite | Oracle Database | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | Google Cloud SQL | nan | nan | nan | nan | nan | nan | nan | Google Data Studio | nan | nan | nan | nan | Qlik | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | Automated model selection (e.g. auto-sklearn, xcessiv) | nan | nan | nan | nan | nan | Google Cloud AutoML | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | None | nan | . 3 924 | 22-24 | Man | Pakistan | Master’s degree | Software Engineer | 1-3 years | Python | nan | nan | nan | C++ | Java | nan | nan | nan | nan | nan | nan | nan | Python | nan | nan | nan | nan | PyCharm | nan | nan | nan | nan | nan | Jupyter Notebook | nan | Other | Kaggle Notebooks | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | A laptop | nan | nan | nan | nan | nan | Other | Never | Matplotlib | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | I do not use machine learning methods | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | Academics/Education | 1000-9,999 employees | 0 | I do not know | nan | nan | nan | nan | nan | nan | None of these activities are an important part of my role at work | nan | $0-999 | $0 ($USD) | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | None | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | DataRobot | nan | nan | nan | nan | nan | nan | MySQL | nan | nan | nan | MongoDB | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | MySQL | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | None | nan | nan | nan | nan | nan | nan | nan | nan | No / None | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | No / None | nan | nan | nan | nan | nan | nan | nan | nan | nan | I do not share my work publicly | nan | nan | nan | nan | DataCamp | nan | nan | nan | nan | nan | nan | nan | nan | Basic statistical software (Microsoft Excel, Google Sheets, etc.) | nan | nan | nan | Kaggle (notebooks, forums, etc) | nan | YouTube (Kaggle YouTube, Cloud AI Adventures, etc) | nan | nan | nan | nan | nan | nan | Amazon Web Services (AWS) | nan | Google Cloud Platform (GCP) | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | Microsoft Azure Virtual Machines | Google Cloud Compute Engine | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | Azure Machine Learning Studio | Google Cloud Vertex AI | DataRobot | nan | nan | nan | nan | nan | nan | MySQL | PostgreSQL | nan | nan | MongoDB | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | Microsoft Power BI | nan | nan | nan | Tableau | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | nan | Automated model selection (e.g. auto-sklearn, xcessiv) | nan | nan | nan | nan | nan | nan | nan | nan | DataRobot AutoML | nan | nan | nan | nan | nan | nan | nan | nan | TensorBoard | nan | nan | nan | nan | nan | nan | nan | . print(&#39;Number of rows:&#39;, df.shape[0]) print(&#39;Number of columns:&#39;, df.shape[1]) . Number of rows: 25973 Number of columns: 369 . &#52395;&#48264;&#51704; &#51656;&#47928; : &#45208;&#51060; . df[&#39;Q1&#39;].value_counts() . 25-29 4931 18-21 4901 22-24 4694 30-34 3441 35-39 2504 40-44 1890 45-49 1375 50-54 964 55-59 592 60-69 553 70+ 128 Name: Q1, dtype: int64 . fig, ax = plt.subplots(figsize=(25,10), facecolor=&quot;w&quot;) # Method for image def make_img(img,zoom, x, y): img = mpimg.imread(img) imagebox = OffsetImage(img, zoom=zoom) ab = AnnotationBbox(imagebox, (x,y),frameon=False) ax.add_artist(ab) img_file = &quot;https://www.freeiconspng.com/thumbs/crown-icon/queen-crown-icon-4.png&quot; zoom = 1 img_y= 4.8 # Creating a DataFrame to get the values and their counts (this was for my purpose) # new_df = pd.DataFrame(df[&#39;Q1&#39;].value_counts()) # I wanted to have the highest value in the middle, so i wrote the following two code lines age_bucket = [&#39;70+&#39;,&#39;55-59&#39;,&#39;45-49&#39;,&#39;35-39&#39;,&#39;22-24&#39;,&#39;25-29&#39;,&#39;18-21&#39;,&#39;30-34&#39;,&#39;40-44&#39;,&#39;50-54&#39;,&#39;60-69&#39;] #new_df.index age_bucket_cnt = [128,592,1375,2504,4694,4931,4901,3441,1890,964,553] #list(new_df.Q1.values) color = [&#39;#E6E6E6&#39;, &#39;#189AB4&#39;,&#39;#E6E6E6&#39;,&#39;#189AB4&#39;,&#39;#E6E6E6&#39;,&#39;#189AB4&#39;,&#39;#E6E6E6&#39;,&#39;#189AB4&#39;,&#39;#E6E6E6&#39;,&#39;#189AB4&#39;,&#39;#E6E6E6&#39;] # Deciding the color width = [0.8, 0.8, 0.8, 0.8, 0.9, 0.9, 0.9, 0.8, 0.8, 0.8, 0.8] # The Width alpha = [0.3, 0.45, 0.5, 0.6, 0.75, 1.0, 0.75, 0.6, 0.5, 0.45, 0.3] # The Opacity fontsize= [20, 20, 20, 20, 25, 35, 30, 20, 20, 20, 20] x_num = [0,1,2,3,4,5,6,7,8,9,10] for i in range(11): plt.bar(x=age_bucket[i],height=age_bucket_cnt[i], width=width[i], color=color[i], alpha=alpha[i]) plt.text(s=age_bucket[i],x=x_num[i],y=age_bucket_cnt[i],va=&#39;bottom&#39;,ha=&#39;center&#39;,fontsize=fontsize[i], alpha=alpha[i]) plt.text(s=&quot;Age Bucket of all Kagglers&quot;,x=5,y=5500, fontsize=50,va=&#39;bottom&#39;,ha=&#39;center&#39;,color=&#39;#189AB4&#39;) # Placing the image make_img(img_file,0.2, 5, 4700) gc.collect() # For Memory Optimization plt.axis(&#39;off&#39;) plt.show() . 확실히 대학생이나 취업 준비생이 많이 이용하는 느낌이다. . 다만 18-21세 연령대 이용률이 생각보다 높은 것이 신기했다. . &#46160;&#48264;&#51704; &#51656;&#47928;: &#49457;&#48324; . df[&#39;Q2&#39;].value_counts() . Man 20598 Woman 4890 Prefer not to say 355 Nonbinary 88 Prefer to self-describe 42 Name: Q2, dtype: int64 . Gender = [&#39;Man&#39;, &#39;Woman&#39;, &#39;Others&#39;] # Setting size in Chart based on # given values Gender_cnt = [20598, 4890, 485] # colors colors = [&#39;#E6E6E6&#39;, &#39;#189AB4&#39;, &#39;#FFFF00&#39;, &#39;#ADFF2F&#39;, &#39;#FFA500&#39;] # explosion explode = (0.05, 0.05, 0.2) plt.figure(figsize=[20,10]) # Pie Chart plt.pie(Gender_cnt, colors=colors, autopct=&#39;%1.1f%%&#39;, pctdistance=1.2, explode=explode,) # draw circle centre_circle = plt.Circle((0, 0), 0.70, fc=&#39;white&#39;) fig = plt.gcf() plt.legend(Gender, loc = &quot;upper right&quot;,title=&quot;Genders&quot;, prop={&#39;size&#39;: 15}) # Adding Circle in Pie chart fig.gca().add_artist(centre_circle) plt.rcParams[&#39;font.size&#39;] = 25 # Adding Title of chart plt.text(s=&quot;Gender Diversity in Kaggle&quot;,x=0,y=1.3, fontsize=50,va=&#39;bottom&#39;,ha=&#39;center&#39;,color=&#39;#189AB4&#39;) gc.collect() # Displaing Chart plt.show() . 남자가 약 80%, 여자가 약 18%이고 기타 이유(공개 희망 안함, 미 기제 등) 2% 입니다. . 확실히 남성이 주류인 분야인 것 같습니다. . &#49464;&#48264;&#51704; &#51656;&#47928;: &#44397;&#51201; . df[&#39;Q3&#39;].value_counts() . India 7434 United States of America 2650 Other 1270 Japan 921 China 814 Brazil 751 Russia 742 Nigeria 702 United Kingdom of Great Britain and Northern Ireland 550 Pakistan 530 Egypt 482 Germany 470 Spain 454 Indonesia 444 Turkey 416 France 401 South Korea 359 Taiwan 334 Canada 331 Bangladesh 317 Italy 311 Mexico 279 Viet Nam 277 Australia 264 Kenya 248 Colombia 225 Poland 219 Iran, Islamic Republic of... 195 Ukraine 186 Singapore 182 Argentina 182 Malaysia 156 Netherlands 153 South Africa 146 Morocco 140 Israel 138 Thailand 123 Portugal 119 Peru 117 United Arab Emirates 111 Tunisia 109 Philippines 108 Sri Lanka 106 Chile 102 Greece 102 Ghana 99 Saudi Arabia 89 Ireland 84 Sweden 81 Hong Kong (S.A.R.) 79 Nepal 75 Switzerland 71 I do not wish to disclose my location 69 Belgium 65 Czech Republic 63 Romania 61 Austria 51 Belarus 51 Ecuador 50 Denmark 48 Uganda 47 Norway 45 Kazakhstan 45 Algeria 44 Ethiopia 43 Iraq 43 Name: Q3, dtype: int64 . !pip install geopandas import geopandas as gpd # List of countries we are interested in lis_countries = [&quot;Algeria&quot;,&quot;Argentina&quot;,&quot;Australia&quot;,&quot;Austria&quot;,&quot;Bangladesh&quot;,&quot;Belarus&quot;,&quot;Belgium&quot;,&quot;Brazil&quot;,&quot;Canada&quot;,&quot;Chile&quot;,&quot;China&quot;,&quot;Colombia&quot;, &quot;Czechia&quot;,&quot;Denmark&quot;,&quot;Ecuador&quot;,&quot;Egypt&quot;,&quot;Ethiopia&quot;,&quot;France&quot;,&quot;Germany&quot;,&quot;Ghana&quot;,&quot;Greece&quot;,&quot;India&quot;,&quot;Indonesia&quot;,&quot;Iraq&quot;,&quot;Ireland&quot;, &quot;Israel&quot;,&quot;Italy&quot;,&quot;Japan&quot;,&quot;Kazakhstan&quot;,&quot;Kenya&quot;,&quot;Malaysia&quot;,&quot;Mexico&quot;,&quot;Morocco&quot;,&quot;Nepal&quot;,&quot;Netherlands&quot;,&quot;Nigeria&quot;,&quot;Norway&quot;,&quot;Pakistan&quot;, &quot;Peru&quot;,&quot;Philippines&quot;,&quot;Poland&quot;,&quot;Portugal&quot;,&quot;Romania&quot;,&quot;Russia&quot;,&quot;Saudi Arabia&quot;,&quot;South Africa&quot;,&quot;South Korea&quot;,&quot;Spain&quot;,&quot;Sri Lanka&quot;, &quot;Sweden&quot;,&quot;Switzerland&quot;,&quot;Taiwan&quot;,&quot;Thailand&quot;,&quot;Tunisia&quot;,&quot;Turkey&quot;,&quot;Uganda&quot;,&quot;Ukraine&quot;,&quot;United Arab Emirates&quot;,&quot;United Kingdom&quot;, &quot;United States of America&quot;,&quot;Vietnam&quot;] # Reading the geopandas data world = gpd.read_file(gpd.datasets.get_path(&#39;naturalearth_lowres&#39;)) country_data = lis_countries # Passing the list of countries here country_geo = list(world[&#39;name&#39;]) # The country list from the geopandas dataset # List of all the values of population of Kagglers from each country lis_pop = [44,182,264,51,317,51,65,751,331,102,814,225,63,48,50,482,43,401,470,99,102,7434,444,43,84,138,311,921,45,248,156,279,140,75,153, 702,45,530,117,108,219,119,61,742,89,146,359,454,106,81,71,334,123,109,416,47,186,111,550,2650,277] # Next we need to create a dataframe with lis_countries and lis_pop our_country_analysis = pd.DataFrame(lis_countries, columns=[&#39;Country&#39;]) our_country_analysis[&#39;KagglePopulation&#39;] = lis_pop # Next, we are going to visualize this... mapped = world.set_index(&#39;name&#39;).join(our_country_analysis.set_index(&#39;Country&#39;)).reset_index() to_be_mapped = &#39;KagglePopulation&#39; vmin, vmax = 0,10000 fig, ax = plt.subplots(1, figsize=(25,30)) mapped.dropna().plot(column=to_be_mapped, cmap=&#39;cividis&#39;, linewidth=0.8, ax=ax, edgecolors=&#39;1&#39;, alpha=0.7) ax.text(s=&quot;Kagglers All Around the Globe&quot;,x=0,y=100, fontsize=50,va=&#39;bottom&#39;,ha=&#39;center&#39;,color=&#39;#189AB4&#39;) ax.set_axis_off() sm = plt.cm.ScalarMappable(cmap=&#39;cividis&#39;, norm=plt.Normalize(vmin=vmin, vmax=vmax)) sm._A = [] gc.collect() cbar = fig.colorbar(sm, orientation=&#39;vertical&#39;, shrink= .25) . Requirement already satisfied: geopandas in /usr/local/lib/python3.7/dist-packages (0.10.2) Requirement already satisfied: fiona&gt;=1.8 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.8.20) Requirement already satisfied: shapely&gt;=1.6 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.8.0) Requirement already satisfied: pyproj&gt;=2.2.0 in /usr/local/lib/python3.7/dist-packages (from geopandas) (3.2.1) Requirement already satisfied: pandas&gt;=0.25.0 in /usr/local/lib/python3.7/dist-packages (from geopandas) (1.1.5) Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from fiona&gt;=1.8-&gt;geopandas) (2021.10.8) Requirement already satisfied: six&gt;=1.7 in /usr/local/lib/python3.7/dist-packages (from fiona&gt;=1.8-&gt;geopandas) (1.15.0) Requirement already satisfied: attrs&gt;=17 in /usr/local/lib/python3.7/dist-packages (from fiona&gt;=1.8-&gt;geopandas) (21.2.0) Requirement already satisfied: munch in /usr/local/lib/python3.7/dist-packages (from fiona&gt;=1.8-&gt;geopandas) (2.5.0) Requirement already satisfied: cligj&gt;=0.5 in /usr/local/lib/python3.7/dist-packages (from fiona&gt;=1.8-&gt;geopandas) (0.7.2) Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from fiona&gt;=1.8-&gt;geopandas) (57.4.0) Requirement already satisfied: click-plugins&gt;=1.0 in /usr/local/lib/python3.7/dist-packages (from fiona&gt;=1.8-&gt;geopandas) (1.1.1) Requirement already satisfied: click&gt;=4.0 in /usr/local/lib/python3.7/dist-packages (from fiona&gt;=1.8-&gt;geopandas) (7.1.2) Requirement already satisfied: pytz&gt;=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas&gt;=0.25.0-&gt;geopandas) (2018.9) Requirement already satisfied: numpy&gt;=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas&gt;=0.25.0-&gt;geopandas) (1.19.5) Requirement already satisfied: python-dateutil&gt;=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas&gt;=0.25.0-&gt;geopandas) (2.8.2) . 포화도가 높을 수록 노란색에 가까워 지는 것을 알 수 있습니다. . 인도 사람들이 확실히 많이 이용하는 모습이군요. . 중간중간 하얗게 빈 나라들도 있습니다. . &#45348;&#48264;&#51704; &#51656;&#47928;: &#54617;&#47141; . df[&#39;Q4&#39;].value_counts() . Master’s degree 10132 Bachelor’s degree 9907 Doctoral degree 2795 Some college/university study without earning a bachelor’s degree 1735 I prefer not to answer 627 No formal education past high school 417 Professional doctorate 360 Name: Q4, dtype: int64 . fig, ax = plt.subplots(figsize=(25,10), facecolor=&quot;w&quot;) # Method for image def make_img(img,zoom, x, y): img = mpimg.imread(img) imagebox = OffsetImage(img, zoom=zoom) ab = AnnotationBbox(imagebox, (x,y),frameon=False) ax.add_artist(ab) img_file = &quot;https://www.freeiconspng.com/thumbs/crown-icon/queen-crown-icon-4.png&quot; zoom = 1 img_y= 4.8 # I wanted to have the highest value in the middle, so i wrote the following two code lines age_bucket = [&#39;Professional Doctorate&#39;,&#39;High School&#39;,&#39;Bachelor’s degree&#39;,&#39;Master’s degree&#39;,&#39;Doctoral degree&#39;,&#39;Others&#39;,&#39;No Answer&#39;] age_bucket_cnt = [360,417,9907,10132,2795,1735,627] color = [&#39;#E6E6E6&#39;,&#39;#189AB4&#39;,&#39;#E6E6E6&#39;,&#39;#189AB4&#39;,&#39;#E6E6E6&#39;,&#39;#189AB4&#39;,&#39;#E6E6E6&#39;] # Deciding the color width = [0.8, 0.8, 0.9, 0.9, 0.9, 0.8, 0.8,] # The Width alpha = [0.5, 0.6, 0.75, 1.0, 0.75, 0.6, 0.5] # The Opacity fontsize= [12, 16, 18, 21, 16, 16, 16] x_num = [0,1,2,3,4,5,6] for i in range(7): plt.bar(x=age_bucket[i],height=age_bucket_cnt[i], width=width[i], color=color[i], alpha=alpha[i]) plt.text(s=age_bucket[i],x=x_num[i],y=age_bucket_cnt[i],va=&#39;bottom&#39;,ha=&#39;center&#39;,fontsize=fontsize[i], alpha=alpha[i]) plt.text(s=&quot;Educational Qualifications of all Kagglers&quot;,x=3,y=11000, fontsize=50,va=&#39;bottom&#39;,ha=&#39;center&#39;,color=&#39;#189AB4&#39;) # Placing the image make_img(img_file,0.25, 3, 9500) gc.collect() # For Memory Optimization plt.axis(&#39;off&#39;) plt.show() . 대부분의 캐글 이용자들은 학사 이상의 학위를 가지고 있습니다. . (Master&#39;s degree : 석사, Bachelor&#39;s degree : 학사, Doctoral degree : 박사 학위) . &#45796;&#49455;&#48264;&#51704; &#51656;&#47928;: &#51649;&#50629; . df[&#39;Q5&#39;].value_counts() . Student 6804 Data Scientist 3616 Software Engineer 2449 Other 2393 Data Analyst 2301 Currently not employed 1986 Research Scientist 1538 Machine Learning Engineer 1499 Business Analyst 968 Program/Project Manager 849 Data Engineer 668 Product Manager 319 Statistician 313 DBA/Database Engineer 171 Developer Relations/Advocacy 99 Name: Q5, dtype: int64 . # Method for image def make_img(img,zoom, x, y): img = mpimg.imread(img) imagebox = OffsetImage(img, zoom=zoom) ab = AnnotationBbox(imagebox, (x,y),frameon=False) ax.add_artist(ab) img_file = &quot;https://www.freeiconspng.com/thumbs/crown-icon/queen-crown-icon-4.png&quot; zoom = 1 img_y= 4.8 fig, ax = plt.subplots(figsize=(25,10), facecolor=&quot;w&quot;) # Creating a DataFrame to get the values and their counts (this was for my purpose) # new_df = pd.DataFrame(df[&#39;Q1&#39;].value_counts()) # I wanted to have the highest value in the middle, so i wrote the following two code lines age_bucket = [&#39;Developer n Relations n/Advocacy&#39;,&#39;Statistician&#39;,&#39;Data n Engineer&#39;,&#39;Business n Analyst&#39;,&#39;Research n Scientist&#39;,&#39;Data n Analyst&#39;,&#39;Software n Engineer&#39;,&#39;Student&#39;, &#39;Data n Scientist&#39;,&#39;Other&#39;,&#39;Unemployed&#39;,&#39;ML n Engineer&#39;,&#39;Project n Manager&#39;,&#39;Product n Manager&#39;,&#39;DB n Engineer&#39;] #new_df.index age_bucket_cnt = [99,313,668,968,1538,2301,2449,6804,3414,2393,1986,1499,849,319,171] #list(new_df.Q1.values) color = [&#39;#E6E6E6&#39;, &#39;#189AB4&#39;, &#39;#E6E6E6&#39;, &#39;#189AB4&#39;,&#39;#E6E6E6&#39;,&#39;#189AB4&#39;,&#39;#E6E6E6&#39;,&#39;#189AB4&#39;,&#39;#E6E6E6&#39;,&#39;#189AB4&#39;,&#39;#E6E6E6&#39;,&#39;#189AB4&#39;,&#39;#E6E6E6&#39;,&#39;#189AB4&#39;, &#39;#E6E6E6&#39;] # Deciding the color width = [0.8, 0.8, 0.8, 0.8, 0.8, 0.8, 0.9, 0.9, 0.9, 0.8, 0.8, 0.8, 0.8, 0.8, 0.8] # The Width alpha = [0.3, 0.45, 0.3, 0.45, 0.5, 0.6, 0.75, 1.0, 0.75, 0.6, 0.5, 0.45, 0.3, 0.3, 0.45] # The Opacity fontsize= [12, 12, 14, 14, 14, 14, 18, 20, 16, 14, 12, 14, 14, 12, 12] x_num = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14] for i in range(15): plt.bar(x=age_bucket[i],height=age_bucket_cnt[i], width=width[i], color=color[i], alpha=alpha[i]) plt.text(s=age_bucket[i],x=x_num[i],y=age_bucket_cnt[i],va=&#39;bottom&#39;,ha=&#39;center&#39;,fontsize=fontsize[i], alpha=alpha[i]) plt.text(s=&quot;Current Role of all Kagglers&quot;,x=7.5,y=7500, fontsize=50,va=&#39;bottom&#39;,ha=&#39;center&#39;,color=&#39;#189AB4&#39;) # Placing the image make_img(img_file,0.15, 7, 6500) gc.collect() # For Memory Optimization plt.axis(&#39;off&#39;) plt.show() . 작성자의 예측과 다르게 학생이 압도적으로 높은 수치가 나왔습니다. . (대부분이 ML 전문가나 데이터 분석가가 나올것이라고 생각한 것 같아요.) . 여기서 주목할 점이 Others 입니다. 꽤 상위권에 위치하는데요. . 타 분야 사람이 캐글 이용에 적극적인 것으로 생각할 수 있는데요. 데이터 분석이 많은 분야에서 응용될 수 있다는 것을 보여주는 것 같아요. . &#50668;&#49455;&#48264;&#51704; &#51656;&#47928;: &#54532;&#47196;&#44536;&#47000;&#48141; &#44221;&#47141; . df[&#39;Q6&#39;].value_counts() . 1-3 years 7874 &lt; 1 years 5881 3-5 years 4061 5-10 years 3099 10-20 years 2166 20+ years 1860 I have never written code 1032 Name: Q6, dtype: int64 . years_bin = [&#39;1-3years&#39;,&#39;&lt;1years&#39;,&#39;3-5years&#39;,&#39;5-10years&#39;,&#39;10-20years&#39;,&#39;20+years&#39;,&#39;Never Coded&#39;] years_cnt = [7874, 5881, 4061, 3099, 2166, 1860, 1032] fig = plt.figure(figsize=(20,10)) plt.barh(width=years_cnt, y=years_bin, height=0.7, color = [&#39;#189AB4&#39;, &#39;#189AB4&#39;,&#39;#189AB4&#39;,&#39;#E6E6E6&#39;,&#39;#E6E6E6&#39;, &#39;#E6E6E6&#39;, &#39;#E6E6E6&#39;], alpha=0.8) ##################### For the Years of Experience ################################### s1 = [&#39;1-3years&#39;,&#39;&lt;1years&#39;,&#39;3-5years&#39;,&#39;5-10years&#39;,&#39;10-20years&#39;,&#39;20+years&#39;,&#39;Never Coded&#39;] x1 = [8874, 6881, 5061, 4099, 3366, 2860, 2432] y1 = [0,1,2,3,4,5,6] for i in range(7): plt.text(s = s1[i], x=x1[i], y=y1[i] ,fontsize=25,va=&#39;center&#39;,ha=&#39;right&#39;,alpha=0.8) plt.title(&quot;Average Years of Programming Experience of Kagglers&quot;, fontsize=42, pad=20, color=&#39;#189AB4&#39;) plt.axis(&#39;off&#39;) plt.gca().invert_yaxis() plt.show() . 캐글 내에 생각보다 코딩 경력이 오래된 사람이 많지 않습니다. . 젏은 플렛폼이라고도 생각할 수 있고, 초보자가 접근하기 어렵지 않다고도 생각할 수 있겠네요. . &#51068;&#44273;&#48264;&#51704; &#51656;&#47928;: &#54532;&#47196;&#44536;&#47000;&#48141; &#50616;&#50612; . df[&#39;Q7_Part_1&#39;].value_counts() . Python 21860 Name: Q7_Part_1, dtype: int64 . df[&#39;Q7_Part_2&#39;].value_counts() . R 5334 Name: Q7_Part_2, dtype: int64 . Tool = [&#39;Python&#39;, &#39;R&#39;] # Setting size in Chart based on # given values Tool_cnt = [21860, 5334] # colors colors = [&#39;#E6E6E6&#39;, &#39;#189AB4&#39;] # explosion explode = (0.05, 0.05) plt.figure(figsize=[20,10]) # Pie Chart plt.pie(Tool_cnt, colors=colors, autopct=&#39;%1.1f%%&#39;, pctdistance=1.2, explode=explode,) # draw circle centre_circle = plt.Circle((0, 0), 0.70, fc=&#39;white&#39;) fig = plt.gcf() plt.legend(Tool, loc = &quot;upper right&quot;,title=&quot;Programming Languages&quot;, prop={&#39;size&#39;: 15}) # Adding Circle in Pie chart fig.gca().add_artist(centre_circle) plt.rcParams[&#39;font.size&#39;] = 25 # Adding Title of chart plt.text(s=&quot;Which Programming Tool do they Prefer?&quot;,x=0,y=1.3, fontsize=50,va=&#39;bottom&#39;,ha=&#39;center&#39;,color=&#39;#189AB4&#39;) gc.collect() # Displaing Chart plt.show() . 파이썬과 R 이외에 다른 선택지도 있었고, 중복 선택이 허용된 문항이지만 작성자는 파이썬과 R만을 비교했습니다. . 파이썬이 80% 이상으로 압도적인 사용률을 보였는데요. . 앞서 조사한 결과에서 학생인 사람이 많고, 타 분야 전문가도 많기 때문에 쉬운 언어인 파이썬의 사용률이 높지 않을까 생각했어요. . &#50668;&#45919;&#48264;&#51704; &#51656;&#47928;: &#54532;&#47196;&#44536;&#47000;&#48141; &#50616;&#50612;2 . df[&#39;Q8&#39;] = df[&#39;Q8&#39;].apply(lambda x: &#39;Others&#39; if x not in [&#39;Python&#39;,&#39;R&#39;,&#39;SQL&#39;] else x) df[&#39;Q8&#39;].value_counts() . Python 20213 Others 2977 R 1445 SQL 1338 Name: Q8, dtype: int64 . Tool = [&#39;Python&#39;, &#39;R&#39;, &#39;SQL&#39;, &#39;Others&#39;] # Setting size in Chart based on # given values Tool_cnt = [20213, 1445, 1338, 2977] # colors colors = [&#39;#E6E6E6&#39;, &#39;#189AB4&#39;, &#39;#FFFF00&#39;, &#39;#ADFF2F&#39;] # explosion explode = (0.05, 0.05, 0.05, 0.05) plt.figure(figsize=[20,10]) # Pie Chart plt.pie(Tool_cnt, colors=colors, autopct=&#39;%1.1f%%&#39;, pctdistance=1.2, explode=explode,) # draw circle centre_circle = plt.Circle((0, 0), 0.70, fc=&#39;white&#39;) fig = plt.gcf() plt.legend(Tool, loc = &quot;upper right&quot;,title=&quot;Programming Languages&quot;, prop={&#39;size&#39;: 15}) # Adding Circle in Pie chart fig.gca().add_artist(centre_circle) plt.rcParams[&#39;font.size&#39;] = 25 # Adding Title of chart plt.text(s=&quot;What do they Recommend for Data Science?&quot;,x=0,y=1.3, fontsize=50,va=&#39;bottom&#39;,ha=&#39;center&#39;,color=&#39;#189AB4&#39;) gc.collect() # Displaing Chart plt.show() . 앞선 조사와 비슷한데, 차이점은 중복선택이 안된다는 점입니다. . 선택지가 꽤 많았는데도 파이썬이 압도적인 선택률을 보이네요. . &#50500;&#54857;&#48264;&#51704; &#51656;&#47928;: &#54532;&#47196;&#44536;&#47000;&#48141; &#54872;&#44221;(IDE) . df[&#39;Q9_Part_1&#39;].value_counts() . Jupyter (JupyterLab, Jupyter Notebooks, etc) 5488 Name: Q9_Part_1, dtype: int64 . df[&#39;Q9_Part_2&#39;].value_counts() . RStudio 4771 Name: Q9_Part_2, dtype: int64 . 이런식으로 값을 추출해서 적용한 것 같아요. . name = [&#39;JupyterLab&#39;,&#39;RStudio&#39;,&#39;Visual Studio&#39;,&#39;VS Code&#39;,&#39;PyCharm&#39;,&#39;Spyder&#39;,&#39;Notepad++&#39;,&#39;Sublime Text&#39;,&#39;Vim/Emacs&#39;,&#39;MATLAB&#39;,&#39;Jupyter Notebook&#39;,&#39;None&#39;,&#39;Other&#39;] value = [5488,4771,4110,10040,7468,3794,3937,2839,1646,2203,16233,526,1491] # Creating a dataframe to store this information df_nine_ = pd.DataFrame(name, columns=[&#39;IDE&#39;]) df_nine_[&#39;Values&#39;] = value df_nine_ = df_nine_.sort_values(by=&quot;Values&quot;, ascending=False) df_nine_ fig = plt.figure(figsize=(20,10)) plt.barh(width=list(df_nine_[&#39;Values&#39;].unique()), y=list(df_nine_[&#39;IDE&#39;].unique()), height=0.7, color = [&#39;#189AB4&#39;, &#39;#189AB4&#39;, &#39;#189AB4&#39;, &#39;#E6E6E6&#39;,&#39;#E6E6E6&#39;,&#39;#E6E6E6&#39;,&#39;#E6E6E6&#39;, &#39;#E6E6E6&#39;, &#39;#E6E6E6&#39;, &#39;#E6E6E6&#39;, &#39;#E6E6E6&#39;, &#39;#E6E6E6&#39;, &#39;#E6E6E6&#39;], alpha=0.8) ##################### For the Years of Experience ################################### s1 = list(df_nine_[&#39;IDE&#39;].unique()) x1 = [19833,12040,9468,7788,6471,6810,6437,5294,5539,4003,3946,2691,1726] y1 = [0,1,2,3,4,5,6,7,8,9,10,11,12] for i in range(13): plt.text(s = s1[i], x=x1[i], y=y1[i] , fontsize=25,va=&#39;center&#39;,ha=&#39;right&#39;,alpha=0.8) plt.title(&quot;Preferred IDE of Kagglers&quot;, fontsize=42, pad=20, color=&#39;#189AB4&#39;) plt.axis(&#39;off&#39;) plt.gca().invert_yaxis() gc.collect() plt.show() . 주피터 노트북이 사용자 친화적이라고 코멘트를 합니다. 시프트+엔터시 결과물이 바로 나와 편리하다는 근거와 함께. . VS CODE는 다른 언어(C) 할때 저도 사용했는데, 깃허브와 연동이 좋아서 사용이 편리합니다. 역시 많은 사용자가 이용하는 것 같아요. . 파이참도 저는 써보진 않았지만 높은 순위를 기록합니다. . R을 사용하는 사람 비율 대비 R스튜디오도 많이 쓰는 모습을 보이는데, 대부분에 R 사용자가 R스튜디오를 사용한다고 생각됩니다. . &#50676;&#48264;&#51704; &#51656;&#47928;: &#51452; &#49324;&#50857; &#45432;&#53944;&#48513; . df[&#39;Q10_Part_1&#39;].value_counts() . Kaggle Notebooks 9507 Name: Q10_Part_1, dtype: int64 . df[&#39;Q10_Part_2&#39;].value_counts() . Colab Notebooks 9792 Name: Q10_Part_2, dtype: int64 . 코랩 노트북, 캐글 노트북 이용자 이외는 Other로 생각한 것 같습니다. . def make_img(img,zoom, x, y): img = mpimg.imread(img) imagebox = OffsetImage(img, zoom=zoom) ab = AnnotationBbox(imagebox, (x,y),frameon=False) ax.add_artist(ab) img_file = &quot;https://www.freeiconspng.com/thumbs/crown-icon/queen-crown-icon-4.png&quot; zoom = 1 img_y= 4.8 # Visualizing the Hosted Notebooks. (Hidden Input) fig, ax = plt.subplots(figsize=(25,10), facecolor=&quot;w&quot;) age_bucket = [&#39;None&#39;,&#39;Colab Notebook&#39;,&#39;Kaggle Notebook&#39;] age_bucket_cnt = [7174,9792,9507] color = [&#39;#E6E6E6&#39;,&#39;#189AB4&#39;,&#39;#E6E6E6&#39;] # Deciding the color width = [0.9, 0.9, 0.9] # The Width alpha = [0.55, 1.0, 0.75] # The Opacity fontsize= [25, 45, 30] x_num = [0,1,2] for i in range(3): plt.bar(x=age_bucket[i],height=age_bucket_cnt[i], width=width[i], color=color[i], alpha=alpha[i]) plt.text(s=age_bucket[i],x=x_num[i],y=age_bucket_cnt[i],va=&#39;bottom&#39;,ha=&#39;center&#39;,fontsize=fontsize[i], alpha=alpha[i]) plt.text(s=&quot;Preferred Hosted Notebooks&quot;,x=1,y=11000, fontsize=50,va=&#39;bottom&#39;,ha=&#39;center&#39;,color=&#39;#189AB4&#39;) # Placing the image make_img(img_file,0.3, 1, 9000) gc.collect() # For Memory Optimization plt.axis(&#39;off&#39;) plt.show() . 코랩 노트북과 캐글 노트북의 사용자 수가 비슷합니다. . 코랩 노트북은 점유율 1위로, GPU 사용이 일부 가능하고 구글 드라이브와 연동이 잘된다는 점을 큰 장점으로 소개합니다. . 물론 캐글 이용자 조사이기 때문에 캐글 데이터와 캐글 노트북 간 호완성, 접근성이 좋아서 캐글 노트북 사용자가 다소 많이 집계됬습니다. . 다만 캐글 노트북 만에 분명한 장점이 있겠죠? 한번 어느 환경인지 기회될때 탐색하는 것도 좋을 것 같아요. . 또 특이한 점은 두 노트북 이외 각자의 PC환경을 사용하는 사람도 꽤 많다는 것입니다. . &#50676;&#54620;&#48264;&#51704; &#51656;&#47928;: &#44032;&#49549;&#44592; &#50976;&#47924; . df[&#39;Q12_Part_1&#39;].value_counts() . NVIDIA GPUs 8036 Name: Q12_Part_1, dtype: int64 . df[&#39;Q12_Part_2&#39;].value_counts() . Google Cloud TPUs 3451 Name: Q12_Part_2, dtype: int64 . df[&#39;Q12_Part_3&#39;].value_counts() . AWS Trainium Chips 414 Name: Q12_Part_3, dtype: int64 . df[&#39;Q12_Part_4&#39;].value_counts() . AWS Inferentia Chips 416 Name: Q12_Part_4, dtype: int64 . df[&#39;Q12_Part_5&#39;].value_counts() . None 13234 Name: Q12_Part_5, dtype: int64 . df[&#39;Q12_OTHER&#39;].value_counts() . Other 867 Name: Q12_OTHER, dtype: int64 . name = [&quot;None&quot;,&quot;NVIDIA GPUs&quot;,&quot;Google Cloud TPUs&quot;,&quot;Other&quot;,&quot;AWS Inferentia Chips&quot;,&quot;AWS Trainium Chips&quot;] count = [13234,8036,3451,867,416,414] # Visualizing using a barh: fig = plt.figure(figsize=(20,10)) plt.barh(width=count, y=name, height=0.7, color = [&#39;#E6E6E6&#39;, &#39;#189AB4&#39;, &#39;#189AB4&#39;, &#39;#E6E6E6&#39;,&#39;#E6E6E6&#39;,&#39;#E6E6E6&#39;], alpha=0.8) ##################### For the Years of Experience ################################### s1 = name x1 = [14234,10236,6651,2067,3916,3714] y1 = [0,1,2,3,4,5] for i in range(6): plt.text(s = s1[i], x=x1[i], y=y1[i] , fontsize=25,va=&#39;center&#39;,ha=&#39;right&#39;,alpha=0.8) plt.title(&quot;Specialized Hardware&quot;, fontsize=42, pad=20, color=&#39;#189AB4&#39;) plt.axis(&#39;off&#39;) plt.gca().invert_yaxis() gc.collect() plt.show() . GPU나 TPU를 사용하지 않는 캐글 사용자가 상당히 많이 있네요. . &#45712;&#45184;&#51216; . 대회참가를 위한 데이터 공부가 아니라 설문조사를 시각화 하는 공부였습니다. . 이쁘게 시각화 하기 위해서 작성자가 다양하게 노력한 모습을 확인했습니다. . 또한 설문조사가 캐글 이용자 관련 설문조사라서 결과에 대해 더 흥미롭게 확인 한 것 같아요. . 가볍게 공부하기 좋은 데이터 셋인것 같습니다. . 대회 출처 : https://www.kaggle.com/c/kaggle-survey-2021 . 코드 출처 : https://www.kaggle.com/vivek468/what-s-up-kaggle-kaggle-survey-2021 .",
            "url": "https://ksy1526.github.io/myblog//myblog/2021/12/19/kagglessu8.html",
            "relUrl": "/2021/12/19/kagglessu8.html",
            "date": " • Dec 19, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "SSUDA) 캐글 제품 분류",
            "content": ". from google.colab import drive drive.mount(&#39;/content/drive&#39;) . Mounted at /content/drive . &#45936;&#51060;&#53552; &#48520;&#47084;&#50724;&#44592; . import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns pd.set_option(&#39;display.max_columns&#39;, 100) pd.set_option(&#39;display.max_rows&#39;, 100) from sklearn.preprocessing import LabelEncoder, OneHotEncoder from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV from sklearn.feature_selection import SelectFromModel from sklearn.metrics import accuracy_score, confusion_matrix, classification_report import xgboost as xg from collections import Counter !pip install kneed # kneed is not installed in kaggle. uncomment the above line. from kneed import KneeLocator import warnings warnings.filterwarnings(&quot;ignore&quot;) . Collecting kneed Downloading kneed-0.7.0-py2.py3-none-any.whl (9.4 kB) Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from kneed) (1.4.1) Requirement already satisfied: numpy&gt;=1.14.2 in /usr/local/lib/python3.7/dist-packages (from kneed) (1.19.5) Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from kneed) (3.2.2) Requirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;kneed) (1.3.2) Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,&gt;=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;kneed) (3.0.6) Requirement already satisfied: python-dateutil&gt;=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;kneed) (2.8.2) Requirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;kneed) (0.11.0) Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil&gt;=2.1-&gt;matplotlib-&gt;kneed) (1.15.0) Installing collected packages: kneed Successfully installed kneed-0.7.0 . path = &#39;/content/drive/MyDrive/otto_group/&#39; train = pd.read_csv(path + &#39;train.csv&#39;) test = pd.read_csv(path + &#39;test.csv&#39;) sample_submission = pd.read_csv(path + &#39;sampleSubmission.csv&#39;) train.head() . id feat_1 feat_2 feat_3 feat_4 feat_5 feat_6 feat_7 feat_8 feat_9 feat_10 feat_11 feat_12 feat_13 feat_14 feat_15 feat_16 feat_17 feat_18 feat_19 feat_20 feat_21 feat_22 feat_23 feat_24 feat_25 feat_26 feat_27 feat_28 feat_29 feat_30 feat_31 feat_32 feat_33 feat_34 feat_35 feat_36 feat_37 feat_38 feat_39 feat_40 feat_41 feat_42 feat_43 feat_44 feat_45 feat_46 feat_47 feat_48 feat_49 feat_50 feat_51 feat_52 feat_53 feat_54 feat_55 feat_56 feat_57 feat_58 feat_59 feat_60 feat_61 feat_62 feat_63 feat_64 feat_65 feat_66 feat_67 feat_68 feat_69 feat_70 feat_71 feat_72 feat_73 feat_74 feat_75 feat_76 feat_77 feat_78 feat_79 feat_80 feat_81 feat_82 feat_83 feat_84 feat_85 feat_86 feat_87 feat_88 feat_89 feat_90 feat_91 feat_92 feat_93 target . 0 1 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 2 | 0 | 0 | 0 | 0 | 1 | 0 | 4 | 1 | 1 | 0 | 0 | 2 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 1 | 0 | 5 | 0 | 0 | 0 | 0 | 0 | 2 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 2 | 0 | 0 | 11 | 0 | 1 | 1 | 0 | 1 | 0 | 7 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 2 | 1 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | Class_1 | . 1 2 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 2 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 2 | 1 | 0 | 1 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | Class_1 | . 2 3 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 6 | 0 | 0 | 2 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | Class_1 | . 3 4 | 1 | 0 | 0 | 1 | 6 | 1 | 5 | 0 | 0 | 1 | 1 | 0 | 1 | 0 | 0 | 1 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 7 | 2 | 2 | 0 | 0 | 0 | 58 | 0 | 10 | 0 | 0 | 0 | 0 | 0 | 3 | 0 | 0 | 0 | 0 | 0 | 2 | 0 | 2 | 0 | 1 | 2 | 1 | 3 | 0 | 0 | 3 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 2 | 1 | 5 | 0 | 0 | 4 | 0 | 0 | 2 | 1 | 0 | 1 | 0 | 0 | 1 | 1 | 2 | 2 | 0 | 22 | 0 | 1 | 2 | 0 | 0 | 0 | 0 | 0 | 0 | Class_1 | . 4 5 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 4 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 2 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 3 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 4 | 0 | 1 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | Class_1 | . &#45936;&#51060;&#53552; &#53456;&#49353; . train.columns . Index([&#39;id&#39;, &#39;feat_1&#39;, &#39;feat_2&#39;, &#39;feat_3&#39;, &#39;feat_4&#39;, &#39;feat_5&#39;, &#39;feat_6&#39;, &#39;feat_7&#39;, &#39;feat_8&#39;, &#39;feat_9&#39;, &#39;feat_10&#39;, &#39;feat_11&#39;, &#39;feat_12&#39;, &#39;feat_13&#39;, &#39;feat_14&#39;, &#39;feat_15&#39;, &#39;feat_16&#39;, &#39;feat_17&#39;, &#39;feat_18&#39;, &#39;feat_19&#39;, &#39;feat_20&#39;, &#39;feat_21&#39;, &#39;feat_22&#39;, &#39;feat_23&#39;, &#39;feat_24&#39;, &#39;feat_25&#39;, &#39;feat_26&#39;, &#39;feat_27&#39;, &#39;feat_28&#39;, &#39;feat_29&#39;, &#39;feat_30&#39;, &#39;feat_31&#39;, &#39;feat_32&#39;, &#39;feat_33&#39;, &#39;feat_34&#39;, &#39;feat_35&#39;, &#39;feat_36&#39;, &#39;feat_37&#39;, &#39;feat_38&#39;, &#39;feat_39&#39;, &#39;feat_40&#39;, &#39;feat_41&#39;, &#39;feat_42&#39;, &#39;feat_43&#39;, &#39;feat_44&#39;, &#39;feat_45&#39;, &#39;feat_46&#39;, &#39;feat_47&#39;, &#39;feat_48&#39;, &#39;feat_49&#39;, &#39;feat_50&#39;, &#39;feat_51&#39;, &#39;feat_52&#39;, &#39;feat_53&#39;, &#39;feat_54&#39;, &#39;feat_55&#39;, &#39;feat_56&#39;, &#39;feat_57&#39;, &#39;feat_58&#39;, &#39;feat_59&#39;, &#39;feat_60&#39;, &#39;feat_61&#39;, &#39;feat_62&#39;, &#39;feat_63&#39;, &#39;feat_64&#39;, &#39;feat_65&#39;, &#39;feat_66&#39;, &#39;feat_67&#39;, &#39;feat_68&#39;, &#39;feat_69&#39;, &#39;feat_70&#39;, &#39;feat_71&#39;, &#39;feat_72&#39;, &#39;feat_73&#39;, &#39;feat_74&#39;, &#39;feat_75&#39;, &#39;feat_76&#39;, &#39;feat_77&#39;, &#39;feat_78&#39;, &#39;feat_79&#39;, &#39;feat_80&#39;, &#39;feat_81&#39;, &#39;feat_82&#39;, &#39;feat_83&#39;, &#39;feat_84&#39;, &#39;feat_85&#39;, &#39;feat_86&#39;, &#39;feat_87&#39;, &#39;feat_88&#39;, &#39;feat_89&#39;, &#39;feat_90&#39;, &#39;feat_91&#39;, &#39;feat_92&#39;, &#39;feat_93&#39;, &#39;target&#39;], dtype=&#39;object&#39;) . 컬럼수는 93개 입니다. . train[&#39;target&#39;].unique() . array([&#39;Class_1&#39;, &#39;Class_2&#39;, &#39;Class_3&#39;, &#39;Class_4&#39;, &#39;Class_5&#39;, &#39;Class_6&#39;, &#39;Class_7&#39;, &#39;Class_8&#39;, &#39;Class_9&#39;], dtype=object) . Y 변수의 클레스 종류가 9개 입니다. . sample_submission.head() . id Class_1 Class_2 Class_3 Class_4 Class_5 Class_6 Class_7 Class_8 Class_9 . 0 1 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 1 2 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 2 3 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 3 4 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 4 5 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 저번이랑 비슷하게 제출 파일 형식은 각 클레스 별로 분류 될 확률을 기제하면 되겠네요. . sum((train.isnull()).sum()) . 0 . 결측값이 있는지 확인했습니다. info 함수로 확인하기에는 피처가 너무 커서 직관적으로 확인하기 힘듭니다. . from sklearn.preprocessing import LabelEncoder le=LabelEncoder() train[&#39;target&#39;]=le.fit_transform(train[&#39;target&#39;]) plt.figure(figsize=(12,5)) sns.countplot(train[&#39;target&#39;]) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fc0cca07b90&gt; . 라벨 인코더를 통해 클레스 이름을 간단하게( Class_1 =&gt; 0) 바꿨습니다. . 클레스 개수가 각각 몇개있는지 파악했는데요. 균등하진 않아보입니다. . &#47784;&#45944; 1 . from sklearn.model_selection import train_test_split list_models=[] list_scores=[] y = train[&#39;target&#39;] x = train.drop([&#39;target&#39;, &#39;id&#39;],axis=1) x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=0,test_size=0.2) . from sklearn.linear_model import LogisticRegression from sklearn.metrics import accuracy_score lr=LogisticRegression(max_iter=100000) lr.fit(x_train,y_train) pred_1=lr.predict(x_test) score_1=accuracy_score(y_test,pred_1) list_models.append(&#39;logistic regression&#39;) list_scores.append(score_1) . fig,axes=plt.subplots(1,2) fig.set_size_inches(11.7, 8.27) sns.countplot(pred_1,ax=axes[0]) sns.countplot(y_test,ax=axes[1]) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fc0cbd85e10&gt; . 간단한 로지스틱 회귀로, 왼쪽이 예측값, 오른쪽이 실제값입니다. 실제 비율이 제일 높은 1번은 더 많이 예측하는 모습을 보입니다. . 비율이 높은 편인 5번, 7번, 8번은 실제 값과 예측 값이 비슷합니다. . 하지만 나머지 값들은 실제 값에 있는 비율 만큼 예측 값에서 비슷한 개수로 추정해주지 못했습니다. . 물론 이 현상만으로 비율을 일관적으로 예측할 수는 없습니다.(8번은 예측/실제 값 개수 비슷, 2번은 실제 값에 비해 예측값이 너무 적음) . 다만 불균형한 테스터 셋을 분류하는 문제에서 다음과 같은 문제가 있다는걸 인지해야겠습니다. . 개수가 많은 클레스를 예측하는 확률은 높아지고, 개수가 적은 클레스를 예측하는 확률은 낮아진다는 점 입니다. . from sklearn.ensemble import RandomForestClassifier rfc=RandomForestClassifier() rfc.fit(x_train,y_train) pred_2=rfc.predict(x_test) score_2=accuracy_score(y_test,pred_2) list_scores.append(score_2) list_models.append(&#39;random forest classifier&#39;) . fig,axes=plt.subplots(1,2) fig.set_size_inches(11.7, 8.27) sns.countplot(pred_2,ax=axes[0]) sns.countplot(y_test,ax=axes[1]) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fc0c14ea1d0&gt; . 렌덤 포레스트 분류기법입니다. 앞서 말한것과 비슷한 일이 벌어집니다. . fig,axes=plt.subplots(1,2) fig.set_size_inches(11.7, 8.27) sns.countplot(pred_1,ax=axes[0]) axes[0].legend(title=&#39;predictions by logistic regression&#39;) sns.countplot(pred_2,ax=axes[1]) axes[1].legend(title=&#39;predictions by random forest&#39;) . No handles with labels found to put in legend. No handles with labels found to put in legend. . &lt;matplotlib.legend.Legend at 0x7fc0c1429ad0&gt; . 두 모델이 비슷한 현상을 보인다는 걸 다시한번 보여준 것 같습니다. . from sklearn.svm import SVC svm=SVC() svm.fit(x_train,y_train) pred_3=svm.predict(x_test) score_3=accuracy_score(y_test,pred_3) list_scores.append(score_3) list_models.append(&#39;support vector machines&#39;) . from xgboost import XGBClassifier xgb=XGBClassifier() xgb.fit(x_train,y_train) pred_4=xgb.predict(x_test) score_4=accuracy_score(y_test,pred_4) list_models.append(&#39;xgboost classifier&#39;) list_scores.append(score_4) . plt.figure(figsize=(12,5)) plt.bar(list_models,list_scores,width=0.3) plt.xlabel(&#39;classifictions models&#39;) plt.ylabel(&#39;accuracy scores&#39;) plt.show() . SVM, XGB 모델도 적용시켜보았습니다. . 랜덤 포레스트 분류 모델이 성능이 가장 괜찮아 보입니다. . &#47784;&#45944; 2 . !pip install &quot;autogluon.tabular[all]==0.1.1b20210312&quot; . Collecting autogluon.tabular[all]==0.1.1b20210312 Downloading autogluon.tabular-0.1.1b20210312-py3-none-any.whl (234 kB) |████████████████████████████████| 234 kB 4.2 MB/s Requirement already satisfied: numpy==1.19.5 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.1.1b20210312) (1.19.5) Collecting scikit-learn&lt;0.25,&gt;=0.22.0 Downloading scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB) |████████████████████████████████| 22.3 MB 1.6 MB/s Collecting autogluon.features==0.1.1b20210312 Downloading autogluon.features-0.1.1b20210312-py3-none-any.whl (48 kB) |████████████████████████████████| 48 kB 4.4 MB/s Requirement already satisfied: pandas&lt;2.0,&gt;=1.0.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.1.1b20210312) (1.1.5) Collecting scipy==1.5.4 Downloading scipy-1.5.4-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB) |████████████████████████████████| 25.9 MB 1.8 MB/s Requirement already satisfied: networkx&lt;3.0,&gt;=2.3 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.1.1b20210312) (2.6.3) Collecting autogluon.core==0.1.1b20210312 Downloading autogluon.core-0.1.1b20210312-py3-none-any.whl (312 kB) |████████████████████████████████| 312 kB 50.1 MB/s Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.1.1b20210312) (3.6.4) Requirement already satisfied: psutil&lt;=5.7.0,&gt;=5.0.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.1.1b20210312) (5.4.8) Requirement already satisfied: torch&lt;2.0,&gt;=1.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.1.1b20210312) (1.10.0+cu111) Requirement already satisfied: fastai&lt;2.0,&gt;=1.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.1.1b20210312) (1.0.61) Collecting lightgbm&lt;4.0,&gt;=3.0 Downloading lightgbm-3.3.1-py3-none-manylinux1_x86_64.whl (2.0 MB) |████████████████████████████████| 2.0 MB 49.3 MB/s Collecting catboost&lt;0.25,&gt;=0.23.0 Downloading catboost-0.24.4-cp37-none-manylinux1_x86_64.whl (65.7 MB) |████████████████████████████████| 65.7 MB 46 kB/s Collecting xgboost&lt;1.4,&gt;=1.3.2 Downloading xgboost-1.3.3-py3-none-manylinux2010_x86_64.whl (157.5 MB) |████████████████████████████████| 157.5 MB 63 kB/s Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (2.23.0) Collecting dill==0.3.3 Downloading dill-0.3.3-py2.py3-none-any.whl (81 kB) |████████████████████████████████| 81 kB 9.6 MB/s Requirement already satisfied: autograd&gt;=1.3 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (1.3) Collecting paramiko&gt;=2.4 Downloading paramiko-2.8.0-py2.py3-none-any.whl (206 kB) |████████████████████████████████| 206 kB 50.7 MB/s Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (0.29.24) Requirement already satisfied: tqdm&gt;=4.38.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (4.62.3) Requirement already satisfied: tornado&gt;=5.0.1 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (5.1.1) Collecting boto3 Downloading boto3-1.20.14-py3-none-any.whl (131 kB) |████████████████████████████████| 131 kB 49.8 MB/s Collecting ConfigSpace==0.4.18 Downloading ConfigSpace-0.4.18.tar.gz (950 kB) |████████████████████████████████| 950 kB 49.4 MB/s Installing build dependencies ... done Getting requirements to build wheel ... done Preparing wheel metadata ... done Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (3.2.2) Collecting graphviz&lt;0.9.0,&gt;=0.8.1 Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB) Collecting distributed&gt;=2.6.0 Downloading distributed-2021.11.2-py3-none-any.whl (802 kB) |████████████████████████████████| 802 kB 50.6 MB/s Requirement already satisfied: dask&gt;=2.6.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (2.12.0) Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from ConfigSpace==0.4.18-&gt;autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (3.0.6) Requirement already satisfied: future&gt;=0.15.2 in /usr/local/lib/python3.7/dist-packages (from autograd&gt;=1.3-&gt;autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (0.16.0) Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost&lt;0.25,&gt;=0.23.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (1.15.0) Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost&lt;0.25,&gt;=0.23.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (4.4.1) Collecting dask&gt;=2.6.0 Downloading dask-2021.11.2-py3-none-any.whl (1.0 MB) |████████████████████████████████| 1.0 MB 40.4 MB/s Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed&gt;=2.6.0-&gt;autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (2.4.0) Requirement already satisfied: toolz&gt;=0.8.2 in /usr/local/lib/python3.7/dist-packages (from distributed&gt;=2.6.0-&gt;autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (0.11.2) Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from distributed&gt;=2.6.0-&gt;autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (2.11.3) Requirement already satisfied: click&gt;=6.6 in /usr/local/lib/python3.7/dist-packages (from distributed&gt;=2.6.0-&gt;autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (7.1.2) Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from distributed&gt;=2.6.0-&gt;autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (57.4.0) Requirement already satisfied: msgpack&gt;=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed&gt;=2.6.0-&gt;autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (1.0.2) Requirement already satisfied: tblib&gt;=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed&gt;=2.6.0-&gt;autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (1.7.0) Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from distributed&gt;=2.6.0-&gt;autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (3.13) Requirement already satisfied: zict&gt;=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed&gt;=2.6.0-&gt;autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (2.0.0) Collecting cloudpickle&gt;=1.5.0 Downloading cloudpickle-2.0.0-py3-none-any.whl (25 kB) Requirement already satisfied: packaging&gt;=20.0 in /usr/local/lib/python3.7/dist-packages (from dask&gt;=2.6.0-&gt;autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (21.3) Collecting partd&gt;=0.3.10 Downloading partd-1.2.0-py3-none-any.whl (19 kB) Collecting fsspec&gt;=0.6.0 Downloading fsspec-2021.11.1-py3-none-any.whl (132 kB) |████████████████████████████████| 132 kB 54.6 MB/s Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from fastai&lt;2.0,&gt;=1.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (0.11.1+cu111) Requirement already satisfied: spacy&gt;=2.0.18 in /usr/local/lib/python3.7/dist-packages (from fastai&lt;2.0,&gt;=1.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (2.2.4) Requirement already satisfied: nvidia-ml-py3 in /usr/local/lib/python3.7/dist-packages (from fastai&lt;2.0,&gt;=1.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (7.352.0) Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from fastai&lt;2.0,&gt;=1.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (2.7.3) Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from fastai&lt;2.0,&gt;=1.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (4.6.3) Requirement already satisfied: fastprogress&gt;=0.2.1 in /usr/local/lib/python3.7/dist-packages (from fastai&lt;2.0,&gt;=1.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (1.0.0) Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from fastai&lt;2.0,&gt;=1.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (7.1.2) Requirement already satisfied: bottleneck in /usr/local/lib/python3.7/dist-packages (from fastai&lt;2.0,&gt;=1.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (1.3.2) Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm&lt;4.0,&gt;=3.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (0.37.0) Requirement already satisfied: pytz&gt;=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas&lt;2.0,&gt;=1.0.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (2018.9) Requirement already satisfied: python-dateutil&gt;=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas&lt;2.0,&gt;=1.0.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (2.8.2) Collecting cryptography&gt;=2.5 Downloading cryptography-36.0.0-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB) |████████████████████████████████| 3.6 MB 43.1 MB/s Collecting pynacl&gt;=1.0.1 Downloading PyNaCl-1.4.0-cp35-abi3-manylinux1_x86_64.whl (961 kB) |████████████████████████████████| 961 kB 45.2 MB/s Collecting bcrypt&gt;=3.1.3 Downloading bcrypt-3.2.0-cp36-abi3-manylinux2010_x86_64.whl (63 kB) |████████████████████████████████| 63 kB 2.3 MB/s Requirement already satisfied: cffi&gt;=1.1 in /usr/local/lib/python3.7/dist-packages (from bcrypt&gt;=3.1.3-&gt;paramiko&gt;=2.4-&gt;autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (1.15.0) Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi&gt;=1.1-&gt;bcrypt&gt;=3.1.3-&gt;paramiko&gt;=2.4-&gt;autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (2.21) Collecting locket Downloading locket-0.2.1-py2.py3-none-any.whl (4.1 kB) Requirement already satisfied: threadpoolctl&gt;=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn&lt;0.25,&gt;=0.22.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (3.0.0) Requirement already satisfied: joblib&gt;=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn&lt;0.25,&gt;=0.22.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (1.1.0) Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy&gt;=2.0.18-&gt;fastai&lt;2.0,&gt;=1.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (7.4.0) Requirement already satisfied: srsly&lt;1.1.0,&gt;=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy&gt;=2.0.18-&gt;fastai&lt;2.0,&gt;=1.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (1.0.5) Requirement already satisfied: wasabi&lt;1.1.0,&gt;=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy&gt;=2.0.18-&gt;fastai&lt;2.0,&gt;=1.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (0.8.2) Requirement already satisfied: cymem&lt;2.1.0,&gt;=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy&gt;=2.0.18-&gt;fastai&lt;2.0,&gt;=1.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (2.0.6) Requirement already satisfied: catalogue&lt;1.1.0,&gt;=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy&gt;=2.0.18-&gt;fastai&lt;2.0,&gt;=1.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (1.0.0) Requirement already satisfied: murmurhash&lt;1.1.0,&gt;=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy&gt;=2.0.18-&gt;fastai&lt;2.0,&gt;=1.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (1.0.6) Requirement already satisfied: preshed&lt;3.1.0,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy&gt;=2.0.18-&gt;fastai&lt;2.0,&gt;=1.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (3.0.6) Requirement already satisfied: plac&lt;1.2.0,&gt;=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy&gt;=2.0.18-&gt;fastai&lt;2.0,&gt;=1.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (1.1.3) Requirement already satisfied: blis&lt;0.5.0,&gt;=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy&gt;=2.0.18-&gt;fastai&lt;2.0,&gt;=1.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (0.4.1) Requirement already satisfied: importlib-metadata&gt;=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue&lt;1.1.0,&gt;=0.0.7-&gt;spacy&gt;=2.0.18-&gt;fastai&lt;2.0,&gt;=1.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (4.8.2) Requirement already satisfied: typing-extensions&gt;=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata&gt;=0.20-&gt;catalogue&lt;1.1.0,&gt;=0.0.7-&gt;spacy&gt;=2.0.18-&gt;fastai&lt;2.0,&gt;=1.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (3.10.0.2) Requirement already satisfied: zipp&gt;=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata&gt;=0.20-&gt;catalogue&lt;1.1.0,&gt;=0.0.7-&gt;spacy&gt;=2.0.18-&gt;fastai&lt;2.0,&gt;=1.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (3.6.0) Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (1.24.3) Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (2.10) Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (2021.10.8) Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (3.0.4) Requirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from zict&gt;=0.1.3-&gt;distributed&gt;=2.6.0-&gt;autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (1.0.1) Collecting jmespath&lt;1.0.0,&gt;=0.7.1 Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB) Collecting botocore&lt;1.24.0,&gt;=1.23.14 Downloading botocore-1.23.14-py3-none-any.whl (8.2 MB) |████████████████████████████████| 8.2 MB 37.3 MB/s Collecting s3transfer&lt;0.6.0,&gt;=0.5.0 Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB) |████████████████████████████████| 79 kB 7.5 MB/s Collecting urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB) |████████████████████████████████| 127 kB 49.6 MB/s Requirement already satisfied: MarkupSafe&gt;=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2-&gt;distributed&gt;=2.6.0-&gt;autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (2.0.1) Requirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (1.3.2) Requirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (0.11.0) Requirement already satisfied: retrying&gt;=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly-&gt;catboost&lt;0.25,&gt;=0.23.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (1.3.3) Requirement already satisfied: attrs&gt;=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest-&gt;autogluon.tabular[all]==0.1.1b20210312) (21.2.0) Requirement already satisfied: more-itertools&gt;=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest-&gt;autogluon.tabular[all]==0.1.1b20210312) (8.11.0) Requirement already satisfied: atomicwrites&gt;=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest-&gt;autogluon.tabular[all]==0.1.1b20210312) (1.4.0) Requirement already satisfied: pluggy&lt;0.8,&gt;=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest-&gt;autogluon.tabular[all]==0.1.1b20210312) (0.7.1) Requirement already satisfied: py&gt;=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest-&gt;autogluon.tabular[all]==0.1.1b20210312) (1.11.0) Building wheels for collected packages: ConfigSpace Building wheel for ConfigSpace (PEP 517) ... done Created wheel for ConfigSpace: filename=ConfigSpace-0.4.18-cp37-cp37m-linux_x86_64.whl size=2880650 sha256=7b9c24d3da86378fe64cff390f09a143606ba3ac7a45f5b37fa2827e1aed4124 Stored in directory: /root/.cache/pip/wheels/36/f7/0f/36f368c419ea1a8024fc3d6c078c3111dfef43fa1d14cfebe0 Successfully built ConfigSpace Installing collected packages: urllib3, locket, jmespath, partd, fsspec, cloudpickle, botocore, scipy, s3transfer, pynacl, dask, cryptography, bcrypt, scikit-learn, paramiko, graphviz, distributed, dill, ConfigSpace, boto3, autogluon.core, autogluon.features, xgboost, lightgbm, catboost, autogluon.tabular Attempting uninstall: urllib3 Found existing installation: urllib3 1.24.3 Uninstalling urllib3-1.24.3: Successfully uninstalled urllib3-1.24.3 Attempting uninstall: cloudpickle Found existing installation: cloudpickle 1.3.0 Uninstalling cloudpickle-1.3.0: Successfully uninstalled cloudpickle-1.3.0 Attempting uninstall: scipy Found existing installation: scipy 1.4.1 Uninstalling scipy-1.4.1: Successfully uninstalled scipy-1.4.1 Attempting uninstall: dask Found existing installation: dask 2.12.0 Uninstalling dask-2.12.0: Successfully uninstalled dask-2.12.0 Attempting uninstall: scikit-learn Found existing installation: scikit-learn 1.0.1 Uninstalling scikit-learn-1.0.1: Successfully uninstalled scikit-learn-1.0.1 Attempting uninstall: graphviz Found existing installation: graphviz 0.10.1 Uninstalling graphviz-0.10.1: Successfully uninstalled graphviz-0.10.1 Attempting uninstall: distributed Found existing installation: distributed 1.25.3 Uninstalling distributed-1.25.3: Successfully uninstalled distributed-1.25.3 Attempting uninstall: dill Found existing installation: dill 0.3.4 Uninstalling dill-0.3.4: Successfully uninstalled dill-0.3.4 Attempting uninstall: xgboost Found existing installation: xgboost 0.90 Uninstalling xgboost-0.90: Successfully uninstalled xgboost-0.90 Attempting uninstall: lightgbm Found existing installation: lightgbm 2.2.3 Uninstalling lightgbm-2.2.3: Successfully uninstalled lightgbm-2.2.3 ERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts. multiprocess 0.70.12.2 requires dill&gt;=0.3.4, but you have dill 0.3.3 which is incompatible. gym 0.17.3 requires cloudpickle&lt;1.7.0,&gt;=1.2.0, but you have cloudpickle 2.0.0 which is incompatible. datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible. albumentations 0.1.12 requires imgaug&lt;0.2.7,&gt;=0.2.5, but you have imgaug 0.2.9 which is incompatible. Successfully installed ConfigSpace-0.4.18 autogluon.core-0.1.1b20210312 autogluon.features-0.1.1b20210312 autogluon.tabular-0.1.1b20210312 bcrypt-3.2.0 boto3-1.20.14 botocore-1.23.14 catboost-0.24.4 cloudpickle-2.0.0 cryptography-36.0.0 dask-2021.11.2 dill-0.3.3 distributed-2021.11.2 fsspec-2021.11.1 graphviz-0.8.4 jmespath-0.10.0 lightgbm-3.3.1 locket-0.2.1 paramiko-2.8.0 partd-1.2.0 pynacl-1.4.0 s3transfer-0.5.0 scikit-learn-0.24.2 scipy-1.5.4 urllib3-1.25.11 xgboost-1.3.3 . from autogluon.tabular import TabularDataset, TabularPredictor from autogluon.tabular.models.knn.knn_rapids_model import KNNRapidsModel from autogluon.tabular.models.lr.lr_rapids_model import LinearRapidsModel path = &#39;/content/drive/MyDrive/otto_group/&#39; train = TabularDataset(path + &#39;train.csv&#39;) test = TabularDataset(path + &#39;test.csv&#39;) label = &#39;target&#39; . Loaded data from: /content/drive/MyDrive/otto_group/train.csv | Columns = 95 / 95 | Rows = 61878 -&gt; 61878 Loaded data from: /content/drive/MyDrive/otto_group/test.csv | Columns = 94 / 94 | Rows = 144368 -&gt; 144368 . !pip install cuml . Collecting cuml Downloading cuml-0.6.1.post1.tar.gz (1.1 kB) Building wheels for collected packages: cuml Building wheel for cuml (setup.py) ... error ERROR: Failed building wheel for cuml Running setup.py clean for cuml Failed to build cuml Installing collected packages: cuml Running setup.py install for cuml ... error ERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c &#39;import io, os, sys, setuptools, tokenize; sys.argv[0] = &#39;&#34;&#39;&#34;&#39;/tmp/pip-install-d9q8bg1e/cuml_e5625faa4a144d1cb1dbda39971d1a35/setup.py&#39;&#34;&#39;&#34;&#39;; __file__=&#39;&#34;&#39;&#34;&#39;/tmp/pip-install-d9q8bg1e/cuml_e5625faa4a144d1cb1dbda39971d1a35/setup.py&#39;&#34;&#39;&#34;&#39;;f = getattr(tokenize, &#39;&#34;&#39;&#34;&#39;open&#39;&#34;&#39;&#34;&#39;, open)(__file__) if os.path.exists(__file__) else io.StringIO(&#39;&#34;&#39;&#34;&#39;from setuptools import setup; setup()&#39;&#34;&#39;&#34;&#39;);code = f.read().replace(&#39;&#34;&#39;&#34;&#39; r n&#39;&#34;&#39;&#34;&#39;, &#39;&#34;&#39;&#34;&#39; n&#39;&#34;&#39;&#34;&#39;);f.close();exec(compile(code, __file__, &#39;&#34;&#39;&#34;&#39;exec&#39;&#34;&#39;&#34;&#39;))&#39; install --record /tmp/pip-record-yfs4_fyl/install-record.txt --single-version-externally-managed --compile --install-headers /usr/local/include/python3.7/cuml Check the logs for full command output. . predictor = TabularPredictor( label=label, eval_metric=&#39;log_loss&#39;, learner_kwargs={&#39;ignored_columns&#39;: [&#39;id&#39;]} ).fit( train, presets=&#39;best_quality&#39;, hyperparameters={ KNNRapidsModel: {}, LinearRapidsModel: {}, &#39;RF&#39;: {}, &#39;XGB&#39;: {&#39;ag_args_fit&#39;: {&#39;num_gpus&#39;: 1}}, &#39;CAT&#39;: {&#39;ag_args_fit&#39;: {&#39;num_gpus&#39;: 1}}, &#39;GBM&#39;: [{}, {&#39;extra_trees&#39;: True, &#39;ag_args&#39;: {&#39;name_suffix&#39;: &#39;XT&#39;}}, &#39;GBMLarge&#39;], &#39;NN&#39;: {&#39;ag_args_fit&#39;: {&#39;num_gpus&#39;: 1}}, &#39;FASTAI&#39;: {&#39;ag_args_fit&#39;: {&#39;num_gpus&#39;: 1}}, }, ) . No path specified. Models will be saved in: &#34;AutogluonModels/ag-20211127_122603/&#34; Presets specified: [&#39;best_quality&#39;] Beginning AutoGluon training ... AutoGluon will save models to &#34;AutogluonModels/ag-20211127_122603/&#34; AutoGluon Version: 0.1.1b20210312 Train Data Rows: 61878 Train Data Columns: 94 Preprocessing data ... AutoGluon infers your prediction problem is: &#39;multiclass&#39; (because dtype of label-column == object). 9 unique label values: [&#39;Class_1&#39;, &#39;Class_2&#39;, &#39;Class_3&#39;, &#39;Class_4&#39;, &#39;Class_5&#39;, &#39;Class_6&#39;, &#39;Class_7&#39;, &#39;Class_8&#39;, &#39;Class_9&#39;] If &#39;multiclass&#39; is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: [&#39;binary&#39;, &#39;multiclass&#39;, &#39;regression&#39;]) Train Data Class Count: 9 Using Feature Generators to preprocess the data ... Dropping user-specified ignored columns: [&#39;id&#39;] Fitting AutoMLPipelineFeatureGenerator... Available Memory: 12407.99 MB Train Data (Original) Memory Usage: 46.04 MB (0.4% of available memory) Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features. Stage 1 Generators: Fitting AsTypeFeatureGenerator... Stage 2 Generators: Fitting FillNaFeatureGenerator... Stage 3 Generators: Fitting IdentityFeatureGenerator... Stage 4 Generators: Fitting DropUniqueFeatureGenerator... Types of features in original data (raw dtype, special dtypes): (&#39;int&#39;, []) : 93 | [&#39;feat_1&#39;, &#39;feat_2&#39;, &#39;feat_3&#39;, &#39;feat_4&#39;, &#39;feat_5&#39;, ...] Types of features in processed data (raw dtype, special dtypes): (&#39;int&#39;, []) : 93 | [&#39;feat_1&#39;, &#39;feat_2&#39;, &#39;feat_3&#39;, &#39;feat_4&#39;, &#39;feat_5&#39;, ...] 0.5s = Fit runtime 93 features in original data used to generate 93 features in processed data. Train Data (Processed) Memory Usage: 46.04 MB (0.4% of available memory) Data preprocessing and feature engineering runtime = 0.7s ... AutoGluon will gauge predictive performance using evaluation metric: &#39;log_loss&#39; This metric expects predicted probabilities rather than predicted class labels, so you&#39;ll need to use predict_proba() instead of predict() To change this, specify the eval_metric argument of fit() Custom Model Type Detected: &lt;class &#39;autogluon.tabular.models.knn.knn_rapids_model.KNNRapidsModel&#39;&gt; Custom Model Type Detected: &lt;class &#39;autogluon.tabular.models.lr.lr_rapids_model.LinearRapidsModel&#39;&gt; . ModuleNotFoundError Traceback (most recent call last) /usr/local/lib/python3.7/dist-packages/autogluon/core/utils/try_import.py in try_import_rapids_cuml() 162 try: --&gt; 163 import cuml 164 except ImportError: ModuleNotFoundError: No module named &#39;cuml&#39; During handling of the above exception, another exception occurred: ImportError Traceback (most recent call last) &lt;ipython-input-12-488de9012a7d&gt; in &lt;module&gt;() 14 &#39;GBM&#39;: [{}, {&#39;extra_trees&#39;: True, &#39;ag_args&#39;: {&#39;name_suffix&#39;: &#39;XT&#39;}}, &#39;GBMLarge&#39;], 15 &#39;NN&#39;: {&#39;ag_args_fit&#39;: {&#39;num_gpus&#39;: 1}}, &gt; 16 &#39;FASTAI&#39;: {&#39;ag_args_fit&#39;: {&#39;num_gpus&#39;: 1}}, 17 }, 18 ) /usr/local/lib/python3.7/dist-packages/autogluon/core/utils/decorators.py in _call(*args, **kwargs) 27 def _call(*args, **kwargs): 28 gargs, gkwargs = g(*other_args, *args, **kwargs) &gt; 29 return f(*gargs, **gkwargs) 30 return _call 31 return _unpack_inner /usr/local/lib/python3.7/dist-packages/autogluon/tabular/predictor/predictor.py in fit(self, train_data, tuning_data, time_limit, presets, hyperparameters, feature_metadata, **kwargs) 689 self._learner.fit(X=train_data, X_val=tuning_data, X_unlabeled=unlabeled_data, 690 holdout_frac=holdout_frac, num_bag_folds=num_bag_folds, num_bag_sets=num_bag_sets, num_stack_levels=num_stack_levels, --&gt; 691 hyperparameters=hyperparameters, core_kwargs=core_kwargs, time_limit=time_limit, verbosity=verbosity) 692 self._set_post_fit_vars() 693 /usr/local/lib/python3.7/dist-packages/autogluon/tabular/learner/abstract_learner.py in fit(self, X, X_val, **kwargs) 124 raise AssertionError(&#39;Learner is already fit.&#39;) 125 self._validate_fit_input(X=X, X_val=X_val, **kwargs) --&gt; 126 return self._fit(X=X, X_val=X_val, **kwargs) 127 128 def _fit(self, X: DataFrame, X_val: DataFrame = None, scheduler_options=None, hyperparameter_tune=False, /usr/local/lib/python3.7/dist-packages/autogluon/tabular/learner/default_learner.py in _fit(self, X, X_val, X_unlabeled, holdout_frac, num_bag_folds, num_bag_sets, time_limit, verbosity, **trainer_fit_kwargs) 93 94 self.save() &gt; 95 trainer.fit(X, y, X_val=X_val, y_val=y_val, X_unlabeled=X_unlabeled, holdout_frac=holdout_frac, time_limit=time_limit_trainer, **trainer_fit_kwargs) 96 self.save_trainer(trainer=trainer) 97 time_end = time.time() /usr/local/lib/python3.7/dist-packages/autogluon/tabular/trainer/auto_trainer.py in fit(self, X, y, hyperparameters, X_val, y_val, X_unlabeled, feature_prune, holdout_frac, num_stack_levels, core_kwargs, time_limit, **kwargs) 50 self._train_multi_and_ensemble(X, y, X_val, y_val, X_unlabeled=X_unlabeled, hyperparameters=hyperparameters, 51 feature_prune=feature_prune, &gt; 52 num_stack_levels=num_stack_levels, time_limit=time_limit, core_kwargs=core_kwargs) 53 54 def get_models_distillation(self, hyperparameters, **kwargs): /usr/local/lib/python3.7/dist-packages/autogluon/tabular/trainer/abstract_trainer.py in _train_multi_and_ensemble(self, X, y, X_val, y_val, hyperparameters, X_unlabeled, num_stack_levels, time_limit, **kwargs) 1290 self._num_cols_train = len(list(X.columns)) 1291 model_names_fit = self.train_multi_levels(X, y, hyperparameters=hyperparameters, X_val=X_val, y_val=y_val, -&gt; 1292 X_unlabeled=X_unlabeled, level_start=1, level_end=num_stack_levels+1, time_limit=time_limit, **kwargs) 1293 if len(self.get_model_names()) == 0: 1294 raise ValueError(&#39;AutoGluon did not successfully train any models&#39;) /usr/local/lib/python3.7/dist-packages/autogluon/tabular/trainer/abstract_trainer.py in train_multi_levels(self, X, y, hyperparameters, X_val, y_val, X_unlabeled, base_model_names, feature_prune, core_kwargs, aux_kwargs, level_start, level_end, time_limit, name_suffix, relative_stack) 259 models=hyperparameters, level=level, base_model_names=base_model_names, 260 feature_prune=feature_prune, --&gt; 261 core_kwargs=core_kwargs_level, aux_kwargs=aux_kwargs_level, name_suffix=name_suffix, 262 ) 263 model_names_fit += base_model_names + aux_models /usr/local/lib/python3.7/dist-packages/autogluon/tabular/trainer/abstract_trainer.py in stack_new_level(self, X, y, models, X_val, y_val, X_unlabeled, level, base_model_names, feature_prune, core_kwargs, aux_kwargs, name_suffix) 285 aux_kwargs[&#39;name_suffix&#39;] = aux_kwargs.get(&#39;name_suffix&#39;, &#39;&#39;) + name_suffix 286 core_models = self.stack_new_level_core(X=X, y=y, X_val=X_val, y_val=y_val, X_unlabeled=X_unlabeled, models=models, --&gt; 287 level=level, base_model_names=base_model_names, feature_prune=feature_prune, **core_kwargs) 288 289 if self.bagged_mode: /usr/local/lib/python3.7/dist-packages/autogluon/tabular/trainer/abstract_trainer.py in stack_new_level_core(self, X, y, models, X_val, y_val, X_unlabeled, level, base_model_names, stack_name, ag_args, ag_args_fit, ag_args_ensemble, excluded_model_types, ensemble_type, name_suffix, get_models_func, **kwargs) 342 )) 343 --&gt; 344 models, model_args_fit = get_models_func(hyperparameters=models, **get_models_kwargs) 345 if model_args_fit: 346 hyperparameter_tune_kwargs = { /usr/local/lib/python3.7/dist-packages/autogluon/tabular/trainer/auto_trainer.py in get_models(self, hyperparameters, **kwargs) 26 return get_preset_models(path=path, problem_type=problem_type, eval_metric=eval_metric, 27 num_classes=num_classes, hyperparameters=hyperparameters, invalid_model_names=invalid_model_names, &gt; 28 feature_metadata=feature_metadata, silent=silent, **kwargs) 29 30 def fit(self, X, y, hyperparameters, X_val=None, y_val=None, X_unlabeled=None, feature_prune=False, holdout_frac=0.1, num_stack_levels=0, core_kwargs: dict = None, time_limit=None, **kwargs): /usr/local/lib/python3.7/dist-packages/autogluon/tabular/trainer/model_presets/presets.py in get_preset_models(path, problem_type, eval_metric, hyperparameters, feature_metadata, num_classes, level, ensemble_type, ensemble_kwargs, ag_args_fit, ag_args, ag_args_ensemble, name_suffix, default_priorities, invalid_model_names, excluded_model_types, hyperparameter_preprocess_func, hyperparameter_preprocess_kwargs, silent) 189 model = model_factory(model_cfg, path=path, problem_type=problem_type, eval_metric=eval_metric, 190 num_classes=num_classes, name_suffix=name_suffix, ensemble_type=ensemble_type, ensemble_kwargs=ensemble_kwargs, --&gt; 191 invalid_name_set=invalid_name_set, level=level, feature_metadata=feature_metadata) 192 invalid_name_set.add(model.name) 193 if &#39;hyperparameter_tune_kwargs&#39; in model_cfg[AG_ARGS]: /usr/local/lib/python3.7/dist-packages/autogluon/tabular/trainer/model_presets/presets.py in model_factory(model, path, problem_type, eval_metric, num_classes, name_suffix, ensemble_type, ensemble_kwargs, invalid_name_set, level, feature_metadata) 296 model_params.pop(AG_ARGS, None) 297 model_params.pop(AG_ARGS_ENSEMBLE, None) --&gt; 298 model_init = model_type(path=path, name=name, problem_type=problem_type, eval_metric=eval_metric, num_classes=num_classes, hyperparameters=model_params, feature_metadata=feature_metadata) 299 300 if ensemble_kwargs is not None: /usr/local/lib/python3.7/dist-packages/autogluon/tabular/models/knn/knn_model.py in __init__(self, **kwargs) 25 def __init__(self, **kwargs): 26 super().__init__(**kwargs) &gt; 27 self._model_type = self._get_model_type() 28 29 def _get_model_type(self): /usr/local/lib/python3.7/dist-packages/autogluon/tabular/models/knn/knn_rapids_model.py in _get_model_type(self) 26 &#34;&#34;&#34; 27 def _get_model_type(self): &gt; 28 try_import_rapids_cuml() 29 from cuml.neighbors import KNeighborsClassifier, KNeighborsRegressor 30 if self.problem_type == REGRESSION: /usr/local/lib/python3.7/dist-packages/autogluon/core/utils/try_import.py in try_import_rapids_cuml() 163 import cuml 164 except ImportError: --&gt; 165 raise ImportError(&#34;`import cuml` failed. n&#34; 166 &#34;Ensure that you have a GPU and CUDA installation, and then install RAPIDS. n&#34; 167 &#34;You will likely need to create a fresh conda environment based off of a RAPIDS install, and then install AutoGluon on it. n&#34; ImportError: `import cuml` failed. Ensure that you have a GPU and CUDA installation, and then install RAPIDS. You will likely need to create a fresh conda environment based off of a RAPIDS install, and then install AutoGluon on it. RAPIDS is highly experimental within AutoGluon, and we recommend to only use RAPIDS if you are an advanced user / developer. Please refer to RAPIDS install instructions for more information: https://rapids.ai/start.html#get-rapids NOTE: If your import is failing due to a missing package, you can manually install dependencies using either !pip or !apt. To view examples of installing some common dependencies, click the &#34;Open Examples&#34; button below. . submission = test[[&#39;id&#39;]] test_pred_proba = predictor.predict_proba(test) submission = pd.concat([submission, test_pred_proba], axis=1) submission.to_csv(&#39;submission.csv&#39;, index=False) submission.head() . 오류가 지속적으로 나서 실행을 못했습니다. (autogluon 모델) . 자동으로 분석해주는 모델인것 같고 실제로 이 모델 점수 상위 1%를 기록했다고 합니다. . &#47784;&#45944; 3 . from patsy import dmatrices from sklearn.neural_network import MLPClassifier columns = train.columns[1:-1] X = train[columns] y = np.ravel(train[&#39;target&#39;]) model = MLPClassifier(solver=&#39;lbfgs&#39;, alpha=1e-5, hidden_layer_sizes = (30, 10), random_state = 0, verbose = True) model.fit(X, y) . MLPClassifier(alpha=1e-05, hidden_layer_sizes=(30, 10), random_state=0, solver=&#39;lbfgs&#39;, verbose=True) . pred = model.predict(X) print(model.score(X, y)) print(sum(pred == y) / len(y)) . 0.8057629529073338 0.8057629529073338 . Xtest = test[test.columns[1:]] test_prob = model.predict_proba(Xtest) solution = pd.DataFrame(test_prob, columns=[&#39;Class_1&#39;,&#39;Class_2&#39;,&#39;Class_3&#39;,&#39;Class_4&#39;,&#39;Class_5&#39;,&#39;Class_6&#39;,&#39;Class_7&#39;,&#39;Class_8&#39;,&#39;Class_9&#39;]) solution[&#39;id&#39;] = test[&#39;id&#39;] cols = solution.columns.tolist() cols = cols[-1:] + cols[:-1] solution = solution[cols] solution.to_csv(&#39;otto_prediction.csv&#39;, index = False) .",
            "url": "https://ksy1526.github.io/myblog//myblog/2021/11/27/kagglessu7.html",
            "relUrl": "/2021/11/27/kagglessu7.html",
            "date": " • Nov 27, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "SSUDA) 신용카드 사용자 연체 예측",
            "content": ". &#45936;&#51060;&#53552; &#48520;&#47084;&#50724;&#44592; . from google.colab import drive drive.mount(&#39;/content/drive&#39;) . Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(&#34;/content/drive&#34;, force_remount=True). . import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns pd.set_option(&#39;display.max_columns&#39;, 100) import warnings warnings.filterwarnings(&quot;ignore&quot;) from lightgbm import LGBMClassifier from sklearn.model_selection import StratifiedKFold from sklearn.preprocessing import OneHotEncoder import random train = pd.read_csv(&quot;/content/drive/MyDrive/carddata/train.csv&quot;) test = pd.read_csv(&#39;/content/drive/MyDrive/carddata/test.csv&#39;) sample_submission = pd.read_csv(&#39;/content/drive/MyDrive/carddata/sample_submission.csv&#39;) train.head() . index gender car reality child_num income_total income_type edu_type family_type house_type DAYS_BIRTH DAYS_EMPLOYED FLAG_MOBIL work_phone phone email occyp_type family_size begin_month credit . 0 0 | F | N | N | 0 | 202500.0 | Commercial associate | Higher education | Married | Municipal apartment | -13899 | -4709 | 1 | 0 | 0 | 0 | NaN | 2.0 | -6.0 | 1.0 | . 1 1 | F | N | Y | 1 | 247500.0 | Commercial associate | Secondary / secondary special | Civil marriage | House / apartment | -11380 | -1540 | 1 | 0 | 0 | 1 | Laborers | 3.0 | -5.0 | 1.0 | . 2 2 | M | Y | Y | 0 | 450000.0 | Working | Higher education | Married | House / apartment | -19087 | -4434 | 1 | 0 | 1 | 0 | Managers | 2.0 | -22.0 | 2.0 | . 3 3 | F | N | Y | 0 | 202500.0 | Commercial associate | Secondary / secondary special | Married | House / apartment | -15088 | -2092 | 1 | 0 | 1 | 0 | Sales staff | 2.0 | -37.0 | 0.0 | . 4 4 | F | Y | Y | 0 | 157500.0 | State servant | Higher education | Married | House / apartment | -15037 | -2105 | 1 | 0 | 0 | 0 | Managers | 2.0 | -26.0 | 2.0 | . &#44592;&#48376; &#48320;&#49688; &#49444;&#47749; . gender : 성별(F/M), car : 차량 소유 유무(Y/N), reality : 부동산 소유 유무(Y/N), child_num : 자녀 수 . income_total : 연간 소득, income_type : 소득 분류(5개로 분리), edu_type : 교육 수준(5개로 분리) . family_type : 결혼 여부(5개로 분리), house_type : 생활 방식(6개로 분리), DAYS_BIRTH : 출생일(수집일부터 음수로 계산) . DAYS_EMPLOYED : 업무 시작일(수집일부터 음수로 계산, 업무 안하는 사람은 365243 값 부여), FLAG_MOBIL : 핸드폰 소유 여부 . work_phone : 업무용 전화 소유 여부, phone : 가정용 전화 소유 여부, email : 이메일 소유 여부 . occyp_type : 직업 유형, family_size: 가족 규모, begin_month : 신용카드 발급 월(수집일로부터 음수 계산) . 반응변수 =&gt; credit : 사용자의 신용카드 대금 연체를 기준으로 한 신용도. 낮을수록 높은 신용임. . train.describe() . index child_num income_total DAYS_BIRTH DAYS_EMPLOYED FLAG_MOBIL work_phone phone email family_size begin_month credit . count 26457.000000 | 26457.000000 | 2.645700e+04 | 26457.000000 | 26457.000000 | 26457.0 | 26457.000000 | 26457.000000 | 26457.000000 | 26457.000000 | 26457.000000 | 26457.000000 | . mean 13228.000000 | 0.428658 | 1.873065e+05 | -15958.053899 | 59068.750728 | 1.0 | 0.224742 | 0.294251 | 0.091280 | 2.196848 | -26.123294 | 1.519560 | . std 7637.622372 | 0.747326 | 1.018784e+05 | 4201.589022 | 137475.427503 | 0.0 | 0.417420 | 0.455714 | 0.288013 | 0.916717 | 16.559550 | 0.702283 | . min 0.000000 | 0.000000 | 2.700000e+04 | -25152.000000 | -15713.000000 | 1.0 | 0.000000 | 0.000000 | 0.000000 | 1.000000 | -60.000000 | 0.000000 | . 25% 6614.000000 | 0.000000 | 1.215000e+05 | -19431.000000 | -3153.000000 | 1.0 | 0.000000 | 0.000000 | 0.000000 | 2.000000 | -39.000000 | 1.000000 | . 50% 13228.000000 | 0.000000 | 1.575000e+05 | -15547.000000 | -1539.000000 | 1.0 | 0.000000 | 0.000000 | 0.000000 | 2.000000 | -24.000000 | 2.000000 | . 75% 19842.000000 | 1.000000 | 2.250000e+05 | -12446.000000 | -407.000000 | 1.0 | 0.000000 | 1.000000 | 0.000000 | 3.000000 | -12.000000 | 2.000000 | . max 26456.000000 | 19.000000 | 1.575000e+06 | -7705.000000 | 365243.000000 | 1.0 | 1.000000 | 1.000000 | 1.000000 | 20.000000 | 0.000000 | 2.000000 | . train.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 26457 entries, 0 to 26456 Data columns (total 20 columns): # Column Non-Null Count Dtype -- -- 0 index 26457 non-null int64 1 gender 26457 non-null object 2 car 26457 non-null object 3 reality 26457 non-null object 4 child_num 26457 non-null int64 5 income_total 26457 non-null float64 6 income_type 26457 non-null object 7 edu_type 26457 non-null object 8 family_type 26457 non-null object 9 house_type 26457 non-null object 10 DAYS_BIRTH 26457 non-null int64 11 DAYS_EMPLOYED 26457 non-null int64 12 FLAG_MOBIL 26457 non-null int64 13 work_phone 26457 non-null int64 14 phone 26457 non-null int64 15 email 26457 non-null int64 16 occyp_type 18286 non-null object 17 family_size 26457 non-null float64 18 begin_month 26457 non-null float64 19 credit 26457 non-null float64 dtypes: float64(4), int64(8), object(8) memory usage: 4.0+ MB . 유일하게 occyp_type(직업유형) 변수가 null 값이 존재합니다. . NAN으로 채워넣겠습니다. . train.fillna(&#39;NAN&#39;, inplace=True) test.fillna(&#39;NAN&#39;, inplace=True) . plt.subplots(figsize = (8,8)) plt.pie(train[&#39;credit&#39;].value_counts(), labels = train[&#39;credit&#39;].value_counts().index, autopct=&quot;%.2f%%&quot;, shadow = True, startangle = 90) plt.title(&#39;credit ratio&#39;, size=20) plt.show() . matplotlib 패키지 내 pie 차트를 이용해 반응변수의 비율을 확인했습니다. . 신용등급이 떨어지는 2번의 비율이 상당히 크군요. . &#48276;&#51452;&#54805; &#48320;&#49688;&#47484; &#49888;&#50857;&#46321;&#44553;&#48324;&#47196; &#51900;&#44060;&#49436; &#44288;&#52272;&#54644;&#48372;&#44592; . train_0 = train[train[&#39;credit&#39;]==0.0] train_1 = train[train[&#39;credit&#39;]==1.0] train_2 = train[train[&#39;credit&#39;]==2.0] def cat_plot(column): f, ax = plt.subplots(1, 3, figsize=(16, 6)) sns.countplot(x = column, data = train_0, ax = ax[0], order = train_0[column].value_counts().index) ax[0].tick_params(labelsize=12) ax[0].set_title(&#39;credit = 0&#39;) ax[0].set_ylabel(&#39;count&#39;) ax[0].tick_params(rotation=50) sns.countplot(x = column, data = train_1, ax = ax[1], order = train_1[column].value_counts().index) ax[1].tick_params(labelsize=12) ax[1].set_title(&#39;credit = 1&#39;) ax[1].set_ylabel(&#39;count&#39;) ax[1].tick_params(rotation=50) sns.countplot(x = column, data = train_2, ax = ax[2], order = train_2[column].value_counts().index) ax[2].tick_params(labelsize=12) ax[2].set_title(&#39;credit = 2&#39;) ax[2].set_ylabel(&#39;count&#39;) ax[2].tick_params(rotation=50) plt.subplots_adjust(wspace=0.3, hspace=0.3) plt.show() cat_plot(&quot;gender&quot;) . train 데이터를 신용등급에 따라 분류한 뒤 설명변수와에 관계를 그래프로 보는 함수를 만들었습니다. . 성별에 대해서 살펴봤는데, 절대적으로 여성이 그냥 많은 것 같습니다. . 더불어 성별에 따른 신용등급 차이는 모두 비슷한 비율에 그래프인 것으로 보아 확인하기 힘듭니다. . cat_plot(&#39;car&#39;) . 우선 차량보유를 하지 않은 사람이 모든 비율에서 많습니다. . 다만 신용 등급과에 연관성은 그래프로 봤을땐 크게 없는 것 같네요. . cat_plot(&#39;reality&#39;) . 모든 신용 등급에서 부동산을 소유한 사람들이 많았습니다. . 딱히 신용 등급에 따른 차이가 존재하지 않는 것 같네요. . cat_plot(&#39;income_type&#39;) . 소득 종류 변수도 신용 등급 별로 차이가 두드러지진 않습니다. . 다만 학생은 신용등급 0에 없는 점이 눈에 띄네요. . cat_plot(&#39;edu_type&#39;) . 교육 수준 변수 또한 신용 등급별로 차이가 있어보이진 않네요. . cat_plot(&#39;family_type&#39;) . 가족 구성 변수에 따른 신용등급 변수도 차이가 없는 것 같아요. . 전반적으로 결혼한 사람이 많은 것이 눈에 띄네요. . cat_plot(&#39;house_type&#39;) . house_type 변수 또한 큰 의미가 없는 변수인 것 같습니다. 대부분 House / apartment 타입이기 때문에 의미가 더더욱 없습니다. . cat_plot(&#39;FLAG_MOBIL&#39;) . 여기에 나온 모든 사람은 스마트폰을 보유하고 있습니다. . cat_plot(&#39;work_phone&#39;) . 신용 등급 그룹 별 가정 전화 비율이 차이가 없습니다. 가정용 전화기 보유률이 떨어지는게 눈에 띄네요. . cat_plot(&#39;email&#39;) . 이메일 변수 또한 유의미하지 않아 보입니다. . f, ax = plt.subplots(1, 3, figsize=(16, 6)) sns.countplot(y = &#39;occyp_type&#39;, data = train_0, order = train_0[&#39;occyp_type&#39;].value_counts().index, ax=ax[0]) sns.countplot(y = &#39;occyp_type&#39;, data = train_1, order = train_1[&#39;occyp_type&#39;].value_counts().index, ax=ax[1]) sns.countplot(y = &#39;occyp_type&#39;, data = train_2, order = train_2[&#39;occyp_type&#39;].value_counts().index, ax=ax[2]) plt.subplots_adjust(wspace=0.5, hspace=0.3) plt.show() . 직업 유형 변수를 신용 등급별로 비교했습니다. . 전반적인 경향은 비슷하지만, 세세한 차이가 조금 있어보입니다. . &#50672;&#49549;&#54805; &#48320;&#49688;&#47484; &#49888;&#50857;&#46321;&#44553;&#48324;&#47196; &#51900;&#44060;&#49436; &#44288;&#52272;&#54644;&#48372;&#44592; . def num_plot(column): fig, axes = plt.subplots(1, 3, figsize=(16, 6)) sns.distplot(train_0[column], ax = axes[0]) axes[0].tick_params(labelsize=12) axes[0].set_title(&#39;credit = 0&#39;) axes[0].set_ylabel(&#39;count&#39;) sns.distplot(train_1[column], ax = axes[1]) axes[1].tick_params(labelsize=12) axes[1].set_title(&#39;credit = 1&#39;) axes[1].set_ylabel(&#39;count&#39;) sns.distplot(train_2[column], ax = axes[2]) axes[2].tick_params(labelsize=12) axes[2].set_title(&#39;credit = 2&#39;) axes[2].set_ylabel(&#39;count&#39;) plt.subplots_adjust(wspace=0.3, hspace=0.3) num_plot(&quot;child_num&quot;) . 자녀 수 변수입니다. 신용 등급별로 큰 차이는 없어보입니다. . 다만 신용등급 2에 자녀가 아주 많은 소수의 변수가 존재하는 걸 알 수 있습니다. . num_plot(&quot;family_size&quot;) . 가족 수 변수도 자식 수 변수와 마찬가지 결과를 보이는 것 같아요. . num_plot(&quot;income_total&quot;) . 신용등급에 따른 월간 소득 차이는 크게 없어 보입니다. (??) . sns.distplot(train_0[&#39;income_total&#39;],label=&#39;0.0&#39;, hist=False) sns.distplot(train_1[&#39;income_total&#39;],label=&#39;0.1&#39;, hist=False) sns.distplot(train_2[&#39;income_total&#39;],label=&#39;0.2&#39;, hist=False) plt.legend() . &lt;matplotlib.legend.Legend at 0x7f8be19fa9d0&gt; . 정확히 확인하기 위해 그래프를 겹첬는데요. 조금 차이는 있으나 많이 비슷한 것을 볼 수 있습니다. . num_plot(&quot;DAYS_BIRTH&quot;) . 숫자의 절대값이 작을 수록 젊은 사람 변수 입니다. 그래프가 전반적으로 비슷해 보입니다. . train_0[&#39;Month&#39;] = abs(train_0[&#39;begin_month&#39;]) train_1[&#39;Month&#39;] = abs(train_1[&#39;begin_month&#39;]) train_2[&#39;Month&#39;] = abs(train_2[&#39;begin_month&#39;]) train_0 = train_0.astype({&#39;Month&#39;: &#39;int&#39;}) train_1 = train_1.astype({&#39;Month&#39;: &#39;int&#39;}) train_2 = train_2.astype({&#39;Month&#39;: &#39;int&#39;}) train_0[&#39;Month&#39;].head() num_plot(&quot;Month&quot;) . 카드 생성일 변수를 양수로 바꿔서 분석했습니다. . 전반적으로 흐름은 비슷해보이는데, 카드 발급 초기에서 약 70프로 정도는 신용등급 1을, 약 30프로는 0을 부여하는 것 같습니다. . &#44036;&#45800;&#54620; &#47784;&#45944; &#51201;&#54633; . object_col = [] for col in train.columns: if train[col].dtype == &#39;object&#39;: object_col.append(col) enc = OneHotEncoder() enc.fit(train.loc[:,object_col]) train_onehot_df = pd.DataFrame(enc.transform(train.loc[:,object_col]).toarray(), columns=enc.get_feature_names(object_col)) train.drop(object_col, axis=1, inplace=True) train = pd.concat([train, train_onehot_df], axis=1) test_onehot_df = pd.DataFrame(enc.transform(test.loc[:,object_col]).toarray(), columns=enc.get_feature_names(object_col)) test.drop(object_col, axis=1, inplace=True) test = pd.concat([test, test_onehot_df], axis=1) . 범주형 변수는 모두 원-핫 인코딩을 해줍니다. . sample_submission . index 0 1 2 . 0 26457 | 0 | 0 | 0 | . 1 26458 | 0 | 0 | 0 | . 2 26459 | 0 | 0 | 0 | . 3 26460 | 0 | 0 | 0 | . 4 26461 | 0 | 0 | 0 | . ... ... | ... | ... | ... | . 9995 36452 | 0 | 0 | 0 | . 9996 36453 | 0 | 0 | 0 | . 9997 36454 | 0 | 0 | 0 | . 9998 36455 | 0 | 0 | 0 | . 9999 36456 | 0 | 0 | 0 | . 10000 rows × 4 columns . 이 대회는 0, 1, 2의 확률이 어떻게 되는지 예측하는 모델입니다. . skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42) folds=[] for train_idx, valid_idx in skf.split(train, train[&#39;credit&#39;]): folds.append((train_idx, valid_idx)) random.seed(42) lgb_models={} for fold in range(5): print(f&#39;===================================={fold+1}============================================&#39;) train_idx, valid_idx = folds[fold] X_train, X_valid, y_train, y_valid = train.drop([&#39;credit&#39;],axis=1).iloc[train_idx].values, train.drop([&#39;credit&#39;],axis=1).iloc[valid_idx].values, train[&#39;credit&#39;][train_idx].values, train[&#39;credit&#39;][valid_idx].values lgb = LGBMClassifier(n_estimators=1000) lgb.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_valid, y_valid)], early_stopping_rounds=30, verbose=100) lgb_models[fold]=lgb print(f&#39;================================================================================ n n&#39;) . ====================================1============================================ Training until validation scores don&#39;t improve for 30 rounds. [100] training&#39;s multi_logloss: 0.676692 valid_1&#39;s multi_logloss: 0.766702 [200] training&#39;s multi_logloss: 0.596634 valid_1&#39;s multi_logloss: 0.755074 [300] training&#39;s multi_logloss: 0.53456 valid_1&#39;s multi_logloss: 0.751863 [400] training&#39;s multi_logloss: 0.482683 valid_1&#39;s multi_logloss: 0.750901 Early stopping, best iteration is: [385] training&#39;s multi_logloss: 0.489523 valid_1&#39;s multi_logloss: 0.750597 ================================================================================ ====================================2============================================ Training until validation scores don&#39;t improve for 30 rounds. [100] training&#39;s multi_logloss: 0.673988 valid_1&#39;s multi_logloss: 0.778812 [200] training&#39;s multi_logloss: 0.593911 valid_1&#39;s multi_logloss: 0.766056 [300] training&#39;s multi_logloss: 0.532019 valid_1&#39;s multi_logloss: 0.762532 Early stopping, best iteration is: [358] training&#39;s multi_logloss: 0.500235 valid_1&#39;s multi_logloss: 0.761024 ================================================================================ ====================================3============================================ Training until validation scores don&#39;t improve for 30 rounds. [100] training&#39;s multi_logloss: 0.676709 valid_1&#39;s multi_logloss: 0.771762 [200] training&#39;s multi_logloss: 0.593522 valid_1&#39;s multi_logloss: 0.758924 Early stopping, best iteration is: [236] training&#39;s multi_logloss: 0.57026 valid_1&#39;s multi_logloss: 0.758105 ================================================================================ ====================================4============================================ Training until validation scores don&#39;t improve for 30 rounds. [100] training&#39;s multi_logloss: 0.675515 valid_1&#39;s multi_logloss: 0.7694 [200] training&#39;s multi_logloss: 0.597206 valid_1&#39;s multi_logloss: 0.758117 [300] training&#39;s multi_logloss: 0.533343 valid_1&#39;s multi_logloss: 0.753141 Early stopping, best iteration is: [308] training&#39;s multi_logloss: 0.528916 valid_1&#39;s multi_logloss: 0.752857 ================================================================================ ====================================5============================================ Training until validation scores don&#39;t improve for 30 rounds. [100] training&#39;s multi_logloss: 0.676696 valid_1&#39;s multi_logloss: 0.767947 [200] training&#39;s multi_logloss: 0.595696 valid_1&#39;s multi_logloss: 0.757343 [300] training&#39;s multi_logloss: 0.531936 valid_1&#39;s multi_logloss: 0.753206 Early stopping, best iteration is: [346] training&#39;s multi_logloss: 0.50629 valid_1&#39;s multi_logloss: 0.752064 ================================================================================ . sample_submission.iloc[:,1:]=0 for fold in range(5): sample_submission.iloc[:,1:] += lgb_models[fold].predict_proba(test)/5 sample_submission.to_csv(&#39;ssu6_submission.csv&#39;, index=False) sample_submission.head() . index 0 1 2 . 0 26457 | 0.018329 | 0.187203 | 0.794468 | . 1 26458 | 0.061934 | 0.121026 | 0.817041 | . 2 26459 | 0.027629 | 0.203945 | 0.768427 | . 3 26460 | 0.067723 | 0.199497 | 0.732780 | . 4 26461 | 0.079370 | 0.229451 | 0.691179 | .",
            "url": "https://ksy1526.github.io/myblog//myblog/2021/11/14/kagglessu6.html",
            "relUrl": "/2021/11/14/kagglessu6.html",
            "date": " • Nov 14, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "SSUDA) 따릉이 데이터 예측 코드",
            "content": ". &#45936;&#51060;&#53552; &#48520;&#47084;&#50724;&#44592; . from google.colab import drive drive.mount(&#39;/content/drive&#39;) . Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(&#34;/content/drive&#34;, force_remount=True). . import pandas as pd import numpy as np import warnings warnings.filterwarnings(&quot;ignore&quot;) train = pd.read_csv(&quot;/content/drive/MyDrive/bicycle/train.csv&quot;) test = pd.read_csv(&#39;/content/drive/MyDrive/bicycle/test.csv&#39;) sample_submission = pd.read_csv(&#39;/content/drive/MyDrive/bicycle/sample_submission.csv&#39;) train.head() . date_time wind_direction sky_condition precipitation_form wind_speed humidity low_temp high_temp Precipitation_Probability number_of_rentals . 0 2018-04-01 | 207.500 | 4.000 | 0.000 | 3.050 | 75.000 | 12.600 | 21.000 | 30.000 | 22994 | . 1 2018-04-02 | 208.317 | 2.950 | 0.000 | 3.278 | 69.833 | 12.812 | 19.000 | 19.500 | 28139 | . 2 2018-04-03 | 213.516 | 2.911 | 0.000 | 2.690 | 74.879 | 10.312 | 15.316 | 19.113 | 26817 | . 3 2018-04-04 | 143.836 | 3.692 | 0.425 | 3.138 | 71.849 | 8.312 | 12.368 | 43.493 | 26034 | . 4 2018-04-05 | 95.905 | 4.000 | 0.723 | 3.186 | 73.784 | 5.875 | 10.421 | 63.378 | 2833 | . &#48320;&#49688; &#53456;&#49353; . train.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 273 entries, 0 to 272 Data columns (total 10 columns): # Column Non-Null Count Dtype -- -- 0 date_time 273 non-null object 1 wind_direction 273 non-null float64 2 sky_condition 273 non-null float64 3 precipitation_form 273 non-null float64 4 wind_speed 273 non-null float64 5 humidity 273 non-null float64 6 low_temp 273 non-null float64 7 high_temp 273 non-null float64 8 Precipitation_Probability 273 non-null float64 9 number_of_rentals 273 non-null int64 dtypes: float64(8), int64(1), object(1) memory usage: 21.5+ KB . number_of_rentals : 따릉이 대여량(Y값), date_time : 날짜, wind_direction : 풍향 . sky_condition : 하늘 상태(1 : 맑음, 3 : 구름 많음, 4 : 흐림, 하루에 8번 측정한 값 평균) . precipitation_form : 강수 형태(0 : 맑음, 1 : 비, 마찬가지로 하루에 8번 측정한 값 평균) . wind_speed : 풍속, humidity : 습도, low_temp : 최저기온, high_temp : 최고기온, precipitation_Probability : 강수확률 . 결측값은 없습니다. . import matplotlib.pyplot as plt plt.figure(figsize=(8,6)) plt.scatter(range(train.shape[0]), np.sort(train[&#39;number_of_rentals&#39;].values)) plt.show() . 반응변수의 이상치은 관찰되지 않는 것으로 보입니다. . train[&#39;date_time&#39;] = pd.to_datetime(train[&#39;date_time&#39;]) test[&#39;date_time&#39;] = pd.to_datetime(test[&#39;date_time&#39;]) train[&#39;day&#39;]=pd.DatetimeIndex(train[&#39;date_time&#39;]).day test[&#39;day&#39;]=pd.DatetimeIndex(test[&#39;date_time&#39;]).day train[&#39;month&#39;]=pd.DatetimeIndex(train[&#39;date_time&#39;]).month test[&#39;month&#39;]=pd.DatetimeIndex(test[&#39;date_time&#39;]).month train[&#39;year&#39;]=pd.DatetimeIndex(train[&#39;date_time&#39;]).year test[&#39;year&#39;]=pd.DatetimeIndex(test[&#39;date_time&#39;]).year train[&#39;weekday&#39;]=pd.DatetimeIndex(train[&#39;date_time&#39;]).weekday test[&#39;weekday&#39;]=pd.DatetimeIndex(test[&#39;date_time&#39;]).weekday . date_time이 날짜 변수이기 때문에 데이터 형식을 datetime으로 바꾸어줍니다. . 그 후 datetime 데이터 형식으로 얻을 수 있는 이점, 날/달/연/주말 변수를 추출합니다. . train[&#39;wind_direction&#39;].hist() train[&#39;wind_direction&#39;].max() . 321.622 . wind_direction은 바람 방향 변수입니다. 아마 방향을 360도로 생각해서 만든 변수인 것 같습니다. . 다만 바람 방향과 따릉이 대여량은 상관 없을 것 같습니다. . 물론, 서울 자전거 도로가 한강 기준으로 많이 구성되어 있어 도로가 동-서 기준으로 많이 있긴 합니다. . 하지만 바람 방향이 오늘은 이쪽이니 자전거를 타자라는 생각을 하진 않을 것 같습니다. 바람 세기가 더 중요하죠. . 또 바람 방향 변수는 하루에도 계속 바뀌기 때문에 평균적인 방향인 것 같은데, 만약 바람이 주로 0에서 20, 340에서 360 각도로 불었을때 평균치는 약 180입니다. . (방향이 동쪽에서 위 아래로만 움직인다면 10에서 350으로 쉽게 바뀔 수 있습니다.) . 이 수치가 과연 유의미할지 개인적으로 의문이 들어서, 이 변수는 빼는 것이 좋아보입니다. . train[&#39;precipitation_form&#39;].corr(train[&#39;Precipitation_Probability&#39;]) . 0.9106089542607185 . train[&#39;precipitation_form&#39;].corr(train[&#39;sky_condition&#39;]) . 0.6738137525457335 . 비가 오는 상황을 예측하는 두 변수 precipitation_form와 Precipitation_Probability간 상관관계는 당연히 높습니다. . 다만 Precipitation_Probability는 강우 확률 예측 변수 입니다. . 때문에 일일 강우 단기예측 기록인 precipitation_form 변수가 하루 비가 오는 날을 더 잘 표현할 것으로 생각됩니다. . 비슷한 부분을 설명하는 두 변수이기 때문에 precipitation_form 변수만 사용하겠습니다. . precipitation_form 변수는 하늘 상태를 나타내는 sky_condition 변수와도 상관관계가 높지만 극단적이진 않습니다. . 날씨가 흐린것 자체가 따릉이 대여량에 부정적인 영향을 준다고 생각하기 때문에 sky_condition 변수는 사용하겠습니다. . import matplotlib.pyplot as plt plt.figure(figsize=(20, 10)) plt.bar(train[&#39;date_time&#39;][train[&#39;year&#39;] == 2018], train[&#39;number_of_rentals&#39;][train[&#39;year&#39;] == 2018], width=0.6, color=&#39;grey&#39;) . &lt;BarContainer object of 91 artists&gt; . train[&#39;day&#39;][train[&#39;month&#39;] == 5] += 30 train[&#39;day&#39;][train[&#39;month&#39;] == 6] += 61 test[&#39;day&#39;][test[&#39;month&#39;] == 5] += 30 test[&#39;day&#39;][test[&#39;month&#39;] == 6] += 61 . 따릉이 대여량을 2018년 기준으로 날짜순으로 확인했습니다. . 4~6월 데이터인 만큼, 날이 점점 따뜻해지는 영향으로 변동이 심하긴 하지만 증가하는 추세가 보이는 것 같습니다. . (중간중간 값이 급격히 작아지는 것은 아마 비가 오는날인거 같습니다.) . 그래서 날짜 변수를 쓰는것 보다, 누적된 날짜가 몇일인지를 기록하는 변수를 쓰는게 좋을 것 같습니다. . (4월 15일 =&gt; 15일, 5월 2일 =&gt; 30일 + 2일 = 32일, 6월 10일 =&gt; 30일 + 31일 + 10일 = 71일) . 이렇게 되면 달 변수 또한 쓰지 않는게 좋을 것 같습니다. 만든 변수가 달 변수가 설명할 부분까지 설명하기 때문이죠. . import seaborn as sns def barplots(variable): plot = train.groupby(variable)[&#39;number_of_rentals&#39;].mean() sns.barplot(plot.index,plot.values) barplots(&#39;year&#39;) . 연도별 따릉이 이용자수를 나타내는 그래프 입니다. . 시간이 지날수록 따릉이 이용자수가 늘어나는 것을 확인할 수 있습니다. 그러므로 연도 변수는 매우 중요한 변수임을 알 수 있겠죠. . barplots(&#39;weekday&#39;) . 요일별 따릉이 이용자수를 나타내는 그래프 입니다. weekday 변수는 0은 월요일, 6은 일요일을 나타내는 요일 변수입니다. . 직관적으로 확인했을때 일요일에 따릉이 이용자수가 유의미하게 적은 것이 눈에 띕니다. . train_label = train[&#39;number_of_rentals&#39;] train.drop([&#39;date_time&#39;,&#39;wind_direction&#39;, &#39;Precipitation_Probability&#39;, &#39;month&#39;, &#39;number_of_rentals&#39;], axis = 1, inplace= True) test.drop([&#39;date_time&#39;,&#39;wind_direction&#39;, &#39;Precipitation_Probability&#39;, &#39;month&#39;], axis = 1, inplace= True) . 앞서 설명한 변수들을 제거합니다. . &#47784;&#45944; &#51201;&#54633; . from sklearn.ensemble import RandomForestRegressor rf = RandomForestRegressor(random_state = 0, n_estimators = 100) rf.fit(train,train_label) sample_submission[&#39;number_of_rentals&#39;] = rf.predict(test) sample_submission.to_csv(&#39;bicycle_final_4.csv&#39;,encoding=&#39;UTF-8&#39;,index=False) . from xgboost import XGBRegressor xgb = XGBRegressor() xgb.fit(train,train_label) sample_submission[&#39;number_of_rentals&#39;] = xgb.predict(test) sample_submission.to_csv(&#39;bicycle_final_7.csv&#39;,encoding=&#39;UTF-8&#39;,index=False) . [11:30:53] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror. . 간단한 랜덤 포레스트 모델을 사용했습니다. 다른 모델을 사용하거나 하이퍼 파라미터를 조정하면 점수가 더 오를수도 있겠죠? .",
            "url": "https://ksy1526.github.io/myblog//myblog/2021/11/04/kagglessu5_plus.html",
            "relUrl": "/2021/11/04/kagglessu5_plus.html",
            "date": " • Nov 4, 2021"
        }
        
    
  
    
        ,"post6": {
            "title": "SSUDA) 판매량 예측 데이터 분석",
            "content": ". &#52880;&#44544;&#44284; &#50672;&#46041;&#54616;&#44592; . !pip install kaggle from google.colab import files files.upload() . Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12) Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.5.30) Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.62.3) Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0) Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3) Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2) Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2) Requirement already satisfied: six&gt;=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0) Requirement already satisfied: text-unidecode&gt;=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify-&gt;kaggle) (1.3) Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;kaggle) (3.0.4) Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;kaggle) (2.10) . Upload widget is only available when the cell has been executed in the current browser session. Please rerun this cell to enable. Saving kaggle.json to kaggle.json . {&#39;kaggle.json&#39;: b&#39;{&#34;username&#34;:&#34;ksy1998&#34;,&#34;key&#34;:&#34;23e68db36970b65937516103c630ba75&#34;}&#39;} . !mkdir -p ~/.kaggle !cp kaggle.json ~/.kaggle/ !chmod 600 ~/.kaggle/kaggle.json . !kaggle competitions download -c competitive-data-science-predict-future-sales . Warning: Looks like you&#39;re using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4) Downloading sample_submission.csv.zip to /content 0% 0.00/468k [00:00&lt;?, ?B/s] 100% 468k/468k [00:00&lt;00:00, 69.0MB/s] Downloading sales_train.csv.zip to /content 38% 5.00M/13.3M [00:00&lt;00:01, 5.79MB/s] 100% 13.3M/13.3M [00:00&lt;00:00, 14.4MB/s] Downloading item_categories.csv to /content 0% 0.00/3.49k [00:00&lt;?, ?B/s] 100% 3.49k/3.49k [00:00&lt;00:00, 2.51MB/s] Downloading shops.csv to /content 0% 0.00/2.91k [00:00&lt;?, ?B/s] 100% 2.91k/2.91k [00:00&lt;00:00, 10.6MB/s] Downloading test.csv.zip to /content 0% 0.00/1.02M [00:00&lt;?, ?B/s] 100% 1.02M/1.02M [00:00&lt;00:00, 156MB/s] Downloading items.csv.zip to /content 0% 0.00/368k [00:00&lt;?, ?B/s] 100% 368k/368k [00:00&lt;00:00, 117MB/s] . !unzip items.csv.zip !unzip sales_train.csv.zip !unzip sample_submission.csv.zip !unzip test.csv.zip . Archive: items.csv.zip inflating: items.csv Archive: sales_train.csv.zip inflating: sales_train.csv Archive: sample_submission.csv.zip inflating: sample_submission.csv Archive: test.csv.zip inflating: test.csv . &#45936;&#51060;&#53552; &#48520;&#47084;&#50724;&#44592; . import numpy as np # linear algebra import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv) from matplotlib import pylab as plt import matplotlib.dates as mdates plt.rcParams[&#39;figure.figsize&#39;] = (15.0, 8.0) import seaborn as sns . train = pd.read_csv(&#39;./sales_train.csv&#39;) print (&#39;number of shops: &#39;, train[&#39;shop_id&#39;].max()) print (&#39;number of items: &#39;, train[&#39;item_id&#39;].max()) num_month = train[&#39;date_block_num&#39;].max() print (&#39;number of month: &#39;, num_month) print (&#39;size of train: &#39;, train.shape) train.head() . number of shops: 59 number of items: 22169 number of month: 33 size of train: (2935849, 6) . date date_block_num shop_id item_id item_price item_cnt_day . 0 02.01.2013 | 0 | 59 | 22154 | 999.00 | 1.0 | . 1 03.01.2013 | 0 | 25 | 2552 | 899.00 | 1.0 | . 2 05.01.2013 | 0 | 25 | 2552 | 899.00 | -1.0 | . 3 06.01.2013 | 0 | 25 | 2554 | 1709.05 | 1.0 | . 4 15.01.2013 | 0 | 25 | 2555 | 1099.00 | 1.0 | . 변수 설명 . date : 날짜 변수, date_block_num : 달 변수(2013년 1월 =&gt; 0, 2015년 10월 =&gt; 33) . shop_id, item_id : 상점/제품의 고유번호 변수 . item_price : 제품의 가격 변수, item_cnt_dat : 그 날 제품이 팔린 개수 . (여기서 item_cnt_dat 변수가 음수인 것은 물건이 반품된 것을 의미하는 것 같습니다.) . test = pd.read_csv(&#39;./test.csv&#39;) test.head() . ID shop_id item_id . 0 0 | 5 | 5037 | . 1 1 | 5 | 5320 | . 2 2 | 5 | 5233 | . 3 3 | 5 | 5232 | . 4 4 | 5 | 5268 | . sub = pd.read_csv(&#39;./sample_submission.csv&#39;) sub.head() . ID item_cnt_month . 0 0 | 0.5 | . 1 1 | 0.5 | . 2 2 | 0.5 | . 3 3 | 0.5 | . 4 4 | 0.5 | . 2015년 11월 데이터를 예측하는 캐글 대회입니다. . date_block_num 변수는 34가 되겠죠. . items = pd.read_csv(&#39;./items.csv&#39;) print (&#39;number of categories: &#39;, items[&#39;item_category_id&#39;].max()) # the maximun number of category id items.head() . number of categories: 83 . item_name item_id item_category_id . 0 ! ВО ВЛАСТИ НАВАЖДЕНИЯ (ПЛАСТ.) D | 0 | 40 | . 1 !ABBYY FineReader 12 Professional Edition Full... | 1 | 76 | . 2 ***В ЛУЧАХ СЛАВЫ (UNV) D | 2 | 40 | . 3 ***ГОЛУБАЯ ВОЛНА (Univ) D | 3 | 40 | . 4 ***КОРОБКА (СТЕКЛО) D | 4 | 40 | . train_clean = train.drop(labels = [&#39;date&#39;, &#39;item_price&#39;], axis = 1) train_clean.head() . date_block_num shop_id item_id item_cnt_day . 0 0 | 59 | 22154 | 1.0 | . 1 0 | 25 | 2552 | 1.0 | . 2 0 | 25 | 2552 | -1.0 | . 3 0 | 25 | 2554 | 1.0 | . 4 0 | 25 | 2555 | 1.0 | . 날짜는 대체하는 date_block_num 변수가 있기 때문에 빼줍니다. . 또 제품 가격 변수 또한 빼줍니다. . train_clean = train_clean.groupby([&quot;item_id&quot;,&quot;shop_id&quot;,&quot;date_block_num&quot;]).sum().reset_index() train_clean = train_clean.rename(index=str, columns = {&quot;item_cnt_day&quot;:&quot;item_cnt_month&quot;}) train_clean = train_clean[[&quot;item_id&quot;,&quot;shop_id&quot;,&quot;date_block_num&quot;,&quot;item_cnt_month&quot;]] train_clean . item_id shop_id date_block_num item_cnt_month . 0 0 | 54 | 20 | 1.0 | . 1 1 | 55 | 15 | 2.0 | . 2 1 | 55 | 18 | 1.0 | . 3 1 | 55 | 19 | 1.0 | . 4 1 | 55 | 20 | 1.0 | . ... ... | ... | ... | ... | . 1609119 22168 | 12 | 8 | 1.0 | . 1609120 22168 | 16 | 1 | 1.0 | . 1609121 22168 | 42 | 1 | 1.0 | . 1609122 22168 | 43 | 2 | 1.0 | . 1609123 22169 | 25 | 14 | 1.0 | . 1609124 rows × 4 columns . 같은 달별로(= date_block_num 변수가 같은 값으로) 묶어줍니다. . 테스트 데이터에서 예측하고자 하는 값의 범위가 달 단위이기 때문입니다. . 변수 이름 또한 그에 맞게 item_cnt_month로 바꿨습니다. . &#49884;&#44228;&#50676; &#45936;&#51060;&#53552; &#50672;&#49845;&#54616;&#44592; . check = train_clean[[&quot;shop_id&quot;,&quot;item_id&quot;,&quot;date_block_num&quot;,&quot;item_cnt_month&quot;]] check = check.loc[check[&#39;shop_id&#39;] == 5] check = check.loc[check[&#39;item_id&#39;] == 5037] check . shop_id item_id date_block_num item_cnt_month . 400439 5 | 5037 | 20 | 1.0 | . 400440 5 | 5037 | 22 | 1.0 | . 400441 5 | 5037 | 23 | 2.0 | . 400442 5 | 5037 | 24 | 2.0 | . 400443 5 | 5037 | 28 | 1.0 | . 400444 5 | 5037 | 29 | 1.0 | . 400445 5 | 5037 | 30 | 1.0 | . 400446 5 | 5037 | 31 | 3.0 | . 400447 5 | 5037 | 32 | 1.0 | . 특정 shop_id와 item_id 값을 가지는 값만 모았습니다. . 시계열 분석을 처음하기 때문에 1차로 소량의 데이터를 다루었습니다. . 이렇게 데이터 분석을 공부하면 보다 직관적으로 LSTM 모델을 학습할 수 있을 것 같습니다. . plt.figure(figsize=(10,4)) plt.title(&#39;Check - Sales of Item 5037 at Shop 5&#39;) plt.xlabel(&#39;Month&#39;) plt.ylabel(&#39;Sales of Item 5037 at Shop 5&#39;) plt.plot(check[&quot;date_block_num&quot;],check[&quot;item_cnt_month&quot;]); . 단순히 Y값에 대해 그림을 그려보았습니다. . month_list=[i for i in range(num_month+1)] # num_month = train[&#39;date_block_num&#39;].max(), 최고값 shop = [] for i in range(num_month+1): shop.append(5) item = [] for i in range(num_month+1): item.append(5037) months_full = pd.DataFrame({&#39;shop_id&#39;:shop, &#39;item_id&#39;:item,&#39;date_block_num&#39;:month_list}) months_full.head(10) . shop_id item_id date_block_num . 0 5 | 5037 | 0 | . 1 5 | 5037 | 1 | . 2 5 | 5037 | 2 | . 3 5 | 5037 | 3 | . 4 5 | 5037 | 4 | . 5 5 | 5037 | 5 | . 6 5 | 5037 | 6 | . 7 5 | 5037 | 7 | . 8 5 | 5037 | 8 | . 9 5 | 5037 | 9 | . 빈 데이터를 없애기 위해 처음부터 데이터프레임을 세팅하는 모습입니다. . shop = [] for i in range(num_month+1): shop.append(5) . 다만 이 코드 보다는 [5]*(num_month+1) 식으로 리스트를 구성하는게 더 깔끔한 것 같습니다. . sales_33month = pd.merge(check, months_full, how=&#39;right&#39;, on=[&#39;shop_id&#39;,&#39;item_id&#39;,&#39;date_block_num&#39;]) sales_33month = sales_33month.sort_values(by=[&#39;date_block_num&#39;]) sales_33month.fillna(0.00,inplace=True) plt.figure(figsize=(10,4)) plt.title(&#39;Check - Sales of Item 5037 at Shop 5 for whole period&#39;) plt.xlabel(&#39;Month&#39;) plt.ylabel(&#39;Sales of Item 5037 at Shop 5&#39;) plt.plot(sales_33month[&quot;date_block_num&quot;],sales_33month[&quot;item_cnt_month&quot;]); . 물품 구매가 없는 데이터까지 0 값을 넣어서 그림을 그렸습니다. . for i in range(1,6): sales_33month[&quot;T_&quot; + str(i)] = sales_33month.item_cnt_month.shift(i) sales_33month.fillna(0.0, inplace=True) df = sales_33month[[&#39;shop_id&#39;,&#39;item_id&#39;,&#39;date_block_num&#39;,&#39;T_1&#39;,&#39;T_2&#39;,&#39;T_3&#39;,&#39;T_4&#39;,&#39;T_5&#39;, &#39;item_cnt_month&#39;]].reset_index() df = df.drop(labels = [&#39;index&#39;], axis = 1) df . shop_id item_id date_block_num T_1 T_2 T_3 T_4 T_5 item_cnt_month . 0 5 | 5037 | 0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 1 5 | 5037 | 1 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 2 5 | 5037 | 2 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 3 5 | 5037 | 3 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 4 5 | 5037 | 4 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 5 5 | 5037 | 5 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 6 5 | 5037 | 6 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 7 5 | 5037 | 7 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 8 5 | 5037 | 8 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 9 5 | 5037 | 9 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 10 5 | 5037 | 10 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 11 5 | 5037 | 11 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 12 5 | 5037 | 12 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 13 5 | 5037 | 13 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 14 5 | 5037 | 14 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 15 5 | 5037 | 15 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 16 5 | 5037 | 16 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 17 5 | 5037 | 17 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 18 5 | 5037 | 18 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 19 5 | 5037 | 19 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 20 5 | 5037 | 20 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | . 21 5 | 5037 | 21 | 1.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 22 5 | 5037 | 22 | 0.0 | 1.0 | 0.0 | 0.0 | 0.0 | 1.0 | . 23 5 | 5037 | 23 | 1.0 | 0.0 | 1.0 | 0.0 | 0.0 | 2.0 | . 24 5 | 5037 | 24 | 2.0 | 1.0 | 0.0 | 1.0 | 0.0 | 2.0 | . 25 5 | 5037 | 25 | 2.0 | 2.0 | 1.0 | 0.0 | 1.0 | 0.0 | . 26 5 | 5037 | 26 | 0.0 | 2.0 | 2.0 | 1.0 | 0.0 | 0.0 | . 27 5 | 5037 | 27 | 0.0 | 0.0 | 2.0 | 2.0 | 1.0 | 0.0 | . 28 5 | 5037 | 28 | 0.0 | 0.0 | 0.0 | 2.0 | 2.0 | 1.0 | . 29 5 | 5037 | 29 | 1.0 | 0.0 | 0.0 | 0.0 | 2.0 | 1.0 | . 30 5 | 5037 | 30 | 1.0 | 1.0 | 0.0 | 0.0 | 0.0 | 1.0 | . 31 5 | 5037 | 31 | 1.0 | 1.0 | 1.0 | 0.0 | 0.0 | 3.0 | . 32 5 | 5037 | 32 | 3.0 | 1.0 | 1.0 | 1.0 | 0.0 | 1.0 | . 33 5 | 5037 | 33 | 1.0 | 3.0 | 1.0 | 1.0 | 1.0 | 0.0 | . 시계열 분석을 기초부터 뜯어본 것 같습니다. . T1 ~ T5에 의미는 최근 5달간 이전 Y값의 기록입니다. 예를 들면 T1은 한달 전 Y값을 나타냅니다. . 시간의 흐름에 따라 예측값이 영향을 받기 때문에 이러한 방식이 지금 이 데이터에서 적절합니다. . LSTM &#47784;&#45944; &#49324;&#50857; . train_df = df[:-3] val_df = df[-3:] x_train,y_train = train_df.drop([&quot;item_cnt_month&quot;],axis=1),train_df.item_cnt_month x_val,y_val = val_df.drop([&quot;item_cnt_month&quot;],axis=1),val_df.item_cnt_month . 맨 마지막 3개 데이터를 test 데이터로 사용합니다. . from keras.models import Sequential from keras.layers import Dense from keras.layers import LSTM model_lstm = Sequential() model_lstm.add(LSTM(15, input_shape=(1,8))) model_lstm.add(Dense(1)) model_lstm.compile(loss=&#39;mean_squared_error&#39;, optimizer=&#39;adam&#39;, metrics=[&#39;accuracy&#39;]) . from sklearn.preprocessing import StandardScaler,MinMaxScaler scaler = StandardScaler() scaler = MinMaxScaler(feature_range=(-1, 1)) x_train_scaled = scaler.fit_transform(x_train) x_valid_scaled = scaler.fit_transform(x_val) . x_train_reshaped = x_train_scaled.reshape((x_train_scaled.shape[0], 1, x_train_scaled.shape[1])) x_val_resaped = x_valid_scaled.reshape((x_valid_scaled.shape[0], 1, x_valid_scaled.shape[1])) history = model_lstm.fit(x_train_reshaped, y_train, validation_data=(x_val_resaped, y_val),epochs=70, batch_size=12, verbose=2, shuffle=False) y_pre = model_lstm.predict(x_val_resaped) . Epoch 1/70 3/3 - 2s - loss: 0.4119 - accuracy: 0.7742 - val_loss: 3.6385 - val_accuracy: 0.3333 Epoch 2/70 3/3 - 0s - loss: 0.3959 - accuracy: 0.7742 - val_loss: 3.5825 - val_accuracy: 0.3333 Epoch 3/70 3/3 - 0s - loss: 0.3818 - accuracy: 0.7742 - val_loss: 3.5290 - val_accuracy: 0.3333 Epoch 4/70 3/3 - 0s - loss: 0.3689 - accuracy: 0.7742 - val_loss: 3.4781 - val_accuracy: 0.3333 Epoch 5/70 3/3 - 0s - loss: 0.3571 - accuracy: 0.7742 - val_loss: 3.4296 - val_accuracy: 0.3333 Epoch 6/70 3/3 - 0s - loss: 0.3464 - accuracy: 0.7742 - val_loss: 3.3839 - val_accuracy: 0.3333 Epoch 7/70 3/3 - 0s - loss: 0.3368 - accuracy: 0.7742 - val_loss: 3.3409 - val_accuracy: 0.3333 Epoch 8/70 3/3 - 0s - loss: 0.3281 - accuracy: 0.7742 - val_loss: 3.3008 - val_accuracy: 0.3333 Epoch 9/70 3/3 - 0s - loss: 0.3203 - accuracy: 0.7742 - val_loss: 3.2637 - val_accuracy: 0.3333 Epoch 10/70 3/3 - 0s - loss: 0.3132 - accuracy: 0.7742 - val_loss: 3.2296 - val_accuracy: 0.3333 Epoch 11/70 3/3 - 0s - loss: 0.3069 - accuracy: 0.7742 - val_loss: 3.1984 - val_accuracy: 0.3333 Epoch 12/70 3/3 - 0s - loss: 0.3012 - accuracy: 0.7742 - val_loss: 3.1702 - val_accuracy: 0.3333 Epoch 13/70 3/3 - 0s - loss: 0.2960 - accuracy: 0.7742 - val_loss: 3.1451 - val_accuracy: 0.3333 Epoch 14/70 3/3 - 0s - loss: 0.2913 - accuracy: 0.7742 - val_loss: 3.1228 - val_accuracy: 0.3333 Epoch 15/70 3/3 - 0s - loss: 0.2869 - accuracy: 0.7742 - val_loss: 3.1035 - val_accuracy: 0.3333 Epoch 16/70 3/3 - 0s - loss: 0.2829 - accuracy: 0.7742 - val_loss: 3.0871 - val_accuracy: 0.3333 Epoch 17/70 3/3 - 0s - loss: 0.2791 - accuracy: 0.7742 - val_loss: 3.0733 - val_accuracy: 0.3333 Epoch 18/70 3/3 - 0s - loss: 0.2755 - accuracy: 0.7742 - val_loss: 3.0623 - val_accuracy: 0.3333 Epoch 19/70 3/3 - 0s - loss: 0.2720 - accuracy: 0.7742 - val_loss: 3.0537 - val_accuracy: 0.3333 Epoch 20/70 3/3 - 0s - loss: 0.2687 - accuracy: 0.7742 - val_loss: 3.0476 - val_accuracy: 0.3333 Epoch 21/70 3/3 - 0s - loss: 0.2654 - accuracy: 0.7742 - val_loss: 3.0437 - val_accuracy: 0.3333 Epoch 22/70 3/3 - 0s - loss: 0.2622 - accuracy: 0.7742 - val_loss: 3.0419 - val_accuracy: 0.3333 Epoch 23/70 3/3 - 0s - loss: 0.2590 - accuracy: 0.7742 - val_loss: 3.0421 - val_accuracy: 0.3333 Epoch 24/70 3/3 - 0s - loss: 0.2558 - accuracy: 0.8065 - val_loss: 3.0440 - val_accuracy: 0.3333 Epoch 25/70 3/3 - 0s - loss: 0.2527 - accuracy: 0.8065 - val_loss: 3.0477 - val_accuracy: 0.3333 Epoch 26/70 3/3 - 0s - loss: 0.2495 - accuracy: 0.8387 - val_loss: 3.0528 - val_accuracy: 0.3333 Epoch 27/70 3/3 - 0s - loss: 0.2463 - accuracy: 0.8387 - val_loss: 3.0592 - val_accuracy: 0.3333 Epoch 28/70 3/3 - 0s - loss: 0.2432 - accuracy: 0.8387 - val_loss: 3.0669 - val_accuracy: 0.3333 Epoch 29/70 3/3 - 0s - loss: 0.2401 - accuracy: 0.8387 - val_loss: 3.0756 - val_accuracy: 0.3333 Epoch 30/70 3/3 - 0s - loss: 0.2370 - accuracy: 0.8387 - val_loss: 3.0853 - val_accuracy: 0.3333 Epoch 31/70 3/3 - 0s - loss: 0.2339 - accuracy: 0.8387 - val_loss: 3.0958 - val_accuracy: 0.3333 Epoch 32/70 3/3 - 0s - loss: 0.2308 - accuracy: 0.8387 - val_loss: 3.1070 - val_accuracy: 0.3333 Epoch 33/70 3/3 - 0s - loss: 0.2278 - accuracy: 0.8065 - val_loss: 3.1187 - val_accuracy: 0.6667 Epoch 34/70 3/3 - 0s - loss: 0.2248 - accuracy: 0.8065 - val_loss: 3.1310 - val_accuracy: 0.6667 Epoch 35/70 3/3 - 0s - loss: 0.2219 - accuracy: 0.8065 - val_loss: 3.1436 - val_accuracy: 0.6667 Epoch 36/70 3/3 - 0s - loss: 0.2190 - accuracy: 0.7742 - val_loss: 3.1565 - val_accuracy: 0.6667 Epoch 37/70 3/3 - 0s - loss: 0.2162 - accuracy: 0.7742 - val_loss: 3.1696 - val_accuracy: 0.3333 Epoch 38/70 3/3 - 0s - loss: 0.2134 - accuracy: 0.7742 - val_loss: 3.1829 - val_accuracy: 0.3333 Epoch 39/70 3/3 - 0s - loss: 0.2107 - accuracy: 0.8065 - val_loss: 3.1963 - val_accuracy: 0.3333 Epoch 40/70 3/3 - 0s - loss: 0.2081 - accuracy: 0.8065 - val_loss: 3.2096 - val_accuracy: 0.3333 Epoch 41/70 3/3 - 0s - loss: 0.2056 - accuracy: 0.8065 - val_loss: 3.2229 - val_accuracy: 0.3333 Epoch 42/70 3/3 - 0s - loss: 0.2031 - accuracy: 0.8065 - val_loss: 3.2361 - val_accuracy: 0.3333 Epoch 43/70 3/3 - 0s - loss: 0.2008 - accuracy: 0.8065 - val_loss: 3.2492 - val_accuracy: 0.3333 Epoch 44/70 3/3 - 0s - loss: 0.1985 - accuracy: 0.8065 - val_loss: 3.2621 - val_accuracy: 0.3333 Epoch 45/70 3/3 - 0s - loss: 0.1963 - accuracy: 0.8065 - val_loss: 3.2748 - val_accuracy: 0.3333 Epoch 46/70 3/3 - 0s - loss: 0.1941 - accuracy: 0.8065 - val_loss: 3.2872 - val_accuracy: 0.3333 Epoch 47/70 3/3 - 0s - loss: 0.1921 - accuracy: 0.8065 - val_loss: 3.2994 - val_accuracy: 0.3333 Epoch 48/70 3/3 - 0s - loss: 0.1901 - accuracy: 0.8065 - val_loss: 3.3113 - val_accuracy: 0.3333 Epoch 49/70 3/3 - 0s - loss: 0.1882 - accuracy: 0.8065 - val_loss: 3.3229 - val_accuracy: 0.3333 Epoch 50/70 3/3 - 0s - loss: 0.1864 - accuracy: 0.8065 - val_loss: 3.3342 - val_accuracy: 0.3333 Epoch 51/70 3/3 - 0s - loss: 0.1847 - accuracy: 0.8065 - val_loss: 3.3451 - val_accuracy: 0.3333 Epoch 52/70 3/3 - 0s - loss: 0.1830 - accuracy: 0.8065 - val_loss: 3.3558 - val_accuracy: 0.3333 Epoch 53/70 3/3 - 0s - loss: 0.1814 - accuracy: 0.8065 - val_loss: 3.3661 - val_accuracy: 0.3333 Epoch 54/70 3/3 - 0s - loss: 0.1799 - accuracy: 0.8065 - val_loss: 3.3760 - val_accuracy: 0.3333 Epoch 55/70 3/3 - 0s - loss: 0.1785 - accuracy: 0.8065 - val_loss: 3.3855 - val_accuracy: 0.3333 Epoch 56/70 3/3 - 0s - loss: 0.1771 - accuracy: 0.8065 - val_loss: 3.3947 - val_accuracy: 0.3333 Epoch 57/70 3/3 - 0s - loss: 0.1757 - accuracy: 0.8065 - val_loss: 3.4036 - val_accuracy: 0.3333 Epoch 58/70 3/3 - 0s - loss: 0.1745 - accuracy: 0.8065 - val_loss: 3.4120 - val_accuracy: 0.3333 Epoch 59/70 3/3 - 0s - loss: 0.1732 - accuracy: 0.8065 - val_loss: 3.4201 - val_accuracy: 0.3333 Epoch 60/70 3/3 - 0s - loss: 0.1720 - accuracy: 0.8065 - val_loss: 3.4278 - val_accuracy: 0.3333 Epoch 61/70 3/3 - 0s - loss: 0.1709 - accuracy: 0.8065 - val_loss: 3.4351 - val_accuracy: 0.3333 Epoch 62/70 3/3 - 0s - loss: 0.1698 - accuracy: 0.8065 - val_loss: 3.4420 - val_accuracy: 0.3333 Epoch 63/70 3/3 - 0s - loss: 0.1687 - accuracy: 0.8065 - val_loss: 3.4485 - val_accuracy: 0.3333 Epoch 64/70 3/3 - 0s - loss: 0.1677 - accuracy: 0.8065 - val_loss: 3.4547 - val_accuracy: 0.3333 Epoch 65/70 3/3 - 0s - loss: 0.1667 - accuracy: 0.8065 - val_loss: 3.4605 - val_accuracy: 0.3333 Epoch 66/70 3/3 - 0s - loss: 0.1658 - accuracy: 0.8065 - val_loss: 3.4659 - val_accuracy: 0.3333 Epoch 67/70 3/3 - 0s - loss: 0.1648 - accuracy: 0.8065 - val_loss: 3.4710 - val_accuracy: 0.3333 Epoch 68/70 3/3 - 0s - loss: 0.1639 - accuracy: 0.8065 - val_loss: 3.4758 - val_accuracy: 0.3333 Epoch 69/70 3/3 - 0s - loss: 0.1631 - accuracy: 0.8065 - val_loss: 3.4802 - val_accuracy: 0.3333 Epoch 70/70 3/3 - 0s - loss: 0.1622 - accuracy: 0.8065 - val_loss: 3.4844 - val_accuracy: 0.3333 . fig, ax = plt.subplots() ax.plot(x_val[&#39;date_block_num&#39;], y_val, label=&#39;Actual&#39;) ax.plot(x_val[&#39;date_block_num&#39;], y_pre, label=&#39;Predicted&#39;) plt.title(&#39;LSTM Prediction vs Actual Sales for last 3 months&#39;) plt.xlabel(&#39;Month&#39;) plt.xticks(x_val[&#39;date_block_num&#39;]) plt.ylabel(&#39;Sales of Item 5037 at Shop 5&#39;) ax.legend() plt.show() . LSTM 모델을 적용시킨 모습입니다. . 잘 맞췄다면 잘 맞췄다고도 말 할수 있고 아쉽다면 아쉽다고 할 수 있는 결과인 것 같습니다. . &#45936;&#51060;&#53552; &#53456;&#49353; . sales_data = pd.read_csv(&#39;./sales_train.csv&#39;) item_cat = pd.read_csv(&#39;./item_categories.csv&#39;) items = pd.read_csv(&#39;./items.csv&#39;) shops = pd.read_csv(&#39;./shops.csv&#39;) sample_submission = pd.read_csv(&#39;./sample_submission.csv&#39;) test_data = pd.read_csv(&#39;./test.csv&#39;) . def basic_eda(df): print(&quot;-TOP 5 RECORDS--&quot;) print(df.head(5)) print(&quot;-INFO--&quot;) print(df.info()) print(&quot;-Describe-&quot;) print(df.describe()) print(&quot;-Columns--&quot;) print(df.columns) print(&quot;-Data Types--&quot;) print(df.dtypes) print(&quot;-Missing Values-&quot;) print(df.isnull().sum()) print(&quot;-NULL values-&quot;) print(df.isna().sum()) print(&quot;--Shape Of Data-&quot;) print(df.shape) print(&quot;=============================Sales Data=============================&quot;) basic_eda(sales_data) print(&quot;=============================Test data=============================&quot;) basic_eda(test_data) print(&quot;=============================Item Categories=============================&quot;) basic_eda(item_cat) print(&quot;=============================Items=============================&quot;) basic_eda(items) print(&quot;=============================Shops=============================&quot;) basic_eda(shops) print(&quot;=============================Sample Submission=============================&quot;) basic_eda(sample_submission) . =============================Sales Data============================= -TOP 5 RECORDS-- date date_block_num shop_id item_id item_price item_cnt_day 0 02.01.2013 0 59 22154 999.00 1.0 1 03.01.2013 0 25 2552 899.00 1.0 2 05.01.2013 0 25 2552 899.00 -1.0 3 06.01.2013 0 25 2554 1709.05 1.0 4 15.01.2013 0 25 2555 1099.00 1.0 -INFO-- &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 2935849 entries, 0 to 2935848 Data columns (total 6 columns): # Column Dtype -- 0 date object 1 date_block_num int64 2 shop_id int64 3 item_id int64 4 item_price float64 5 item_cnt_day float64 dtypes: float64(2), int64(3), object(1) memory usage: 134.4+ MB None -Describe- date_block_num shop_id item_id item_price item_cnt_day count 2.935849e+06 2.935849e+06 2.935849e+06 2.935849e+06 2.935849e+06 mean 1.456991e+01 3.300173e+01 1.019723e+04 8.908532e+02 1.242641e+00 std 9.422988e+00 1.622697e+01 6.324297e+03 1.729800e+03 2.618834e+00 min 0.000000e+00 0.000000e+00 0.000000e+00 -1.000000e+00 -2.200000e+01 25% 7.000000e+00 2.200000e+01 4.476000e+03 2.490000e+02 1.000000e+00 50% 1.400000e+01 3.100000e+01 9.343000e+03 3.990000e+02 1.000000e+00 75% 2.300000e+01 4.700000e+01 1.568400e+04 9.990000e+02 1.000000e+00 max 3.300000e+01 5.900000e+01 2.216900e+04 3.079800e+05 2.169000e+03 -Columns-- Index([&#39;date&#39;, &#39;date_block_num&#39;, &#39;shop_id&#39;, &#39;item_id&#39;, &#39;item_price&#39;, &#39;item_cnt_day&#39;], dtype=&#39;object&#39;) -Data Types-- date object date_block_num int64 shop_id int64 item_id int64 item_price float64 item_cnt_day float64 dtype: object -Missing Values- date 0 date_block_num 0 shop_id 0 item_id 0 item_price 0 item_cnt_day 0 dtype: int64 -NULL values- date 0 date_block_num 0 shop_id 0 item_id 0 item_price 0 item_cnt_day 0 dtype: int64 --Shape Of Data- (2935849, 6) =============================Test data============================= -TOP 5 RECORDS-- ID shop_id item_id 0 0 5 5037 1 1 5 5320 2 2 5 5233 3 3 5 5232 4 4 5 5268 -INFO-- &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 214200 entries, 0 to 214199 Data columns (total 3 columns): # Column Non-Null Count Dtype -- -- 0 ID 214200 non-null int64 1 shop_id 214200 non-null int64 2 item_id 214200 non-null int64 dtypes: int64(3) memory usage: 4.9 MB None -Describe- ID shop_id item_id count 214200.000000 214200.000000 214200.000000 mean 107099.500000 31.642857 11019.398627 std 61834.358168 17.561933 6252.644590 min 0.000000 2.000000 30.000000 25% 53549.750000 16.000000 5381.500000 50% 107099.500000 34.500000 11203.000000 75% 160649.250000 47.000000 16071.500000 max 214199.000000 59.000000 22167.000000 -Columns-- Index([&#39;ID&#39;, &#39;shop_id&#39;, &#39;item_id&#39;], dtype=&#39;object&#39;) -Data Types-- ID int64 shop_id int64 item_id int64 dtype: object -Missing Values- ID 0 shop_id 0 item_id 0 dtype: int64 -NULL values- ID 0 shop_id 0 item_id 0 dtype: int64 --Shape Of Data- (214200, 3) =============================Item Categories============================= -TOP 5 RECORDS-- item_category_name item_category_id 0 PC - Гарнитуры/Наушники 0 1 Аксессуары - PS2 1 2 Аксессуары - PS3 2 3 Аксессуары - PS4 3 4 Аксессуары - PSP 4 -INFO-- &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 84 entries, 0 to 83 Data columns (total 2 columns): # Column Non-Null Count Dtype -- -- 0 item_category_name 84 non-null object 1 item_category_id 84 non-null int64 dtypes: int64(1), object(1) memory usage: 1.4+ KB None -Describe- item_category_id count 84.000000 mean 41.500000 std 24.392622 min 0.000000 25% 20.750000 50% 41.500000 75% 62.250000 max 83.000000 -Columns-- Index([&#39;item_category_name&#39;, &#39;item_category_id&#39;], dtype=&#39;object&#39;) -Data Types-- item_category_name object item_category_id int64 dtype: object -Missing Values- item_category_name 0 item_category_id 0 dtype: int64 -NULL values- item_category_name 0 item_category_id 0 dtype: int64 --Shape Of Data- (84, 2) =============================Items============================= -TOP 5 RECORDS-- item_name item_id item_category_id 0 ! ВО ВЛАСТИ НАВАЖДЕНИЯ (ПЛАСТ.) D 0 40 1 !ABBYY FineReader 12 Professional Edition Full... 1 76 2 ***В ЛУЧАХ СЛАВЫ (UNV) D 2 40 3 ***ГОЛУБАЯ ВОЛНА (Univ) D 3 40 4 ***КОРОБКА (СТЕКЛО) D 4 40 -INFO-- &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 22170 entries, 0 to 22169 Data columns (total 3 columns): # Column Non-Null Count Dtype -- -- 0 item_name 22170 non-null object 1 item_id 22170 non-null int64 2 item_category_id 22170 non-null int64 dtypes: int64(2), object(1) memory usage: 519.7+ KB None -Describe- item_id item_category_id count 22170.00000 22170.000000 mean 11084.50000 46.290753 std 6400.07207 15.941486 min 0.00000 0.000000 25% 5542.25000 37.000000 50% 11084.50000 40.000000 75% 16626.75000 58.000000 max 22169.00000 83.000000 -Columns-- Index([&#39;item_name&#39;, &#39;item_id&#39;, &#39;item_category_id&#39;], dtype=&#39;object&#39;) -Data Types-- item_name object item_id int64 item_category_id int64 dtype: object -Missing Values- item_name 0 item_id 0 item_category_id 0 dtype: int64 -NULL values- item_name 0 item_id 0 item_category_id 0 dtype: int64 --Shape Of Data- (22170, 3) =============================Shops============================= -TOP 5 RECORDS-- shop_name shop_id 0 !Якутск Орджоникидзе, 56 фран 0 1 !Якутск ТЦ &#34;Центральный&#34; фран 1 2 Адыгея ТЦ &#34;Мега&#34; 2 3 Балашиха ТРК &#34;Октябрь-Киномир&#34; 3 4 Волжский ТЦ &#34;Волга Молл&#34; 4 -INFO-- &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 60 entries, 0 to 59 Data columns (total 2 columns): # Column Non-Null Count Dtype -- -- 0 shop_name 60 non-null object 1 shop_id 60 non-null int64 dtypes: int64(1), object(1) memory usage: 1.1+ KB None -Describe- shop_id count 60.000000 mean 29.500000 std 17.464249 min 0.000000 25% 14.750000 50% 29.500000 75% 44.250000 max 59.000000 -Columns-- Index([&#39;shop_name&#39;, &#39;shop_id&#39;], dtype=&#39;object&#39;) -Data Types-- shop_name object shop_id int64 dtype: object -Missing Values- shop_name 0 shop_id 0 dtype: int64 -NULL values- shop_name 0 shop_id 0 dtype: int64 --Shape Of Data- (60, 2) =============================Sample Submission============================= -TOP 5 RECORDS-- ID item_cnt_month 0 0 0.5 1 1 0.5 2 2 0.5 3 3 0.5 4 4 0.5 -INFO-- &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 214200 entries, 0 to 214199 Data columns (total 2 columns): # Column Non-Null Count Dtype -- -- 0 ID 214200 non-null int64 1 item_cnt_month 214200 non-null float64 dtypes: float64(1), int64(1) memory usage: 3.3 MB None -Describe- ID item_cnt_month count 214200.000000 214200.0 mean 107099.500000 0.5 std 61834.358168 0.0 min 0.000000 0.5 25% 53549.750000 0.5 50% 107099.500000 0.5 75% 160649.250000 0.5 max 214199.000000 0.5 -Columns-- Index([&#39;ID&#39;, &#39;item_cnt_month&#39;], dtype=&#39;object&#39;) -Data Types-- ID int64 item_cnt_month float64 dtype: object -Missing Values- ID 0 item_cnt_month 0 dtype: int64 -NULL values- ID 0 item_cnt_month 0 dtype: int64 --Shape Of Data- (214200, 2) . 앞 코드와 다른 사람 코드입니다. . 여기서 train 데이터 프레임을 이 사람은 sales_data 이름으로 했네요. . 사실 데이터 탐색하는 함수를 잘 만들어 놓은것 같아서 향후 다른 데이터 분석시 복사를 위해 가져왔습니다. . &#45936;&#51060;&#53552; &#51204;&#52376;&#47532; . sales_data[&#39;date&#39;] = pd.to_datetime(sales_data[&#39;date&#39;],format = &#39;%d.%m.%Y&#39;) dataset = sales_data.pivot_table(index = [&#39;shop_id&#39;,&#39;item_id&#39;], values = [&#39;item_cnt_day&#39;],columns = [&#39;date_block_num&#39;],fill_value = 0,aggfunc=&#39;sum&#39;) dataset.reset_index(inplace = True) dataset.head() . shop_id item_id item_cnt_day . date_block_num 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 . 0 0 | 30 | 0 | 31 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 1 0 | 31 | 0 | 11 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 2 0 | 32 | 6 | 10 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 3 0 | 33 | 3 | 3 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 4 0 | 35 | 1 | 14 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 판다스 내 피벗 테이블을 사용하는 모습입니다. group_by 함수를 확장한 것으로 생각할 수 있습니다. . 피벗 테이블은 우선 index로 데이터를 구분 짓습니다. 여기서 shop_id, item_id가 모두 같은 값을 가진 행끼리 그룹을 짓습니다. . 다음으로 columns로 한번 더 데이터를 구분 짓습니다. 같은 상점, 같은 제품을 달별로 나누었습니다. . values는 실제 적용되는 값을 의미합니다. 여기서는 item_cnt_day 변수를 사용했습니다. . 상점, 제품, 달이 같은 데이터 별로 구분했을때 여러개의 item_cnt_day 값을 더해주는 함수(aggfunc=&#39;sum&#39;)를 사용합니다. . 빈 값도 충분히 존재할 가능성이 있는데, 그 경우 거래 기록이 존재하지 않았다는 의미이므로 0값을 채웁니다.(fill_value = 0) . dataset = pd.merge(test_data,dataset,on = [&#39;item_id&#39;,&#39;shop_id&#39;],how = &#39;left&#39;) dataset.fillna(0,inplace = True) dataset.head() . /usr/local/lib/python3.7/dist-packages/pandas/core/reshape/merge.py:643: UserWarning: merging between different levels can give an unintended result (1 levels on the left,2 on the right) warnings.warn(msg, UserWarning) /usr/local/lib/python3.7/dist-packages/pandas/core/generic.py:3889: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance. obj = obj._drop_axis(labels, axis, level=level, errors=errors) . ID shop_id item_id (item_cnt_day, 0) (item_cnt_day, 1) (item_cnt_day, 2) (item_cnt_day, 3) (item_cnt_day, 4) (item_cnt_day, 5) (item_cnt_day, 6) (item_cnt_day, 7) (item_cnt_day, 8) (item_cnt_day, 9) (item_cnt_day, 10) (item_cnt_day, 11) (item_cnt_day, 12) (item_cnt_day, 13) (item_cnt_day, 14) (item_cnt_day, 15) (item_cnt_day, 16) (item_cnt_day, 17) (item_cnt_day, 18) (item_cnt_day, 19) (item_cnt_day, 20) (item_cnt_day, 21) (item_cnt_day, 22) (item_cnt_day, 23) (item_cnt_day, 24) (item_cnt_day, 25) (item_cnt_day, 26) (item_cnt_day, 27) (item_cnt_day, 28) (item_cnt_day, 29) (item_cnt_day, 30) (item_cnt_day, 31) (item_cnt_day, 32) (item_cnt_day, 33) . 0 0 | 5 | 5037 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 1.0 | 2.0 | 2.0 | 0.0 | 0.0 | 0.0 | 1.0 | 1.0 | 1.0 | 3.0 | 1.0 | 0.0 | . 1 1 | 5 | 5320 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 2 2 | 5 | 5233 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 3.0 | 2.0 | 0.0 | 1.0 | 3.0 | 1.0 | . 3 3 | 5 | 5232 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 1.0 | 0.0 | 0.0 | . 4 4 | 5 | 5268 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | 0.0 | . 피벗 테이블을 사용해 같은 상점, 제품을 달 별로 거래기록이 몇건 있었는가를 나타내는 데이터 프레임입니다. . 이를 활용해 test 데이터 프레임과 병합한다면 테스트 데이터에 있는 상점, 제품의 이전 달별 거래기록을 전부 알 수 있습니다. . 이때 만약 병합이 안된 데이터가 있다면(이전 거래기록이 없는 데이터이겠죠?) 0으로 값을 넣어줍니다. . &#45936;&#51060;&#53552; &#47784;&#45944;&#47553; . dataset.drop([&#39;shop_id&#39;,&#39;item_id&#39;,&#39;ID&#39;],inplace = True, axis = 1) dataset.head() X_train = np.expand_dims(dataset.values[:,:-1],axis = 2) y_train = dataset.values[:,-1:] X_test = np.expand_dims(dataset.values[:,1:],axis = 2) print(X_train.shape,y_train.shape,X_test.shape) . (214200, 33, 1) (214200, 1) (214200, 33, 1) . 데이터를 모델링 하기 위해 상점, 제품 데이터를 지우고, train과 test 데이터 셋을 만들었습니다. . X_train : 0번째 달부터 32번째 달까지 거래 기록 데이터 . y_train : 33번째 달 거래 기록 데이터 . X_test : 1번째 달부터 33번째 달까지 거래 기록 데이터(train과 test간 데이터 형식을 맞추기 위해) . 우리가 예측해야할 y_test는 34번째 달 거래 기록 데이터, 즉 2015년 10월 거래 기록 데이터 입니다. . from keras.models import Sequential from keras.layers import LSTM,Dense,Dropout my_model = Sequential() my_model.add(LSTM(units = 64,input_shape = (33,1))) my_model.add(Dropout(0.4)) my_model.add(Dense(1)) my_model.compile(loss = &#39;mse&#39;,optimizer = &#39;adam&#39;, metrics = [&#39;mean_squared_error&#39;]) my_model.summary() . Model: &#34;sequential_1&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= lstm_1 (LSTM) (None, 64) 16896 _________________________________________________________________ dropout (Dropout) (None, 64) 0 _________________________________________________________________ dense_1 (Dense) (None, 1) 65 ================================================================= Total params: 16,961 Trainable params: 16,961 Non-trainable params: 0 _________________________________________________________________ . my_model.fit(X_train,y_train,batch_size = 4096,epochs = 10) . Epoch 1/10 53/53 [==============================] - 27s 471ms/step - loss: 30.6011 - mean_squared_error: 30.6011 Epoch 2/10 53/53 [==============================] - 25s 466ms/step - loss: 30.2430 - mean_squared_error: 30.2430 Epoch 3/10 53/53 [==============================] - 24s 462ms/step - loss: 30.0014 - mean_squared_error: 30.0014 Epoch 4/10 53/53 [==============================] - 25s 481ms/step - loss: 29.8476 - mean_squared_error: 29.8476 Epoch 5/10 53/53 [==============================] - 26s 482ms/step - loss: 29.7404 - mean_squared_error: 29.7404 Epoch 6/10 53/53 [==============================] - 26s 487ms/step - loss: 29.7396 - mean_squared_error: 29.7396 Epoch 7/10 53/53 [==============================] - 25s 480ms/step - loss: 29.7369 - mean_squared_error: 29.7369 Epoch 8/10 53/53 [==============================] - 25s 473ms/step - loss: 29.6503 - mean_squared_error: 29.6503 Epoch 9/10 53/53 [==============================] - 25s 472ms/step - loss: 29.6353 - mean_squared_error: 29.6353 Epoch 10/10 53/53 [==============================] - 25s 468ms/step - loss: 29.5096 - mean_squared_error: 29.5096 . &lt;keras.callbacks.History at 0x7f2b3e51ff90&gt; . 모델을 LSTM(시계열 분석) 방법을 사용해서 분석합니다. 사실 LSTM 모델을 처음 사용했는데요. . 이번주에 다소 시간이 부족해 LSTM 모델의 사용방법이나 원리 등은 아직 파악하지 못했네요. (다른 사람 발표를 경청하겠습니다.) . submission_pfs = my_model.predict(X_test) submission_pfs = submission_pfs.clip(0,20) submission = pd.DataFrame({&#39;ID&#39;:test_data[&#39;ID&#39;],&#39;item_cnt_month&#39;:submission_pfs.ravel()}) submission.to_csv(&#39;./submission.csv&#39;,index = False) submission . ID item_cnt_month . 0 0 | 0.396485 | . 1 1 | 0.103207 | . 2 2 | 0.743674 | . 3 3 | 0.135947 | . 4 4 | 0.103207 | . ... ... | ... | . 214195 214195 | 0.331131 | . 214196 214196 | 0.103207 | . 214197 214197 | 0.097571 | . 214198 214198 | 0.103207 | . 214199 214199 | 0.069235 | . 214200 rows × 2 columns . 데이터를 모델에 적용시켜 예측값을 찾은 뒤, 제출 형식에 맞게 데이터 프레임 형식을 조정했습니다. . 이때 clip 함수는 이상치 조정 함수입니다. . clip(최솟값, 최댓값) 구조로 범위를 벗어나면 범위 내로 값을 조정시켜줍니다. . &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; data = {&#39;col_0&#39;: [9, -3, 0, -1, 5], &#39;col_1&#39;: [-2, -7, 6, 8, -5]} df = pd.DataFrame(data) df . col_0 col_1 . 0 9 | -2 | . 1 -3 | -7 | . 2 0 | 6 | . 3 -1 | 8 | . 4 5 | -5 | . df.clip(-4, 6) . col_0 col_1 . 0 6 | -2 | . 1 -3 | -4 | . 2 0 | 6 | . 3 -1 | 6 | . 4 5 | -4 | . 예시를 보면 보다 직관적으로 이해가 가능할 것 같습니다. . 이 함수는 범용성이 넓으니 다른 데이터 분석에 자주 쓰일 수 있어 따로 정리했네요. . !kaggle competitions submit -c competitive-data-science-predict-future-sales -f submission.csv -m &quot;Message&quot; . Warning: Looks like you&#39;re using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4) 100% 3.55M/3.55M [00:04&lt;00:00, 769kB/s] Successfully submitted to Predict Future Sales . 캐글에 파일을 자동 제출하는 코드입니다. . 스코어는 약 1.02로 만 2천명 중 6천등 정도를 기록합니다. . &#45712;&#45184;&#51216; . 우선 공부하기 좋은 데이터를 찾아 줘서 고맙습니다. . 시계열 자료가 현실에서 상당히 많아 꼭 공부해보고 싶은 분야였는데, 이번 기회에 분석하게 되서 너무 좋습니다. . 개인적으로 공부하고 싶은 분야가 이미지 분류같은 것 보다는 자연어 처리, 시계열 분석 등 현실 세계를 설명할 수 있는 것 입니다. . 이번엔 시간이 다소 부족해서 자주쓰는 시계열 모델인 LSTM 모델의 탐구가 부족했습니다. . 다른 사람 발표 경청하고, 시간이 있을때 LSTM 모델을 열심히 공부해보고 싶네요. . 감사합니다. . &lt;/div&gt;",
            "url": "https://ksy1526.github.io/myblog//myblog/2021/10/28/kagglessu4.html",
            "relUrl": "/2021/10/28/kagglessu4.html",
            "date": " • Oct 28, 2021"
        }
        
    
  
    
        ,"post7": {
            "title": "시뮬레이션) 중간고사 범위 복습",
            "content": ". &#53076;&#47017;&#50640;&#49436; R &#49324;&#50857;&#48277; by &#54805;&#46973; . https://colab.research.google.com/notebook#create=true&amp;language=r . 뒷부분에 language=r 만 붙여주면 정상적으로 코랩 R버전이 실행됩니다. . for (i in 1:10){ print(i) } . [1] 1 [1] 2 [1] 3 [1] 4 [1] 5 [1] 6 [1] 7 [1] 8 [1] 9 [1] 10 . 6.6&#51208; &#48372;&#54744;&#44552; &#52397;&#44396; &#47928;&#51228; . 기존 보험 가입자 n0(사용값 1명), 기존 자본금 a0 (사용값 25000), 기간 365. 보함 가입자는 기간 1당 보험금 C(사용값 11000)을 각각 지불합니다. . 이때 자본금이 음이 되지 않을 확률을 모의실험으로 구하는 문제 입니다. . 일어날 사건은 보험금청구, 신규고객 가입, 기존계약해지 인데요. . 보험금 청구는 도착률 알파(사용값 10)인 포아송 과정, 이때 청구 금액은 지수분포 (사용 람다값 1/1000)을 따릅니다. . 포아송 과정이란 사건 발생 시간 분포가 평균 1/알파인 지수분포 입니다. . 이 모의실험을 300번 실시해봅니다. . (신규고객 가입, 기존계약 해지는 무시합니다.) . n.sim &lt;- 300 # 모의실험 실행 횟수 n0 &lt;- 1; a0 &lt;- 25000; T &lt;- 365; c &lt;- 11000 # 가입자, 자본금, 기간, 단위기간당 보험금 초기값 부여 alpha &lt;- 10; nu &lt;- 0; mu &lt;- 0 # 알파값, 신규계약과 기존계약 해지는 무시합니다. generate.Y &lt;- function() rexp(1, rate = 1/1000) # 청구금액 만드는 함수를 생성합니다. I &lt;- numeric(length = n.sim) # 자본금이 음이되는지 여부를 실험마다 기록하는 변수 입니다. for (i in 1:n.sim){ # 실험 n.sim(300)번 실행 t &lt;- 0; a &lt;- a0; n &lt;- n0 # 시점, 자본금, 고객 수 초기값 부여 total.rate &lt;- nu + n * mu + n * alpha # 사건 발생 람다값 부여. 여기서 유효한 값은 n * alpha(보험금 청구) 입니다. tE &lt;- rexp(1, rate = total.rate) # 첫 사건 발생 시간 repeat{ if (tE &gt; T) { # 주어진 기간을 초과했을 경우 I[i] &lt;- 1 # 중간에 중단되지 않고 주어진 기간(365)를 무사히 초과했기 때문에 이번 실험은 성공임을 기록해줍니다. break # 반복분 끝내기. 다음 모의 실험이 실행되겠죠. } if (tE &lt;= T){ # 주어진 기간 내. a &lt;- a + n * c * (tE - t) # 보험금 수금. 여기서 tE는 새 사건 발생 시간, t는 과거 사건 발생시간. t &lt;- tE # 시점을 새 사건 발생시간에 맞춰줍니다. J &lt;- sample(1:3, 1, prob = c(nu, n*mu, n*alpha)) # 이번 사건은 어떤사건인지 정해줍니다. 하지만 여기선 무조건 J는 3이됩니다. if (J == 1) n &lt;- n + 1 # 신규고객 가입 if (J == 2) n &lt;- n - 1 # 기존고객 해지 if (J == 3){ Y &lt;- generate.Y(); # 보험금 청구 금액 찾기 if (Y &gt; a){ # 현재 자본금보다 보험 청구 금액이 많으면 = 자본금이 음수가 됨. I[i] &lt;- 0 # 이번 실험은 실패임을 기록 break # 반복문 끝내기 } else a &lt;- a - Y # 자본금이 음수가 되는 일이 벌어지지 않으면 자본금에서 돈을 쓰면 되겠죠. } tE &lt;- t + rexp(1,rate=total.rate) # 다음 사건이 일어날 시점을 탐색합니다. } } } mean(I) cat(&#39;자본금이 남아있을 확률 95%신뢰구간 [&#39;,mean(I)- 1.96*sd(I) /sqrt(n.sim),&#39;,&#39;,mean(I) + 1.96*sd(I)/sqrt(n.sim), &#39;] n&#39;) . 0.916666666666667 자본금이 남아있을 확률 95%신뢰구간 [ 0.8853385 , 0.9479949 ] . 자본금이 음수가 되지 않을 확률이 90%정도 됩니다. 신뢰구간도 구할 수 있군요. . 강의는 여기까지 가르쳤는데요. 시험문제는 이를 응용하는 문제가 나올 수 있습니다. . 제일 쉬운 예시로 고객의 가입과 탈퇴가 포함된 함수를 만드는 문제가 나올수도 있겠습니다. . 신규고객 가입을 람다가 1인 포아송 과정으로, 기존 고객 탈퇴를 람다가 0.1인 포아송 과정으로 하겠습니다. . 그리고 기존 고객의 초기 수를 10으로 하겠습니다. . n.sim &lt;- 100 n0 &lt;- 10; a0 &lt;- 25000; T &lt;- 365; c &lt;- 11000 alpha &lt;- 10; nu &lt;- 1; mu &lt;- 0.1 # 이부분만 바꿔주면 됨 generate.Y &lt;- function() rexp(1, rate = 1/1000) I &lt;- numeric(length = n.sim) for (i in 1:n.sim){ t &lt;- 0; a &lt;- a0; n &lt;- n0 total.rate &lt;- nu + n * mu + n * alpha tE &lt;- rexp(1, rate = total.rate) repeat{ if (tE &gt; T) { I[i] &lt;- 1 break } if (tE &lt;= T){ a &lt;- a + n * c * (tE - t) t &lt;- tE J &lt;- sample(1:3, 1, prob = c(nu, n*mu, n*alpha)) if (J == 1) n &lt;- n + 1 if (J == 2){ n &lt;- n - 1 if (n == 0){ #보험금이 0이된 경우. I[i] &lt;- 0 break } } if (J == 3){ Y &lt;- generate.Y(); if (Y &gt; a){ I[i] &lt;- 0 break } else a &lt;- a - Y } tE &lt;- t + rexp(1,rate=total.rate) } } } mean(I) cat(&#39;자본금이 남아있을 확률 95%신뢰구간 [&#39;,mean(I)- 1.96*sd(I) /sqrt(n.sim),&#39;,&#39;,mean(I) + 1.96*sd(I)/sqrt(n.sim), &#39;] n&#39;) . 0.36 자본금이 남아있을 확률 95%신뢰구간 [ 0.265446 , 0.454554 ] . 이미 세 사건이 일어날걸 가정하고 함수를 다 만들어나서 단순히 nu와 mu값만 넣어주면 됩니다. . 다만 보험 가입자가 0명이 될 경우도 있는데 그 경우 또한 실패로 하겠습니다. . 확실히 가입자가 늘어나고 탈퇴를 할 수 있는 등 불확실성이 커지니 자본금이 음이 될 확률이 줄어들었습니다. . 6.8&#51208; &#51452;&#49885; &#50741;&#49496; &#54665;&#49324; &#51204;&#47029; . t시점에 주식 가격 S(t) = S(0) * exp(x1 + x2 .. + xt) 이라고 가정합니다. 이때 xi는 iid인 정규분포 변수입니다. . 알파 &lt; 평균 + 분산 / 2 (정규분포 평균, 분산) 일때 좋은 전략이 다음과 같이 알려져있습니다. . P(m) = S(N-m) 이라고 할때(만기를 m 앞둔 시점에서의 주가) 다음 조건이 만족하면 옵션을 행사합니다. . P(m) &gt; K(옵션권한가격 = 초기가격) 쉽게 얘기해 주식 가격이 초기가격보다 높아야합니다. 당연하죠. | P(m) &gt; K + f(i) 을 i = 1,2, .. , m 구간에서 모두 만족해야합니다. f(i)는 식이 복잡해 생략합니다. | 또 다른 전략은 끝나는 시점까지 기다렸다가 최종 시점 주식 가격이 K보다 클때만 사는 전략입니다. . 두 전략중 어떤 전략이 좋을지 모의실험 1000회를 통해 알아봅시다. . n.sim &lt;- 1000 # 실험횟수 N &lt;- 20; K &lt;- 100; S.zero &lt;- 100; mu &lt;- -0.05 # N : 기간, K, S.zero : 초기 금액(사실 어느값을 써도 비슷함) sg &lt;- 0.3; alp &lt;- mu + 0.5*sg^2 # mu = -0.05, 시그마 = 0.3 E &lt;- numeric(length = n.sim) E2 &lt;- numeric(length = n.sim) for (i in 1:n.sim){ S &lt;- S.zero * exp(cumsum(rnorm(N,mu,sg))) # 주식 가격을 구해놓음. E2[i] &lt;- max(S[N] - K, 0) # 최종시점 주식 가격이 K보다 크면 그만큼 이득, 아니면 이득 0. P &lt;- numeric(length=N+1) # P[0]은 R에서 쓸수 없음. 그래서 길이 자체를 N+1로 해줌. P[N+1] &lt;- S.zero #초기값 부여 m &lt;- N - 1 # m 초기값 부여. 미리 값 1을 뺀 모양새.(위에서 P[N+1] 초기값을 부여했기 때문에) flag &lt;- FALSE repeat{ m.plus &lt;- m + 1 # P에서는 m값을 1을 올려서 해줌. P[m.plus] &lt;- S[N-m] # 값 넣어줌. if(P[m.plus] &gt; K) flag &lt;- TRUE # 1번조건 만족 표현 if(flag &amp; m &gt; 0){ # 조건1만족 + m이 0아닐때(m이 0일때는 1번조건만 따짐.) b &lt;- ((1:m)*mu - log(K/P[m.plus])) / (sg*sqrt(1:m)) op &lt;- P[m.plus] * exp((1:m)*alp)* pnorm(sg*sqrt(1:m) + b) - K * pnorm(b) # 복잡한 식 f(i), 벡터 형태로 되어있음. flag &lt;- all(P[m.plus] &gt; K + op) # all은 모든 조건이 true일때만 true를 보내줌. } if(flag) break else m &lt;- m - 1 # 조건을 모두 만족하면 즉시 옵션 행사. if(m &lt; 0) break # 시점이 모두 끝났으면 종료. } if (flag) E[i] &lt;- P[m.plus] - K else E[i] &lt;- 0 # 조건 만족시 이득본 만큼 기록. } cat(&#39;전략1 95%신뢰구간 [&#39;,mean(E) - 1.96*sd(E)/sqrt(n.sim), &#39;,&#39;,mean(E) + 1.96*sd(E)/sqrt(n.sim), &#39;] n&#39;) cat(&#39;전략2 95%신뢰구간 [&#39;,mean(E2) - 1.96*sd(E2)/sqrt(n.sim), &#39;,&#39;,mean(E2) + 1.96*sd(E2)/sqrt(n.sim), &#39;] n&#39;) . 전략1 95%신뢰구간 [ 35.36105 , 45.49005 ] 전략2 95%신뢰구간 [ 28.57401 , 44.68403 ] . 여러번 실행을 해보면 전략1과 전략2의 이득 평균이 비슷합니다. . 다만 전략2의 신뢰구간이 큰 것은 그만큼 전략2가 불안정한 전략임을 알 수 있습니다. . &#48512;&#53944;&#49828;&#53944;&#47129; &#51060;&#47200; . 뽑힌 표본들을 새로운 분포로 가정하여 반복추출(복원추출)을 통해 모수를 추정하는 방법 입니다. . 표본들이 실제 분포와 비슷할 수록 모수 추정이 더 정확해집니다. . 이 방법의 장점은 중심극한정리 등 분포가정을 하지 않아도 된다는 점입니다. . 다음은 부트스트렙 예시로, 표본들이 있을때 Var(s^2)의 추정량을 구하는 문제입니다. . x &lt;- c(5,4,9,6,21,17,11,20,7,10,21,15,13,16,8) n &lt;- 15 B &lt;- 400 # 400번 실시 f.var &lt;- function(x) var(sample(x, n, rep = T)) b.var &lt;- replicate(B, f.var(x)) var(b.var) # estimate of var(s^2) hist(b.var) . 57.6508361857024",
            "url": "https://ksy1526.github.io/myblog//myblog/2021/10/21/%EC%8B%9C%EB%AE%AC%EB%A0%88%EC%9D%B4%EC%85%98_%EA%B3%BC%EB%AA%A9_%EB%B3%B5%EC%8A%B5.html",
            "relUrl": "/2021/10/21/%EC%8B%9C%EB%AE%AC%EB%A0%88%EC%9D%B4%EC%85%98_%EA%B3%BC%EB%AA%A9_%EB%B3%B5%EC%8A%B5.html",
            "date": " • Oct 21, 2021"
        }
        
    
  
    
        ,"post8": {
            "title": "[SSUDA] 택시 데이터 분석",
            "content": ". &#45936;&#51060;&#53552; &#48520;&#47084;&#50724;&#44592; . !pip install kaggle from google.colab import files files.upload() . Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12) Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0) Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.62.3) Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.5.30) Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3) Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2) Requirement already satisfied: six&gt;=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0) Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2) Requirement already satisfied: text-unidecode&gt;=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify-&gt;kaggle) (1.3) Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;kaggle) (2.10) Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;kaggle) (3.0.4) . Upload widget is only available when the cell has been executed in the current browser session. Please rerun this cell to enable. Saving kaggle.json to kaggle (3).json . {&#39;kaggle.json&#39;: b&#39;{&#34;username&#34;:&#34;ksy1998&#34;,&#34;key&#34;:&#34;23e68db36970b65937516103c630ba75&#34;}&#39;} . !mkdir -p ~/.kaggle !cp kaggle.json ~/.kaggle/ !chmod 600 ~/.kaggle/kaggle.json . !kaggle competitions download -c nyc-taxi-trip-duration . Warning: Looks like you&#39;re using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4) train.zip: Skipping, found more recently modified local copy (use --force to force download) test.zip: Skipping, found more recently modified local copy (use --force to force download) sample_submission.zip: Skipping, found more recently modified local copy (use --force to force download) . !unzip train.zip !unzip test.zip !unzip sample_submission.zip . Archive: train.zip replace train.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: Y inflating: train.csv Archive: test.zip replace test.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: Y inflating: test.csv Archive: sample_submission.zip replace sample_submission.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: Y inflating: sample_submission.csv . 압축되어 있는 데이터라서 압축 풀어줍니다. . %matplotlib inline import pandas as pd from datetime import datetime import pandas as pd from sklearn.model_selection import train_test_split from sklearn.linear_model import LinearRegression, Ridge,BayesianRidge from sklearn.cluster import MiniBatchKMeans from sklearn.metrics import mean_squared_error from math import radians, cos, sin, asin, sqrt import seaborn as sns import matplotlib import numpy as np import matplotlib.pyplot as plt plt.rcParams[&#39;figure.figsize&#39;] = [16, 10] . train = pd.read_csv(&#39;./train.csv&#39;) test = pd.read_csv(&#39;./test.csv&#39;) . &#45936;&#51060;&#53552; &#53456;&#49353; . train.head() . id vendor_id pickup_datetime dropoff_datetime passenger_count pickup_longitude pickup_latitude dropoff_longitude dropoff_latitude store_and_fwd_flag trip_duration . 0 id2875421 | 2 | 2016-03-14 17:24:55 | 2016-03-14 17:32:30 | 1 | -73.982155 | 40.767937 | -73.964630 | 40.765602 | N | 455 | . 1 id2377394 | 1 | 2016-06-12 00:43:35 | 2016-06-12 00:54:38 | 1 | -73.980415 | 40.738564 | -73.999481 | 40.731152 | N | 663 | . 2 id3858529 | 2 | 2016-01-19 11:35:24 | 2016-01-19 12:10:48 | 1 | -73.979027 | 40.763939 | -74.005333 | 40.710087 | N | 2124 | . 3 id3504673 | 2 | 2016-04-06 19:32:31 | 2016-04-06 19:39:40 | 1 | -74.010040 | 40.719971 | -74.012268 | 40.706718 | N | 429 | . 4 id2181028 | 2 | 2016-03-26 13:30:55 | 2016-03-26 13:38:10 | 1 | -73.973053 | 40.793209 | -73.972923 | 40.782520 | N | 435 | . train.describe() . vendor_id passenger_count pickup_longitude pickup_latitude dropoff_longitude dropoff_latitude trip_duration . count 1.458644e+06 | 1.458644e+06 | 1.458644e+06 | 1.458644e+06 | 1.458644e+06 | 1.458644e+06 | 1.458644e+06 | . mean 1.534950e+00 | 1.664530e+00 | -7.397349e+01 | 4.075092e+01 | -7.397342e+01 | 4.075180e+01 | 9.594923e+02 | . std 4.987772e-01 | 1.314242e+00 | 7.090186e-02 | 3.288119e-02 | 7.064327e-02 | 3.589056e-02 | 5.237432e+03 | . min 1.000000e+00 | 0.000000e+00 | -1.219333e+02 | 3.435970e+01 | -1.219333e+02 | 3.218114e+01 | 1.000000e+00 | . 25% 1.000000e+00 | 1.000000e+00 | -7.399187e+01 | 4.073735e+01 | -7.399133e+01 | 4.073588e+01 | 3.970000e+02 | . 50% 2.000000e+00 | 1.000000e+00 | -7.398174e+01 | 4.075410e+01 | -7.397975e+01 | 4.075452e+01 | 6.620000e+02 | . 75% 2.000000e+00 | 2.000000e+00 | -7.396733e+01 | 4.076836e+01 | -7.396301e+01 | 4.076981e+01 | 1.075000e+03 | . max 2.000000e+00 | 9.000000e+00 | -6.133553e+01 | 5.188108e+01 | -6.133553e+01 | 4.392103e+01 | 3.526282e+06 | . train.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 1458644 entries, 0 to 1458643 Data columns (total 11 columns): # Column Non-Null Count Dtype -- -- 0 id 1458644 non-null object 1 vendor_id 1458644 non-null int64 2 pickup_datetime 1458644 non-null object 3 dropoff_datetime 1458644 non-null object 4 passenger_count 1458644 non-null int64 5 pickup_longitude 1458644 non-null float64 6 pickup_latitude 1458644 non-null float64 7 dropoff_longitude 1458644 non-null float64 8 dropoff_latitude 1458644 non-null float64 9 store_and_fwd_flag 1458644 non-null object 10 trip_duration 1458644 non-null int64 dtypes: float64(4), int64(3), object(4) memory usage: 122.4+ MB . test.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 625134 entries, 0 to 625133 Data columns (total 9 columns): # Column Non-Null Count Dtype -- -- 0 id 625134 non-null object 1 vendor_id 625134 non-null int64 2 pickup_datetime 625134 non-null object 3 passenger_count 625134 non-null int64 4 pickup_longitude 625134 non-null float64 5 pickup_latitude 625134 non-null float64 6 dropoff_longitude 625134 non-null float64 7 dropoff_latitude 625134 non-null float64 8 store_and_fwd_flag 625134 non-null object dtypes: float64(4), int64(2), object(3) memory usage: 42.9+ MB . dropoff_datetime 변수가 test에는 없습니다. 도착 시간을 맞추는 예제이기 때문에 그렇습니다. . &#48152;&#51025;&#48320;&#49688; &#44288;&#52272; . plt.figure(figsize=(8,6)) plt.scatter(range(train.shape[0]), np.sort(train.trip_duration.values)) plt.xlabel(&#39;index&#39;, fontsize=12) plt.ylabel(&#39;trip duration&#39;, fontsize=12) plt.show() . 반응변수의 이상치가 많아보입니다. 제거하겠습니다. . m = np.mean(train[&#39;trip_duration&#39;]) s = np.std(train[&#39;trip_duration&#39;]) train = train[train[&#39;trip_duration&#39;] &lt;= m + 2*s] train = train[train[&#39;trip_duration&#39;] &gt;= m - 2*s] plt.figure(figsize=(8,6)) plt.scatter(range(train.shape[0]), np.sort(train.trip_duration.values)) plt.xlabel(&#39;index&#39;, fontsize=12) plt.ylabel(&#39;trip duration&#39;, fontsize=12) plt.show() . 이상치는 대부분 제거된 것 같습니다. 다만 일부 데이터가 큰 값을 갖는거 같아요. . plt.hist(train[&#39;trip_duration&#39;].values, bins=100) plt.xlabel(&#39;trip_duration&#39;) plt.ylabel(&#39;number of train records&#39;) plt.show() . 히스토그램으로 확인하니 그렇습니다. 우측 꼬리가 긴 모양으로 로그변환이 필요해보입니다. . train[&#39;log_trip_duration&#39;] = np.log(train[&#39;trip_duration&#39;].values + 1) plt.hist(train[&#39;log_trip_duration&#39;].values, bins=100) plt.xlabel(&#39;log(trip_duration)&#39;) plt.ylabel(&#39;number of train records&#39;) plt.show() sns.distplot(train[&quot;log_trip_duration&quot;], bins =100) . /usr/local/lib/python3.7/dist-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms). warnings.warn(msg, FutureWarning) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f99495dd450&gt; . 확실히 그래프 모양이 괜찮아졌습니다. distplot 함수를 통해 그리기도 하였네요 . &#45936;&#51060;&#53552; &#51204;&#52376;&#47532; . train = train[train[&#39;pickup_longitude&#39;] &lt;= -73.75] train = train[train[&#39;pickup_longitude&#39;] &gt;= -74.03] train = train[train[&#39;pickup_latitude&#39;] &lt;= 40.85] train = train[train[&#39;pickup_latitude&#39;] &gt;= 40.63] train = train[train[&#39;dropoff_longitude&#39;] &lt;= -73.75] train = train[train[&#39;dropoff_longitude&#39;] &gt;= -74.03] train = train[train[&#39;dropoff_latitude&#39;] &lt;= 40.85] train = train[train[&#39;dropoff_latitude&#39;] &gt;= 40.63] . 뉴욕의 위도는 (-74.03, -73.75) 경도는 (40.63, 40.85) 사이 입니다. . 이 값을 벗어나는 위도/경도 데이터를 제거하겠습니다. . train[&#39;pickup_datetime&#39;] = pd.to_datetime(train.pickup_datetime) test[&#39;pickup_datetime&#39;] = pd.to_datetime(test.pickup_datetime) train.loc[:, &#39;pickup_date&#39;] = train[&#39;pickup_datetime&#39;].dt.date test.loc[:, &#39;pickup_date&#39;] = test[&#39;pickup_datetime&#39;].dt.date train[&#39;dropoff_datetime&#39;] = pd.to_datetime(train.dropoff_datetime) #Not in Test . to_datetime 함수로 datetime 변수로 바궈주었습니다. . plt.plot(train.groupby(&#39;pickup_date&#39;).count()[[&#39;id&#39;]], &#39;o-&#39;, label=&#39;train&#39;) plt.plot(test.groupby(&#39;pickup_date&#39;).count()[[&#39;id&#39;]], &#39;o-&#39;, label=&#39;test&#39;) plt.title(&#39;Trips over Time.&#39;) plt.legend(loc=0) plt.ylabel(&#39;Trips&#39;) plt.show() . 트레인과 테스트 데이터를 같이 그리니 유사한 측면을 발견하기가 쉬운것 같아요. . 1월 하순경 이동횟수가 급격하게 감소한것이 관찰됩니다. 또 5월 하순경 감소세가 또 관찰됩니다. . 계절적으로 추운것도 있겠지만 작성자는 다른 요인이 있지 않을까 생각하네요. . import warnings warnings.filterwarnings(&quot;ignore&quot;) plot_vendor = train.groupby(&#39;vendor_id&#39;)[&#39;trip_duration&#39;].mean() plt.subplots(1,1,figsize=(17,10)) plt.ylim(ymin=800) plt.ylim(ymax=840) sns.barplot(plot_vendor.index,plot_vendor.values) plt.title(&#39;Time per Vendor&#39;) plt.legend(loc=0) plt.ylabel(&#39;Time in Seconds&#39;) . No handles with labels found to put in legend. . Text(0, 0.5, &#39;Time in Seconds&#39;) . 범위를 800~840으로 두어서 그렇지 두 vendor 간 큰 차이를 보이진 않습니다. . snwflag = train.groupby(&#39;store_and_fwd_flag&#39;)[&#39;trip_duration&#39;].mean() plt.subplots(1,1,figsize=(17,10)) plt.ylim(ymin=0) plt.ylim(ymax=1100) plt.title(&#39;Time per store_and_fwd_flag&#39;) plt.legend(loc=0) plt.ylabel(&#39;Time in Seconds&#39;) sns.barplot(snwflag.index,snwflag.values) . No handles with labels found to put in legend. . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f993c2c18d0&gt; . 공급업체에 보내기 전 기록이 잘 저장되었는지 나타내는 변수로 꽤 많이 차이가 납니다. . 작성자는 일부 직원이 이동시간을 정확히 기록하지 못해 발생하는 왜곡이라고 말합니다. . pc = train.groupby(&#39;passenger_count&#39;)[&#39;trip_duration&#39;].mean() plt.subplots(1,1,figsize=(17,10)) plt.ylim(ymin=0) plt.ylim(ymax=1100) plt.title(&#39;Time per store_and_fwd_flag&#39;) plt.legend(loc=0) plt.ylabel(&#39;Time in Seconds&#39;) sns.barplot(pc.index,pc.values) . No handles with labels found to put in legend. . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f993c2b0550&gt; . 승객 수는 뚜렷한 여행을 주지 못합니다. . 승객을 아무도 태우지 않았는데 4분정도 이동한 것은 직원의 실수로 보입니다. . train.groupby(&#39;passenger_count&#39;).size() . passenger_count 0 52 1 1018715 2 206864 3 58989 4 27957 5 76912 6 47639 dtype: int64 . &#50948;&#52824; &#45936;&#51060;&#53552; . city_long_border = (-74.03, -73.75) city_lat_border = (40.63, 40.85) fig, ax = plt.subplots(ncols=2, sharex=True, sharey=True) ax[0].scatter(train[&#39;pickup_longitude&#39;].values[:100000], train[&#39;pickup_latitude&#39;].values[:100000], color=&#39;blue&#39;, s=1, label=&#39;train&#39;, alpha=0.1) ax[1].scatter(test[&#39;pickup_longitude&#39;].values[:100000], test[&#39;pickup_latitude&#39;].values[:100000], color=&#39;green&#39;, s=1, label=&#39;test&#39;, alpha=0.1) fig.suptitle(&#39;Train and test area complete overlap.&#39;) ax[0].legend(loc=0) ax[0].set_ylabel(&#39;latitude&#39;) ax[0].set_xlabel(&#39;longitude&#39;) ax[1].set_xlabel(&#39;longitude&#39;) ax[1].legend(loc=0) plt.ylim(city_lat_border) plt.xlim(city_long_border) plt.show() . 자세한 코드 관찰은 위치 데이터 분석을 할때 다시 확인하겠습니다. . train, test 간 위치 데이터가 매우 유사함을 알 수 있습니다. . def haversine_array(lat1, lng1, lat2, lng2): lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2)) AVG_EARTH_RADIUS = 6371 # in km lat = lat2 - lat1 lng = lng2 - lng1 d = np.sin(lat * 0.5) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(lng * 0.5) ** 2 h = 2 * AVG_EARTH_RADIUS * np.arcsin(np.sqrt(d)) return h def dummy_manhattan_distance(lat1, lng1, lat2, lng2): a = haversine_array(lat1, lng1, lat1, lng2) b = haversine_array(lat1, lng1, lat2, lng1) return a + b def bearing_array(lat1, lng1, lat2, lng2): AVG_EARTH_RADIUS = 6371 # in km lng_delta_rad = np.radians(lng2 - lng1) lat1, lng1, lat2, lng2 = map(np.radians, (lat1, lng1, lat2, lng2)) y = np.sin(lng_delta_rad) * np.cos(lat2) x = np.cos(lat1) * np.sin(lat2) - np.sin(lat1) * np.cos(lat2) * np.cos(lng_delta_rad) return np.degrees(np.arctan2(y, x)) . train.loc[:, &#39;distance_haversine&#39;] = haversine_array(train[&#39;pickup_latitude&#39;].values, train[&#39;pickup_longitude&#39;].values, train[&#39;dropoff_latitude&#39;].values, train[&#39;dropoff_longitude&#39;].values) test.loc[:, &#39;distance_haversine&#39;] = haversine_array(test[&#39;pickup_latitude&#39;].values, test[&#39;pickup_longitude&#39;].values, test[&#39;dropoff_latitude&#39;].values, test[&#39;dropoff_longitude&#39;].values) train.loc[:, &#39;distance_dummy_manhattan&#39;] = dummy_manhattan_distance(train[&#39;pickup_latitude&#39;].values, train[&#39;pickup_longitude&#39;].values, train[&#39;dropoff_latitude&#39;].values, train[&#39;dropoff_longitude&#39;].values) test.loc[:, &#39;distance_dummy_manhattan&#39;] = dummy_manhattan_distance(test[&#39;pickup_latitude&#39;].values, test[&#39;pickup_longitude&#39;].values, test[&#39;dropoff_latitude&#39;].values, test[&#39;dropoff_longitude&#39;].values) train.loc[:, &#39;direction&#39;] = bearing_array(train[&#39;pickup_latitude&#39;].values, train[&#39;pickup_longitude&#39;].values, train[&#39;dropoff_latitude&#39;].values, train[&#39;dropoff_longitude&#39;].values) test.loc[:, &#39;direction&#39;] = bearing_array(test[&#39;pickup_latitude&#39;].values, test[&#39;pickup_longitude&#39;].values, test[&#39;dropoff_latitude&#39;].values, test[&#39;dropoff_longitude&#39;].values) . 위도/경도를 활용하여 다양한 관측값을 나타내는 함수입니다. . 이해하기에 조금 벅차서 일단 다양한 변수를 추가해줄수 있구나 하고 넘어갔네요. . coords = np.vstack((train[[&#39;pickup_latitude&#39;, &#39;pickup_longitude&#39;]].values, train[[&#39;dropoff_latitude&#39;, &#39;dropoff_longitude&#39;]].values)) sample_ind = np.random.permutation(len(coords))[:500000] kmeans = MiniBatchKMeans(n_clusters=100, batch_size=10000).fit(coords[sample_ind]) train.loc[:, &#39;pickup_cluster&#39;] = kmeans.predict(train[[&#39;pickup_latitude&#39;, &#39;pickup_longitude&#39;]]) train.loc[:, &#39;dropoff_cluster&#39;] = kmeans.predict(train[[&#39;dropoff_latitude&#39;, &#39;dropoff_longitude&#39;]]) test.loc[:, &#39;pickup_cluster&#39;] = kmeans.predict(test[[&#39;pickup_latitude&#39;, &#39;pickup_longitude&#39;]]) test.loc[:, &#39;dropoff_cluster&#39;] = kmeans.predict(test[[&#39;dropoff_latitude&#39;, &#39;dropoff_longitude&#39;]]) . np.vstack는 데이터를 묶어주는 함수입니다. . 위도, 경도 데이터를 클러스트로 묶어주었습니다. . fig, ax = plt.subplots(ncols=1, nrows=1) ax.scatter(train.pickup_longitude.values[:500000], train.pickup_latitude.values[:500000], s=10, lw=0, c=train.pickup_cluster[:500000].values, cmap=&#39;autumn&#39;, alpha=0.2) ax.set_xlim(city_long_border) ax.set_ylim(city_lat_border) ax.set_xlabel(&#39;Longitude&#39;) ax.set_ylabel(&#39;Latitude&#39;) plt.show() . 군집화가 잘된 것을 시각적으로 확인하였습니다. . &#45216;&#51676; &#45936;&#51060;&#53552; . train[&#39;Month&#39;] = train[&#39;pickup_datetime&#39;].dt.month test[&#39;Month&#39;] = test[&#39;pickup_datetime&#39;].dt.month train[&#39;DayofMonth&#39;] = train[&#39;pickup_datetime&#39;].dt.day test[&#39;DayofMonth&#39;] = test[&#39;pickup_datetime&#39;].dt.day train[&#39;Hour&#39;] = train[&#39;pickup_datetime&#39;].dt.hour test[&#39;Hour&#39;] = test[&#39;pickup_datetime&#39;].dt.hour train[&#39;dayofweek&#39;] = train[&#39;pickup_datetime&#39;].dt.dayofweek test[&#39;dayofweek&#39;] = test[&#39;pickup_datetime&#39;].dt.dayofweek . 픽업된 시간으로 다양한 파생 날짜/시간 데이터를 생성한 모습입니다. datetime 변수이기에 가능한 모습입니다. . 여기서 dayofweek 변수는 요일변수로 0을 일요일로 생각하여 6을 토요일까지 쓰는 변수입니다. . train.loc[:, &#39;avg_speed_h&#39;] = 1000 * train[&#39;distance_haversine&#39;] / train[&#39;trip_duration&#39;] train.loc[:, &#39;avg_speed_m&#39;] = 1000 * train[&#39;distance_dummy_manhattan&#39;] / train[&#39;trip_duration&#39;] fig, ax = plt.subplots(ncols=3, sharey=True) ax[0].plot(train.groupby(&#39;Hour&#39;).mean()[&#39;avg_speed_h&#39;], &#39;bo-&#39;, lw=2, alpha=0.7) ax[1].plot(train.groupby(&#39;dayofweek&#39;).mean()[&#39;avg_speed_h&#39;], &#39;go-&#39;, lw=2, alpha=0.7) ax[2].plot(train.groupby(&#39;Month&#39;).mean()[&#39;avg_speed_h&#39;], &#39;ro-&#39;, lw=2, alpha=0.7) ax[0].set_xlabel(&#39;Hour of Day&#39;) ax[1].set_xlabel(&#39;Day of Week&#39;) ax[2].set_xlabel(&#39;Month of Year&#39;) ax[0].set_ylabel(&#39;Average Speed&#39;) fig.suptitle(&#39;Average Traffic Speed by Date-part&#39;) plt.show() . 정확히 이해하진 못했지만 distance_haversine가 위치 변수를 보고 만든 거리 변수입니다. . 그렇기 때문에 거리 / 시간 = 평균속도 변수를 만들었습니다. 이 평균속도를 시각/요일/달 별로 얼마나 다른지 시각화했습니다. . 물론 분모인 시간이 반응변수 이기 때문에 분석에 사용할수는 없습니다. . 보통 오전 5시~9시, 오후 5시(17시) ~ 7시(19시) 사이가 가장 도로가 혼잡해 속도가 떨어집니다. . 예상과 어느정도 일치하면서도 출/퇴근 이외 근무시간도 속도가 출/퇴근 시간과 비슷하게 떨어집니다. . 또 금토일의 평균속도가 상대적으로 빠르며 달별로는 겨울의 평균속도가 빠릅니다. . &#50896;&#54635;&#51064;&#53076;&#46377; . vendor_train = pd.get_dummies(train[&#39;vendor_id&#39;], prefix=&#39;vi&#39;, prefix_sep=&#39;_&#39;) vendor_test = pd.get_dummies(test[&#39;vendor_id&#39;], prefix=&#39;vi&#39;, prefix_sep=&#39;_&#39;) passenger_count_train = pd.get_dummies(train[&#39;passenger_count&#39;], prefix=&#39;pc&#39;, prefix_sep=&#39;_&#39;) passenger_count_test = pd.get_dummies(test[&#39;passenger_count&#39;], prefix=&#39;pc&#39;, prefix_sep=&#39;_&#39;) store_and_fwd_flag_train = pd.get_dummies(train[&#39;store_and_fwd_flag&#39;], prefix=&#39;sf&#39;, prefix_sep=&#39;_&#39;) store_and_fwd_flag_test = pd.get_dummies(test[&#39;store_and_fwd_flag&#39;], prefix=&#39;sf&#39;, prefix_sep=&#39;_&#39;) cluster_pickup_train = pd.get_dummies(train[&#39;pickup_cluster&#39;], prefix=&#39;p&#39;, prefix_sep=&#39;_&#39;) cluster_pickup_test = pd.get_dummies(test[&#39;pickup_cluster&#39;], prefix=&#39;p&#39;, prefix_sep=&#39;_&#39;) cluster_dropoff_train = pd.get_dummies(train[&#39;dropoff_cluster&#39;], prefix=&#39;d&#39;, prefix_sep=&#39;_&#39;) cluster_dropoff_test = pd.get_dummies(test[&#39;dropoff_cluster&#39;], prefix=&#39;d&#39;, prefix_sep=&#39;_&#39;) month_train = pd.get_dummies(train[&#39;Month&#39;], prefix=&#39;m&#39;, prefix_sep=&#39;_&#39;) month_test = pd.get_dummies(test[&#39;Month&#39;], prefix=&#39;m&#39;, prefix_sep=&#39;_&#39;) dom_train = pd.get_dummies(train[&#39;DayofMonth&#39;], prefix=&#39;dom&#39;, prefix_sep=&#39;_&#39;) dom_test = pd.get_dummies(test[&#39;DayofMonth&#39;], prefix=&#39;dom&#39;, prefix_sep=&#39;_&#39;) hour_train = pd.get_dummies(train[&#39;Hour&#39;], prefix=&#39;h&#39;, prefix_sep=&#39;_&#39;) hour_test = pd.get_dummies(test[&#39;Hour&#39;], prefix=&#39;h&#39;, prefix_sep=&#39;_&#39;) dow_train = pd.get_dummies(train[&#39;dayofweek&#39;], prefix=&#39;dow&#39;, prefix_sep=&#39;_&#39;) dow_test = pd.get_dummies(test[&#39;dayofweek&#39;], prefix=&#39;dow&#39;, prefix_sep=&#39;_&#39;) . 범주형 변수들을 전부 원핫인코딩을 했습니다. . prefix 와 prefix_sep 으로 원핫인코딩 변수 이름도 설정할수 있네요. . passenger_count_test = passenger_count_test.drop(&#39;pc_9&#39;, axis = 1) . 다만 9명이 탑승한 2건은 표본이 너무 적어 과적합될수도 있고 직관적으로도 말이 안되서 열을 삭제합니다. . train = train.drop([&#39;id&#39;,&#39;vendor_id&#39;,&#39;passenger_count&#39;,&#39;store_and_fwd_flag&#39;,&#39;Month&#39;,&#39;DayofMonth&#39;,&#39;Hour&#39;,&#39;dayofweek&#39;,&#39;pickup_datetime&#39;, &#39;pickup_date&#39;,&#39;pickup_longitude&#39;,&#39;pickup_latitude&#39;,&#39;dropoff_longitude&#39;,&#39;dropoff_latitude&#39;],axis = 1) Test_id = test[&#39;id&#39;] test = test.drop([&#39;id&#39;,&#39;vendor_id&#39;,&#39;passenger_count&#39;,&#39;store_and_fwd_flag&#39;,&#39;Month&#39;,&#39;DayofMonth&#39;,&#39;Hour&#39;,&#39;dayofweek&#39;, &#39;pickup_datetime&#39;, &#39;pickup_date&#39;, &#39;pickup_longitude&#39;,&#39;pickup_latitude&#39;,&#39;dropoff_longitude&#39;,&#39;dropoff_latitude&#39;], axis = 1) train = train.drop([&#39;dropoff_datetime&#39;,&#39;avg_speed_h&#39;,&#39;avg_speed_m&#39;,&#39;trip_duration&#39;], axis = 1) . 원핫인코딩 된 변수들, 시각화를 위해 만들었던 변수들, 변환한 변수들, id 등 필요없는 변수를 제거합니다. . Train_Master = pd.concat([train, vendor_train, passenger_count_train, store_and_fwd_flag_train, cluster_pickup_train, cluster_dropoff_train, month_train, dom_train, hour_test, dow_train ], axis=1) Test_master = pd.concat([test, vendor_test, passenger_count_test, store_and_fwd_flag_test, cluster_pickup_test, cluster_dropoff_test, month_test, dom_test, hour_test, dow_test], axis=1) Train_Master.shape,Test_master.shape . ((1446345, 285), (625134, 284)) . 원핫인코딩했던 변수들을 합쳐줍니다. . &#47784;&#45944; &#51201;&#54633; . X_train = Train_Master.drop([&#39;log_trip_duration&#39;], axis=1) Y_train = Train_Master[&quot;log_trip_duration&quot;] Y_train = Y_train.reset_index().drop(&#39;index&#39;,axis = 1) . 이 코드 이후로 모델적합을 해야하는데 코랩에서 계속 램이 부족하다고 하네요. . 데이터도 크고, 열 개수도 원핫인코딩으로 늘려서 그런거 같습니다. . XGB였다가 LGB로 바꾸고, 노말모델로 하고 어떻게 해도 계속 램이 부족해서 실행이 안되네요. . 코드를 리뷰하는 목적이고 요즘 시간이 넉넉하지 못해서 여기까지 하겠습니다. . from lightgbm import LGBMRegressor model = LGBMRegressor() model.fit(X_train, Y_train) . pred = model.predict(Test_master) pred = np.exp(pred) submission = pd.concat([Test_id, pd.DataFrame(pred)], axis=1) submission.columns = [&#39;id&#39;,&#39;trip_duration&#39;] submission[&#39;trip_duration&#39;] = submission.apply(lambda x : 1 if (x[&#39;trip_duration&#39;] &lt;= 0) else x[&#39;trip_duration&#39;], axis = 1) submission.to_csv(&quot;./submission.csv&quot;, index=False) . !kaggle competitions submit -c nyc-taxi-trip-duration -f submission.csv -m &quot;Message&quot; . &#45712;&#45184;&#51216; . 우선 스스로 고른 데이터인데 위도, 경도를 이용한 데이터여서 조금 어려웠습니다. . 주에 하나씩 코드 리뷰를 하는데 열심히 하면 위치 데이터를 이해하는데 큰 도움이 되겠지만 당장 필요한 기술이 아니라 넘어갔네요. . 한것만 보면 크게 고생한거 같진 않지만, 너무 복잡한 코드들이 많아서 어느정도 했다가 어려워서 처음부터 다시 세번정도 한거 같습니다. . 그래도 남의 코드를 보면서 참 많은걸 배우네요. 시간이 생각보다 많이 들긴 했는데, 그 만큼 배워가는게 있는거 같아요. . 여기에 못담고 지운 코드들 중에도 배운 코드가 많아요. 예를 들어 판다스 옵션을 건드는 코드? . 데이콘 대회에도 도움이 될 거 같습니다. .",
            "url": "https://ksy1526.github.io/myblog//myblog/ssuda/jupyter/kaggle/datetime/scale/location/regression/2021/10/07/kagglestudy3.html",
            "relUrl": "/ssuda/jupyter/kaggle/datetime/scale/location/regression/2021/10/07/kagglestudy3.html",
            "date": " • Oct 7, 2021"
        }
        
    
  
    
        ,"post9": {
            "title": "[머신러닝 가이드] 6-1 주성분 분석(PCA)",
            "content": ". &#48531;&#44867; &#45936;&#51060;&#53552; . from sklearn.datasets import load_iris import pandas as pd import matplotlib.pyplot as plt %matplotlib inline iris = load_iris() columns = [&#39;sepal_length&#39;, &#39;sepal_width&#39;, &#39;petal_length&#39;, &#39;petal_width&#39;] irisDF = pd.DataFrame(iris.data, columns = columns) irisDF[&#39;target&#39;] = iris.target irisDF.head(3) . sepal_length sepal_width petal_length petal_width target . 0 5.1 | 3.5 | 1.4 | 0.2 | 0 | . 1 4.9 | 3.0 | 1.4 | 0.2 | 0 | . 2 4.7 | 3.2 | 1.3 | 0.2 | 0 | . markers = [&#39;^&#39;,&#39;s&#39;,&#39;o&#39;] for i, marker in enumerate(markers): x_axis_data = irisDF[irisDF[&#39;target&#39;] == i][&#39;sepal_length&#39;] y_axis_data = irisDF[irisDF[&#39;target&#39;] == i][&#39;sepal_width&#39;] plt.scatter(x_axis_data, y_axis_data, marker = marker, label = iris.target_names[i]) plt.legend() plt.xlabel(&#39;sepal length&#39;) plt.ylabel(&#39;sepal width&#39;) plt.show() . 길이를 x축 너비를 y축으로, 도형으로 붓꽃 데이터를 구분했습니다. . 파란색 데이터는 y축값 3이상, x축값 6이하인 곳에 일정하게 분포돼 있습니다. . 노란색과 초록색 데이터는 이 두 특성으로 구분하기 힘듭니다. . from sklearn.preprocessing import StandardScaler iris_scaled = StandardScaler().fit_transform(irisDF.iloc[:,:-1]) . 타겟 값을 제외한 모든 특성을 표준 정규 분포를 따르게 변환했습니다. . PCA방법은 특성의 스케일에 영향을 받기 때문에 동일한 스케일로 변환하는 것이 필수입니다. . from sklearn.decomposition import PCA pca = PCA(n_components = 2) pca.fit(iris_scaled) iris_pca = pca.transform(iris_scaled) print(iris_pca.shape) . (150, 2) . 4차원 데이터를 2차원 PCA 데이터로 변환하였습니다. . pca_columns = [&#39;pca_component_1&#39;, &#39;pca_component_2&#39;] irisDF_pca = pd.DataFrame(iris_pca, columns = pca_columns) irisDF_pca[&#39;target&#39;] = iris.target irisDF_pca.head(3) . pca_component_1 pca_component_2 target . 0 -2.264703 | 0.480027 | 0 | . 1 -2.080961 | -0.674134 | 0 | . 2 -2.364229 | -0.341908 | 0 | . 만들어진 PCA 특성 값으로 데이터 프레임을 만들었습니다. . markers = [&#39;^&#39;,&#39;s&#39;,&#39;o&#39;] for i, marker in enumerate(markers): x_axis_data = irisDF_pca[irisDF[&#39;target&#39;] == i][&#39;pca_component_1&#39;] y_axis_data = irisDF_pca[irisDF[&#39;target&#39;] == i][&#39;pca_component_2&#39;] plt.scatter(x_axis_data, y_axis_data, marker = marker, label = iris.target_names[i]) plt.legend() plt.xlabel(&#39;pca_component_1&#39;) plt.ylabel(&#39;pca_component_2&#39;) plt.show() . 두 개의 pca 특성 값으로 노란색과 초록색 데이터 까지 분류가 가능해집니다. . 사실 두 개의 pca 특성 값에 네 개의 특성값이 섞여있다고 볼 수 있는데요. . 삼차원 이상에 데이터는 시각화 하기 힘들기 때문에 이렇게 시각화 할 수 있는것이 pca분석의 장점이라고 할 수 있습니다. . print(pca.explained_variance_ratio_) . [0.72962445 0.22850762] . explained_varianceratio 값은 변환 된 특성이 얼마나 변동을 설명하는 가를 보여쥽니다. . 두 개의 pca 특성이 약 95% 정도에 변동을 설명하고 있습니다. . from sklearn.ensemble import RandomForestClassifier from sklearn.model_selection import cross_val_score import numpy as np rcf = RandomForestClassifier(random_state = 156) scores = cross_val_score(rcf, iris.data, iris.target, scoring = &#39;accuracy&#39;, cv = 3) print(&#39;개별 정확도 :&#39;, scores) print(&#39;평균 정확도 :&#39;, np.mean(scores)) . 개별 정확도 : [0.98 0.94 0.96] 평균 정확도 : 0.96 . 기존 4차원 데이터를 랜덤포레스트 기법을 이용해서 검정했습니다. . 평균 정확도는 약 96%가 나옵니다. . pca_x = irisDF_pca[[&#39;pca_component_1&#39;,&#39;pca_component_2&#39;]] scores_pca = cross_val_score(rcf, pca_x, iris.target, scoring=&#39;accuracy&#39;, cv = 3) print(&#39;개별 정확도 :&#39;, scores_pca) print(&#39;평균 정확도 :&#39;, np.mean(scores_pca)) . 개별 정확도 : [0.88 0.88 0.88] 평균 정확도 : 0.88 . PCA기법으로 변환한 데이터를 통해 분석한 결과, 평균 정확도는 약 88%가 나옵니다. . 성능이 다소 감소했다고도 볼 수 있습니다. . 하지만 특성 수가 절반이 된 걸 생각해보면 원본 데이터의 특성을 상당부분 잘 유지하고 있다고도 볼 수 있습니다. . &#49888;&#50857;&#52852;&#46300; &#44256;&#44061; &#45936;&#51060;&#53552; &#49464;&#53944; . from google.colab import drive drive.mount(&#39;/content/drive&#39;) . Mounted at /content/drive . import pandas as pd df = pd.read_excel(&#39;/content/drive/MyDrive/credit_card.xls&#39;, header = 1, sheet_name=&#39;Data&#39;).iloc[0:,1:] print(df.shape) df.head(3) . (30000, 24) . LIMIT_BAL SEX EDUCATION MARRIAGE AGE PAY_0 PAY_2 PAY_3 PAY_4 PAY_5 PAY_6 BILL_AMT1 BILL_AMT2 BILL_AMT3 BILL_AMT4 BILL_AMT5 BILL_AMT6 PAY_AMT1 PAY_AMT2 PAY_AMT3 PAY_AMT4 PAY_AMT5 PAY_AMT6 default payment next month . 0 20000 | 2 | 2 | 1 | 24 | 2 | 2 | -1 | -1 | -2 | -2 | 3913 | 3102 | 689 | 0 | 0 | 0 | 0 | 689 | 0 | 0 | 0 | 0 | 1 | . 1 120000 | 2 | 2 | 2 | 26 | -1 | 2 | 0 | 0 | 0 | 2 | 2682 | 1725 | 2682 | 3272 | 3455 | 3261 | 0 | 1000 | 1000 | 1000 | 0 | 2000 | 1 | . 2 90000 | 2 | 2 | 2 | 34 | 0 | 0 | 0 | 0 | 0 | 0 | 29239 | 14027 | 13559 | 14331 | 14948 | 15549 | 1518 | 1500 | 1000 | 1000 | 1000 | 5000 | 0 | . 24개의 특성과 3만개의 데이터가 있습니다. . df.rename(columns={&#39;PAY_0&#39;:&#39;PAY_1&#39;, &#39;default payment next month&#39;:&#39;default&#39;}, inplace=True) y_target = df[&#39;default&#39;] x_features = df.drop(&#39;default&#39;, axis = 1) . pay_0 다음 pay_2 칼럼이 있어서 pay_1로 이름 변경했습니다. . default.. 칼럼도 길어서 짧게 바꿨습니다. . import seaborn as sns import matplotlib.pyplot as plt %matplotlib inline corr = x_features.corr() plt.figure(figsize = (14,14)) sns.heatmap(corr, annot=True, fmt = &#39;.1g&#39;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f76d75da490&gt; . 상관계수 행렬을 관찰해본 결과 PAY 변수끼리, 또 BILL 변수 끼리 상관계수가 매우 높은 것을 알 수 있습니다. . 다중공선성 등 상당부분 문제가 있기 때문에 PCA 방법으로 조정해보겠습니다. . from sklearn.decomposition import PCA from sklearn.preprocessing import StandardScaler cols_bill = [&#39;BILL_AMT&#39;+str(i) for i in range(1,7)] print(&#39;대상 속성명:&#39;, cols_bill) scaler = StandardScaler() df_cols_scaled = scaler.fit_transform(x_features[cols_bill]) pca = PCA(n_components = 2) pca.fit(df_cols_scaled) print(&#39;변동성:&#39;, pca.explained_variance_ratio_) . 대상 속성명: [&#39;BILL_AMT1&#39;, &#39;BILL_AMT2&#39;, &#39;BILL_AMT3&#39;, &#39;BILL_AMT4&#39;, &#39;BILL_AMT5&#39;, &#39;BILL_AMT6&#39;] 변동성: [0.90555253 0.0509867 ] . 단 두 개의 pca 특성으로 변동성을 95프로이상 설명할 수 있습니다. . import numpy as np from sklearn.ensemble import RandomForestClassifier from sklearn.model_selection import cross_val_score rcf = RandomForestClassifier(n_estimators = 300, random_state = 156) scores = cross_val_score(rcf, x_features, y_target, scoring=&#39;accuracy&#39;, cv = 3) print(&#39;개별 정확도:&#39;, scores) print(&#39;평균 정확도:&#39;, np.mean(scores)) . 개별 정확도: [0.8083 0.8196 0.8232] 평균 정확도: 0.8170333333333333 . 원본 데이터를 그대로 적용했을 때 정확도 입니다. . scaler = StandardScaler() df_scaled = scaler.fit_transform(x_features) pca = PCA(n_components = 6) df_pca = pca.fit_transform(df_scaled) scores_pca = cross_val_score(rcf, df_pca, y_target, scoring=&#39;accuracy&#39;, cv = 3) print(&#39;개별 정확도:&#39;, scores_pca) print(&#39;평균 정확도:&#39;, np.mean(scores_pca)) . 개별 정확도: [0.7924 0.7969 0.8012] 평균 정확도: 0.7968333333333334 . 전체 23개의 속성중 6개 속성만 이용했음에도 정확도가 원본 데이터 대비 크게 떨어지지 않습니다. . 이 기법은 최근 컴퓨터 비전 분야에 많이 쓰입니다. .",
            "url": "https://ksy1526.github.io/myblog//myblog/book/jupyter/guide/pca/scale/randomforest/2021/10/06/PythonMachine6_1.html",
            "relUrl": "/book/jupyter/guide/pca/scale/randomforest/2021/10/06/PythonMachine6_1.html",
            "date": " • Oct 6, 2021"
        }
        
    
  
    
        ,"post10": {
            "title": "[머신러닝 가이드] 5-4 실전분석(자전거 대여 수요 예측)",
            "content": ". &#52880;&#44544;&#50640;&#49436; &#45936;&#51060;&#53552; &#51649;&#51217; &#48520;&#47084;&#50724;&#44592; . pip install kaggle --upgrade . Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12) Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.5.30) Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3) Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0) Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2) Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2) Requirement already satisfied: six&gt;=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0) Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.62.2) Requirement already satisfied: text-unidecode&gt;=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify-&gt;kaggle) (1.3) Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;kaggle) (3.0.4) Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;kaggle) (2.10) . !pip install kaggle from google.colab import files files.upload() . Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12) Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2) Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.5.30) Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0) Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3) Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.62.2) Requirement already satisfied: six&gt;=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0) Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2) Requirement already satisfied: text-unidecode&gt;=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify-&gt;kaggle) (1.3) Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;kaggle) (2.10) Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;kaggle) (3.0.4) . Upload widget is only available when the cell has been executed in the current browser session. Please rerun this cell to enable. Saving kaggle.json to kaggle.json . {&#39;kaggle.json&#39;: b&#39;{&#34;username&#34;:&#34;ksy1998&#34;,&#34;key&#34;:&#34;0c820de52cea65ec11954012ef8b00d2&#34;}&#39;} . !mkdir -p ~/.kaggle !cp kaggle.json ~/.kaggle/ # Permission Warning이 발생하지 않도록 해줍니다. !chmod 600 ~/.kaggle/kaggle.json . ! kaggle competitions download -c bike-sharing-demand . Warning: Looks like you&#39;re using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4) Downloading sampleSubmission.csv to /content 0% 0.00/140k [00:00&lt;?, ?B/s] 100% 140k/140k [00:00&lt;00:00, 50.8MB/s] Downloading test.csv to /content 0% 0.00/316k [00:00&lt;?, ?B/s] 100% 316k/316k [00:00&lt;00:00, 44.9MB/s] Downloading train.csv to /content 0% 0.00/633k [00:00&lt;?, ?B/s] 100% 633k/633k [00:00&lt;00:00, 40.4MB/s] . &#45936;&#51060;&#53552; &#46168;&#47084;&#48372;&#44592; &#48143; &#44032;&#44277; . import numpy as np import pandas as pd import seaborn as sns import matplotlib.pyplot as plt %matplotlib inline import warnings warnings.filterwarnings(&#39;ignore&#39;, category = RuntimeWarning) bike_df = pd.read_csv(&#39;./train.csv&#39;) print(bike_df.shape) bike_df.head() . (10886, 12) . datetime season holiday workingday weather temp atemp humidity windspeed casual registered count . 0 2011-01-01 00:00:00 | 1 | 0 | 0 | 1 | 9.84 | 14.395 | 81 | 0.0 | 3 | 13 | 16 | . 1 2011-01-01 01:00:00 | 1 | 0 | 0 | 1 | 9.02 | 13.635 | 80 | 0.0 | 8 | 32 | 40 | . 2 2011-01-01 02:00:00 | 1 | 0 | 0 | 1 | 9.02 | 13.635 | 80 | 0.0 | 5 | 27 | 32 | . 3 2011-01-01 03:00:00 | 1 | 0 | 0 | 1 | 9.84 | 14.395 | 75 | 0.0 | 3 | 10 | 13 | . 4 2011-01-01 04:00:00 | 1 | 0 | 0 | 1 | 9.84 | 14.395 | 75 | 0.0 | 0 | 1 | 1 | . 변수는 11개, 10886개 데이터가 있습니다. datetime변수는 가공이 필요합니다. . bike_df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 10886 entries, 0 to 10885 Data columns (total 12 columns): # Column Non-Null Count Dtype -- -- 0 datetime 10886 non-null object 1 season 10886 non-null int64 2 holiday 10886 non-null int64 3 workingday 10886 non-null int64 4 weather 10886 non-null int64 5 temp 10886 non-null float64 6 atemp 10886 non-null float64 7 humidity 10886 non-null int64 8 windspeed 10886 non-null float64 9 casual 10886 non-null int64 10 registered 10886 non-null int64 11 count 10886 non-null int64 dtypes: float64(3), int64(8), object(1) memory usage: 1020.7+ KB . 결측값은 없습니다. . bike_df[&#39;datetime&#39;] = bike_df.datetime.apply(pd.to_datetime) bike_df[&#39;year&#39;] = bike_df.datetime.apply(lambda x : x.year) bike_df[&#39;month&#39;] = bike_df.datetime.apply(lambda x : x.month) bike_df[&#39;day&#39;] = bike_df.datetime.apply(lambda x : x.day) bike_df[&#39;hour&#39;] = bike_df.datetime.apply(lambda x : x.hour) bike_df.head(3) . datetime season holiday workingday weather temp atemp humidity windspeed casual registered count year month day hour . 0 2011-01-01 00:00:00 | 1 | 0 | 0 | 1 | 9.84 | 14.395 | 81 | 0.0 | 3 | 13 | 16 | 2011 | 1 | 1 | 0 | . 1 2011-01-01 01:00:00 | 1 | 0 | 0 | 1 | 9.02 | 13.635 | 80 | 0.0 | 8 | 32 | 40 | 2011 | 1 | 1 | 1 | . 2 2011-01-01 02:00:00 | 1 | 0 | 0 | 1 | 9.02 | 13.635 | 80 | 0.0 | 5 | 27 | 32 | 2011 | 1 | 1 | 2 | . pd.to_datetime 함수를 통해 데이터 타임을 datetime으로 바꿨습니다. . datetime 데이터 타입은 year, month 등등으로 구분할 수 있습니다. . 이를 활용하여 년, 달, 날, 시간 변수로 각각 생성하였습니다. . drop_columns = [&#39;datetime&#39;, &#39;casual&#39;, &#39;registered&#39;] bike_df.drop(drop_columns, axis = 1, inplace = True) . datetime 변수는 분해를 했기 때문에 원본 변수가 필요 없어졌습니다. . casual + registered = count 변수 이므로 두 변수 모두 제외하겠습니다. . from sklearn.metrics import mean_squared_error, mean_absolute_error def rmsle(y, pred): log_y = np.log1p(y) log_pred = np.log1p(pred) squared_error = (log_y - log_pred) ** 2 rmsle = np.sqrt(np.mean(squared_error)) return rmsle def rmse(y, pred): return np.sqrt(mean_squared_error(y, pred)) def evaluate_regr(y, pred): rmsle_val = rmsle(y, pred) rmse_val = rmse(y, pred) mae_val = mean_absolute_error(y, pred) print(&#39;rmsle :&#39;, np.round(rmsle_val, 4), &#39;rmse :&#39;, np.round(rmse_val, 4), &#39;mse :&#39;, np.round(mae_val, 4)) . 이번 분석의 성능 평가 방법은 rmsle 이기 때문에 이를 구현했습니다. . &#52395;&#48264;&#51704; &#48516;&#49437; . from sklearn.model_selection import train_test_split, GridSearchCV from sklearn.linear_model import LinearRegression, Ridge, Lasso y_target = bike_df[&#39;count&#39;] x_features = bike_df.drop([&#39;count&#39;], axis = 1, inplace = False) x_train, x_test, y_train, y_test = train_test_split(x_features, y_target, test_size = 0.3, random_state = 0) lr_reg = LinearRegression() lr_reg.fit(x_train, y_train) pred = lr_reg.predict(x_test) evaluate_regr(y_test, pred) . rmsle : 1.1647 rmse : 140.8996 mse : 105.9244 . 실제 타겟 값이 대여 횟수임으로 지금 rmse 값은 매우 크다고 볼 수 있습니다. . def get_top_error_data(y_test, pred, n_tops = 5): result_df = pd.DataFrame(y_test.values, columns=[&#39;real_count&#39;]) result_df[&#39;predicted_count&#39;] = np.round(pred) result_df[&#39;diff&#39;] = np.abs(result_df[&#39;real_count&#39;] - result_df[&#39;predicted_count&#39;]) print(result_df.sort_values(&#39;diff&#39;, ascending= False)[:n_tops]) get_top_error_data(y_test, pred) . real_count predicted_count diff 1618 890 322.0 568.0 3151 798 241.0 557.0 966 884 327.0 557.0 412 745 194.0 551.0 2817 856 310.0 546.0 . 실제값과 예측값이 가장 차이가 큰 5개 데이터를 출력했습니다. . 상당히 차이가 많이 나는걸 볼 수 있는데요. . 타겟값의 분포가 치우쳐 있는지 확인을 해볼 필요가 있겠습니다. . y_target.hist() . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f853c8fd090&gt; . 오른쪽 꼬리가 매우 두터운 형태임을 알 수 있습니다. . 이런 형태일 때 가장 자주 쓰이는 로그변환을 적용해보겠습니다. . y_log_transform = np.log1p(y_target) y_log_transform.hist() . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f853c792690&gt; . 정규분포와는 다소 차이가 있지만 변환 전보다 왜곡 정도가 많이 개선됐습니다. . y_target_log = np.log1p(y_target) x_train, x_test, y_train, y_test = train_test_split(x_features, y_target_log, test_size= 0.3, random_state=0) lr_reg = LinearRegression() lr_reg.fit(x_train, y_train) pred = lr_reg.predict(x_test) y_test_exp = np.expm1(y_test) pred_exp = np.expm1(pred) evaluate_regr(y_test_exp, pred_exp) . rmsle : 1.0168 rmse : 162.5943 mse : 109.2862 . mse 값은 전보다 개선 되었지만 rmse 값은 더 증가하였습니다. . 무슨 이유일까요? . &#46160;&#48264;&#51704; &#48516;&#49437; . coef = pd.Series(lr_reg.coef_, index=x_features.columns) coef_sort = coef.sort_values(ascending = False) sns.barplot(x=coef_sort.values, y = coef_sort.index) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f853c1f0990&gt; . 다른 값에 비해 year값이 높습니다. . year값은 년도인데 년도가 이렇게 큰 영향을 미치는 것을 일반적인 사실로 받아들이기 힘듭니다. . 이유를 추정해보자면 연도 변수의 값이 큰 점을 들 수 있습니다.(2011,2012) . 비슷한 이유로 범주형 변수로 변환할 필요가 있는 변수들을 원핫인코딩방식으로 변환하겠습니다. . x_features_ohe = pd.get_dummies(x_features, columns = [&#39;year&#39;, &#39;month&#39;,&#39;day&#39;,&#39;hour&#39;,&#39;holiday&#39;, &#39;workingday&#39;, &#39;season&#39;, &#39;weather&#39;]) x_features_ohe.shape . (10886, 73) . 원핫 인코딩 결과 열 개수가 73개로 크게 늘어났습니다. . x_train, x_test, y_train, y_test = train_test_split(x_features_ohe, y_target_log, test_size= 0.3, random_state=0) def get_model_predict(model, x_train, x_test, y_train, y_test, is_expm1 = False): model.fit(x_train, y_train) pred = model.predict(x_test) if is_expm1: y_test = np.expm1(y_test) pred = np.expm1(pred) print(model.__class__.__name__) evaluate_regr(y_test, pred) lr_reg = LinearRegression() ridge_reg = Ridge(alpha = 10) lasso_reg = Lasso(alpha = 0.01) for model in [lr_reg, ridge_reg, lasso_reg]: get_model_predict(model, x_train, x_test, y_train, y_test, is_expm1 = True) . LinearRegression rmsle : 0.5896 rmse : 97.6878 mse : 63.3821 Ridge rmsle : 0.5901 rmse : 98.5286 mse : 63.8934 Lasso rmsle : 0.6348 rmse : 113.2188 mse : 72.8027 . 원핫 인코딩을 적용한 후 결과가 눈에 띄게 좋아졌습니다. . coef = pd.Series(lr_reg.coef_, index=x_features_ohe.columns) coef_sort = coef.sort_values(ascending = False)[:20] sns.barplot(x = coef_sort.values, y = coef_sort.index) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f853c772bd0&gt; . 회귀계수가 높은 피처 20개를 출력해보았습니다. . &#49464;&#48264;&#51704; &#48516;&#49437; . from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor from xgboost import XGBRegressor from lightgbm import LGBMRegressor rf_reg = RandomForestRegressor(n_estimators = 500) gbm_reg = GradientBoostingRegressor(n_estimators = 500) xgb_reg = XGBRegressor(n_estimaters = 500) lgbm_reg = LGBMRegressor(n_estimaters = 500) for model in [rf_reg, gbm_reg, xgb_reg, lgbm_reg]: get_model_predict(model, x_train.values, x_test.values, y_train.values, y_test.values, is_expm1=True) . RandomForestRegressor rmsle : 0.3549 rmse : 50.2976 mse : 31.1562 GradientBoostingRegressor rmsle : 0.3299 rmse : 53.3352 mse : 32.7448 [16:01:03] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror. XGBRegressor rmsle : 0.4828 rmse : 95.6137 mse : 59.2047 LGBMRegressor rmsle : 0.3315 rmse : 51.3807 mse : 31.8325 . 부스팅 모델을 사용하면 더 좋은 성능을 보일 수 있습니다. .",
            "url": "https://ksy1526.github.io/myblog//myblog/book/jupyter/guide/datetime/scale/randomforest/boost/regression/2021/10/02/PythonMachine5_4.html",
            "relUrl": "/book/jupyter/guide/datetime/scale/randomforest/boost/regression/2021/10/02/PythonMachine5_4.html",
            "date": " • Oct 2, 2021"
        }
        
    
  
    
        ,"post11": {
            "title": "[SSUDA] 자전거 수요 예측 모델",
            "content": ". &#45936;&#51060;&#53552; &#48520;&#47084;&#50724;&#44592; . pip install kaggle --upgrade . Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12) Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.5.30) Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2) Requirement already satisfied: six&gt;=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0) Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3) Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0) Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2) Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.62.2) Requirement already satisfied: text-unidecode&gt;=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify-&gt;kaggle) (1.3) Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;kaggle) (2.10) Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;kaggle) (3.0.4) . !pip install kaggle from google.colab import files files.upload() . Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12) Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0) Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.5.30) Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.62.2) Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3) Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2) Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2) Requirement already satisfied: six&gt;=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0) Requirement already satisfied: text-unidecode&gt;=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify-&gt;kaggle) (1.3) Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;kaggle) (3.0.4) Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;kaggle) (2.10) . Upload widget is only available when the cell has been executed in the current browser session. Please rerun this cell to enable. Saving kaggle.json to kaggle (1).json . {&#39;kaggle.json&#39;: b&#39;{&#34;username&#34;:&#34;ksy1998&#34;,&#34;key&#34;:&#34;0c820de52cea65ec11954012ef8b00d2&#34;}&#39;} . kaggle.json 파일 선택합니다. . !mkdir -p ~/.kaggle !cp kaggle.json ~/.kaggle/ !chmod 600 ~/.kaggle/kaggle.json . !kaggle competitions download -c bike-sharing-demand . Warning: Looks like you&#39;re using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4) Downloading train.csv to /content 0% 0.00/633k [00:00&lt;?, ?B/s] 100% 633k/633k [00:00&lt;00:00, 42.8MB/s] Downloading sampleSubmission.csv to /content 0% 0.00/140k [00:00&lt;?, ?B/s] 100% 140k/140k [00:00&lt;00:00, 44.0MB/s] Downloading test.csv to /content 0% 0.00/316k [00:00&lt;?, ?B/s] 100% 316k/316k [00:00&lt;00:00, 41.9MB/s] . 캐글에서 복사한 코드에 느낌표만 붙여줍니다. . import sklearn import pandas as pd import numpy as np import matplotlib.pyplot as plt import seaborn as sns import numpy as np from sklearn.linear_model import LinearRegression from sklearn.linear_model import Ridge ,Lasso from sklearn.model_selection import train_test_split from sklearn.metrics import r2_score from sklearn.feature_selection import VarianceThreshold from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, PolynomialFeatures from sklearn.metrics import mean_squared_log_error as msle import numpy as np import matplotlib.pyplot as plt from mpl_toolkits.mplot3d import Axes3D from sklearn.ensemble import GradientBoostingRegressor from sklearn.ensemble import RandomForestRegressor from sklearn.model_selection import GridSearchCV from xgboost import XGBRegressor %matplotlib inline . train=pd.read_csv(&#39;./train.csv&#39;) test=pd.read_csv(&#39;./test.csv&#39;) . &#45936;&#51060;&#53552; &#46168;&#47084;&#48372;&#44592; . train.head() . datetime season holiday workingday weather temp atemp humidity windspeed casual registered count . 0 2011-01-01 00:00:00 | 1 | 0 | 0 | 1 | 9.84 | 14.395 | 81 | 0.0 | 3 | 13 | 16 | . 1 2011-01-01 01:00:00 | 1 | 0 | 0 | 1 | 9.02 | 13.635 | 80 | 0.0 | 8 | 32 | 40 | . 2 2011-01-01 02:00:00 | 1 | 0 | 0 | 1 | 9.02 | 13.635 | 80 | 0.0 | 5 | 27 | 32 | . 3 2011-01-01 03:00:00 | 1 | 0 | 0 | 1 | 9.84 | 14.395 | 75 | 0.0 | 3 | 10 | 13 | . 4 2011-01-01 04:00:00 | 1 | 0 | 0 | 1 | 9.84 | 14.395 | 75 | 0.0 | 0 | 1 | 1 | . test.head() . datetime season holiday workingday weather temp atemp humidity windspeed . 0 2011-01-20 00:00:00 | 1 | 0 | 1 | 1 | 10.66 | 11.365 | 56 | 26.0027 | . 1 2011-01-20 01:00:00 | 1 | 0 | 1 | 1 | 10.66 | 13.635 | 56 | 0.0000 | . 2 2011-01-20 02:00:00 | 1 | 0 | 1 | 1 | 10.66 | 13.635 | 56 | 0.0000 | . 3 2011-01-20 03:00:00 | 1 | 0 | 1 | 1 | 10.66 | 12.880 | 56 | 11.0014 | . 4 2011-01-20 04:00:00 | 1 | 0 | 1 | 1 | 10.66 | 12.880 | 56 | 11.0014 | . 변수가 3개 차이 나는데, casual + registered = count 변수 입니다. . 테스트 데이터에서는 count를 맞추는것이 목적입니다. . train.drop([&#39;casual&#39;,&#39;registered&#39;],1,inplace=True) . 글쓴이는 이런 이유로 쿨하게 두 변수를 날렸습니다. . train.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 10886 entries, 0 to 10885 Data columns (total 10 columns): # Column Non-Null Count Dtype -- -- 0 datetime 10886 non-null object 1 season 10886 non-null int64 2 holiday 10886 non-null int64 3 workingday 10886 non-null int64 4 weather 10886 non-null int64 5 temp 10886 non-null float64 6 atemp 10886 non-null float64 7 humidity 10886 non-null int64 8 windspeed 10886 non-null float64 9 count 10886 non-null int64 dtypes: float64(3), int64(6), object(1) memory usage: 850.6+ KB . 데이터 10886개, count를 제외한 변수 개수 9개, 결측값은 없습니다. . train.describe() . season holiday workingday weather temp atemp humidity windspeed count . count 10886.000000 | 10886.000000 | 10886.000000 | 10886.000000 | 10886.00000 | 10886.000000 | 10886.000000 | 10886.000000 | 10886.000000 | . mean 2.506614 | 0.028569 | 0.680875 | 1.418427 | 20.23086 | 23.655084 | 61.886460 | 12.799395 | 191.574132 | . std 1.116174 | 0.166599 | 0.466159 | 0.633839 | 7.79159 | 8.474601 | 19.245033 | 8.164537 | 181.144454 | . min 1.000000 | 0.000000 | 0.000000 | 1.000000 | 0.82000 | 0.760000 | 0.000000 | 0.000000 | 1.000000 | . 25% 2.000000 | 0.000000 | 0.000000 | 1.000000 | 13.94000 | 16.665000 | 47.000000 | 7.001500 | 42.000000 | . 50% 3.000000 | 0.000000 | 1.000000 | 1.000000 | 20.50000 | 24.240000 | 62.000000 | 12.998000 | 145.000000 | . 75% 4.000000 | 0.000000 | 1.000000 | 2.000000 | 26.24000 | 31.060000 | 77.000000 | 16.997900 | 284.000000 | . max 4.000000 | 1.000000 | 1.000000 | 4.000000 | 41.00000 | 45.455000 | 100.000000 | 56.996900 | 977.000000 | . 최솟값 또는 최댓값에 이상한 값은 없습니다. . 또 값을 관찰해보면 season, holiday, workingday, weather 변수는 범주형 변수인 것을 알 수 있습니다. . 그리고 datetime 변수는 형태가 특수하여 이 표에 표현되지 않습니다. . datetime &#48320;&#49688;&#50640; &#45824;&#54644; . train[&#39;datetime&#39;] . 0 2011-01-01 00:00:00 1 2011-01-01 01:00:00 2 2011-01-01 02:00:00 3 2011-01-01 03:00:00 4 2011-01-01 04:00:00 ... 10881 2012-12-19 19:00:00 10882 2012-12-19 20:00:00 10883 2012-12-19 21:00:00 10884 2012-12-19 22:00:00 10885 2012-12-19 23:00:00 Name: datetime, Length: 10886, dtype: object . datetime 변수는 날짜 + 시간 변수 입니다. . 데이터 타입은 현재 object 타입인데요. 변경해보겠습니다. . train[&#39;datetime&#39;] = pd.to_datetime(train[&#39;datetime&#39;]) test[&#39;datetime&#39;] = pd.to_datetime(test[&#39;datetime&#39;]) train[&#39;Month&#39;]=pd.DatetimeIndex(train[&#39;datetime&#39;]).month test[&#39;Month&#39;]=pd.DatetimeIndex(test[&#39;datetime&#39;]).month train[&#39;Year&#39;]=pd.DatetimeIndex(train[&#39;datetime&#39;]).year test[&#39;Year&#39;]=pd.DatetimeIndex(test[&#39;datetime&#39;]).year train[&#39;WeekDay&#39;]=pd.DatetimeIndex(train[&#39;datetime&#39;]).weekday test[&#39;WeekDay&#39;]=pd.DatetimeIndex(test[&#39;datetime&#39;]).weekday train[&#39;Hour&#39;]=pd.DatetimeIndex(train[&#39;datetime&#39;]).hour test[&#39;Hour&#39;]=pd.DatetimeIndex(test[&#39;datetime&#39;]).hour train.head(3) . datetime season holiday workingday weather temp atemp humidity windspeed count Month Year WeekDay Hour . 0 2011-01-01 00:00:00 | 1 | 0 | 0 | 1 | 9.84 | 14.395 | 81 | 0.0 | 16 | 1 | 2011 | 5 | 0 | . 1 2011-01-01 01:00:00 | 1 | 0 | 0 | 1 | 9.02 | 13.635 | 80 | 0.0 | 40 | 1 | 2011 | 5 | 1 | . 2 2011-01-01 02:00:00 | 1 | 0 | 0 | 1 | 9.02 | 13.635 | 80 | 0.0 | 32 | 1 | 2011 | 5 | 2 | . 판다스에 to_* 함수를 통해 데이터 타입을 바꿀 수 있습니다. . 여기서는 to_datetime 함수로 &#39;datetime&#39; 데이터 형으로 바꿨습니다. . 이 데이터 형에 특징은 DatetimeIndex함수를 이용하여 연도/달/일 등을 쉽게 추출할 수 있다는 것 입니다. . &#45936;&#51060;&#53552; &#49548;&#44060; . season =&gt; 계절 변수, 1 : 봄, 2 : 여름, 3 : 가을, 4 : 겨울 . holiday =&gt; 휴일 변수, 날짜가 휴일이면 1 아니면 0 . workingday =&gt; 근무일 변수, 날짜가 주말도 휴일도 아니라면 1 . weather =&gt; 날씨 변수, 맑음이 1 폭우가 4. 흐릴수록 값이 점차 증가. . temp =&gt; 온도, atemp =&gt; 체감온도, humidity =&gt; 습도, windspeed =&gt; 풍속 . categorical_cols=[&#39;season&#39;,&#39;holiday&#39;,&#39;workingday&#39;,&#39;weather&#39;] numerical_cols=[&#39;temp&#39;,&#39;atemp&#39;,&#39;humidity&#39;,&#39;windspeed&#39;] label=&#39;count&#39; . 변수를 범주형 변수와 연속형 변수로 나눴습니다. . &#49884;&#44036; &#45936;&#51060;&#53552; &#44288;&#52769; . def encodetime(train,test,col,label): d3=train[[col,label]].groupby(col).mean() d3.sort_values(by=&#39;count&#39;,ascending=False) plt.scatter(x=d3.index,y=d3[&#39;count&#39;]) d3=d3.sort_values(by=&#39;count&#39;) d3[&#39;w&#39;]=np.arange(train[col].nunique()) #순서 dic=dict(zip(d3.index,d3[&#39;w&#39;])) train[col]=train[col].map(dic) test[col]=test[col].map(dic) . .nunique() =&gt; 유니크한 범주 개수 출력 . dict(zip()) =&gt; 두 시리즈 변수를 튜플로 묶고 딕셔러니 자료형으로 변환 . map =&gt; 주로 함수를 입력하는데, 여기서는 딕셔너리 키 값을 받을때 value 값을 반환해주는 함수로 사용 . 즉 이 함수는 col 변수로 변수가 입력되면 그 변수의 plot를 출력해주고 0~n 까지 레이블 인코딩을 해줍니다. . encodetime(train,test,&#39;Year&#39;,label) . 연도별로 차이가 있습니다. . encodetime(train,test,&#39;Month&#39;,label) . 날씨가 따뜻한 여름 부근에 확실히 값이 큽니다. . encodetime(train,test,&#39;Hour&#39;,label) . 야간시간에 값이 떨어집니다. . encodetime(train,test,&#39;WeekDay&#39;,label) . 0부터 월요일이므로 값이 많이 떨어지는 6은 일요일입니다. . &#48276;&#51452;&#54805; &#51088;&#47308; &#49884;&#44033;&#54868; . def boxplot(x,y,**kwargs): sns.boxplot(x=x,y=y) x=plt.xticks(rotation=90) f=pd.melt(train,id_vars=[&#39;count&#39;],value_vars=categorical_cols) g=sns.FacetGrid(f,col=&#39;variable&#39;,col_wrap=2,sharex=False) g.map(boxplot,&#39;value&#39;,&#39;count&#39;) . &lt;seaborn.axisgrid.FacetGrid at 0x7fd4625d22d0&gt; . boxplot 모형입니다. count변수의 이상치가 변수에 상관없이 존재합니다. . 파이썬 문법 : 함수 인자 내 **kwargs에 대해서. . 단순하게 함수 인자 내 *이나 **이 보일 경우 C언어에서 사용하는 포인터 개념이 아닙니다. . 몇개의 인자를 보낼지 모를때 사용되며, **같은 경우 딕셔너리 형태일때 사용합니다. . 다만 이 코드는 너무 복잡해서 지금 실력에서 어떻게 해석을 못하겠습니다. . sns.pairplot(train[[*numerical_cols,&#39;count&#39;]]) . &lt;seaborn.axisgrid.PairGrid at 0x7fd460faa110&gt; . *numerical_cols은 리스트를 해체한다고 이해하면 편할 것 같아요. . pairplot함수를 통해 연속형 변수 간에 산점도를 한 눈에 볼 수 있습니다. . f, ax = plt.subplots(figsize=(15, 15)) corr = train[[*numerical_cols,&#39;count&#39;]].corr() sns.heatmap(corr,cmap=sns.diverging_palette(220, 10, as_cmap=True),square=True, ax=ax, annot = True) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fd461781f50&gt; . heatmap 함수는 아까 본 산점도를 상관계수 버전으로 보여줍니다. . square는 셀을 정사각형으로 출력하는 것, annot은 셀 안에 숫자를 출력해주는 것을 의미합니다. . 여기서는 체감온도와 실제 온도 간 상관계수가 엄청 높은 것이 눈에 띄네요. . f, ax = plt.subplots(figsize=(15, 15)) corr = train.corr() sns.heatmap(corr,cmap=sns.diverging_palette(220, 10, as_cmap=True),square=True, ax=ax, annot = True) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7fd4602b2650&gt; . 조금 더 확장해서 모든 변수간 상관계수를 살펴보았습니다. . &#48152;&#51025;&#48320;&#49688; &#48320;&#54872; . sns.displot(train[label] , kde=True, height=8.27, aspect=11.7/8.27) sns.displot(np.log(train[label]) , kde=True, height=8.27, aspect=11.7/8.27) . &lt;seaborn.axisgrid.FacetGrid at 0x7fd46015a090&gt; . count 변수를 로그변환 해보았는데요. . 로그변환 전 우측 꼬리가 긴 그래프였는데 변환 후 상대적으로 더 정규분포에 가까워졌습니다. . 다만 왼쪽 꼬리가 다소 길어져 변환 정도를 조절할 필요가 있겠습니다. . def trans(x,l1=0.3,l2=0): if l1!=0: return ((x+l2)**l1-1)/l1 else: return np.log(x+l2) def rev_trans(x,l1=0.3,l2=0): return (x*l1+1)**(1/l1)-l2 z=train[label].apply(trans) sns.displot(z , kde=True, height=8.27, aspect=11.7/8.27) . &lt;seaborn.axisgrid.FacetGrid at 0x7fd45feda3d0&gt; . l2가 0일때 이는 람다가 l1인 box-cox 변환입니다. . 이 변환은 정규분포가 아닌 값을 정규분포형태로 변환합니다. . 그림을 확인해보면 이전 대비 그래프가 확연히 정규분포 형태에 가까운 것을 알 수 있습니다. . &#45936;&#51060;&#53552; &#47784;&#45944;&#47553; . x=train.drop([&#39;count&#39;,&#39;datetime&#39;,&#39;atemp&#39;],1) xtest=test.drop([&#39;datetime&#39;,&#39;atemp&#39;],1) y=train[&#39;count&#39;] xt,xv,yt,yv=train_test_split(x,y,test_size=0.2,random_state=101) . 변수이름을 조금 대충 만들었네요. . 보면서 생각난 점은 데이터 분석 프로젝트롤 여러명이서 할 경우 변수명 통일이 상당히 중요하다는 점 입니다. . def redun(x): return x def mk_model_RF(xt1,xv1,yt,yv,md=None,func1=redun,func2=redun,mss=2,n_est=100,al=0): ytt=yt.apply(func1) yvt=yv.apply(func2) model=RandomForestRegressor(max_depth=md, random_state=0,min_samples_split=mss,n_estimators=n_est,ccp_alpha=al) model.fit(xt1,ytt) ypt=np.apply_along_axis(func2,arr=model.predict(xt1),axis=0) ypv=np.apply_along_axis(func2,arr=model.predict(xv1),axis=0) print(&#39;training r2:&#39;,r2_score(yt,ypt)) print(&#39;Validation r2:&#39;,r2_score(yv,ypv)) print(&#39;training rmsle:&#39;,np.sqrt(msle(yt,ypt))) print(&#39;validation rmsle:&#39;,np.sqrt(msle(yv,ypv))) return model . 함수를 조금 복잡하게 만들었는데 함수 한 개만 소개하겠습니다. . np.apply_along_axis 함수는 인자가 (함수, 어레이, 행/열 여부) 입니다. . apply와 비슷한 역할의 함수인데 넘파이 함수라서 실행속도가 엄청 빠릅니다. . mk_model_RF(xt,xv,yt,yv) . training r2: 0.9922090269471024 Validation r2: 0.9338288545809785 training rmsle: 0.16871805329660905 validation rmsle: 0.379570233664069 . RandomForestRegressor(bootstrap=True, ccp_alpha=0, criterion=&#39;mse&#39;, max_depth=None, max_features=&#39;auto&#39;, max_leaf_nodes=None, max_samples=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None, oob_score=False, random_state=0, verbose=0, warm_start=False) . 랜덤 포레스트 방법이네요. . count 변수에 box-cox변환을 하지 않은 결과입니다. . mk_model_RF(xt,xv,yt,yv,func1=trans,func2=rev_trans,n_est=400,md=20) . training r2: 0.9916973216662878 Validation r2: 0.9338712883052291 training rmsle: 0.12704646646266962 validation rmsle: 0.34592422107196 . RandomForestRegressor(bootstrap=True, ccp_alpha=0, criterion=&#39;mse&#39;, max_depth=20, max_features=&#39;auto&#39;, max_leaf_nodes=None, max_samples=None, min_impurity_decrease=0.0, min_impurity_split=None, min_samples_leaf=1, min_samples_split=2, min_weight_fraction_leaf=0.0, n_estimators=400, n_jobs=None, oob_score=False, random_state=0, verbose=0, warm_start=False) . box-cox 변환을 한 결과가 조금 더 좋은 것 같습니다. . def mk_model_xgb(xt,xv,yt,yv,func1=redun,func2=redun,lr=1,min_child_weight =25,colsample_bytree = 0.8,md=None): model =XGBRegressor( colsample_bytree = colsample_bytree, learning_rate = lr,min_child_weight =min_child_weight, max_depth=md ) ytt=yt.apply(func1) model.fit(xt,ytt) ypt=np.apply_along_axis(func2,arr=model.predict(xt),axis=0) ypv=np.apply_along_axis(func2,arr=model.predict(xv),axis=0) print(&#39;training r2:&#39;,r2_score(yt,ypt)) print(&#39;Validation r2:&#39;,r2_score(yv,ypv)) print(&#39;training rmsle:&#39;,np.sqrt(msle(yt,ypt))) print(&#39;validation rmsle:&#39;,np.sqrt(msle(yv,ypv))) return model . mk_model_xgb(xt,xv,yt,yv,func1=trans,func2=rev_trans,lr=0.2,min_child_weight =20,colsample_bytree = 0.8,md=20) . [14:54:06] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror. training r2: 0.9945096180099459 Validation r2: 0.9504273424389956 training rmsle: 0.10444065614264901 validation rmsle: 0.3133324307194445 . XGBRegressor(base_score=0.5, booster=&#39;gbtree&#39;, colsample_bylevel=1, colsample_bynode=1, colsample_bytree=0.8, gamma=0, importance_type=&#39;gain&#39;, learning_rate=0.2, max_delta_step=0, max_depth=20, min_child_weight=20, missing=None, n_estimators=100, n_jobs=1, nthread=None, objective=&#39;reg:linear&#39;, random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None, silent=None, subsample=1, verbosity=1) . xgboost 사용 결과 값이 더 좋게 나옵니다. box-cox 변환을 한 결과입니다. . model=XGBRegressor(colsample_bytree = 0.8, learning_rate = 0.2,min_child_weight =20, max_depth=20).fit(x,y.apply(trans)) . [14:55:11] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror. . 그래서 box-cox변환 후 xgboost를 사용해 모델을 적합시켰습니다. . &#48516;&#49437; &#44208;&#44284; &#51228;&#52636; . yp=np.apply_along_axis(rev_trans,arr=model.predict(xtest),axis=0) . plt.hist(yp) . (array([2543., 1497., 1057., 606., 367., 184., 125., 69., 34., 11.]), array([7.3024821e-01, 9.8740685e+01, 1.9675111e+02, 2.9476157e+02, 3.9277197e+02, 4.9078241e+02, 5.8879285e+02, 6.8680328e+02, 7.8481372e+02, 8.8282416e+02, 9.8083459e+02], dtype=float32), &lt;a list of 10 Patch objects&gt;) . test[&#39;count&#39;]=yp test[[&#39;datetime&#39;, &#39;count&#39;]].to_csv(&#39;./submission.csv&#39;, index=False) !kaggle competitions submit -c bike-sharing-demand -f submission.csv -m &quot;Message&quot; . Warning: Looks like you&#39;re using an outdated API Version, please consider updating (server 1.5.12 / client 1.5.4) 100% 188k/188k [00:01&lt;00:00, 106kB/s] Successfully submitted to Bike Sharing Demand . 별도에 작업 없이 캐글과 연동하여 바로 제출할 수 있습니다. . &#45712;&#45184;&#51216; . 우선 이번 데이터 분석은 저번보다 열심히 한 것 같네요. . 중점으로 두었던 것은 제가 시각화 부분이 많이 부족해서 이 부분 공부해보려고 이번 코드 골랐습니다. . 잊고 있었던 box-cox 정규분포 변환에 대해 다시 떠올리게 되었던 것도 큰 수확인것 같네요. . 이 사람이 코드 설명을 크게 한 것이 없어 찾아보느라도 고생한 것 같습니다. . 결과는 0.41정도로 상위권은 아니지만 노력 대비 어느정도 성과가 있습니다. . 이번 코드 리뷰를 통해서 많이 배운것 같습니다. . 대회 출처 : https://www.kaggle.com/c/bike-sharing-demand . 코드 출처 : https://www.kaggle.com/muhammedmamdouhsalah/bike-sharing .",
            "url": "https://ksy1526.github.io/myblog//myblog/ssuda/jupyter/kaggle/randomforest/scale/boxcox/xgboost/regression/2021/10/01/kagglessu3.html",
            "relUrl": "/ssuda/jupyter/kaggle/randomforest/scale/boxcox/xgboost/regression/2021/10/01/kagglessu3.html",
            "date": " • Oct 1, 2021"
        }
        
    
  
    
        ,"post12": {
            "title": "[머신러닝 가이드] 5-3 다양한 회귀",
            "content": ". &#47196;&#51648;&#49828;&#54001; &#54924;&#44480; . import pandas as pd import matplotlib.pyplot as plt %matplotlib inline from sklearn.datasets import load_breast_cancer from sklearn.linear_model import LogisticRegression cancer = load_breast_cancer() . from sklearn.preprocessing import StandardScaler from sklearn.model_selection import train_test_split scaler = StandardScaler() data_scaled = scaler.fit_transform(cancer.data) x_train, x_test, y_train, y_test = train_test_split(data_scaled, cancer.target, test_size = 0.3, random_state = 0) . 평균이 0, 분산이 1인 정규분포 형태로 형 변환을 했습니다. . 로지스틱 회귀기법은 선형 회귀 방식에 응용으로 데이터의 정규분포도에 영향을 많이 받습니다. . from sklearn.metrics import accuracy_score, roc_auc_score import numpy as np lr_clf = LogisticRegression() lr_clf.fit(x_train, y_train) lr_preds = lr_clf.predict(x_test) print(&#39;정확도 :&#39;, np.round(accuracy_score(y_test, lr_preds), 4)) print(&#39;roc 커브 :&#39;, np.round(roc_auc_score(y_test, lr_preds), 4)) . 정확도 : 0.9766 roc 커브 : 0.9716 . from sklearn.model_selection import GridSearchCV params = {&#39;penalty&#39; : [&#39;l2&#39;, &#39;l1&#39;], &#39;C&#39; : [0.01, 0.1, 1, 5, 10]} grid_clf = GridSearchCV(lr_clf, param_grid = params, scoring = &#39;accuracy&#39;, cv = 3) grid_clf.fit(data_scaled, cancer.target) print(&#39;최적 파라미터 : &#39;, grid_clf.best_params_, &#39;최적 평균 정확도&#39;, grid_clf.best_score_) . /usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty. FitFailedWarning) /usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty. FitFailedWarning) /usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty. FitFailedWarning) /usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty. FitFailedWarning) . 최적 파라미터 : {&#39;C&#39;: 1, &#39;penalty&#39;: &#39;l2&#39;} 최적 평균 정확도 0.975392184164114 . /usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: ValueError: Solver lbfgs supports only &#39;l2&#39; or &#39;none&#39; penalties, got l1 penalty. FitFailedWarning) . 최적 파라미터는 l2 규제로(릿지 회귀) c가(알파의 역수) 1일때 입니다. . &#53944;&#47532; &#44592;&#48152; &#54924;&#44480; &#47784;&#45944; . from sklearn.datasets import load_boston from sklearn.model_selection import cross_val_score from sklearn.ensemble import RandomForestRegressor import pandas as pd import numpy as np boston = load_boston() bostonDF = pd.DataFrame(boston.data, columns = boston.feature_names) bostonDF[&#39;PRICE&#39;] = boston.target y_target = bostonDF[&#39;PRICE&#39;] x_data = bostonDF.drop([&#39;PRICE&#39;], axis = 1, inplace=False) rf = RandomForestRegressor(random_state = 0, n_estimators = 1000) neg_mse_scores = cross_val_score(rf, x_data, y_target, scoring = &#39;neg_mean_squared_error&#39;, cv = 5) rmse_scores = np.sqrt(-1 * neg_mse_scores) avg_rmse = np.mean(rmse_scores) print(&#39;mse score : &#39;, np.round(neg_mse_scores, 4)) print(&#39;rmse score : &#39;, np.round(rmse_scores, 4)) print(&#39;평균 rmse score : &#39;, np.round(avg_rmse, 4)) . mse score : [ -7.933 -13.0584 -20.5278 -46.3057 -18.8008] rmse score : [2.8166 3.6136 4.5308 6.8048 4.336 ] 평균 rmse score : 4.4204 . 랜덤 포레스트 회귀 입니다. 평균 rmse 값은 4.42로 꽤 좋은 수치 입니다. . def get_model_cv_prediction(model, x_data, y_target): neg_mse_scores = cross_val_score(model, x_data, y_target, scoring = &#39;neg_mean_squared_error&#39;, cv = 5) rmse_scores = np.sqrt(-1 * neg_mse_scores) avg_rmse = np.mean(rmse_scores) print(model.__class__.__name__) print(&#39;평균 rmse : &#39;, np.round(avg_rmse, 4)) . from sklearn.tree import DecisionTreeRegressor from sklearn.ensemble import GradientBoostingRegressor from xgboost import XGBRegressor from lightgbm import LGBMRegressor dt_reg = DecisionTreeRegressor(random_state = 0, max_depth = 4) rf_reg = RandomForestRegressor(random_state = 0, n_estimators = 1000) gb_reg = GradientBoostingRegressor(random_state = 0, n_estimators = 1000) xgb_reg = XGBRegressor(random_state = 0, n_estimators = 1000) lgb_reg = LGBMRegressor(random_state = 0, n_estimators = 1000) models = [dt_reg, rf_reg, gb_reg, xgb_reg, lgb_reg] for model in models: get_model_cv_prediction(model, x_data, y_target) . DecisionTreeRegressor 평균 rmse : 6.2377 RandomForestRegressor 평균 rmse : 4.4204 GradientBoostingRegressor 평균 rmse : 4.2692 [13:18:05] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror. [13:18:07] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror. [13:18:07] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror. [13:18:07] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror. [13:18:08] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror. XGBRegressor 평균 rmse : 4.0889 LGBMRegressor 평균 rmse : 4.6464 . 여러 모델을 테스트 해보았습니다. . xgb부스팅 모델의 성능이 가장 우수하게 나왔습니다. .",
            "url": "https://ksy1526.github.io/myblog//myblog/book/jupyter/guide/logistic/randomforest/boost/regression/2021/09/30/PythonMachine5_3.html",
            "relUrl": "/book/jupyter/guide/logistic/randomforest/boost/regression/2021/09/30/PythonMachine5_3.html",
            "date": " • Sep 30, 2021"
        }
        
    
  
    
        ,"post13": {
            "title": "[머신러닝 가이드] 5-2 선형회귀응용",
            "content": ". &#45796;&#54637; &#54924;&#44480; . from sklearn.preprocessing import PolynomialFeatures import numpy as np x = np.arange(4).reshape(2,2) # 행 부터 숫자 채워짐 print(&#39;일차 단항식 계수 피처: n&#39;, x) poly = PolynomialFeatures(degree = 2) poly.fit(x) poly_ftr = poly.transform(x) print(&#39;변환된 2차 다항식 계수 피처: n&#39;, poly_ftr) . 일차 단항식 계수 피처: [[0 1] [2 3]] 변환된 2차 다항식 계수 피처: [[1. 0. 1. 0. 0. 1.] [1. 2. 3. 4. 6. 9.]] . 2차 다항계수는 [1, x1, x2, x1^2, x1x2, x2^2] 로 구성되어 있습니다. . def polynomial_func(x): y = 1 + 2 * x[:,0] + 3 * x[:,0] **2 + 4 * x[:,1] **3 return y y = polynomial_func(x) . from sklearn.linear_model import LinearRegression poly_ftr = PolynomialFeatures(degree = 3).fit_transform(x) print(&#39;3차 다항식 계수 feature: n&#39;, poly_ftr) model = LinearRegression() model.fit(poly_ftr, y) print(&#39;회귀 계수 n&#39;, np.round(model.coef_,2)) print(&#39;회귀 shape&#39;, model.coef_.shape) . 3차 다항식 계수 feature: [[ 1. 0. 1. 0. 0. 1. 0. 0. 0. 1.] [ 1. 2. 3. 4. 6. 9. 8. 12. 18. 27.]] 회귀 계수 [0. 0.18 0.18 0.36 0.54 0.72 0.72 1.08 1.62 2.34] 회귀 shape (10,) . poly함수로 다항식 계수를 생성한 뒤 단순 선형 회귀 함수에 대입해줍니다. . 원하는 값인 [1,2,0,3,0,0,0,0,0,4] 와 다소 차이가 있긴 합니다. . &#47551;&#51648; &#54924;&#44480; . from sklearn.preprocessing import PolynomialFeatures from sklearn.linear_model import LinearRegression from sklearn.pipeline import Pipeline import numpy as np model = Pipeline([(&#39;poly&#39;, PolynomialFeatures(degree=3)), (&#39;linear&#39;, LinearRegression())]) model = model.fit(x,y) print(&#39;회귀 계수 n&#39;, np.round(model.named_steps[&#39;linear&#39;].coef_,2)) . 회귀 계수 [0. 0.18 0.18 0.36 0.54 0.72 0.72 1.08 1.62 2.34] . 파이프 라인 함수로 다항식으로에 변환과 선형 회귀를 한번에 한 모습입니다. . from sklearn.linear_model import Ridge from sklearn.model_selection import cross_val_score from sklearn.datasets import load_boston import pandas as pd boston = load_boston() bostonDF = pd.DataFrame(boston.data, columns = boston.feature_names) bostonDF[&#39;PRICE&#39;] = boston.target y_target = bostonDF[&#39;PRICE&#39;] x_data = bostonDF.drop([&#39;PRICE&#39;], axis = 1, inplace=False) ridge = Ridge(alpha = 10) neg_mse_scores = cross_val_score(ridge, x_data, y_target, scoring = &#39;neg_mean_squared_error&#39;, cv = 5) rmse_scores = np.sqrt(-1 * neg_mse_scores) avg_rmse = np.mean(rmse_scores) print(&#39;mse scores&#39;, np.round(neg_mse_scores,2)) print(&#39;rmse scores&#39;, np.round(rmse_scores, 2)) print(&#39;평균 rmse score:&#39;, np.round(avg_rmse,2)) . mse scores [-11.42 -24.29 -28.14 -74.6 -28.52] rmse scores [3.38 4.93 5.31 8.64 5.34] 평균 rmse score: 5.52 . 단순 선형회귀 모델 rmse 평균값이 5.84로 릿지 회귀가 더 좋은 퍼포먼스를 보입니다. . alphas = [0,0.1,1,10,100] for alpha in alphas: ridge = Ridge(alpha=alpha) neg_mse_scores = cross_val_score(ridge, x_data, y_target, scoring = &#39;neg_mean_squared_error&#39;, cv = 5) avg_rmse = np.mean(np.sqrt(-neg_mse_scores)) print(&#39;alpha 값 &#39;, alpha, &#39;일때 평균 rmse :&#39;, np.round(avg_rmse,4)) . alpha 값 0 일때 평균 rmse : 5.8287 alpha 값 0.1 일때 평균 rmse : 5.7885 alpha 값 1 일때 평균 rmse : 5.6526 alpha 값 10 일때 평균 rmse : 5.5182 alpha 값 100 일때 평균 rmse : 5.3296 . alpha 값이 100일때가 가장 값이 좋습니다. . import matplotlib.pyplot as plt import seaborn as sns fig, axs = plt.subplots(figsize= (18,6), nrows = 1, ncols = 5) coeff_df = pd.DataFrame() for pos, alpha in enumerate(alphas): ridge = Ridge(alpha = alpha) ridge.fit(x_data, y_target) coeff = pd.Series(data=ridge.coef_, index = x_data.columns) colname = &#39;alpha:&#39;+str(alpha) coeff_df[colname] = coeff coeff = coeff.sort_values(ascending = False) axs[pos].set_title(colname) axs[pos].set_xlim(-3, 6) sns.barplot(x=coeff.values, y = coeff.index, ax = axs[pos]) plt.show() . 알파 값이 커지면(=규제가 세지면) 회귀계수 값이 전반적으로 작아집니다. . 다만 릿지 회귀에 경우 회귀 계수를 0으로 만들지는 않습니다. . &#46972;&#50136; &#54924;&#44480; . from sklearn.linear_model import Lasso, ElasticNet def get_linear_reg_eval(model_name, params = None, x_data_n = None, y_target_n = None, verbose= True, return_coeff = True): coeff_df = pd.DataFrame() if verbose : print(model_name) for param in params: if model_name ==&#39;Ridge&#39; : model = Ridge(alpha = param) elif model_name ==&#39;Lasso&#39; : model = Lasso(alpha = param) elif model_name ==&#39;ElasticNet&#39; : model = ElasticNet(alpha = param, l1_ratio=0.7) neg_mse_scores = cross_val_score(model, x_data_n, y_target_n, scoring = &#39;neg_mean_squared_error&#39;, cv = 5) avg_rmse = np.mean(np.sqrt(-1*neg_mse_scores)) print(&#39;alpha &#39;, param, &#39;일때 평균 rmse:&#39;, np.round(avg_rmse,2)) model.fit(x_data_n, y_target_n) if return_coeff: coeff = pd.Series(data=model.coef_, index = x_data_n.columns) colname = &#39;alpha:&#39;+str(param) coeff_df[colname] = coeff return coeff_df . lasso_alphas = [0.07,0.1,0.5,1,3] coeff_lasso_df = get_linear_reg_eval(&#39;Lasso&#39;,params=lasso_alphas, x_data_n = x_data, y_target_n= y_target) . Lasso alpha 0.07 일때 평균 rmse: 5.61 alpha 0.1 일때 평균 rmse: 5.62 alpha 0.5 일때 평균 rmse: 5.67 alpha 1 일때 평균 rmse: 5.78 alpha 3 일때 평균 rmse: 6.19 . 알파 값이 0.07일때 최고 성능을 보여줍니다. . 앞서 한 릿지보다는 성능이 떨어지지만, 단순 선형 회귀 모델보다 값이 크므로 쓰임새가 있습니다. . sort_column = &#39;alpha:&#39;+str(lasso_alphas[0]) coeff_lasso_df.sort_values(by = sort_column, ascending=False) . alpha:0.07 alpha:0.1 alpha:0.5 alpha:1 alpha:3 . RM 3.789725 | 3.703202 | 2.498212 | 0.949811 | 0.000000 | . CHAS 1.434343 | 0.955190 | 0.000000 | 0.000000 | 0.000000 | . RAD 0.270936 | 0.274707 | 0.277451 | 0.264206 | 0.061864 | . ZN 0.049059 | 0.049211 | 0.049544 | 0.049165 | 0.037231 | . B 0.010248 | 0.010249 | 0.009469 | 0.008247 | 0.006510 | . NOX -0.000000 | -0.000000 | -0.000000 | -0.000000 | 0.000000 | . AGE -0.011706 | -0.010037 | 0.003604 | 0.020910 | 0.042495 | . TAX -0.014290 | -0.014570 | -0.015442 | -0.015212 | -0.008602 | . INDUS -0.042120 | -0.036619 | -0.005253 | -0.000000 | -0.000000 | . CRIM -0.098193 | -0.097894 | -0.083289 | -0.063437 | -0.000000 | . LSTAT -0.560431 | -0.568769 | -0.656290 | -0.761115 | -0.807679 | . PTRATIO -0.765107 | -0.770654 | -0.758752 | -0.722966 | -0.265072 | . DIS -1.176583 | -1.160538 | -0.936605 | -0.668790 | -0.000000 | . 계수가 0인것이 보입니다. 알파값이 커질수록 회귀 계수가 0인 것이 늘어납니다. . &#50648;&#46972;&#49828;&#54001; &#54924;&#44480; . 다음은 엘라스틱 회귀 입니다. 쉽게 라쏘회귀 + 릿지 회귀로 볼 수 있습니다. . 라쏘 회귀에 경우 서로 상관관계가 높은 피처가 있으면 중요 피처를 제외하고 모두 회귀계수를 0으로 만듭니다. . 이를 다소 완화해주기 위한 목적으로 만들어졌습니다. 다만 수행시간이 다소 깁니다. . 여기서 알파는 알파1 + 알파 2 이며, l1_ratio는 말 그대로 l1규제(라쏘) 비율입니다. . elastic_alphas = [0.07,0.1,0.5,1,3] coeff_lasso_df = get_linear_reg_eval(&#39;ElasticNet&#39;, params=elastic_alphas, x_data_n= x_data, y_target_n= y_target) . ElasticNet alpha 0.07 일때 평균 rmse: 5.54 alpha 0.1 일때 평균 rmse: 5.53 alpha 0.5 일때 평균 rmse: 5.47 alpha 1 일때 평균 rmse: 5.6 alpha 3 일때 평균 rmse: 6.07 . 알파값이 0.5일때 가장 좋은 예측 성능을 보여줍니다. . sort_column = &#39;alpha:&#39;+str(elastic_alphas[0]) coeff_lasso_df.sort_values(by= sort_column, ascending=False) . alpha:0.07 alpha:0.1 alpha:0.5 alpha:1 alpha:3 . RM 3.574162 | 3.414154 | 1.918419 | 0.938789 | 0.000000 | . CHAS 1.330724 | 0.979706 | 0.000000 | 0.000000 | 0.000000 | . RAD 0.278880 | 0.283443 | 0.300761 | 0.289299 | 0.146846 | . ZN 0.050107 | 0.050617 | 0.052878 | 0.052136 | 0.038268 | . B 0.010122 | 0.010067 | 0.009114 | 0.008320 | 0.007020 | . AGE -0.010116 | -0.008276 | 0.007760 | 0.020348 | 0.043446 | . TAX -0.014522 | -0.014814 | -0.016046 | -0.016218 | -0.011417 | . INDUS -0.044855 | -0.042719 | -0.023252 | -0.000000 | -0.000000 | . CRIM -0.099468 | -0.099213 | -0.089070 | -0.073577 | -0.019058 | . NOX -0.175072 | -0.000000 | -0.000000 | -0.000000 | -0.000000 | . LSTAT -0.574822 | -0.587702 | -0.693861 | -0.760457 | -0.800368 | . PTRATIO -0.779498 | -0.784725 | -0.790969 | -0.738672 | -0.423065 | . DIS -1.189438 | -1.173647 | -0.975902 | -0.725174 | -0.031208 | . 라쏘모델에 비해 회귀계수를 0으로 만드는 개수가 다소 줄었습니다. . &#49440;&#54805; &#54924;&#44480; &#47784;&#45944;&#51012; &#50948;&#54620; &#45936;&#51060;&#53552; &#48320;&#54872; . 선형 회귀에서 중요한 것 중 하나가 데이터 분포도의 정규화 입니다. . 특히 타깃값의 분포가 정규분포가 아닌 왜곡(skew)된 분포는 예측 성능에 부정적입니다. . 따라서 선형 회귀 모델을 적용하기 전 먼저 데이터 스케일링/정규화 작업을 수행해주어야 합니다. . from sklearn.preprocessing import StandardScaler, MinMaxScaler def get_scaled_data(method=&#39;None&#39;, p_degree = None, input_data = None): if method == &#39;Standard&#39;: scaled_data = StandardScaler().fit_transform(input_data) elif method == &#39;MinMax&#39;: scaled_data = MinMaxScaler().fit_transform(input_data) if method == &#39;Log&#39;: scaled_data = np.log1p(input_data) else: scaled_data = input_data if p_degree != None: scaled_data = PolynomialFeatures(degree=p_degree, include_bias=False).fit_transform(scaled_data) return scaled_data . alphas = [0.1, 1, 10, 100] scale_methods=[(None, None), (&#39;Standard&#39;, None), (&#39;Standard&#39;,2), (&#39;MinMax&#39;,None), (&#39;MinMax&#39;, 2), (&#39;Log&#39;, None)] for scale_method in scale_methods: x_data_scaled = get_scaled_data(method=scale_method[0], p_degree=scale_method[1], input_data=x_data) print(&#39; n 변환유형:&#39;, scale_method[0], &#39;, Polynomial Degree:&#39;, scale_method[1]) get_linear_reg_eval(&#39;Ridge&#39;, params = alphas, x_data_n=x_data_scaled, y_target_n= y_target, verbose=False, return_coeff = False) . 변환유형: None , Polynomial Degree: None alpha 0.1 일때 평균 rmse: 5.79 alpha 1 일때 평균 rmse: 5.65 alpha 10 일때 평균 rmse: 5.52 alpha 100 일때 평균 rmse: 5.33 변환유형: Standard , Polynomial Degree: None alpha 0.1 일때 평균 rmse: 5.79 alpha 1 일때 평균 rmse: 5.65 alpha 10 일때 평균 rmse: 5.52 alpha 100 일때 평균 rmse: 5.33 변환유형: Standard , Polynomial Degree: 2 alpha 0.1 일때 평균 rmse: 9.14 alpha 1 일때 평균 rmse: 8.94 alpha 10 일때 평균 rmse: 10.56 alpha 100 일때 평균 rmse: 10.57 변환유형: MinMax , Polynomial Degree: None alpha 0.1 일때 평균 rmse: 5.79 alpha 1 일때 평균 rmse: 5.65 alpha 10 일때 평균 rmse: 5.52 alpha 100 일때 평균 rmse: 5.33 변환유형: MinMax , Polynomial Degree: 2 alpha 0.1 일때 평균 rmse: 9.14 alpha 1 일때 평균 rmse: 8.94 alpha 10 일때 평균 rmse: 10.56 alpha 100 일때 평균 rmse: 10.57 변환유형: Log , Polynomial Degree: None alpha 0.1 일때 평균 rmse: 4.77 alpha 1 일때 평균 rmse: 4.68 alpha 10 일때 평균 rmse: 4.84 alpha 100 일때 평균 rmse: 6.24 . log 변환이 다른 변환에 비해 성능이 뛰어난 걸 볼 수 있습니다. .",
            "url": "https://ksy1526.github.io/myblog//myblog/book/jupyter/guide/poly/ridge/lasso/regression/2021/09/25/PythonMachine5_2.html",
            "relUrl": "/book/jupyter/guide/poly/ridge/lasso/regression/2021/09/25/PythonMachine5_2.html",
            "date": " • Sep 25, 2021"
        }
        
    
  
    
        ,"post14": {
            "title": "[SSUDA] 심장병 데이터 분석",
            "content": ". &#45936;&#51060;&#53552; &#48520;&#47084;&#50724;&#44592; . from google.colab import drive drive.mount(&#39;/content/drive&#39;) . Mounted at /content/drive . import pandas as pd data = pd.read_csv(&quot;/content/drive/MyDrive/heart.csv&quot;) . Verson 1. &#49900;&#54540;&#54620; &#47196;&#51648;&#49828;&#54001; &#54924;&#44480; &#47784;&#54805; . &#45936;&#51060;&#53552; &#51060;&#54644; . df = data.copy() df.head() . age sex cp trtbps chol fbs restecg thalachh exng oldpeak slp caa thall output . 0 63 | 1 | 3 | 145 | 233 | 1 | 0 | 150 | 0 | 2.3 | 0 | 0 | 1 | 1 | . 1 37 | 1 | 2 | 130 | 250 | 0 | 1 | 187 | 0 | 3.5 | 0 | 0 | 2 | 1 | . 2 41 | 0 | 1 | 130 | 204 | 0 | 0 | 172 | 0 | 1.4 | 2 | 0 | 2 | 1 | . 3 56 | 1 | 1 | 120 | 236 | 0 | 1 | 178 | 0 | 0.8 | 2 | 0 | 2 | 1 | . 4 57 | 0 | 0 | 120 | 354 | 0 | 1 | 163 | 1 | 0.6 | 2 | 0 | 2 | 1 | . 디폴트 값은 5입니다. . df.columns . Index([&#39;age&#39;, &#39;sex&#39;, &#39;cp&#39;, &#39;trtbps&#39;, &#39;chol&#39;, &#39;fbs&#39;, &#39;restecg&#39;, &#39;thalachh&#39;, &#39;exng&#39;, &#39;oldpeak&#39;, &#39;slp&#39;, &#39;caa&#39;, &#39;thall&#39;, &#39;output&#39;], dtype=&#39;object&#39;) . df.columns.values.tolist() . [&#39;age&#39;, &#39;sex&#39;, &#39;cp&#39;, &#39;trtbps&#39;, &#39;chol&#39;, &#39;fbs&#39;, &#39;restecg&#39;, &#39;thalachh&#39;, &#39;exng&#39;, &#39;oldpeak&#39;, &#39;slp&#39;, &#39;caa&#39;, &#39;thall&#39;, &#39;output&#39;] . 컬럼은 이런 방식으로 확인할 수 있습니다. . 밑에 DataFrame.columns.values.tolist() 함수는 컬럼 추출 중 가장 런타임이 빠르다고 합니다. . print(&#39;Shape is&#39;,df.shape) . Shape is (303, 14) . 303개 데이터, 14개 특성값이 있습니다. . df.isnull().sum() . age 0 sex 0 cp 0 trtbps 0 chol 0 fbs 0 restecg 0 thalachh 0 exng 0 oldpeak 0 slp 0 caa 0 thall 0 output 0 dtype: int64 . df.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 303 entries, 0 to 302 Data columns (total 14 columns): # Column Non-Null Count Dtype -- -- 0 age 303 non-null int64 1 sex 303 non-null int64 2 cp 303 non-null int64 3 trtbps 303 non-null int64 4 chol 303 non-null int64 5 fbs 303 non-null int64 6 restecg 303 non-null int64 7 thalachh 303 non-null int64 8 exng 303 non-null int64 9 oldpeak 303 non-null float64 10 slp 303 non-null int64 11 caa 303 non-null int64 12 thall 303 non-null int64 13 output 303 non-null int64 dtypes: float64(1), int64(13) memory usage: 33.3 KB . 글쓴이는 윗방식으로 null값 유무를 체크했습니다. . 그러나 df.info() 방식이 여러가지 정보를 같이 줘 더 효율적입니다. . df.describe() . age sex cp trtbps chol fbs restecg thalachh exng oldpeak slp caa thall output . count 303.000000 | 303.000000 | 303.000000 | 303.000000 | 303.000000 | 303.000000 | 303.000000 | 303.000000 | 303.000000 | 303.000000 | 303.000000 | 303.000000 | 303.000000 | 303.000000 | . mean 54.366337 | 0.683168 | 0.966997 | 131.623762 | 246.264026 | 0.148515 | 0.528053 | 149.646865 | 0.326733 | 1.039604 | 1.399340 | 0.729373 | 2.313531 | 0.544554 | . std 9.082101 | 0.466011 | 1.032052 | 17.538143 | 51.830751 | 0.356198 | 0.525860 | 22.905161 | 0.469794 | 1.161075 | 0.616226 | 1.022606 | 0.612277 | 0.498835 | . min 29.000000 | 0.000000 | 0.000000 | 94.000000 | 126.000000 | 0.000000 | 0.000000 | 71.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | . 25% 47.500000 | 0.000000 | 0.000000 | 120.000000 | 211.000000 | 0.000000 | 0.000000 | 133.500000 | 0.000000 | 0.000000 | 1.000000 | 0.000000 | 2.000000 | 0.000000 | . 50% 55.000000 | 1.000000 | 1.000000 | 130.000000 | 240.000000 | 0.000000 | 1.000000 | 153.000000 | 0.000000 | 0.800000 | 1.000000 | 0.000000 | 2.000000 | 1.000000 | . 75% 61.000000 | 1.000000 | 2.000000 | 140.000000 | 274.500000 | 0.000000 | 1.000000 | 166.000000 | 1.000000 | 1.600000 | 2.000000 | 1.000000 | 3.000000 | 1.000000 | . max 77.000000 | 1.000000 | 3.000000 | 200.000000 | 564.000000 | 1.000000 | 2.000000 | 202.000000 | 1.000000 | 6.200000 | 2.000000 | 4.000000 | 3.000000 | 1.000000 | . 데이터를 보면 어느정도 스케일링이 필요하다는 것을 알 수 있습니다. . &#53945;&#49457; &#49828;&#52992;&#51068;&#47553; . df[&#39;age&#39;] = df[&#39;age&#39;]/max(df[&#39;age&#39;]) df[&#39;cp&#39;] = df[&#39;cp&#39;]/max(df[&#39;cp&#39;]) df[&#39;trtbps&#39;] = df[&#39;trtbps&#39;]/max(df[&#39;trtbps&#39;]) df[&#39;chol&#39;] = df[&#39;chol&#39;]/max(df[&#39;chol&#39;]) df[&#39;thalachh&#39;] = df[&#39;thalachh&#39;]/max(df[&#39;thalachh&#39;]) . df.describe() . age sex cp trtbps chol fbs restecg thalachh exng oldpeak slp caa thall output . count 303.000000 | 303.000000 | 303.000000 | 303.000000 | 303.000000 | 303.000000 | 303.000000 | 303.000000 | 303.000000 | 303.000000 | 303.000000 | 303.000000 | 303.000000 | 303.000000 | . mean 0.706056 | 0.683168 | 0.322332 | 0.658119 | 0.436638 | 0.148515 | 0.528053 | 0.740826 | 0.326733 | 1.039604 | 1.399340 | 0.729373 | 2.313531 | 0.544554 | . std 0.117949 | 0.466011 | 0.344017 | 0.087691 | 0.091898 | 0.356198 | 0.525860 | 0.113392 | 0.469794 | 1.161075 | 0.616226 | 1.022606 | 0.612277 | 0.498835 | . min 0.376623 | 0.000000 | 0.000000 | 0.470000 | 0.223404 | 0.000000 | 0.000000 | 0.351485 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | . 25% 0.616883 | 0.000000 | 0.000000 | 0.600000 | 0.374113 | 0.000000 | 0.000000 | 0.660891 | 0.000000 | 0.000000 | 1.000000 | 0.000000 | 2.000000 | 0.000000 | . 50% 0.714286 | 1.000000 | 0.333333 | 0.650000 | 0.425532 | 0.000000 | 1.000000 | 0.757426 | 0.000000 | 0.800000 | 1.000000 | 0.000000 | 2.000000 | 1.000000 | . 75% 0.792208 | 1.000000 | 0.666667 | 0.700000 | 0.486702 | 0.000000 | 1.000000 | 0.821782 | 1.000000 | 1.600000 | 2.000000 | 1.000000 | 3.000000 | 1.000000 | . max 1.000000 | 1.000000 | 1.000000 | 1.000000 | 1.000000 | 1.000000 | 2.000000 | 1.000000 | 1.000000 | 6.200000 | 2.000000 | 4.000000 | 3.000000 | 1.000000 | . 이전과 달리 특성 스케일이 확실히 비슷해졌습니다. . &#45936;&#51060;&#53552; &#47784;&#45944;&#47553; . from sklearn.model_selection import train_test_split #splitting data into training data and testing data X_train, X_test, y_train, y_test = train_test_split( df.drop([&#39;output&#39;], axis=1), df.output, test_size= 0.2, # 20% test data &amp; 80% train data random_state=0, stratify=df.output ) . stratify 속성 =&gt; y값의 공평한 분배를 위해 사용하는 속성입니다. . from sklearn.linear_model import LogisticRegression clf = LogisticRegression() clf.fit(X_train, y_train) from sklearn.metrics import accuracy_score Y_pred = clf.predict(X_test) acc=accuracy_score(y_test, Y_pred) print(&#39;Accuracy is&#39;,round(acc,2)*100,&#39;%&#39;) . Accuracy is 89.0 % . 로지스틱 회귀 모형을 별다른 튜닝 없이 사용했습니다. . 정확도 측면에서만 보면 캐글에 있는 다른 코드와 별반 다르지 않습니다. . Verson 2. &#49900;&#54540;&#54620; &#46373;&#47084;&#45789; &#47784;&#54805; . &#45936;&#51060;&#53552; &#51060;&#54644;2 . df = data.copy() df.output.value_counts() . 1 165 0 138 Name: output, dtype: int64 . 이전 모델에서 생략(?)된 부분인거 같은데 1과 0 값의 비율이 조금 차이가 있습니다. . df.corr().abs()[&#39;output&#39;].sort_values(ascending = False) . output 1.000000 exng 0.436757 cp 0.433798 oldpeak 0.430696 thalachh 0.421741 caa 0.391724 slp 0.345877 thall 0.344029 sex 0.280937 age 0.225439 trtbps 0.144931 restecg 0.137230 chol 0.085239 fbs 0.028046 Name: output, dtype: float64 . Y값과의 상관계수가 어느정도 되는지 확인해보았습니다. . &#45936;&#51060;&#53552; &#47784;&#45944;&#47553;2 . from sklearn.model_selection import train_test_split from sklearn.metrics import accuracy_score X = df.drop(&#39;output&#39;, axis = 1) y = df[&#39;output&#39;] X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42) X_train.shape . (242, 13) . from sklearn.preprocessing import StandardScaler sc = StandardScaler() X_train = sc.fit_transform(X_train) X_test = sc.transform(X_test) . 여기서는 StandardScaler를 사용해 스케일링을 했습니다. . 평균 0, 분산 1로 조정합니다. 이 스케일링은 이상치가 있을때 잘 작용하지 않을 수 있습니다. . from tensorflow import keras model = keras.Sequential( [ keras.layers.Dense( 256, activation=&quot;relu&quot;, input_shape=[13] ), keras.layers.Dense(515, activation=&quot;relu&quot;), keras.layers.Dropout(0.3), keras.layers.Dense(50, activation=&quot;relu&quot;), keras.layers.Dropout(0.3), keras.layers.Dense(1, activation=&quot;sigmoid&quot;), ] ) model.summary() . Model: &#34;sequential_5&#34; _________________________________________________________________ Layer (type) Output Shape Param # ================================================================= dense_20 (Dense) (None, 256) 3584 _________________________________________________________________ dense_21 (Dense) (None, 515) 132355 _________________________________________________________________ dropout_10 (Dropout) (None, 515) 0 _________________________________________________________________ dense_22 (Dense) (None, 50) 25800 _________________________________________________________________ dropout_11 (Dropout) (None, 50) 0 _________________________________________________________________ dense_23 (Dense) (None, 1) 51 ================================================================= Total params: 161,790 Trainable params: 161,790 Non-trainable params: 0 _________________________________________________________________ . 활성화 함수로 제일 많이 사용하는 relu와 sigmoid함수를 사용했습니다. . relu함수 : 입력이 양수일 경우 그대로 반환, 음수일경우 0으로 만듭니다. . sigmoid함수 : 1 / (1 + e^z) 함수. 값을 0에서 1 사이로 변환합니다. . 첫번째 구간에 아웃풋 값을 256개 주었는데, 변수값이 13개임으로 모수가 14개입니다. . 그래서 256*14 = 3584개 파라미터가 나오게 된 것입니다. . 중간에 있는 드롭아웃은 일정 비율만큼 뉴런을 랜덤하게 꺼서 과대적합을 막는 역할을 합니다. . model.compile(optimizer = &#39;Adam&#39;, loss = &#39;binary_crossentropy&#39;, metrics = [&#39;binary_accuracy&#39;]) early_stopping = keras.callbacks.EarlyStopping( patience = 20, min_delta = 0.001, restore_best_weights =True ) history = model.fit( X_train, y_train, validation_data=(X_test, y_test), batch_size=15, epochs=50, callbacks = [early_stopping], verbose=1, ) . Epoch 1/50 17/17 [==============================] - 1s 15ms/step - loss: 0.5500 - binary_accuracy: 0.7190 - val_loss: 0.3814 - val_binary_accuracy: 0.8852 Epoch 2/50 17/17 [==============================] - 0s 6ms/step - loss: 0.3823 - binary_accuracy: 0.8347 - val_loss: 0.3797 - val_binary_accuracy: 0.8852 Epoch 3/50 17/17 [==============================] - 0s 6ms/step - loss: 0.3354 - binary_accuracy: 0.8719 - val_loss: 0.4391 - val_binary_accuracy: 0.8197 Epoch 4/50 17/17 [==============================] - 0s 6ms/step - loss: 0.3017 - binary_accuracy: 0.8802 - val_loss: 0.4147 - val_binary_accuracy: 0.8689 Epoch 5/50 17/17 [==============================] - 0s 6ms/step - loss: 0.2589 - binary_accuracy: 0.9091 - val_loss: 0.4388 - val_binary_accuracy: 0.8689 Epoch 6/50 17/17 [==============================] - 0s 6ms/step - loss: 0.2579 - binary_accuracy: 0.9256 - val_loss: 0.4795 - val_binary_accuracy: 0.8525 Epoch 7/50 17/17 [==============================] - 0s 7ms/step - loss: 0.2019 - binary_accuracy: 0.9256 - val_loss: 0.4895 - val_binary_accuracy: 0.8689 Epoch 8/50 17/17 [==============================] - 0s 6ms/step - loss: 0.1889 - binary_accuracy: 0.9298 - val_loss: 0.5359 - val_binary_accuracy: 0.8361 Epoch 9/50 17/17 [==============================] - 0s 6ms/step - loss: 0.1887 - binary_accuracy: 0.9215 - val_loss: 0.5324 - val_binary_accuracy: 0.8525 Epoch 10/50 17/17 [==============================] - 0s 6ms/step - loss: 0.1578 - binary_accuracy: 0.9545 - val_loss: 0.5441 - val_binary_accuracy: 0.8689 Epoch 11/50 17/17 [==============================] - 0s 6ms/step - loss: 0.1686 - binary_accuracy: 0.9215 - val_loss: 0.6338 - val_binary_accuracy: 0.8689 Epoch 12/50 17/17 [==============================] - 0s 6ms/step - loss: 0.1448 - binary_accuracy: 0.9504 - val_loss: 0.6872 - val_binary_accuracy: 0.8197 Epoch 13/50 17/17 [==============================] - 0s 6ms/step - loss: 0.1065 - binary_accuracy: 0.9628 - val_loss: 0.7682 - val_binary_accuracy: 0.8197 Epoch 14/50 17/17 [==============================] - 0s 7ms/step - loss: 0.0879 - binary_accuracy: 0.9835 - val_loss: 0.8583 - val_binary_accuracy: 0.8197 Epoch 15/50 17/17 [==============================] - 0s 6ms/step - loss: 0.0877 - binary_accuracy: 0.9711 - val_loss: 0.9300 - val_binary_accuracy: 0.8361 Epoch 16/50 17/17 [==============================] - 0s 6ms/step - loss: 0.0688 - binary_accuracy: 0.9835 - val_loss: 0.9281 - val_binary_accuracy: 0.8361 Epoch 17/50 17/17 [==============================] - 0s 8ms/step - loss: 0.0615 - binary_accuracy: 0.9835 - val_loss: 0.9688 - val_binary_accuracy: 0.8361 Epoch 18/50 17/17 [==============================] - 0s 6ms/step - loss: 0.0496 - binary_accuracy: 0.9835 - val_loss: 1.0818 - val_binary_accuracy: 0.8197 Epoch 19/50 17/17 [==============================] - 0s 6ms/step - loss: 0.0915 - binary_accuracy: 0.9628 - val_loss: 1.3326 - val_binary_accuracy: 0.8525 Epoch 20/50 17/17 [==============================] - 0s 6ms/step - loss: 0.0953 - binary_accuracy: 0.9669 - val_loss: 1.1602 - val_binary_accuracy: 0.8525 Epoch 21/50 17/17 [==============================] - 0s 7ms/step - loss: 0.0366 - binary_accuracy: 0.9959 - val_loss: 1.1617 - val_binary_accuracy: 0.8525 Epoch 22/50 17/17 [==============================] - 0s 6ms/step - loss: 0.0407 - binary_accuracy: 0.9876 - val_loss: 1.2300 - val_binary_accuracy: 0.8361 . model.evaluate(X_test, y_test) . 2/2 [==============================] - 0s 7ms/step - loss: 0.3797 - binary_accuracy: 0.8852 . [0.3796648383140564, 0.8852459192276001] . predictions =(model.predict(X_test)&gt;0.5).astype(&quot;int32&quot;) from sklearn.metrics import classification_report, confusion_matrix, accuracy_score accuracy_score(y_test, predictions) . 0.8852459016393442 . 아까 결과와 비슷한 수치를 보입니다. . print(classification_report(y_test, predictions)) . precision recall f1-score support 0 0.00 0.00 0.00 29 1 0.52 1.00 0.69 32 accuracy 0.52 61 macro avg 0.26 0.50 0.34 61 weighted avg 0.28 0.52 0.36 61 . classification_report 함수가 상당히 유용한 걸 알 수있습니다. . 한번에 정밀도, 재현율, f1-score 값 까지 보여줍니다. . &#45712;&#45184;&#51216; . 분류에 기본적인 로지스틱 회귀모형과 단순한 딥러닝 코드를 따라해봤습니다. . 특히 딥러닝 부분에 경우 정말 기본적인 것밖에 몰라 코드 해석에 시간이 많이 걸렸네요. . 여러가지로 코드를 만져가며 느낀점은 이번 데이터에 경우 스케일링이 많이 중요한 것 같습니다. . 스케일링 종류에 따라서 정확도 값이 크게 변하는 것을 관찰했습니다. . 특히 트리기반 부스팅 모델이 아니라 더 그런 것 같습니다. . 너무 복잡한 모델을 급하게 이해하기 보다, 이해할 수 있는 모델을 관찰하며 데이터 분석은 어떤 과정으로 하는가를 살펴봤습니다. .",
            "url": "https://ksy1526.github.io/myblog//myblog/ssuda/jupyter/kaggle/logistic/scale/keras/regression/2021/09/24/kagglessu2.html",
            "relUrl": "/ssuda/jupyter/kaggle/logistic/scale/keras/regression/2021/09/24/kagglessu2.html",
            "date": " • Sep 24, 2021"
        }
        
    
  
    
        ,"post15": {
            "title": "[머신러닝 가이드] 5-1 단순선형회귀",
            "content": ". &#44221;&#49324;&#54616;&#44053;&#48277; . import numpy as np import matplotlib.pyplot as plt %matplotlib inline np.random.seed(8) x = 2 * np.random.randn(100,1) y = 6 + 4 * x + np.random.randn(100,1) plt.scatter(x,y) . &lt;matplotlib.collections.PathCollection at 0x7f6bcf5bb850&gt; . y = 4x + 6 근사 . np.random.randn =&gt; 표준정규분포에서 값 생성. 100,1 은 값 행렬 형식 선언 입니다. . def get_cost(y, y_pred): N = len(y) cost = np.sum(np.square(y-y_pred)) / N return cost . 편차 제곱 평균을 계산해주는 함수. . np.square =&gt; 제곱 해주는 함수 . def get_weight_updates(w1, w0, x, y, learning_rate = 0.01): N = len(y) # w1, w0 동일한 행렬 크기를 갖는 0 값으로 초기화 w1_update = np.zeros_like(w1) w0_update = np.zeros_like(w0) #np.dot 행렬의 곱 y_pred = np.dot(x, w1.T) + w0 diff = y - y_pred w0_factors = np.ones((N, 1)) w1_update = -(2/N) * learning_rate * (np.dot(x.T, diff)) w0_update = -(2/N) * learning_rate * (np.dot(w0_factors.T, diff)) return w1_update, w0_update . 편미분한 w1, w0값을 이용해서 w0, w1값을 지속적으로 업데이트 해줍니다 . np.zeros_like(w1) =&gt; w1값과 같은 형태에 값은 0인 행렬 생성 . np.dot(,) =&gt; 행렬 연산 . def gradient_descent_steps(x,y, iters = 10000): w0 = np.zeros((1,1)) w1 = np.zeros((1,1)) for ind in range(iters): w1_update, w0_update = get_weight_updates(w1, w0, x, y, learning_rate=0.01) w1 = w1 - w1_update w0 = w0 - w0_update return w1, w0 . 위 두 함수를 통해 w1, w0 값을 지속적으로 업데이트 하여 최적에 값에 도달하게 합니다. . w1, w0 = gradient_descent_steps(x,y, 1000) print(&#39;w1 :&#39;, np.round(w1[0,0],4), &#39;w0 :&#39;, np.round(w0[0,0],4)) y_pred = w1[0,0] * x + w0 print(&#39;편차제곱평균:&#39;, np.round(get_cost(y, y_pred),4)) . w1 : 3.9974 w0 : 5.9649 편차제곱평균: 1.1967 . plt.scatter(x,y) plt.plot(x,y_pred) . [&lt;matplotlib.lines.Line2D at 0x7f6bcf10f110&gt;] . 경사하강법을 이용해 회귀선이 잘 만들어졌습니다. . 다만 데이터에 개수가 100개보다 훨씬 많아지면 전체데이터로 계수를 업데이트 하지 못합니다. . 그 때문에 실전에서는 대부분 (미니배치)확률적 경사 하강법을 이용합니다. . 이 방식은 전체 데이터가 아닌 일부 데이터로 계수를 업데이트 하기 때문에 속도가 상대적으로 빠릅니다. . 이를 구현해보겠습니다. . def stochastic_gradient_descent_steps(x,y,batch_size = 10, iters = 1000): w0 = np.zeros((1,1)) w1 = np.zeros((1,1)) prev_cost = 100000 iter_index = 0 for ind in range(iters): np.random.seed(ind) stochastic_random_index = np.random.permutation(x.shape[0]) sample_x = x[stochastic_random_index[0:batch_size]] sample_y = y[stochastic_random_index[0:batch_size]] w1_update, w0_update = get_weight_updates(w1, w0, sample_x, sample_y) w1 = w1 - w1_update w0 = w0 - w0_update return w1, w0 . np.random.permutation(x.shape[0]) =&gt; 주어진 데이터를 셔플해서 출력함 . 앞 함수와 바뀐 부분은 x, y를 샘플링해서 넣는다는 점 입니다. . w1, w0 = stochastic_gradient_descent_steps(x,y,iters=1000) print(&#39;w1:&#39;, np.round(w1[0,0],3), &#39;w0:&#39;, np.round(w0[0,0],4)) y_pred = w1[0,0] * x + w0 print(&#39;편차제곱 평균:&#39;, np.round(get_cost(y,y_pred),4)) . w1: 4.006 w0: 5.9135 편차제곱 평균: 1.1996 . 편차제곱 평균 값이 전체 x,y를 투입했을때와 큰 차이가 없습니다. . 그러므로 계산 속도가 훨씬 빠른 미니배치 경사하강법을 많이 사용합니다. . &#45800;&#49692; &#49440;&#54805; &#54924;&#44480;(&#48372;&#49828;&#53556; &#51452;&#53469; &#44032;&#44201;) . import numpy as np import matplotlib.pyplot as plt import pandas as pd import seaborn as sns from scipy import stats from sklearn.datasets import load_boston %matplotlib inline boston = load_boston() bostonDF = pd.DataFrame(boston.data, columns = boston.feature_names) bostonDF[&#39;PRICE&#39;] = boston.target print(&#39;보스턴 데이터 세트 크기:&#39;, bostonDF.shape) bostonDF.head() . 보스턴 데이터 세트 크기: (506, 14) . CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT PRICE . 0 0.00632 | 18.0 | 2.31 | 0.0 | 0.538 | 6.575 | 65.2 | 4.0900 | 1.0 | 296.0 | 15.3 | 396.90 | 4.98 | 24.0 | . 1 0.02731 | 0.0 | 7.07 | 0.0 | 0.469 | 6.421 | 78.9 | 4.9671 | 2.0 | 242.0 | 17.8 | 396.90 | 9.14 | 21.6 | . 2 0.02729 | 0.0 | 7.07 | 0.0 | 0.469 | 7.185 | 61.1 | 4.9671 | 2.0 | 242.0 | 17.8 | 392.83 | 4.03 | 34.7 | . 3 0.03237 | 0.0 | 2.18 | 0.0 | 0.458 | 6.998 | 45.8 | 6.0622 | 3.0 | 222.0 | 18.7 | 394.63 | 2.94 | 33.4 | . 4 0.06905 | 0.0 | 2.18 | 0.0 | 0.458 | 7.147 | 54.2 | 6.0622 | 3.0 | 222.0 | 18.7 | 396.90 | 5.33 | 36.2 | . 사이킷런에 내장되어있는 보스턴 주택 데이터를 불러왔습니다. . bostonDF.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 506 entries, 0 to 505 Data columns (total 14 columns): # Column Non-Null Count Dtype -- -- 0 CRIM 506 non-null float64 1 ZN 506 non-null float64 2 INDUS 506 non-null float64 3 CHAS 506 non-null float64 4 NOX 506 non-null float64 5 RM 506 non-null float64 6 AGE 506 non-null float64 7 DIS 506 non-null float64 8 RAD 506 non-null float64 9 TAX 506 non-null float64 10 PTRATIO 506 non-null float64 11 B 506 non-null float64 12 LSTAT 506 non-null float64 13 PRICE 506 non-null float64 dtypes: float64(14) memory usage: 55.5 KB . 결측값은 없으며 모든 피처가 float 형 입니다. . fig, axs = plt.subplots(figsize=(16,8), ncols = 4, nrows = 2) lm_features = [&#39;RM&#39;,&#39;ZN&#39;, &#39;INDUS&#39;,&#39;NOX&#39;,&#39;AGE&#39;,&#39;PTRATIO&#39;,&#39;LSTAT&#39;,&#39;RAD&#39;] for i, feature in enumerate(lm_features): row = int(i/4) col = i%4 sns.regplot(x=feature, y=&#39;PRICE&#39;, data=bostonDF, ax=axs[row][col]) . sns.regplot(x,y) =&gt; x,y 산점도와 함께 회귀직선을 그려줌. . plt.subplots(ncols = , nrows= ) 여러개의 그림을 그릴 수 있게 해줌. . RM과 LSTAT 변수가 가장 PRICE 변수와 연관성이 있어보입니다. . from sklearn.model_selection import train_test_split from sklearn.linear_model import LinearRegression from sklearn.metrics import mean_squared_error, r2_score y_target = bostonDF[&#39;PRICE&#39;] x_data = bostonDF.drop([&#39;PRICE&#39;], axis = 1, inplace=False) x_train, x_test, y_train, y_test = train_test_split(x_data, y_target, test_size = 0.3, random_state = 156) lr = LinearRegression() lr.fit(x_train, y_train) y_preds = lr.predict(x_test) mse = mean_squared_error(y_test, y_preds) rmse = np.sqrt(mse) print(&#39;mse :&#39;, np.round(mse,4), &#39;, rmse :&#39;, np.round(rmse, 4)) print(&#39;결정계수:&#39;, np.round(r2_score(y_test, y_preds), 4)) . mse : 17.2969 , rmse : 4.159 결정계수: 0.7572 . 모델을 어느정도 설명해 준 모습입니다. . print(&#39;절편 값:&#39;,lr.intercept_) print(&#39;회귀 계수값:&#39;, np.round(lr.coef_,1)) . 절편 값: 40.995595172164755 회귀 계수값: [ -0.1 0.1 0. 3. -19.8 3.4 0. -1.7 0.4 -0. -0.9 0. -0.6] . coeff = pd.Series(data=np.round(lr.coef_, 1), index = x_data.columns) coeff.sort_values(ascending=False) . RM 3.4 CHAS 3.0 RAD 0.4 ZN 0.1 B 0.0 TAX -0.0 AGE 0.0 INDUS 0.0 CRIM -0.1 LSTAT -0.6 PTRATIO -0.9 DIS -1.7 NOX -19.8 dtype: float64 . 변수 이름과 추정 회귀 계수를 맵핑 시킨 모습입니다. . NOX 변수의 계수 값이 크게 작아보입니다. . from sklearn.model_selection import cross_val_score neg_mse_scores = cross_val_score(lr, x_data, y_target, scoring=&#39;neg_mean_squared_error&#39;, cv = 5) rmse_scores = np.sqrt(-1 * neg_mse_scores) avg_rmse = np.mean(rmse_scores) print(&#39;mse scores&#39;, np.round(neg_mse_scores,2)) print(&#39;rmse scores&#39;, np.round(rmse_scores, 2)) print(&#39;평균 rmse score:&#39;, np.round(avg_rmse,2)) . mse scores [-12.46 -26.05 -33.07 -80.76 -33.31] rmse scores [3.53 5.1 5.75 8.99 5.77] 평균 rmse score: 5.83 . 5개의 폴드 세트를 이용한 교차검증 입니다. . scoring = &#39;neg_mean_squared_error&#39; 같은 경우 보통 모델 평가를 위한 값이 커야 좋은 값인데, mse 값은 작아야 좋습니다. . 그러므로 음수를 붙여서 보정해준다고 생각하면 좋습니다. . 다음에는 다항회귀, 릿지/라쏘 회귀 부분을 공부하겠습니다. .",
            "url": "https://ksy1526.github.io/myblog//myblog/book/jupyter/guide/math/regression/2021/09/20/PythonMachine5_1.html",
            "relUrl": "/book/jupyter/guide/math/regression/2021/09/20/PythonMachine5_1.html",
            "date": " • Sep 20, 2021"
        }
        
    
  
    
        ,"post16": {
            "title": "[SSUDA] 주택 가격 예측",
            "content": ". https://www.kaggle.com/c/house-prices-advanced-regression-techniques . 캐글에 있는 주택 가격 예측 데이터 분석입니다. . 부스팅 모델들이 튜닝하는데 시간이 걸리기 때문에 좀 더 간단한 선형 회귀 모델을 사용하겠습니다. . 분류 관련 공부를 조금 해본 경험으로, 회귀에 기본인 선형 회귀모델을 이번 데이터를 이용해 공부해보겠습니다. . 이번 분석에 핵심 포인트는 숫자 변수 대부분이 치우쳐 있으므로 숫자 변수를 log_transform하는 것입니다. . &#45936;&#51060;&#53552; &#48520;&#47084;&#50724;&#44592; &#48143; &#46168;&#47084;&#48372;&#44592; . import pandas as pd import numpy as np import seaborn as sns import matplotlib import matplotlib.pyplot as plt from scipy.stats import skew from scipy.stats.stats import pearsonr %config InlineBackend.figure_format = &#39;retina&#39; #set &#39;png&#39; here when working on notebook %matplotlib inline . from google.colab import drive drive.mount(&#39;/content/drive&#39;) . Mounted at /content/drive . train = pd.read_csv(&quot;/content/drive/MyDrive/house/train.csv&quot;) test = pd.read_csv(&quot;/content/drive/MyDrive/house/test.csv&quot;) . train.head() . Id MSSubClass MSZoning LotFrontage LotArea Street Alley LotShape LandContour Utilities LotConfig LandSlope Neighborhood Condition1 Condition2 BldgType HouseStyle OverallQual OverallCond YearBuilt YearRemodAdd RoofStyle RoofMatl Exterior1st Exterior2nd MasVnrType MasVnrArea ExterQual ExterCond Foundation BsmtQual BsmtCond BsmtExposure BsmtFinType1 BsmtFinSF1 BsmtFinType2 BsmtFinSF2 BsmtUnfSF TotalBsmtSF Heating ... CentralAir Electrical 1stFlrSF 2ndFlrSF LowQualFinSF GrLivArea BsmtFullBath BsmtHalfBath FullBath HalfBath BedroomAbvGr KitchenAbvGr KitchenQual TotRmsAbvGrd Functional Fireplaces FireplaceQu GarageType GarageYrBlt GarageFinish GarageCars GarageArea GarageQual GarageCond PavedDrive WoodDeckSF OpenPorchSF EnclosedPorch 3SsnPorch ScreenPorch PoolArea PoolQC Fence MiscFeature MiscVal MoSold YrSold SaleType SaleCondition SalePrice . 0 1 | 60 | RL | 65.0 | 8450 | Pave | NaN | Reg | Lvl | AllPub | Inside | Gtl | CollgCr | Norm | Norm | 1Fam | 2Story | 7 | 5 | 2003 | 2003 | Gable | CompShg | VinylSd | VinylSd | BrkFace | 196.0 | Gd | TA | PConc | Gd | TA | No | GLQ | 706 | Unf | 0 | 150 | 856 | GasA | ... | Y | SBrkr | 856 | 854 | 0 | 1710 | 1 | 0 | 2 | 1 | 3 | 1 | Gd | 8 | Typ | 0 | NaN | Attchd | 2003.0 | RFn | 2 | 548 | TA | TA | Y | 0 | 61 | 0 | 0 | 0 | 0 | NaN | NaN | NaN | 0 | 2 | 2008 | WD | Normal | 208500 | . 1 2 | 20 | RL | 80.0 | 9600 | Pave | NaN | Reg | Lvl | AllPub | FR2 | Gtl | Veenker | Feedr | Norm | 1Fam | 1Story | 6 | 8 | 1976 | 1976 | Gable | CompShg | MetalSd | MetalSd | None | 0.0 | TA | TA | CBlock | Gd | TA | Gd | ALQ | 978 | Unf | 0 | 284 | 1262 | GasA | ... | Y | SBrkr | 1262 | 0 | 0 | 1262 | 0 | 1 | 2 | 0 | 3 | 1 | TA | 6 | Typ | 1 | TA | Attchd | 1976.0 | RFn | 2 | 460 | TA | TA | Y | 298 | 0 | 0 | 0 | 0 | 0 | NaN | NaN | NaN | 0 | 5 | 2007 | WD | Normal | 181500 | . 2 3 | 60 | RL | 68.0 | 11250 | Pave | NaN | IR1 | Lvl | AllPub | Inside | Gtl | CollgCr | Norm | Norm | 1Fam | 2Story | 7 | 5 | 2001 | 2002 | Gable | CompShg | VinylSd | VinylSd | BrkFace | 162.0 | Gd | TA | PConc | Gd | TA | Mn | GLQ | 486 | Unf | 0 | 434 | 920 | GasA | ... | Y | SBrkr | 920 | 866 | 0 | 1786 | 1 | 0 | 2 | 1 | 3 | 1 | Gd | 6 | Typ | 1 | TA | Attchd | 2001.0 | RFn | 2 | 608 | TA | TA | Y | 0 | 42 | 0 | 0 | 0 | 0 | NaN | NaN | NaN | 0 | 9 | 2008 | WD | Normal | 223500 | . 3 4 | 70 | RL | 60.0 | 9550 | Pave | NaN | IR1 | Lvl | AllPub | Corner | Gtl | Crawfor | Norm | Norm | 1Fam | 2Story | 7 | 5 | 1915 | 1970 | Gable | CompShg | Wd Sdng | Wd Shng | None | 0.0 | TA | TA | BrkTil | TA | Gd | No | ALQ | 216 | Unf | 0 | 540 | 756 | GasA | ... | Y | SBrkr | 961 | 756 | 0 | 1717 | 1 | 0 | 1 | 0 | 3 | 1 | Gd | 7 | Typ | 1 | Gd | Detchd | 1998.0 | Unf | 3 | 642 | TA | TA | Y | 0 | 35 | 272 | 0 | 0 | 0 | NaN | NaN | NaN | 0 | 2 | 2006 | WD | Abnorml | 140000 | . 4 5 | 60 | RL | 84.0 | 14260 | Pave | NaN | IR1 | Lvl | AllPub | FR2 | Gtl | NoRidge | Norm | Norm | 1Fam | 2Story | 8 | 5 | 2000 | 2000 | Gable | CompShg | VinylSd | VinylSd | BrkFace | 350.0 | Gd | TA | PConc | Gd | TA | Av | GLQ | 655 | Unf | 0 | 490 | 1145 | GasA | ... | Y | SBrkr | 1145 | 1053 | 0 | 2198 | 1 | 0 | 2 | 1 | 4 | 1 | Gd | 9 | Typ | 1 | TA | Attchd | 2000.0 | RFn | 3 | 836 | TA | TA | Y | 192 | 84 | 0 | 0 | 0 | 0 | NaN | NaN | NaN | 0 | 12 | 2008 | WD | Normal | 250000 | . 5 rows × 81 columns . train.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 1460 entries, 0 to 1459 Data columns (total 81 columns): # Column Non-Null Count Dtype -- -- 0 Id 1460 non-null int64 1 MSSubClass 1460 non-null int64 2 MSZoning 1460 non-null object 3 LotFrontage 1201 non-null float64 4 LotArea 1460 non-null int64 5 Street 1460 non-null object 6 Alley 91 non-null object 7 LotShape 1460 non-null object 8 LandContour 1460 non-null object 9 Utilities 1460 non-null object 10 LotConfig 1460 non-null object 11 LandSlope 1460 non-null object 12 Neighborhood 1460 non-null object 13 Condition1 1460 non-null object 14 Condition2 1460 non-null object 15 BldgType 1460 non-null object 16 HouseStyle 1460 non-null object 17 OverallQual 1460 non-null int64 18 OverallCond 1460 non-null int64 19 YearBuilt 1460 non-null int64 20 YearRemodAdd 1460 non-null int64 21 RoofStyle 1460 non-null object 22 RoofMatl 1460 non-null object 23 Exterior1st 1460 non-null object 24 Exterior2nd 1460 non-null object 25 MasVnrType 1452 non-null object 26 MasVnrArea 1452 non-null float64 27 ExterQual 1460 non-null object 28 ExterCond 1460 non-null object 29 Foundation 1460 non-null object 30 BsmtQual 1423 non-null object 31 BsmtCond 1423 non-null object 32 BsmtExposure 1422 non-null object 33 BsmtFinType1 1423 non-null object 34 BsmtFinSF1 1460 non-null int64 35 BsmtFinType2 1422 non-null object 36 BsmtFinSF2 1460 non-null int64 37 BsmtUnfSF 1460 non-null int64 38 TotalBsmtSF 1460 non-null int64 39 Heating 1460 non-null object 40 HeatingQC 1460 non-null object 41 CentralAir 1460 non-null object 42 Electrical 1459 non-null object 43 1stFlrSF 1460 non-null int64 44 2ndFlrSF 1460 non-null int64 45 LowQualFinSF 1460 non-null int64 46 GrLivArea 1460 non-null int64 47 BsmtFullBath 1460 non-null int64 48 BsmtHalfBath 1460 non-null int64 49 FullBath 1460 non-null int64 50 HalfBath 1460 non-null int64 51 BedroomAbvGr 1460 non-null int64 52 KitchenAbvGr 1460 non-null int64 53 KitchenQual 1460 non-null object 54 TotRmsAbvGrd 1460 non-null int64 55 Functional 1460 non-null object 56 Fireplaces 1460 non-null int64 57 FireplaceQu 770 non-null object 58 GarageType 1379 non-null object 59 GarageYrBlt 1379 non-null float64 60 GarageFinish 1379 non-null object 61 GarageCars 1460 non-null int64 62 GarageArea 1460 non-null int64 63 GarageQual 1379 non-null object 64 GarageCond 1379 non-null object 65 PavedDrive 1460 non-null object 66 WoodDeckSF 1460 non-null int64 67 OpenPorchSF 1460 non-null int64 68 EnclosedPorch 1460 non-null int64 69 3SsnPorch 1460 non-null int64 70 ScreenPorch 1460 non-null int64 71 PoolArea 1460 non-null int64 72 PoolQC 7 non-null object 73 Fence 281 non-null object 74 MiscFeature 54 non-null object 75 MiscVal 1460 non-null int64 76 MoSold 1460 non-null int64 77 YrSold 1460 non-null int64 78 SaleType 1460 non-null object 79 SaleCondition 1460 non-null object 80 SalePrice 1460 non-null int64 dtypes: float64(3), int64(35), object(43) memory usage: 924.0+ KB . all_data = pd.concat((train.loc[:,&#39;MSSubClass&#39;:&#39;SaleCondition&#39;], test.loc[:,&#39;MSSubClass&#39;:&#39;SaleCondition&#39;])) . id(고유번호)와 설명변수를 뺀 나머지 변수들을 전처리를 위해 all_data 변수로 합쳐주었습니다. . &#45936;&#51060;&#53552; &#51204;&#52376;&#47532; . 이 코드의 데이터 전처리는 화려하지 않습니다. 기본에 충실합니다. . 다음 3가지로 요약할 수 있습니다. . 로그(기능 + 1)를 사용하여 오른쪽으로 꼬리가 긴 그래프를 변환합니다. 그러면 어느정도 정규화됩니다. | 범주형 형상에 대한 더미 변수 생성 | 숫자 결측값(NaN)을 각 열의 평균으로 바꾸기 | 설명변수를 로그변환 해보기 . matplotlib.rcParams[&#39;figure.figsize&#39;] = (12.0, 6.0) prices = pd.DataFrame({&quot;price&quot;:train[&quot;SalePrice&quot;], &quot;log(price + 1)&quot;:np.log1p(train[&quot;SalePrice&quot;])}) prices.hist() . array([[&lt;matplotlib.axes._subplots.AxesSubplot object at 0x7f3be1089890&gt;, &lt;matplotlib.axes._subplots.AxesSubplot object at 0x7f3be1052b10&gt;]], dtype=object) . 로그변환 전 우측 꼬리가 두터운 느낌이였는데 잘 정규화 된 모습입니다. . all_data.dtypes . MSSubClass int64 MSZoning object LotFrontage float64 LotArea int64 Street object ... MiscVal int64 MoSold int64 YrSold int64 SaleType object SaleCondition object Length: 79, dtype: object . train[&quot;SalePrice&quot;] = np.log1p(train[&quot;SalePrice&quot;]) numeric_feats = all_data.dtypes[all_data.dtypes != &quot;object&quot;].index . all_data.dtypes =&gt; 데이터 타입 나열. 여기서 인덱스는 변수이름이기 때문에 이런 방식으로 쉽게 추출. . skewed_feats = train[numeric_feats].apply(lambda x: skew(x.dropna())) skewed_feats = skewed_feats[skewed_feats &gt; 0.75] skewed_feats = skewed_feats.index all_data[skewed_feats] = np.log1p(all_data[skewed_feats]) . shew = 왜도 값을 나타네는 함수. 왜도란 그래프가 비 대칭적인 모양인 것 . shew값이 큰 양수값이면 오른쪽으로 긴 꼬리를 가지는 분포를 가집니다. . 그러므로 shew값을 기준으로 로그변환을 할 변수를 찾을 수 있습니다. . 참고로 apply 함수는 파이썬 데이터 프레임에 적용하는 함수인데, 원하는 함수를 적용하고 싶을때 사용합니다. . 이때 apply 기본인자는 axis = 0이므로 열을 기준으로 함수를 적용합니다. . all_data = pd.get_dummies(all_data) all_data.head(5) . MSSubClass LotFrontage LotArea OverallQual OverallCond YearBuilt YearRemodAdd MasVnrArea BsmtFinSF1 BsmtFinSF2 BsmtUnfSF TotalBsmtSF 1stFlrSF 2ndFlrSF LowQualFinSF GrLivArea BsmtFullBath BsmtHalfBath FullBath HalfBath BedroomAbvGr KitchenAbvGr TotRmsAbvGrd Fireplaces GarageYrBlt GarageCars GarageArea WoodDeckSF OpenPorchSF EnclosedPorch 3SsnPorch ScreenPorch PoolArea MiscVal MoSold YrSold MSZoning_C (all) MSZoning_FV MSZoning_RH MSZoning_RL ... GarageFinish_Unf GarageQual_Ex GarageQual_Fa GarageQual_Gd GarageQual_Po GarageQual_TA GarageCond_Ex GarageCond_Fa GarageCond_Gd GarageCond_Po GarageCond_TA PavedDrive_N PavedDrive_P PavedDrive_Y PoolQC_Ex PoolQC_Fa PoolQC_Gd Fence_GdPrv Fence_GdWo Fence_MnPrv Fence_MnWw MiscFeature_Gar2 MiscFeature_Othr MiscFeature_Shed MiscFeature_TenC SaleType_COD SaleType_CWD SaleType_Con SaleType_ConLD SaleType_ConLI SaleType_ConLw SaleType_New SaleType_Oth SaleType_WD SaleCondition_Abnorml SaleCondition_AdjLand SaleCondition_Alloca SaleCondition_Family SaleCondition_Normal SaleCondition_Partial . 0 4.110874 | 4.189655 | 9.042040 | 7 | 5 | 2003 | 2003 | 5.283204 | 6.561031 | 0.0 | 5.017280 | 6.753438 | 6.753438 | 6.751101 | 0.0 | 7.444833 | 1.0 | 0.000000 | 2 | 1 | 3 | 0.693147 | 8 | 0 | 2003.0 | 2.0 | 548.0 | 0.000000 | 4.127134 | 0.000000 | 0.0 | 0.0 | 0.0 | 0.0 | 2 | 2008 | 0 | 0 | 0 | 1 | ... | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 1 | 0 | . 1 3.044522 | 4.394449 | 9.169623 | 6 | 8 | 1976 | 1976 | 0.000000 | 6.886532 | 0.0 | 5.652489 | 7.141245 | 7.141245 | 0.000000 | 0.0 | 7.141245 | 0.0 | 0.693147 | 2 | 0 | 3 | 0.693147 | 6 | 1 | 1976.0 | 2.0 | 460.0 | 5.700444 | 0.000000 | 0.000000 | 0.0 | 0.0 | 0.0 | 0.0 | 5 | 2007 | 0 | 0 | 0 | 1 | ... | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 1 | 0 | . 2 4.110874 | 4.234107 | 9.328212 | 7 | 5 | 2001 | 2002 | 5.093750 | 6.188264 | 0.0 | 6.075346 | 6.825460 | 6.825460 | 6.765039 | 0.0 | 7.488294 | 1.0 | 0.000000 | 2 | 1 | 3 | 0.693147 | 6 | 1 | 2001.0 | 2.0 | 608.0 | 0.000000 | 3.761200 | 0.000000 | 0.0 | 0.0 | 0.0 | 0.0 | 9 | 2008 | 0 | 0 | 0 | 1 | ... | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 1 | 0 | . 3 4.262680 | 4.110874 | 9.164401 | 7 | 5 | 1915 | 1970 | 0.000000 | 5.379897 | 0.0 | 6.293419 | 6.629363 | 6.869014 | 6.629363 | 0.0 | 7.448916 | 1.0 | 0.000000 | 1 | 0 | 3 | 0.693147 | 7 | 1 | 1998.0 | 3.0 | 642.0 | 0.000000 | 3.583519 | 5.609472 | 0.0 | 0.0 | 0.0 | 0.0 | 2 | 2006 | 0 | 0 | 0 | 1 | ... | 1 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 1 | 0 | 0 | 0 | 0 | 0 | . 4 4.110874 | 4.442651 | 9.565284 | 8 | 5 | 2000 | 2000 | 5.860786 | 6.486161 | 0.0 | 6.196444 | 7.044033 | 7.044033 | 6.960348 | 0.0 | 7.695758 | 1.0 | 0.000000 | 2 | 1 | 4 | 0.693147 | 9 | 1 | 2000.0 | 3.0 | 836.0 | 5.262690 | 4.442651 | 0.000000 | 0.0 | 0.0 | 0.0 | 0.0 | 12 | 2008 | 0 | 0 | 0 | 1 | ... | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 1 | 0 | 0 | 0 | 0 | 1 | 0 | . 5 rows × 288 columns . get_dummies 함수로 모든 object형 값이 원핫인코딩 됐습니다. . 저번에 프로젝트 할 때 변수를 하나하나 입력했던 것이 생각나는데 더 편한 방식을 알게 되었습니다. . all_data = all_data.fillna(all_data.mean()) . 결측값이 있을때 각 열의 평균값으로 대체하는 일반적인 방식입니다. . 윗 코드와 마찬가지로 저번 프로젝트에서 열마다 함수를 돌려 사용했는데 더 편한 방식을 알게 됐습니다. . X_train = all_data[:train.shape[0]] X_test = all_data[train.shape[0]:] y = train.SalePrice . 저번 프로젝트에서 트레인, 테스트 데이터에 각각 전처리를 적용했습니다. . 하지만 이 방법처럼 all_data로 묶고 한번에 전처리 하는 방식이 깔끔한 것 같습니다. . &#47551;&#51648; &#47784;&#45944; . 선형 회귀 모델 적합을 하겠습니다. . 이때 라쏘, 릿지 방법을 모두 사용해서 최적의 rmse 값을 찾겠습니다. . from sklearn.linear_model import Ridge, RidgeCV, ElasticNet, LassoCV, LassoLarsCV, Lasso from sklearn.model_selection import cross_val_score def rmse_cv(model): rmse= np.sqrt(-cross_val_score(model, X_train, y, scoring=&quot;neg_mean_squared_error&quot;, cv = 5)) return(rmse) . cross_val_score 함수는 교차 검증 후 정확도를 리스트로 보여줍니다. . 여기서 cv = 5 이기 때문에 5-fold로 교차검증 하게 됩니다. . model_ridge = Ridge() . 릿지 모델의 주요 파라미터는 알파입니다. . 알파값이 높아지면 규제가 심해지고 과적합을 방지해줍니다. . 다만 너무 많이 높아지면 과소적합이 되기 때문에 적절한 값을 찾아야합니다. . alphas = [0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 50, 75] cv_ridge = [rmse_cv(Ridge(alpha = alpha)).mean() for alpha in alphas] . 다양한 알파값을 릿지 함수에 적용시켰습니다. . 여기서 [값 for alpha in alphas] 는 for루프를 리스트 내에서 돌리는 것 입니다. . cv_ridge = pd.Series(cv_ridge, index = alphas) cv_ridge.plot(title = &quot;Validation - Just Do It&quot;) plt.xlabel(&quot;alpha&quot;) plt.ylabel(&quot;rmse&quot;) . Text(0, 0.5, &#39;rmse&#39;) . 시리즈에 plot를 하면 그래프가 생깁니다. . 이때 x축은 인덱스, y축은 본 값이 들어갑니다. . 알파값이 10일때 rmse값이 최소로, 알파는 10을 쓰는 것이 좋겠습니다. . 보통 규제하는 변수와 예측도를 측정하는 값간에 그래프는 U자형태가 잘 나옵니다. . 그 이유는 규제가 약할때와 쌜 때 각각 과소적합, 과적합이 일어나 예측도를 측정하는 값이 커지기 때문입니다. . cv_ridge.min() . 0.1273373466867076 . 최적의 rmse값은 0.1273입니다. . &#46972;&#50136; &#47784;&#45944; . 이번엔 라쏘 모델입니다. . 라쏘 모델은 릿지 모델과 다르게 영향력이 작은 변수의 계수를 0으로 만듭니다. . 변수 선택 과정까지 한번에 할 수 있다는 것이 장점입니다. . model_lasso = LassoCV(alphas = [1, 0.1, 0.001, 0.0005]).fit(X_train, y) . LassoCV 함수로 여러가지 알파값을 동시에 검정할 수 있습니다. . model_lasso.alpha_ . 0.0005 . rmse_cv(model_lasso).mean() . 0.12256735885048142 . 라쏘 모델이 rmse 값이 훨씬 낮아서 좋습니다. . 라쏘 모델을 사용하겠습니다. . coef = pd.Series(model_lasso.coef_, index = X_train.columns) . 회귀 모델.coef_ =&gt; 계수를 컬럼순으로 보여줍니다. . print(&quot;Lasso picked &quot; + str(sum(coef != 0)) + &quot; variables and eliminated the other &quot; + str(sum(coef == 0)) + &quot; variables&quot;) . Lasso picked 110 variables and eliminated the other 178 variables . 110개 변수는 선택되었고 178개 변수는 계수가 0, 즉 선택하지 않은 변수들입니다. . coef . MSSubClass -0.007480 LotFrontage 0.000000 LotArea 0.071826 OverallQual 0.053160 OverallCond 0.043027 ... SaleCondition_AdjLand 0.000000 SaleCondition_Alloca -0.000000 SaleCondition_Family -0.007925 SaleCondition_Normal 0.019666 SaleCondition_Partial 0.000000 Length: 288, dtype: float64 . imp_coef = pd.concat([coef.sort_values().head(10), coef.sort_values().tail(10)]) matplotlib.rcParams[&#39;figure.figsize&#39;] = (8.0, 10.0) imp_coef.plot(kind = &quot;barh&quot;) plt.title(&quot;Coefficients in the Lasso Model&quot;) . Text(0.5, 1.0, &#39;Coefficients in the Lasso Model&#39;) . sort_values() 함수는 범주형 변수의 히스토그램을 아는데 유용한 함수입니다. . 여기선 정렬기능으로 사용했는데, 정렬기능으로도 충분히 우수한 것을 보여줬습니다. . 정렬된 값 상위 10개, 하위 10개를 시각화했는데, 이 변수들이 핵심 변수입니다. . 왜냐하면 계수의 절대값이 큰 값이기 때문입니다. . 양의 값으로 가장 큰 GrLivArea변수는 면적으로 주택가격에 당연히 큰 영향을 끼칩니다. . matplotlib.rcParams[&#39;figure.figsize&#39;] = (6.0, 6.0) preds = pd.DataFrame({&quot;preds&quot;:model_lasso.predict(X_train), &quot;true&quot;:y}) preds[&quot;residuals&quot;] = preds[&quot;true&quot;] - preds[&quot;preds&quot;] preds.plot(x = &quot;preds&quot;, y = &quot;residuals&quot;,kind = &quot;scatter&quot;) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f3bd2529490&gt; . 잔차 그림도 큰 이상이 없습니다. . model_lasso = Lasso(alpha = 0.0005).fit(X_train, y) pred = model_lasso.predict(X_test) pred2 = np.exp(pred) - 1 X_test[&#39;SalePrice&#39;] = pred2 X_test[&#39;Id&#39;] = test[&#39;Id&#39;] final = X_test[[&#39;Id&#39;,&#39;SalePrice&#39;]] final.to_csv(&#39;/content/drive/MyDrive/houselasso2.csv&#39;,encoding=&#39;UTF-8&#39;, index=False) . /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy after removing the cwd from sys.path. /usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy &#34;&#34;&#34; . 알파값 0.0005인 라쏘 모델로 모델을 적합시키고 그 모델로 예측 파일을 만들었습니다. .",
            "url": "https://ksy1526.github.io/myblog//myblog/ssuda/jupyter/kaggle/ridge/lasso/regression/2021/09/15/kagglessu1.html",
            "relUrl": "/ssuda/jupyter/kaggle/ridge/lasso/regression/2021/09/15/kagglessu1.html",
            "date": " • Sep 15, 2021"
        }
        
    
  
    
        ,"post17": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://ksy1526.github.io/myblog//myblog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post18": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://ksy1526.github.io/myblog//myblog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://ksy1526.github.io/myblog//myblog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  

  
  

  
      ,"page11": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://ksy1526.github.io/myblog//myblog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}