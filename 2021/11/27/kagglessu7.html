<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>SSUDA) 캐글 제품 분류 | 나의 빅데이터 공부 기록</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="SSUDA) 캐글 제품 분류" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="다양한 머신러닝/딥러닝 코드들이 기록되어 있습니다." />
<meta property="og:description" content="다양한 머신러닝/딥러닝 코드들이 기록되어 있습니다." />
<link rel="canonical" href="https://ksy1526.github.io/myblog//myblog/2021/11/27/kagglessu7.html" />
<meta property="og:url" content="https://ksy1526.github.io/myblog//myblog/2021/11/27/kagglessu7.html" />
<meta property="og:site_name" content="나의 빅데이터 공부 기록" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-11-27T00:00:00-06:00" />
<script type="application/ld+json">
{"datePublished":"2021-11-27T00:00:00-06:00","url":"https://ksy1526.github.io/myblog//myblog/2021/11/27/kagglessu7.html","@type":"BlogPosting","headline":"SSUDA) 캐글 제품 분류","dateModified":"2021-11-27T00:00:00-06:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://ksy1526.github.io/myblog//myblog/2021/11/27/kagglessu7.html"},"description":"다양한 머신러닝/딥러닝 코드들이 기록되어 있습니다.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/myblog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://ksy1526.github.io/myblog//myblog/feed.xml" title="나의 빅데이터 공부 기록" /><link rel="shortcut icon" type="image/x-icon" href="/myblog/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/myblog/">나의 빅데이터 공부 기록</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/myblog/about/">About Me</a><a class="page-link" href="/myblog/search/">Search</a><a class="page-link" href="/myblog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">SSUDA) 캐글 제품 분류</h1><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-11-27T00:00:00-06:00" itemprop="datePublished">
        Nov 27, 2021
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      20 min read
    
</span></p>

    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/KSY1526/https:github.com/tree/master/_notebooks/2021-11-27-kagglessu7.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/myblog/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/KSY1526/https:github.com/master?filepath=_notebooks%2F2021-11-27-kagglessu7.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/myblog/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/KSY1526/https:github.com/blob/master/_notebooks/2021-11-27-kagglessu7.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/myblog/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-11-27-kagglessu7.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="https://colab.research.google.com/github/KSY1526/myblog/blob/master/_notebooks/2021-11-27-kagglessu7.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">google.colab</span> <span class="kn">import</span> <span class="n">drive</span>
<span class="n">drive</span><span class="o">.</span><span class="n">mount</span><span class="p">(</span><span class="s1">&#39;/content/drive&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Mounted at /content/drive
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="&#45936;&#51060;&#53552;-&#48520;&#47084;&#50724;&#44592;">&#45936;&#51060;&#53552; &#48520;&#47084;&#50724;&#44592;<a class="anchor-link" href="#&#45936;&#51060;&#53552;-&#48520;&#47084;&#50724;&#44592;"> </a></h1>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.max_columns&#39;</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span> 
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;display.max_rows&#39;</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span> 



<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span><span class="p">,</span> <span class="n">OneHotEncoder</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span><span class="p">,</span> <span class="n">StratifiedKFold</span><span class="p">,</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">SelectFromModel</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span><span class="p">,</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">classification_report</span>
<span class="kn">import</span> <span class="nn">xgboost</span> <span class="k">as</span> <span class="nn">xg</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">Counter</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">kneed</span>
<span class="c1"># kneed is not installed in kaggle. uncomment the above line.</span>
<span class="kn">from</span> <span class="nn">kneed</span> <span class="kn">import</span> <span class="n">KneeLocator</span>



<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Collecting kneed
  Downloading kneed-0.7.0-py2.py3-none-any.whl (9.4 kB)
Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from kneed) (1.4.1)
Requirement already satisfied: numpy&gt;=1.14.2 in /usr/local/lib/python3.7/dist-packages (from kneed) (1.19.5)
Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from kneed) (3.2.2)
Requirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;kneed) (1.3.2)
Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,&gt;=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;kneed) (3.0.6)
Requirement already satisfied: python-dateutil&gt;=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;kneed) (2.8.2)
Requirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;kneed) (0.11.0)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil&gt;=2.1-&gt;matplotlib-&gt;kneed) (1.15.0)
Installing collected packages: kneed
Successfully installed kneed-0.7.0
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">path</span> <span class="o">=</span> <span class="s1">&#39;/content/drive/MyDrive/otto_group/&#39;</span>

<span class="n">train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">path</span> <span class="o">+</span> <span class="s1">&#39;train.csv&#39;</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">path</span> <span class="o">+</span> <span class="s1">&#39;test.csv&#39;</span><span class="p">)</span>
<span class="n">sample_submission</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">path</span> <span class="o">+</span> <span class="s1">&#39;sampleSubmission.csv&#39;</span><span class="p">)</span>
<span class="n">train</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>feat_1</th>
      <th>feat_2</th>
      <th>feat_3</th>
      <th>feat_4</th>
      <th>feat_5</th>
      <th>feat_6</th>
      <th>feat_7</th>
      <th>feat_8</th>
      <th>feat_9</th>
      <th>feat_10</th>
      <th>feat_11</th>
      <th>feat_12</th>
      <th>feat_13</th>
      <th>feat_14</th>
      <th>feat_15</th>
      <th>feat_16</th>
      <th>feat_17</th>
      <th>feat_18</th>
      <th>feat_19</th>
      <th>feat_20</th>
      <th>feat_21</th>
      <th>feat_22</th>
      <th>feat_23</th>
      <th>feat_24</th>
      <th>feat_25</th>
      <th>feat_26</th>
      <th>feat_27</th>
      <th>feat_28</th>
      <th>feat_29</th>
      <th>feat_30</th>
      <th>feat_31</th>
      <th>feat_32</th>
      <th>feat_33</th>
      <th>feat_34</th>
      <th>feat_35</th>
      <th>feat_36</th>
      <th>feat_37</th>
      <th>feat_38</th>
      <th>feat_39</th>
      <th>feat_40</th>
      <th>feat_41</th>
      <th>feat_42</th>
      <th>feat_43</th>
      <th>feat_44</th>
      <th>feat_45</th>
      <th>feat_46</th>
      <th>feat_47</th>
      <th>feat_48</th>
      <th>feat_49</th>
      <th>feat_50</th>
      <th>feat_51</th>
      <th>feat_52</th>
      <th>feat_53</th>
      <th>feat_54</th>
      <th>feat_55</th>
      <th>feat_56</th>
      <th>feat_57</th>
      <th>feat_58</th>
      <th>feat_59</th>
      <th>feat_60</th>
      <th>feat_61</th>
      <th>feat_62</th>
      <th>feat_63</th>
      <th>feat_64</th>
      <th>feat_65</th>
      <th>feat_66</th>
      <th>feat_67</th>
      <th>feat_68</th>
      <th>feat_69</th>
      <th>feat_70</th>
      <th>feat_71</th>
      <th>feat_72</th>
      <th>feat_73</th>
      <th>feat_74</th>
      <th>feat_75</th>
      <th>feat_76</th>
      <th>feat_77</th>
      <th>feat_78</th>
      <th>feat_79</th>
      <th>feat_80</th>
      <th>feat_81</th>
      <th>feat_82</th>
      <th>feat_83</th>
      <th>feat_84</th>
      <th>feat_85</th>
      <th>feat_86</th>
      <th>feat_87</th>
      <th>feat_88</th>
      <th>feat_89</th>
      <th>feat_90</th>
      <th>feat_91</th>
      <th>feat_92</th>
      <th>feat_93</th>
      <th>target</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>4</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>5</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>11</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>7</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>Class_1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>Class_1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>6</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>Class_1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>6</td>
      <td>1</td>
      <td>5</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>7</td>
      <td>2</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>58</td>
      <td>0</td>
      <td>10</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>1</td>
      <td>2</td>
      <td>1</td>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>1</td>
      <td>5</td>
      <td>0</td>
      <td>0</td>
      <td>4</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>2</td>
      <td>2</td>
      <td>0</td>
      <td>22</td>
      <td>0</td>
      <td>1</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>Class_1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>4</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>4</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>Class_1</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="&#45936;&#51060;&#53552;-&#53456;&#49353;">&#45936;&#51060;&#53552; &#53456;&#49353;<a class="anchor-link" href="#&#45936;&#51060;&#53552;-&#53456;&#49353;"> </a></h1>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">train</span><span class="o">.</span><span class="n">columns</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Index([&#39;id&#39;, &#39;feat_1&#39;, &#39;feat_2&#39;, &#39;feat_3&#39;, &#39;feat_4&#39;, &#39;feat_5&#39;, &#39;feat_6&#39;,
       &#39;feat_7&#39;, &#39;feat_8&#39;, &#39;feat_9&#39;, &#39;feat_10&#39;, &#39;feat_11&#39;, &#39;feat_12&#39;,
       &#39;feat_13&#39;, &#39;feat_14&#39;, &#39;feat_15&#39;, &#39;feat_16&#39;, &#39;feat_17&#39;, &#39;feat_18&#39;,
       &#39;feat_19&#39;, &#39;feat_20&#39;, &#39;feat_21&#39;, &#39;feat_22&#39;, &#39;feat_23&#39;, &#39;feat_24&#39;,
       &#39;feat_25&#39;, &#39;feat_26&#39;, &#39;feat_27&#39;, &#39;feat_28&#39;, &#39;feat_29&#39;, &#39;feat_30&#39;,
       &#39;feat_31&#39;, &#39;feat_32&#39;, &#39;feat_33&#39;, &#39;feat_34&#39;, &#39;feat_35&#39;, &#39;feat_36&#39;,
       &#39;feat_37&#39;, &#39;feat_38&#39;, &#39;feat_39&#39;, &#39;feat_40&#39;, &#39;feat_41&#39;, &#39;feat_42&#39;,
       &#39;feat_43&#39;, &#39;feat_44&#39;, &#39;feat_45&#39;, &#39;feat_46&#39;, &#39;feat_47&#39;, &#39;feat_48&#39;,
       &#39;feat_49&#39;, &#39;feat_50&#39;, &#39;feat_51&#39;, &#39;feat_52&#39;, &#39;feat_53&#39;, &#39;feat_54&#39;,
       &#39;feat_55&#39;, &#39;feat_56&#39;, &#39;feat_57&#39;, &#39;feat_58&#39;, &#39;feat_59&#39;, &#39;feat_60&#39;,
       &#39;feat_61&#39;, &#39;feat_62&#39;, &#39;feat_63&#39;, &#39;feat_64&#39;, &#39;feat_65&#39;, &#39;feat_66&#39;,
       &#39;feat_67&#39;, &#39;feat_68&#39;, &#39;feat_69&#39;, &#39;feat_70&#39;, &#39;feat_71&#39;, &#39;feat_72&#39;,
       &#39;feat_73&#39;, &#39;feat_74&#39;, &#39;feat_75&#39;, &#39;feat_76&#39;, &#39;feat_77&#39;, &#39;feat_78&#39;,
       &#39;feat_79&#39;, &#39;feat_80&#39;, &#39;feat_81&#39;, &#39;feat_82&#39;, &#39;feat_83&#39;, &#39;feat_84&#39;,
       &#39;feat_85&#39;, &#39;feat_86&#39;, &#39;feat_87&#39;, &#39;feat_88&#39;, &#39;feat_89&#39;, &#39;feat_90&#39;,
       &#39;feat_91&#39;, &#39;feat_92&#39;, &#39;feat_93&#39;, &#39;target&#39;],
      dtype=&#39;object&#39;)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>컬럼수는 93개 입니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">train</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">unique</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>array([&#39;Class_1&#39;, &#39;Class_2&#39;, &#39;Class_3&#39;, &#39;Class_4&#39;, &#39;Class_5&#39;, &#39;Class_6&#39;,
       &#39;Class_7&#39;, &#39;Class_8&#39;, &#39;Class_9&#39;], dtype=object)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Y 변수의 클레스 종류가 9개 입니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">sample_submission</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>id</th>
      <th>Class_1</th>
      <th>Class_2</th>
      <th>Class_3</th>
      <th>Class_4</th>
      <th>Class_5</th>
      <th>Class_6</th>
      <th>Class_7</th>
      <th>Class_8</th>
      <th>Class_9</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>저번이랑 비슷하게 제출 파일 형식은 각 클레스 별로 분류 될 확률을 기제하면 되겠네요.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="nb">sum</span><span class="p">((</span><span class="n">train</span><span class="o">.</span><span class="n">isnull</span><span class="p">())</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>0</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>결측값이 있는지 확인했습니다. info 함수로 확인하기에는 피처가 너무 커서 직관적으로 확인하기 힘듭니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>

<span class="n">le</span><span class="o">=</span><span class="n">LabelEncoder</span><span class="p">()</span>
<span class="n">train</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span><span class="o">=</span><span class="n">le</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7fc0cca07b90&gt;</pre>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
" />
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>라벨 인코더를 통해 클레스 이름을 간단하게( Class_1 =&gt; 0) 바꿨습니다.</p>
<p>클레스 개수가 각각 몇개있는지 파악했는데요. 균등하진 않아보입니다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="&#47784;&#45944;-1">&#47784;&#45944; 1<a class="anchor-link" href="#&#47784;&#45944;-1"> </a></h1>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="n">list_models</span><span class="o">=</span><span class="p">[]</span>
<span class="n">list_scores</span><span class="o">=</span><span class="p">[]</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">]</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;target&#39;</span><span class="p">,</span> <span class="s1">&#39;id&#39;</span><span class="p">],</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">x_train</span><span class="p">,</span><span class="n">x_test</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">y_test</span><span class="o">=</span><span class="n">train_test_split</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>

<span class="n">lr</span><span class="o">=</span><span class="n">LogisticRegression</span><span class="p">(</span><span class="n">max_iter</span><span class="o">=</span><span class="mi">100000</span><span class="p">)</span>
<span class="n">lr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">pred_1</span><span class="o">=</span><span class="n">lr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="n">score_1</span><span class="o">=</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">pred_1</span><span class="p">)</span>
<span class="n">list_models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;logistic regression&#39;</span><span class="p">)</span>
<span class="n">list_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">score_1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">fig</span><span class="p">,</span><span class="n">axes</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mf">11.7</span><span class="p">,</span> <span class="mf">8.27</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">pred_1</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7fc0cbd85e10&gt;</pre>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
" />
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>간단한 로지스틱 회귀로, 왼쪽이 예측값, 오른쪽이 실제값입니다. 실제 비율이 제일 높은 1번은 더 많이 예측하는 모습을 보입니다.</p>
<p>비율이 높은 편인 5번, 7번, 8번은 실제 값과 예측 값이 비슷합니다.</p>
<p>하지만 나머지 값들은 실제 값에 있는 비율 만큼 예측 값에서 비슷한 개수로 추정해주지 못했습니다.</p>
<p>물론 이 현상만으로 비율을 일관적으로 예측할 수는 없습니다.(8번은 예측/실제 값 개수 비슷, 2번은 실제 값에 비해 예측값이 너무 적음)</p>
<p>다만 불균형한 테스터 셋을 분류하는 문제에서 다음과 같은 문제가 있다는걸 인지해야겠습니다.</p>
<p>개수가 많은 클레스를 예측하는 확률은 높아지고, 개수가 적은 클레스를 예측하는 확률은 낮아진다는 점 입니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="n">rfc</span><span class="o">=</span><span class="n">RandomForestClassifier</span><span class="p">()</span>
<span class="n">rfc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">pred_2</span><span class="o">=</span><span class="n">rfc</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="n">score_2</span><span class="o">=</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">pred_2</span><span class="p">)</span>
<span class="n">list_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">score_2</span><span class="p">)</span>
<span class="n">list_models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;random forest classifier&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">fig</span><span class="p">,</span><span class="n">axes</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mf">11.7</span><span class="p">,</span> <span class="mf">8.27</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">pred_2</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7fc0c14ea1d0&gt;</pre>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
" />
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>렌덤 포레스트 분류기법입니다. 앞서 말한것과 비슷한 일이 벌어집니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">fig</span><span class="p">,</span><span class="n">axes</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mf">11.7</span><span class="p">,</span> <span class="mf">8.27</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">pred_1</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;predictions by logistic regression&#39;</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">countplot</span><span class="p">(</span><span class="n">pred_2</span><span class="p">,</span><span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="s1">&#39;predictions by random forest&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>No handles with labels found to put in legend.
No handles with labels found to put in legend.
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>&lt;matplotlib.legend.Legend at 0x7fc0c1429ad0&gt;</pre>
</div>

</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
" />
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>두 모델이 비슷한 현상을 보인다는 걸 다시한번 보여준 것 같습니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="n">svm</span><span class="o">=</span><span class="n">SVC</span><span class="p">()</span>
<span class="n">svm</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">pred_3</span><span class="o">=</span><span class="n">svm</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="n">score_3</span><span class="o">=</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">pred_3</span><span class="p">)</span>
<span class="n">list_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">score_3</span><span class="p">)</span>
<span class="n">list_models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;support vector machines&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">xgboost</span> <span class="kn">import</span> <span class="n">XGBClassifier</span>
<span class="n">xgb</span><span class="o">=</span><span class="n">XGBClassifier</span><span class="p">()</span>
<span class="n">xgb</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
<span class="n">pred_4</span><span class="o">=</span><span class="n">xgb</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">x_test</span><span class="p">)</span>
<span class="n">score_4</span><span class="o">=</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">pred_4</span><span class="p">)</span>
<span class="n">list_models</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;xgboost classifier&#39;</span><span class="p">)</span>
<span class="n">list_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">score_4</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">bar</span><span class="p">(</span><span class="n">list_models</span><span class="p">,</span><span class="n">list_scores</span><span class="p">,</span><span class="n">width</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;classifictions models&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;accuracy scores&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
" />
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>SVM, XGB 모델도 적용시켜보았습니다.</p>
<p>랜덤 포레스트 분류 모델이 성능이 가장 괜찮아 보입니다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="&#47784;&#45944;-2">&#47784;&#45944; 2<a class="anchor-link" href="#&#47784;&#45944;-2"> </a></h1>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="s2">&quot;autogluon.tabular[all]==0.1.1b20210312&quot;</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Collecting autogluon.tabular[all]==0.1.1b20210312
  Downloading autogluon.tabular-0.1.1b20210312-py3-none-any.whl (234 kB)
     |████████████████████████████████| 234 kB 4.2 MB/s 
Requirement already satisfied: numpy==1.19.5 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.1.1b20210312) (1.19.5)
Collecting scikit-learn&lt;0.25,&gt;=0.22.0
  Downloading scikit_learn-0.24.2-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)
     |████████████████████████████████| 22.3 MB 1.6 MB/s 
Collecting autogluon.features==0.1.1b20210312
  Downloading autogluon.features-0.1.1b20210312-py3-none-any.whl (48 kB)
     |████████████████████████████████| 48 kB 4.4 MB/s 
Requirement already satisfied: pandas&lt;2.0,&gt;=1.0.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.1.1b20210312) (1.1.5)
Collecting scipy==1.5.4
  Downloading scipy-1.5.4-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)
     |████████████████████████████████| 25.9 MB 1.8 MB/s 
Requirement already satisfied: networkx&lt;3.0,&gt;=2.3 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.1.1b20210312) (2.6.3)
Collecting autogluon.core==0.1.1b20210312
  Downloading autogluon.core-0.1.1b20210312-py3-none-any.whl (312 kB)
     |████████████████████████████████| 312 kB 50.1 MB/s 
Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.1.1b20210312) (3.6.4)
Requirement already satisfied: psutil&lt;=5.7.0,&gt;=5.0.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.1.1b20210312) (5.4.8)
Requirement already satisfied: torch&lt;2.0,&gt;=1.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.1.1b20210312) (1.10.0+cu111)
Requirement already satisfied: fastai&lt;2.0,&gt;=1.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.tabular[all]==0.1.1b20210312) (1.0.61)
Collecting lightgbm&lt;4.0,&gt;=3.0
  Downloading lightgbm-3.3.1-py3-none-manylinux1_x86_64.whl (2.0 MB)
     |████████████████████████████████| 2.0 MB 49.3 MB/s 
Collecting catboost&lt;0.25,&gt;=0.23.0
  Downloading catboost-0.24.4-cp37-none-manylinux1_x86_64.whl (65.7 MB)
     |████████████████████████████████| 65.7 MB 46 kB/s 
Collecting xgboost&lt;1.4,&gt;=1.3.2
  Downloading xgboost-1.3.3-py3-none-manylinux2010_x86_64.whl (157.5 MB)
     |████████████████████████████████| 157.5 MB 63 kB/s 
Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (2.23.0)
Collecting dill==0.3.3
  Downloading dill-0.3.3-py2.py3-none-any.whl (81 kB)
     |████████████████████████████████| 81 kB 9.6 MB/s 
Requirement already satisfied: autograd&gt;=1.3 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (1.3)
Collecting paramiko&gt;=2.4
  Downloading paramiko-2.8.0-py2.py3-none-any.whl (206 kB)
     |████████████████████████████████| 206 kB 50.7 MB/s 
Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (0.29.24)
Requirement already satisfied: tqdm&gt;=4.38.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (4.62.3)
Requirement already satisfied: tornado&gt;=5.0.1 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (5.1.1)
Collecting boto3
  Downloading boto3-1.20.14-py3-none-any.whl (131 kB)
     |████████████████████████████████| 131 kB 49.8 MB/s 
Collecting ConfigSpace==0.4.18
  Downloading ConfigSpace-0.4.18.tar.gz (950 kB)
     |████████████████████████████████| 950 kB 49.4 MB/s 
  Installing build dependencies ... done
  Getting requirements to build wheel ... done
    Preparing wheel metadata ... done
Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (3.2.2)
Collecting graphviz&lt;0.9.0,&gt;=0.8.1
  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)
Collecting distributed&gt;=2.6.0
  Downloading distributed-2021.11.2-py3-none-any.whl (802 kB)
     |████████████████████████████████| 802 kB 50.6 MB/s 
Requirement already satisfied: dask&gt;=2.6.0 in /usr/local/lib/python3.7/dist-packages (from autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (2.12.0)
Requirement already satisfied: pyparsing in /usr/local/lib/python3.7/dist-packages (from ConfigSpace==0.4.18-&gt;autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (3.0.6)
Requirement already satisfied: future&gt;=0.15.2 in /usr/local/lib/python3.7/dist-packages (from autograd&gt;=1.3-&gt;autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (0.16.0)
Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost&lt;0.25,&gt;=0.23.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (1.15.0)
Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost&lt;0.25,&gt;=0.23.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (4.4.1)
Collecting dask&gt;=2.6.0
  Downloading dask-2021.11.2-py3-none-any.whl (1.0 MB)
     |████████████████████████████████| 1.0 MB 40.4 MB/s 
Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed&gt;=2.6.0-&gt;autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (2.4.0)
Requirement already satisfied: toolz&gt;=0.8.2 in /usr/local/lib/python3.7/dist-packages (from distributed&gt;=2.6.0-&gt;autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (0.11.2)
Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from distributed&gt;=2.6.0-&gt;autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (2.11.3)
Requirement already satisfied: click&gt;=6.6 in /usr/local/lib/python3.7/dist-packages (from distributed&gt;=2.6.0-&gt;autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (7.1.2)
Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from distributed&gt;=2.6.0-&gt;autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (57.4.0)
Requirement already satisfied: msgpack&gt;=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed&gt;=2.6.0-&gt;autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (1.0.2)
Requirement already satisfied: tblib&gt;=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed&gt;=2.6.0-&gt;autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (1.7.0)
Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from distributed&gt;=2.6.0-&gt;autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (3.13)
Requirement already satisfied: zict&gt;=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed&gt;=2.6.0-&gt;autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (2.0.0)
Collecting cloudpickle&gt;=1.5.0
  Downloading cloudpickle-2.0.0-py3-none-any.whl (25 kB)
Requirement already satisfied: packaging&gt;=20.0 in /usr/local/lib/python3.7/dist-packages (from dask&gt;=2.6.0-&gt;autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (21.3)
Collecting partd&gt;=0.3.10
  Downloading partd-1.2.0-py3-none-any.whl (19 kB)
Collecting fsspec&gt;=0.6.0
  Downloading fsspec-2021.11.1-py3-none-any.whl (132 kB)
     |████████████████████████████████| 132 kB 54.6 MB/s 
Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from fastai&lt;2.0,&gt;=1.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (0.11.1+cu111)
Requirement already satisfied: spacy&gt;=2.0.18 in /usr/local/lib/python3.7/dist-packages (from fastai&lt;2.0,&gt;=1.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (2.2.4)
Requirement already satisfied: nvidia-ml-py3 in /usr/local/lib/python3.7/dist-packages (from fastai&lt;2.0,&gt;=1.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (7.352.0)
Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from fastai&lt;2.0,&gt;=1.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (2.7.3)
Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from fastai&lt;2.0,&gt;=1.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (4.6.3)
Requirement already satisfied: fastprogress&gt;=0.2.1 in /usr/local/lib/python3.7/dist-packages (from fastai&lt;2.0,&gt;=1.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (1.0.0)
Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from fastai&lt;2.0,&gt;=1.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (7.1.2)
Requirement already satisfied: bottleneck in /usr/local/lib/python3.7/dist-packages (from fastai&lt;2.0,&gt;=1.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (1.3.2)
Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm&lt;4.0,&gt;=3.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (0.37.0)
Requirement already satisfied: pytz&gt;=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas&lt;2.0,&gt;=1.0.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (2018.9)
Requirement already satisfied: python-dateutil&gt;=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas&lt;2.0,&gt;=1.0.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (2.8.2)
Collecting cryptography&gt;=2.5
  Downloading cryptography-36.0.0-cp36-abi3-manylinux_2_24_x86_64.whl (3.6 MB)
     |████████████████████████████████| 3.6 MB 43.1 MB/s 
Collecting pynacl&gt;=1.0.1
  Downloading PyNaCl-1.4.0-cp35-abi3-manylinux1_x86_64.whl (961 kB)
     |████████████████████████████████| 961 kB 45.2 MB/s 
Collecting bcrypt&gt;=3.1.3
  Downloading bcrypt-3.2.0-cp36-abi3-manylinux2010_x86_64.whl (63 kB)
     |████████████████████████████████| 63 kB 2.3 MB/s 
Requirement already satisfied: cffi&gt;=1.1 in /usr/local/lib/python3.7/dist-packages (from bcrypt&gt;=3.1.3-&gt;paramiko&gt;=2.4-&gt;autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (1.15.0)
Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi&gt;=1.1-&gt;bcrypt&gt;=3.1.3-&gt;paramiko&gt;=2.4-&gt;autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (2.21)
Collecting locket
  Downloading locket-0.2.1-py2.py3-none-any.whl (4.1 kB)
Requirement already satisfied: threadpoolctl&gt;=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn&lt;0.25,&gt;=0.22.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (3.0.0)
Requirement already satisfied: joblib&gt;=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn&lt;0.25,&gt;=0.22.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (1.1.0)
Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy&gt;=2.0.18-&gt;fastai&lt;2.0,&gt;=1.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (7.4.0)
Requirement already satisfied: srsly&lt;1.1.0,&gt;=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy&gt;=2.0.18-&gt;fastai&lt;2.0,&gt;=1.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (1.0.5)
Requirement already satisfied: wasabi&lt;1.1.0,&gt;=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy&gt;=2.0.18-&gt;fastai&lt;2.0,&gt;=1.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (0.8.2)
Requirement already satisfied: cymem&lt;2.1.0,&gt;=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy&gt;=2.0.18-&gt;fastai&lt;2.0,&gt;=1.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (2.0.6)
Requirement already satisfied: catalogue&lt;1.1.0,&gt;=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy&gt;=2.0.18-&gt;fastai&lt;2.0,&gt;=1.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (1.0.0)
Requirement already satisfied: murmurhash&lt;1.1.0,&gt;=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy&gt;=2.0.18-&gt;fastai&lt;2.0,&gt;=1.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (1.0.6)
Requirement already satisfied: preshed&lt;3.1.0,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy&gt;=2.0.18-&gt;fastai&lt;2.0,&gt;=1.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (3.0.6)
Requirement already satisfied: plac&lt;1.2.0,&gt;=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy&gt;=2.0.18-&gt;fastai&lt;2.0,&gt;=1.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (1.1.3)
Requirement already satisfied: blis&lt;0.5.0,&gt;=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy&gt;=2.0.18-&gt;fastai&lt;2.0,&gt;=1.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (0.4.1)
Requirement already satisfied: importlib-metadata&gt;=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue&lt;1.1.0,&gt;=0.0.7-&gt;spacy&gt;=2.0.18-&gt;fastai&lt;2.0,&gt;=1.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (4.8.2)
Requirement already satisfied: typing-extensions&gt;=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata&gt;=0.20-&gt;catalogue&lt;1.1.0,&gt;=0.0.7-&gt;spacy&gt;=2.0.18-&gt;fastai&lt;2.0,&gt;=1.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (3.10.0.2)
Requirement already satisfied: zipp&gt;=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata&gt;=0.20-&gt;catalogue&lt;1.1.0,&gt;=0.0.7-&gt;spacy&gt;=2.0.18-&gt;fastai&lt;2.0,&gt;=1.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (3.6.0)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (1.24.3)
Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (2.10)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (2021.10.8)
Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (3.0.4)
Requirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from zict&gt;=0.1.3-&gt;distributed&gt;=2.6.0-&gt;autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (1.0.1)
Collecting jmespath&lt;1.0.0,&gt;=0.7.1
  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)
Collecting botocore&lt;1.24.0,&gt;=1.23.14
  Downloading botocore-1.23.14-py3-none-any.whl (8.2 MB)
     |████████████████████████████████| 8.2 MB 37.3 MB/s 
Collecting s3transfer&lt;0.6.0,&gt;=0.5.0
  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)
     |████████████████████████████████| 79 kB 7.5 MB/s 
Collecting urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1
  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)
     |████████████████████████████████| 127 kB 49.6 MB/s 
Requirement already satisfied: MarkupSafe&gt;=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2-&gt;distributed&gt;=2.6.0-&gt;autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (2.0.1)
Requirement already satisfied: kiwisolver&gt;=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (1.3.2)
Requirement already satisfied: cycler&gt;=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib-&gt;autogluon.core==0.1.1b20210312-&gt;autogluon.tabular[all]==0.1.1b20210312) (0.11.0)
Requirement already satisfied: retrying&gt;=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly-&gt;catboost&lt;0.25,&gt;=0.23.0-&gt;autogluon.tabular[all]==0.1.1b20210312) (1.3.3)
Requirement already satisfied: attrs&gt;=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest-&gt;autogluon.tabular[all]==0.1.1b20210312) (21.2.0)
Requirement already satisfied: more-itertools&gt;=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest-&gt;autogluon.tabular[all]==0.1.1b20210312) (8.11.0)
Requirement already satisfied: atomicwrites&gt;=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest-&gt;autogluon.tabular[all]==0.1.1b20210312) (1.4.0)
Requirement already satisfied: pluggy&lt;0.8,&gt;=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest-&gt;autogluon.tabular[all]==0.1.1b20210312) (0.7.1)
Requirement already satisfied: py&gt;=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest-&gt;autogluon.tabular[all]==0.1.1b20210312) (1.11.0)
Building wheels for collected packages: ConfigSpace
  Building wheel for ConfigSpace (PEP 517) ... done
  Created wheel for ConfigSpace: filename=ConfigSpace-0.4.18-cp37-cp37m-linux_x86_64.whl size=2880650 sha256=7b9c24d3da86378fe64cff390f09a143606ba3ac7a45f5b37fa2827e1aed4124
  Stored in directory: /root/.cache/pip/wheels/36/f7/0f/36f368c419ea1a8024fc3d6c078c3111dfef43fa1d14cfebe0
Successfully built ConfigSpace
Installing collected packages: urllib3, locket, jmespath, partd, fsspec, cloudpickle, botocore, scipy, s3transfer, pynacl, dask, cryptography, bcrypt, scikit-learn, paramiko, graphviz, distributed, dill, ConfigSpace, boto3, autogluon.core, autogluon.features, xgboost, lightgbm, catboost, autogluon.tabular
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.3
    Uninstalling urllib3-1.24.3:
      Successfully uninstalled urllib3-1.24.3
  Attempting uninstall: cloudpickle
    Found existing installation: cloudpickle 1.3.0
    Uninstalling cloudpickle-1.3.0:
      Successfully uninstalled cloudpickle-1.3.0
  Attempting uninstall: scipy
    Found existing installation: scipy 1.4.1
    Uninstalling scipy-1.4.1:
      Successfully uninstalled scipy-1.4.1
  Attempting uninstall: dask
    Found existing installation: dask 2.12.0
    Uninstalling dask-2.12.0:
      Successfully uninstalled dask-2.12.0
  Attempting uninstall: scikit-learn
    Found existing installation: scikit-learn 1.0.1
    Uninstalling scikit-learn-1.0.1:
      Successfully uninstalled scikit-learn-1.0.1
  Attempting uninstall: graphviz
    Found existing installation: graphviz 0.10.1
    Uninstalling graphviz-0.10.1:
      Successfully uninstalled graphviz-0.10.1
  Attempting uninstall: distributed
    Found existing installation: distributed 1.25.3
    Uninstalling distributed-1.25.3:
      Successfully uninstalled distributed-1.25.3
  Attempting uninstall: dill
    Found existing installation: dill 0.3.4
    Uninstalling dill-0.3.4:
      Successfully uninstalled dill-0.3.4
  Attempting uninstall: xgboost
    Found existing installation: xgboost 0.90
    Uninstalling xgboost-0.90:
      Successfully uninstalled xgboost-0.90
  Attempting uninstall: lightgbm
    Found existing installation: lightgbm 2.2.3
    Uninstalling lightgbm-2.2.3:
      Successfully uninstalled lightgbm-2.2.3
<span class="ansi-red-fg">ERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
multiprocess 0.70.12.2 requires dill&gt;=0.3.4, but you have dill 0.3.3 which is incompatible.
gym 0.17.3 requires cloudpickle&lt;1.7.0,&gt;=1.2.0, but you have cloudpickle 2.0.0 which is incompatible.
datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.
albumentations 0.1.12 requires imgaug&lt;0.2.7,&gt;=0.2.5, but you have imgaug 0.2.9 which is incompatible.</span>
Successfully installed ConfigSpace-0.4.18 autogluon.core-0.1.1b20210312 autogluon.features-0.1.1b20210312 autogluon.tabular-0.1.1b20210312 bcrypt-3.2.0 boto3-1.20.14 botocore-1.23.14 catboost-0.24.4 cloudpickle-2.0.0 cryptography-36.0.0 dask-2021.11.2 dill-0.3.3 distributed-2021.11.2 fsspec-2021.11.1 graphviz-0.8.4 jmespath-0.10.0 lightgbm-3.3.1 locket-0.2.1 paramiko-2.8.0 partd-1.2.0 pynacl-1.4.0 s3transfer-0.5.0 scikit-learn-0.24.2 scipy-1.5.4 urllib3-1.25.11 xgboost-1.3.3
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">autogluon.tabular</span> <span class="kn">import</span> <span class="n">TabularDataset</span><span class="p">,</span> <span class="n">TabularPredictor</span>
<span class="kn">from</span> <span class="nn">autogluon.tabular.models.knn.knn_rapids_model</span> <span class="kn">import</span> <span class="n">KNNRapidsModel</span>
<span class="kn">from</span> <span class="nn">autogluon.tabular.models.lr.lr_rapids_model</span> <span class="kn">import</span> <span class="n">LinearRapidsModel</span>

<span class="n">path</span> <span class="o">=</span> <span class="s1">&#39;/content/drive/MyDrive/otto_group/&#39;</span>

<span class="n">train</span> <span class="o">=</span> <span class="n">TabularDataset</span><span class="p">(</span><span class="n">path</span> <span class="o">+</span> <span class="s1">&#39;train.csv&#39;</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">TabularDataset</span><span class="p">(</span><span class="n">path</span> <span class="o">+</span> <span class="s1">&#39;test.csv&#39;</span><span class="p">)</span>

<span class="n">label</span> <span class="o">=</span> <span class="s1">&#39;target&#39;</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>Loaded data from: /content/drive/MyDrive/otto_group/train.csv | Columns = 95 / 95 | Rows = 61878 -&gt; 61878
Loaded data from: /content/drive/MyDrive/otto_group/test.csv | Columns = 94 / 94 | Rows = 144368 -&gt; 144368
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">cuml</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Collecting cuml
  Downloading cuml-0.6.1.post1.tar.gz (1.1 kB)
Building wheels for collected packages: cuml
  Building wheel for cuml (setup.py) ... error
<span class="ansi-red-fg">  ERROR: Failed building wheel for cuml</span>
  Running setup.py clean for cuml
Failed to build cuml
Installing collected packages: cuml
    Running setup.py install for cuml ... error
<span class="ansi-red-fg">ERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c &#39;import io, os, sys, setuptools, tokenize; sys.argv[0] = &#39;&#34;&#39;&#34;&#39;/tmp/pip-install-d9q8bg1e/cuml_e5625faa4a144d1cb1dbda39971d1a35/setup.py&#39;&#34;&#39;&#34;&#39;; __file__=&#39;&#34;&#39;&#34;&#39;/tmp/pip-install-d9q8bg1e/cuml_e5625faa4a144d1cb1dbda39971d1a35/setup.py&#39;&#34;&#39;&#34;&#39;;f = getattr(tokenize, &#39;&#34;&#39;&#34;&#39;open&#39;&#34;&#39;&#34;&#39;, open)(__file__) if os.path.exists(__file__) else io.StringIO(&#39;&#34;&#39;&#34;&#39;from setuptools import setup; setup()&#39;&#34;&#39;&#34;&#39;);code = f.read().replace(&#39;&#34;&#39;&#34;&#39;\r\n&#39;&#34;&#39;&#34;&#39;, &#39;&#34;&#39;&#34;&#39;\n&#39;&#34;&#39;&#34;&#39;);f.close();exec(compile(code, __file__, &#39;&#34;&#39;&#34;&#39;exec&#39;&#34;&#39;&#34;&#39;))&#39; install --record /tmp/pip-record-yfs4_fyl/install-record.txt --single-version-externally-managed --compile --install-headers /usr/local/include/python3.7/cuml Check the logs for full command output.</span>
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">predictor</span> <span class="o">=</span> <span class="n">TabularPredictor</span><span class="p">(</span>
    <span class="n">label</span><span class="o">=</span><span class="n">label</span><span class="p">,</span>
    <span class="n">eval_metric</span><span class="o">=</span><span class="s1">&#39;log_loss&#39;</span><span class="p">,</span>
    <span class="n">learner_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;ignored_columns&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">]}</span>
<span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">train</span><span class="p">,</span>
    <span class="n">presets</span><span class="o">=</span><span class="s1">&#39;best_quality&#39;</span><span class="p">,</span>
    <span class="n">hyperparameters</span><span class="o">=</span><span class="p">{</span>
        <span class="n">KNNRapidsModel</span><span class="p">:</span> <span class="p">{},</span>
        <span class="n">LinearRapidsModel</span><span class="p">:</span> <span class="p">{},</span>
        <span class="s1">&#39;RF&#39;</span><span class="p">:</span> <span class="p">{},</span>
        <span class="s1">&#39;XGB&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;ag_args_fit&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;num_gpus&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">}},</span>
        <span class="s1">&#39;CAT&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;ag_args_fit&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;num_gpus&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">}},</span>
        <span class="s1">&#39;GBM&#39;</span><span class="p">:</span> <span class="p">[{},</span> <span class="p">{</span><span class="s1">&#39;extra_trees&#39;</span><span class="p">:</span> <span class="kc">True</span><span class="p">,</span> <span class="s1">&#39;ag_args&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;name_suffix&#39;</span><span class="p">:</span> <span class="s1">&#39;XT&#39;</span><span class="p">}},</span> <span class="s1">&#39;GBMLarge&#39;</span><span class="p">],</span>
        <span class="s1">&#39;NN&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;ag_args_fit&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;num_gpus&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">}},</span>
        <span class="s1">&#39;FASTAI&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;ag_args_fit&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;num_gpus&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">}},</span>
    <span class="p">},</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>No path specified. Models will be saved in: &#34;AutogluonModels/ag-20211127_122603/&#34;
Presets specified: [&#39;best_quality&#39;]
Beginning AutoGluon training ...
AutoGluon will save models to &#34;AutogluonModels/ag-20211127_122603/&#34;
AutoGluon Version:  0.1.1b20210312
Train Data Rows:    61878
Train Data Columns: 94
Preprocessing data ...
AutoGluon infers your prediction problem is: &#39;multiclass&#39; (because dtype of label-column == object).
	9 unique label values:  [&#39;Class_1&#39;, &#39;Class_2&#39;, &#39;Class_3&#39;, &#39;Class_4&#39;, &#39;Class_5&#39;, &#39;Class_6&#39;, &#39;Class_7&#39;, &#39;Class_8&#39;, &#39;Class_9&#39;]
	If &#39;multiclass&#39; is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: [&#39;binary&#39;, &#39;multiclass&#39;, &#39;regression&#39;])
Train Data Class Count: 9
Using Feature Generators to preprocess the data ...
Dropping user-specified ignored columns: [&#39;id&#39;]
Fitting AutoMLPipelineFeatureGenerator...
	Available Memory:                    12407.99 MB
	Train Data (Original)  Memory Usage: 46.04 MB (0.4% of available memory)
	Inferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.
	Stage 1 Generators:
		Fitting AsTypeFeatureGenerator...
	Stage 2 Generators:
		Fitting FillNaFeatureGenerator...
	Stage 3 Generators:
		Fitting IdentityFeatureGenerator...
	Stage 4 Generators:
		Fitting DropUniqueFeatureGenerator...
	Types of features in original data (raw dtype, special dtypes):
		(&#39;int&#39;, []) : 93 | [&#39;feat_1&#39;, &#39;feat_2&#39;, &#39;feat_3&#39;, &#39;feat_4&#39;, &#39;feat_5&#39;, ...]
	Types of features in processed data (raw dtype, special dtypes):
		(&#39;int&#39;, []) : 93 | [&#39;feat_1&#39;, &#39;feat_2&#39;, &#39;feat_3&#39;, &#39;feat_4&#39;, &#39;feat_5&#39;, ...]
	0.5s = Fit runtime
	93 features in original data used to generate 93 features in processed data.
	Train Data (Processed) Memory Usage: 46.04 MB (0.4% of available memory)
Data preprocessing and feature engineering runtime = 0.7s ...
AutoGluon will gauge predictive performance using evaluation metric: &#39;log_loss&#39;
	This metric expects predicted probabilities rather than predicted class labels, so you&#39;ll need to use predict_proba() instead of predict()
	To change this, specify the eval_metric argument of fit()
Custom Model Type Detected: &lt;class &#39;autogluon.tabular.models.knn.knn_rapids_model.KNNRapidsModel&#39;&gt;
Custom Model Type Detected: &lt;class &#39;autogluon.tabular.models.lr.lr_rapids_model.LinearRapidsModel&#39;&gt;
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_text output_error">
<pre>
<span class="ansi-red-fg">---------------------------------------------------------------------------</span>
<span class="ansi-red-fg">ModuleNotFoundError</span>                       Traceback (most recent call last)
<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/autogluon/core/utils/try_import.py</span> in <span class="ansi-cyan-fg">try_import_rapids_cuml</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">    162</span>     <span class="ansi-green-fg">try</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 163</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">import</span> cuml
<span class="ansi-green-intense-fg ansi-bold">    164</span>     <span class="ansi-green-fg">except</span> ImportError<span class="ansi-blue-fg">:</span>

<span class="ansi-red-fg">ModuleNotFoundError</span>: No module named &#39;cuml&#39;

During handling of the above exception, another exception occurred:

<span class="ansi-red-fg">ImportError</span>                               Traceback (most recent call last)
<span class="ansi-green-fg">&lt;ipython-input-12-488de9012a7d&gt;</span> in <span class="ansi-cyan-fg">&lt;module&gt;</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">     14</span>         <span class="ansi-blue-fg">&#39;GBM&#39;</span><span class="ansi-blue-fg">:</span> <span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">{</span><span class="ansi-blue-fg">}</span><span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">{</span><span class="ansi-blue-fg">&#39;extra_trees&#39;</span><span class="ansi-blue-fg">:</span> <span class="ansi-green-fg">True</span><span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">&#39;ag_args&#39;</span><span class="ansi-blue-fg">:</span> <span class="ansi-blue-fg">{</span><span class="ansi-blue-fg">&#39;name_suffix&#39;</span><span class="ansi-blue-fg">:</span> <span class="ansi-blue-fg">&#39;XT&#39;</span><span class="ansi-blue-fg">}</span><span class="ansi-blue-fg">}</span><span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">&#39;GBMLarge&#39;</span><span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">     15</span>         <span class="ansi-blue-fg">&#39;NN&#39;</span><span class="ansi-blue-fg">:</span> <span class="ansi-blue-fg">{</span><span class="ansi-blue-fg">&#39;ag_args_fit&#39;</span><span class="ansi-blue-fg">:</span> <span class="ansi-blue-fg">{</span><span class="ansi-blue-fg">&#39;num_gpus&#39;</span><span class="ansi-blue-fg">:</span> <span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">}</span><span class="ansi-blue-fg">}</span><span class="ansi-blue-fg">,</span>
<span class="ansi-green-fg">---&gt; 16</span><span class="ansi-red-fg">         </span><span class="ansi-blue-fg">&#39;FASTAI&#39;</span><span class="ansi-blue-fg">:</span> <span class="ansi-blue-fg">{</span><span class="ansi-blue-fg">&#39;ag_args_fit&#39;</span><span class="ansi-blue-fg">:</span> <span class="ansi-blue-fg">{</span><span class="ansi-blue-fg">&#39;num_gpus&#39;</span><span class="ansi-blue-fg">:</span> <span class="ansi-cyan-fg">1</span><span class="ansi-blue-fg">}</span><span class="ansi-blue-fg">}</span><span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">     17</span>     },
<span class="ansi-green-intense-fg ansi-bold">     18</span> )

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/autogluon/core/utils/decorators.py</span> in <span class="ansi-cyan-fg">_call</span><span class="ansi-blue-fg">(*args, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">     27</span>         <span class="ansi-green-fg">def</span> _call<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">     28</span>             gargs<span class="ansi-blue-fg">,</span> gkwargs <span class="ansi-blue-fg">=</span> g<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>other_args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">*</span>args<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">---&gt; 29</span><span class="ansi-red-fg">             </span><span class="ansi-green-fg">return</span> f<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">*</span>gargs<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>gkwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     30</span>         <span class="ansi-green-fg">return</span> _call
<span class="ansi-green-intense-fg ansi-bold">     31</span>     <span class="ansi-green-fg">return</span> _unpack_inner

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/autogluon/tabular/predictor/predictor.py</span> in <span class="ansi-cyan-fg">fit</span><span class="ansi-blue-fg">(self, train_data, tuning_data, time_limit, presets, hyperparameters, feature_metadata, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    689</span>         self._learner.fit(X=train_data, X_val=tuning_data, X_unlabeled=unlabeled_data,
<span class="ansi-green-intense-fg ansi-bold">    690</span>                           holdout_frac<span class="ansi-blue-fg">=</span>holdout_frac<span class="ansi-blue-fg">,</span> num_bag_folds<span class="ansi-blue-fg">=</span>num_bag_folds<span class="ansi-blue-fg">,</span> num_bag_sets<span class="ansi-blue-fg">=</span>num_bag_sets<span class="ansi-blue-fg">,</span> num_stack_levels<span class="ansi-blue-fg">=</span>num_stack_levels<span class="ansi-blue-fg">,</span>
<span class="ansi-green-fg">--&gt; 691</span><span class="ansi-red-fg">                           hyperparameters=hyperparameters, core_kwargs=core_kwargs, time_limit=time_limit, verbosity=verbosity)
</span><span class="ansi-green-intense-fg ansi-bold">    692</span>         self<span class="ansi-blue-fg">.</span>_set_post_fit_vars<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    693</span> 

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/autogluon/tabular/learner/abstract_learner.py</span> in <span class="ansi-cyan-fg">fit</span><span class="ansi-blue-fg">(self, X, X_val, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    124</span>             <span class="ansi-green-fg">raise</span> AssertionError<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#39;Learner is already fit.&#39;</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    125</span>         self<span class="ansi-blue-fg">.</span>_validate_fit_input<span class="ansi-blue-fg">(</span>X<span class="ansi-blue-fg">=</span>X<span class="ansi-blue-fg">,</span> X_val<span class="ansi-blue-fg">=</span>X_val<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 126</span><span class="ansi-red-fg">         </span><span class="ansi-green-fg">return</span> self<span class="ansi-blue-fg">.</span>_fit<span class="ansi-blue-fg">(</span>X<span class="ansi-blue-fg">=</span>X<span class="ansi-blue-fg">,</span> X_val<span class="ansi-blue-fg">=</span>X_val<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    127</span> 
<span class="ansi-green-intense-fg ansi-bold">    128</span>     def _fit(self, X: DataFrame, X_val: DataFrame = None, scheduler_options=None, hyperparameter_tune=False,

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/autogluon/tabular/learner/default_learner.py</span> in <span class="ansi-cyan-fg">_fit</span><span class="ansi-blue-fg">(self, X, X_val, X_unlabeled, holdout_frac, num_bag_folds, num_bag_sets, time_limit, verbosity, **trainer_fit_kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">     93</span> 
<span class="ansi-green-intense-fg ansi-bold">     94</span>         self<span class="ansi-blue-fg">.</span>save<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">---&gt; 95</span><span class="ansi-red-fg">         </span>trainer<span class="ansi-blue-fg">.</span>fit<span class="ansi-blue-fg">(</span>X<span class="ansi-blue-fg">,</span> y<span class="ansi-blue-fg">,</span> X_val<span class="ansi-blue-fg">=</span>X_val<span class="ansi-blue-fg">,</span> y_val<span class="ansi-blue-fg">=</span>y_val<span class="ansi-blue-fg">,</span> X_unlabeled<span class="ansi-blue-fg">=</span>X_unlabeled<span class="ansi-blue-fg">,</span> holdout_frac<span class="ansi-blue-fg">=</span>holdout_frac<span class="ansi-blue-fg">,</span> time_limit<span class="ansi-blue-fg">=</span>time_limit_trainer<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>trainer_fit_kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     96</span>         self<span class="ansi-blue-fg">.</span>save_trainer<span class="ansi-blue-fg">(</span>trainer<span class="ansi-blue-fg">=</span>trainer<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     97</span>         time_end <span class="ansi-blue-fg">=</span> time<span class="ansi-blue-fg">.</span>time<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/autogluon/tabular/trainer/auto_trainer.py</span> in <span class="ansi-cyan-fg">fit</span><span class="ansi-blue-fg">(self, X, y, hyperparameters, X_val, y_val, X_unlabeled, feature_prune, holdout_frac, num_stack_levels, core_kwargs, time_limit, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">     50</span>         self._train_multi_and_ensemble(X, y, X_val, y_val, X_unlabeled=X_unlabeled, hyperparameters=hyperparameters,
<span class="ansi-green-intense-fg ansi-bold">     51</span>                                        feature_prune<span class="ansi-blue-fg">=</span>feature_prune<span class="ansi-blue-fg">,</span>
<span class="ansi-green-fg">---&gt; 52</span><span class="ansi-red-fg">                                        num_stack_levels=num_stack_levels, time_limit=time_limit, core_kwargs=core_kwargs)
</span><span class="ansi-green-intense-fg ansi-bold">     53</span> 
<span class="ansi-green-intense-fg ansi-bold">     54</span>     <span class="ansi-green-fg">def</span> get_models_distillation<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> hyperparameters<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/autogluon/tabular/trainer/abstract_trainer.py</span> in <span class="ansi-cyan-fg">_train_multi_and_ensemble</span><span class="ansi-blue-fg">(self, X, y, X_val, y_val, hyperparameters, X_unlabeled, num_stack_levels, time_limit, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">   1290</span>         self<span class="ansi-blue-fg">.</span>_num_cols_train <span class="ansi-blue-fg">=</span> len<span class="ansi-blue-fg">(</span>list<span class="ansi-blue-fg">(</span>X<span class="ansi-blue-fg">.</span>columns<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">   1291</span>         model_names_fit = self.train_multi_levels(X, y, hyperparameters=hyperparameters, X_val=X_val, y_val=y_val,
<span class="ansi-green-fg">-&gt; 1292</span><span class="ansi-red-fg">                                                   X_unlabeled=X_unlabeled, level_start=1, level_end=num_stack_levels+1, time_limit=time_limit, **kwargs)
</span><span class="ansi-green-intense-fg ansi-bold">   1293</span>         <span class="ansi-green-fg">if</span> len<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">.</span>get_model_names<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">==</span> <span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">   1294</span>             <span class="ansi-green-fg">raise</span> ValueError<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#39;AutoGluon did not successfully train any models&#39;</span><span class="ansi-blue-fg">)</span>

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/autogluon/tabular/trainer/abstract_trainer.py</span> in <span class="ansi-cyan-fg">train_multi_levels</span><span class="ansi-blue-fg">(self, X, y, hyperparameters, X_val, y_val, X_unlabeled, base_model_names, feature_prune, core_kwargs, aux_kwargs, level_start, level_end, time_limit, name_suffix, relative_stack)</span>
<span class="ansi-green-intense-fg ansi-bold">    259</span>                 models<span class="ansi-blue-fg">=</span>hyperparameters<span class="ansi-blue-fg">,</span> level<span class="ansi-blue-fg">=</span>level<span class="ansi-blue-fg">,</span> base_model_names<span class="ansi-blue-fg">=</span>base_model_names<span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    260</span>                 feature_prune<span class="ansi-blue-fg">=</span>feature_prune<span class="ansi-blue-fg">,</span>
<span class="ansi-green-fg">--&gt; 261</span><span class="ansi-red-fg">                 </span>core_kwargs<span class="ansi-blue-fg">=</span>core_kwargs_level<span class="ansi-blue-fg">,</span> aux_kwargs<span class="ansi-blue-fg">=</span>aux_kwargs_level<span class="ansi-blue-fg">,</span> name_suffix<span class="ansi-blue-fg">=</span>name_suffix<span class="ansi-blue-fg">,</span>
<span class="ansi-green-intense-fg ansi-bold">    262</span>             )
<span class="ansi-green-intense-fg ansi-bold">    263</span>             model_names_fit <span class="ansi-blue-fg">+=</span> base_model_names <span class="ansi-blue-fg">+</span> aux_models

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/autogluon/tabular/trainer/abstract_trainer.py</span> in <span class="ansi-cyan-fg">stack_new_level</span><span class="ansi-blue-fg">(self, X, y, models, X_val, y_val, X_unlabeled, level, base_model_names, feature_prune, core_kwargs, aux_kwargs, name_suffix)</span>
<span class="ansi-green-intense-fg ansi-bold">    285</span>             aux_kwargs<span class="ansi-blue-fg">[</span><span class="ansi-blue-fg">&#39;name_suffix&#39;</span><span class="ansi-blue-fg">]</span> <span class="ansi-blue-fg">=</span> aux_kwargs<span class="ansi-blue-fg">.</span>get<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">&#39;name_suffix&#39;</span><span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">&#39;&#39;</span><span class="ansi-blue-fg">)</span> <span class="ansi-blue-fg">+</span> name_suffix
<span class="ansi-green-intense-fg ansi-bold">    286</span>         core_models = self.stack_new_level_core(X=X, y=y, X_val=X_val, y_val=y_val, X_unlabeled=X_unlabeled, models=models,
<span class="ansi-green-fg">--&gt; 287</span><span class="ansi-red-fg">                                                 level=level, base_model_names=base_model_names, feature_prune=feature_prune, **core_kwargs)
</span><span class="ansi-green-intense-fg ansi-bold">    288</span> 
<span class="ansi-green-intense-fg ansi-bold">    289</span>         <span class="ansi-green-fg">if</span> self<span class="ansi-blue-fg">.</span>bagged_mode<span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/autogluon/tabular/trainer/abstract_trainer.py</span> in <span class="ansi-cyan-fg">stack_new_level_core</span><span class="ansi-blue-fg">(self, X, y, models, X_val, y_val, X_unlabeled, level, base_model_names, stack_name, ag_args, ag_args_fit, ag_args_ensemble, excluded_model_types, ensemble_type, name_suffix, get_models_func, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">    342</span>                 ))
<span class="ansi-green-intense-fg ansi-bold">    343</span> 
<span class="ansi-green-fg">--&gt; 344</span><span class="ansi-red-fg">             </span>models<span class="ansi-blue-fg">,</span> model_args_fit <span class="ansi-blue-fg">=</span> get_models_func<span class="ansi-blue-fg">(</span>hyperparameters<span class="ansi-blue-fg">=</span>models<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>get_models_kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    345</span>             <span class="ansi-green-fg">if</span> model_args_fit<span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">    346</span>                 hyperparameter_tune_kwargs = {

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/autogluon/tabular/trainer/auto_trainer.py</span> in <span class="ansi-cyan-fg">get_models</span><span class="ansi-blue-fg">(self, hyperparameters, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">     26</span>         return get_preset_models(path=path, problem_type=problem_type, eval_metric=eval_metric,
<span class="ansi-green-intense-fg ansi-bold">     27</span>                                  num_classes<span class="ansi-blue-fg">=</span>num_classes<span class="ansi-blue-fg">,</span> hyperparameters<span class="ansi-blue-fg">=</span>hyperparameters<span class="ansi-blue-fg">,</span> invalid_model_names<span class="ansi-blue-fg">=</span>invalid_model_names<span class="ansi-blue-fg">,</span>
<span class="ansi-green-fg">---&gt; 28</span><span class="ansi-red-fg">                                  feature_metadata=feature_metadata, silent=silent, **kwargs)
</span><span class="ansi-green-intense-fg ansi-bold">     29</span> 
<span class="ansi-green-intense-fg ansi-bold">     30</span>     <span class="ansi-green-fg">def</span> fit<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> X<span class="ansi-blue-fg">,</span> y<span class="ansi-blue-fg">,</span> hyperparameters<span class="ansi-blue-fg">,</span> X_val<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">None</span><span class="ansi-blue-fg">,</span> y_val<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">None</span><span class="ansi-blue-fg">,</span> X_unlabeled<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">None</span><span class="ansi-blue-fg">,</span> feature_prune<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">False</span><span class="ansi-blue-fg">,</span> holdout_frac<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">0.1</span><span class="ansi-blue-fg">,</span> num_stack_levels<span class="ansi-blue-fg">=</span><span class="ansi-cyan-fg">0</span><span class="ansi-blue-fg">,</span> core_kwargs<span class="ansi-blue-fg">:</span> dict <span class="ansi-blue-fg">=</span> <span class="ansi-green-fg">None</span><span class="ansi-blue-fg">,</span> time_limit<span class="ansi-blue-fg">=</span><span class="ansi-green-fg">None</span><span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/autogluon/tabular/trainer/model_presets/presets.py</span> in <span class="ansi-cyan-fg">get_preset_models</span><span class="ansi-blue-fg">(path, problem_type, eval_metric, hyperparameters, feature_metadata, num_classes, level, ensemble_type, ensemble_kwargs, ag_args_fit, ag_args, ag_args_ensemble, name_suffix, default_priorities, invalid_model_names, excluded_model_types, hyperparameter_preprocess_func, hyperparameter_preprocess_kwargs, silent)</span>
<span class="ansi-green-intense-fg ansi-bold">    189</span>         model = model_factory(model_cfg, path=path, problem_type=problem_type, eval_metric=eval_metric,
<span class="ansi-green-intense-fg ansi-bold">    190</span>                               num_classes<span class="ansi-blue-fg">=</span>num_classes<span class="ansi-blue-fg">,</span> name_suffix<span class="ansi-blue-fg">=</span>name_suffix<span class="ansi-blue-fg">,</span> ensemble_type<span class="ansi-blue-fg">=</span>ensemble_type<span class="ansi-blue-fg">,</span> ensemble_kwargs<span class="ansi-blue-fg">=</span>ensemble_kwargs<span class="ansi-blue-fg">,</span>
<span class="ansi-green-fg">--&gt; 191</span><span class="ansi-red-fg">                               invalid_name_set=invalid_name_set, level=level, feature_metadata=feature_metadata)
</span><span class="ansi-green-intense-fg ansi-bold">    192</span>         invalid_name_set<span class="ansi-blue-fg">.</span>add<span class="ansi-blue-fg">(</span>model<span class="ansi-blue-fg">.</span>name<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    193</span>         <span class="ansi-green-fg">if</span> <span class="ansi-blue-fg">&#39;hyperparameter_tune_kwargs&#39;</span> <span class="ansi-green-fg">in</span> model_cfg<span class="ansi-blue-fg">[</span>AG_ARGS<span class="ansi-blue-fg">]</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/autogluon/tabular/trainer/model_presets/presets.py</span> in <span class="ansi-cyan-fg">model_factory</span><span class="ansi-blue-fg">(model, path, problem_type, eval_metric, num_classes, name_suffix, ensemble_type, ensemble_kwargs, invalid_name_set, level, feature_metadata)</span>
<span class="ansi-green-intense-fg ansi-bold">    296</span>     model_params<span class="ansi-blue-fg">.</span>pop<span class="ansi-blue-fg">(</span>AG_ARGS<span class="ansi-blue-fg">,</span> <span class="ansi-green-fg">None</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    297</span>     model_params<span class="ansi-blue-fg">.</span>pop<span class="ansi-blue-fg">(</span>AG_ARGS_ENSEMBLE<span class="ansi-blue-fg">,</span> <span class="ansi-green-fg">None</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">--&gt; 298</span><span class="ansi-red-fg">     </span>model_init <span class="ansi-blue-fg">=</span> model_type<span class="ansi-blue-fg">(</span>path<span class="ansi-blue-fg">=</span>path<span class="ansi-blue-fg">,</span> name<span class="ansi-blue-fg">=</span>name<span class="ansi-blue-fg">,</span> problem_type<span class="ansi-blue-fg">=</span>problem_type<span class="ansi-blue-fg">,</span> eval_metric<span class="ansi-blue-fg">=</span>eval_metric<span class="ansi-blue-fg">,</span> num_classes<span class="ansi-blue-fg">=</span>num_classes<span class="ansi-blue-fg">,</span> hyperparameters<span class="ansi-blue-fg">=</span>model_params<span class="ansi-blue-fg">,</span> feature_metadata<span class="ansi-blue-fg">=</span>feature_metadata<span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">    299</span> 
<span class="ansi-green-intense-fg ansi-bold">    300</span>     <span class="ansi-green-fg">if</span> ensemble_kwargs <span class="ansi-green-fg">is</span> <span class="ansi-green-fg">not</span> <span class="ansi-green-fg">None</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/autogluon/tabular/models/knn/knn_model.py</span> in <span class="ansi-cyan-fg">__init__</span><span class="ansi-blue-fg">(self, **kwargs)</span>
<span class="ansi-green-intense-fg ansi-bold">     25</span>     <span class="ansi-green-fg">def</span> __init__<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">,</span> <span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-intense-fg ansi-bold">     26</span>         super<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">.</span>__init__<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">**</span>kwargs<span class="ansi-blue-fg">)</span>
<span class="ansi-green-fg">---&gt; 27</span><span class="ansi-red-fg">         </span>self<span class="ansi-blue-fg">.</span>_model_type <span class="ansi-blue-fg">=</span> self<span class="ansi-blue-fg">.</span>_get_model_type<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     28</span> 
<span class="ansi-green-intense-fg ansi-bold">     29</span>     <span class="ansi-green-fg">def</span> _get_model_type<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/autogluon/tabular/models/knn/knn_rapids_model.py</span> in <span class="ansi-cyan-fg">_get_model_type</span><span class="ansi-blue-fg">(self)</span>
<span class="ansi-green-intense-fg ansi-bold">     26</span>     &#34;&#34;&#34;
<span class="ansi-green-intense-fg ansi-bold">     27</span>     <span class="ansi-green-fg">def</span> _get_model_type<span class="ansi-blue-fg">(</span>self<span class="ansi-blue-fg">)</span><span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">---&gt; 28</span><span class="ansi-red-fg">         </span>try_import_rapids_cuml<span class="ansi-blue-fg">(</span><span class="ansi-blue-fg">)</span>
<span class="ansi-green-intense-fg ansi-bold">     29</span>         <span class="ansi-green-fg">from</span> cuml<span class="ansi-blue-fg">.</span>neighbors <span class="ansi-green-fg">import</span> KNeighborsClassifier<span class="ansi-blue-fg">,</span> KNeighborsRegressor
<span class="ansi-green-intense-fg ansi-bold">     30</span>         <span class="ansi-green-fg">if</span> self<span class="ansi-blue-fg">.</span>problem_type <span class="ansi-blue-fg">==</span> REGRESSION<span class="ansi-blue-fg">:</span>

<span class="ansi-green-fg">/usr/local/lib/python3.7/dist-packages/autogluon/core/utils/try_import.py</span> in <span class="ansi-cyan-fg">try_import_rapids_cuml</span><span class="ansi-blue-fg">()</span>
<span class="ansi-green-intense-fg ansi-bold">    163</span>         <span class="ansi-green-fg">import</span> cuml
<span class="ansi-green-intense-fg ansi-bold">    164</span>     <span class="ansi-green-fg">except</span> ImportError<span class="ansi-blue-fg">:</span>
<span class="ansi-green-fg">--&gt; 165</span><span class="ansi-red-fg">         raise ImportError(&#34;`import cuml` failed.\n&#34;
</span><span class="ansi-green-intense-fg ansi-bold">    166</span>                           <span class="ansi-blue-fg">&#34;Ensure that you have a GPU and CUDA installation, and then install RAPIDS.\n&#34;</span>
<span class="ansi-green-intense-fg ansi-bold">    167</span>                           <span class="ansi-blue-fg">&#34;You will likely need to create a fresh conda environment based off of a RAPIDS install, and then install AutoGluon on it.\n&#34;</span>

<span class="ansi-red-fg">ImportError</span>: `import cuml` failed.
Ensure that you have a GPU and CUDA installation, and then install RAPIDS.
You will likely need to create a fresh conda environment based off of a RAPIDS install, and then install AutoGluon on it.
RAPIDS is highly experimental within AutoGluon, and we recommend to only use RAPIDS if you are an advanced user / developer.
Please refer to RAPIDS install instructions for more information: https://rapids.ai/start.html#get-rapids

<span class="ansi-red-fg">---------------------------------------------------------------------------</span><span class="ansi-green-fg">
NOTE: If your import is failing due to a missing package, you can
manually install dependencies using either !pip or !apt.

To view examples of installing some common dependencies, click the
&#34;Open Examples&#34; button below.
</span><span class="ansi-red-fg">---------------------------------------------------------------------------</span>
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">submission</span> <span class="o">=</span> <span class="n">test</span><span class="p">[[</span><span class="s1">&#39;id&#39;</span><span class="p">]]</span>
<span class="n">test_pred_proba</span> <span class="o">=</span> <span class="n">predictor</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>
<span class="n">submission</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">submission</span><span class="p">,</span> <span class="n">test_pred_proba</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">submission</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;submission.csv&#39;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">submission</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>오류가 지속적으로 나서 실행을 못했습니다. (autogluon 모델)</p>
<p>자동으로 분석해주는 모델인것 같고 실제로 이 모델 점수 상위 1%를 기록했다고 합니다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="&#47784;&#45944;-3">&#47784;&#45944; 3<a class="anchor-link" href="#&#47784;&#45944;-3"> </a></h1>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">patsy</span> <span class="kn">import</span> <span class="n">dmatrices</span>
<span class="kn">from</span> <span class="nn">sklearn.neural_network</span> <span class="kn">import</span> <span class="n">MLPClassifier</span>

<span class="n">columns</span> <span class="o">=</span> <span class="n">train</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">train</span><span class="p">[</span><span class="n">columns</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ravel</span><span class="p">(</span><span class="n">train</span><span class="p">[</span><span class="s1">&#39;target&#39;</span><span class="p">])</span>


<span class="n">model</span> <span class="o">=</span> <span class="n">MLPClassifier</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;lbfgs&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">,</span> <span class="n">hidden_layer_sizes</span> <span class="o">=</span> <span class="p">(</span><span class="mi">30</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span> <span class="n">random_state</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>MLPClassifier(alpha=1e-05, hidden_layer_sizes=(30, 10), random_state=0,
              solver=&#39;lbfgs&#39;, verbose=True)</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">pred</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="n">pred</span> <span class="o">==</span> <span class="n">y</span><span class="p">)</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>0.8057629529073338
0.8057629529073338
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">Xtest</span> <span class="o">=</span> <span class="n">test</span><span class="p">[</span><span class="n">test</span><span class="o">.</span><span class="n">columns</span><span class="p">[</span><span class="mi">1</span><span class="p">:]]</span>

<span class="n">test_prob</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">Xtest</span><span class="p">)</span>
<span class="n">solution</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">test_prob</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;Class_1&#39;</span><span class="p">,</span><span class="s1">&#39;Class_2&#39;</span><span class="p">,</span><span class="s1">&#39;Class_3&#39;</span><span class="p">,</span><span class="s1">&#39;Class_4&#39;</span><span class="p">,</span><span class="s1">&#39;Class_5&#39;</span><span class="p">,</span><span class="s1">&#39;Class_6&#39;</span><span class="p">,</span><span class="s1">&#39;Class_7&#39;</span><span class="p">,</span><span class="s1">&#39;Class_8&#39;</span><span class="p">,</span><span class="s1">&#39;Class_9&#39;</span><span class="p">])</span>
<span class="n">solution</span><span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">test</span><span class="p">[</span><span class="s1">&#39;id&#39;</span><span class="p">]</span>
<span class="n">cols</span> <span class="o">=</span> <span class="n">solution</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">cols</span> <span class="o">=</span> <span class="n">cols</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">:]</span> <span class="o">+</span> <span class="n">cols</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">solution</span> <span class="o">=</span> <span class="n">solution</span><span class="p">[</span><span class="n">cols</span><span class="p">]</span>

<span class="n">solution</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;otto_prediction.csv&#39;</span><span class="p">,</span> <span class="n">index</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

</div>



  </div><a class="u-url" href="/myblog/2021/11/27/kagglessu7.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/myblog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/myblog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/myblog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>다양한 머신러닝/딥러닝 코드들이 기록되어 있습니다.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/https%3A%2F%2Fgithub.com%2FKSY1526%2FMyProject" title="https://github.com/KSY1526/MyProject"><svg class="svg-icon grey"><use xlink:href="/myblog/assets/minima-social-icons.svg#github"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
