---
toc: true
layout: post
description: 부스트캠프 8일차 공부 정리.
image : images/2209282.PNG
categories: [BoostCamp, Python, Pytorch, torchsummary, Multi-GPU, Model, Pre-train]
title: "[BoostCamp]Day8 파이토치 사용법2"
---
# 8일차 공부 정리
## Pytorch 기능들
### torchsummary

케라스를 사용하면 모델 형태를 한 눈에 보기 좋게 요약해줍니다. 파이토치에서도 이를 지원하는 라이브러리 입니다.

~~~python
# 코렙에서 설치가 필요합니다.
!pip install torchsummary

from torchsummary import summary
# summary(모델, 입력데이터크기(튜플형태))
summary(model, (3, 224, 224))
~~~

![summary](https://user-images.githubusercontent.com/79916736/192696952-a511c4d3-8f63-4b6f-af17-e842a454803e.png)

### model.state_dict()

모델의 파라미터를 표시하는 model.state_dict 함수 입니다.

~~~python
for param_tensor in model.state_dict():
    # 뒤에 size()을 빼면 실제 파라미터값 나옴
    # model.state_dict() : OrderedDict 형태. 레이어이름-파라미터
    # param_tensor : layer1.0.weight. 레이어 이름
    # model.state_dict()[param_tensor] : 실제 파라미터
    print(param_tensor, "\t", model.state_dict()[param_tensor].size())

### 결과
# layer1.0.weight 	 torch.Size([16, 3, 3, 3])
# layer1.0.bias 	 torch.Size([16])
# layer1.1.weight 	 torch.Size([16])
# layer1.1.bias 	 torch.Size([16]) 
~~~

### 모델 저장

모델 저장에는 모델 파라미터 저장, 모델 저장 이렇게 두 가지가 존재합니다. 확장자는 pt, pth를 사용할 수 있는데 pt를 권장합니다.

~~~python
# MODEL_PATH : 저장 주소 (코렙이라면 구글 드라이브에 저장해야 휘발x)

# 모델 파라미터 저장. 불러올 때 크기와 구성이 동일한 모델 필요.
torch.save(model.state_dict(), os.path.join(MODEL_PATH, "model.pt"))
# 모델 자체를 저장
torch.save(model, os.path.join(MODEL_PATH, "model_pickle.pt"))

# 모델 불러오기, TheModelClass : 기존 모델과 동일한 클래스
new_model = TheModelClass()
# new_model에 파라미터 불러오기
new_model.load_state_dict(torch.load(os.path.join(MODEL_PATH, "model.pt")))
# 모델 자체를 불러오기
model = torch.load(os.path.join(MODEL_PATH, "model_pickle.pt"))
# 모델을 추론 모드로 변경. (드롭아웃 등 비활성화) 
# 이 과정을 빠뜨리기 쉬움.
model.eval()

# 체크포인트 저장
# torch.save( {저장할 것}, '저장 주소 + 파일명.pt')
torch.save({
        'epoch': e,
        'model_state_dict': model.state_dict(), # 모델 파라미터 저장
        'optimizer_state_dict': optimizer.state_dict(), # 옵티마이저 저장
        'loss': epoch_loss, # 로스값 저장
        }, PATH + f"checkpoint_model_{e}_{epoch_loss/len(dataloader)}_{epoch_acc/len(dataloader)}.pt")

# 체크포인트 불러오기
checkpoint = torch.load(os.path.join(PATH, "생략.pt"))
model.load_state_dict(checkpoint['model_state_dict'])
optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
epoch = checkpoint['epoch']
loss = checkpoint['loss']
~~~

### pre-train 모델 사용

최근에는 목적은 조금 다르나 검증된 모델에 많은 데이터를 사용하여 만든 사전학습 모델에 뒷 부분을 조금 변형하여 현재 데이터를 이용해 재 학습하는 방식을 많이 사용합니다.

간단한 예시를 보겠습니다. 먼저 vgg19라는 사전학습 모델을 사용할텐데요. 형태부터 확인합니다. 

~~~python
from torchsummary import summary
vgg = models.vgg19(pretrained=True).to(device)
# 모델 형태 깔끔히 출력
summary(vgg, (3, 224, 224)) 
# 출력물을 확인하고 모델의 마지막 출력값이 1000개임을 인지
~~~

하고자 하는 목적이 2진분류라면 마지막 출력값은 2개 혹은 1개가 되면 좋겠죠. 프리트레인 모델을 사용한 새 모델을 만듭니다.

~~~python
from torch import nn
from torchvision import models

class MyNewNet(nn.Module):   
    def __init__(self):
        super(MyNewNet, self).__init__()
        self.vgg19 = models.vgg19(pretrained=True)
        self.linear_layers = nn.Linear(1000, 1) # 1개 값 출력

    def forward(self, x):
        x = self.vgg19(x)        
        return self.linear_layers(x)
~~~

사전학습한 모델은 가중치 업데이트를 일으키지 않고 새로 추가한 linear_layers 부분만 가중치 업데이트를 진행합니다.

이와 같은 방식을 모델을 frozen 시킨다고 합니다. 모델을 frozen 시키는 정도는 사용자가 유동적으로 판단하면 됩니다.

~~~python
my_model = MyNewNet()
my_model = my_model.to(device)

# 모델 전역적인 파라미터 가중치 업데이트를 막음
for param in my_model.parameters(): 
    param.requires_grad = False

# 사전학습 모델이 아닌 마지막 레이어는 가중치 업데이트를 진행.
for param in my_model.linear_layers.parameters():
    param.requires_grad = True
~~~


## 멀티 GPU

최근 DL 모델이 거대해지고, 데이터 크기도 커지고 형태도 복잡해져서 멀티 GPU의 수요가 늘어납니다.

학습 과정에선 쓸 일이 드물지만 실제 현장에선 이런 문제를 꽤 접한다고 합니다.

우선 ML/DL 작업 환경을 크게 3가지로 구분할 수 있습니다.
- Single 노드 Single GPU (일반적인 환경)
- Single 노드 Multi GPU (좋은 클라우드 환경)
- Multi 노드 Multi GPU (서버 컴퓨터..)
  
Multi GPU를 효율적으로 사용하기 위해선 여러 GPU를 동시에(병렬적으로) 일 시켜야 합니다.

병렬적으로 일 시키는 데는 '데이터를 쪼갠다', '모델을 쪼갠다' 두 가지가 존재합니다.

우선 '데이터를 쪼갠다' 부터 확인하면 파이토치에서는 DataParallel, DistributedDataParallel 두 가지를 사용합니다.

![gpu](https://user-images.githubusercontent.com/79916736/192708551-b060550f-bff7-4e13-80fa-2482d36207eb.png)

먼저 DataParallel을 사용하는 'Single 노드 Multi GPU'에 경우 이런 식으로 순전파, 역전파 진행 시는 GPU를 따로 쓰더라도 중간에 결과를 합칠 때 하나의 GPU가 과부하가 오게 된다는 단점이 있습니다.

다음으로 DistributedDataParallel을 사용하는 'Multi 노드 Multi GPU'에 경우 모든 GPU마다 따로 학습을 진행시킨 뒤(mini batch와 유사) 파라미터들의 평균 값을 사용해 모델을 구성합니다.

'모델을 쪼갠다' 분야는 과거부터 많이 연구 되었으나 다음 그림을 보면 알겠지만 꽤나 난이도 높은 부분이라 간단하게 언급하고 넘어가겠습니다.

![gpu2](https://user-images.githubusercontent.com/79916736/192709519-dae94eda-71cf-419f-bf1a-d0fafe2b49e1.png)


## 느낀점

모델 저장 부분을 보며 저번에 진행했던 프로젝트 관리가 미흡했음을 알게됬습니다.

이를 잘 이용한다면 코렙 환경에서도 효율적으로 버전 관리가 진행될 것 같습니다.

머리에 많은걸 우겨 넣는 느낌입니다. 화이팅!

** 위 수식과 그림은 부스트캠프 AI Tech 교육 자료를 참고하였습니다.

