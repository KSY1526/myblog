---
toc: true
layout: post
description: 부스트캠프 9일차 공부 정리.
image : images/220929.PNG
categories: [BoostCamp, Python, Pytorch, tensorboard, wandb, ray, OOM]
title: "[BoostCamp]Day9 파이토치 꿀팁들"
---
# 9일차 공부 정리
## 텐서보드

파이토치를 사용해 모델을 학습하면 모델이 어느정도 학습되었는지 알기 위한 시각화 툴의 필요성을 느낍니다.

텐서플로우에서 먼저 사용됬던 텐서보드가 파이토치에도 적용되는데, 사용법을 간단히 공부했습니다.

~~~python
### 코렙 환경

## 1) 폴더 만들어주기
import os
logs_base_dir = "logs"
os.makedirs(logs_base_dir, exist_ok=True)

## 2) 텐서보드 객체 만들고 값 넣기
from torch.utils.tensorboard import SummaryWriter
import numpy as np

exp  = f"{logs_base_dir}/ex3"
# SummaryWriter(경로)로 객체 선언
writer = SummaryWriter(exp)
# 값 입력 
for n_iter in range(100):
    # writer.add_scalar('트리/구조', 값, 순서)
    # add_histogram, add_images, add_hparams 등이 존재
    writer.add_scalar('Loss/train', np.random.random(), n_iter)
    writer.add_scalar('Loss/test', np.random.random(), n_iter)
    writer.add_scalar('Accuracy/train', np.random.random(), n_iter)
    writer.add_scalar('Accuracy/test', np.random.random(), n_iter)

# 버퍼 내 값 파일에 기록(disk에 쓰기)
writer.flush()
# 입력을 닫음
writer.close()

## 3) 텐서보드 실행하기
# jupyter 상에서 텐서보드 수행 알림
%load_ext tensorboard
# 파일 위치 지정해서 텐서보드 실행
%tensorboard --logdir "logs"
~~~

![tensorboard](https://user-images.githubusercontent.com/79916736/192917916-69192028-f227-4f80-bd10-d2efdc11e381.png)

실제 텐서보드를 실행해보니 이 도구를 잘 사용 한다면 효율이 굉장하겠구나 생각했습니다. 다양한 기능들은 실제 필요시 더 공부해보겠습니다.


## wandb

딥러닝 모델을 사용하다 보면 하이퍼 파라미터에 따른 모델의 성능지표를 시각적으로 확인하는 것이 중요합니다.

제 경험에 빗대어 얘기해보면 분명 더 좋은 성능을 냈었는데.. 어떻게 돌렸었는지 하는 사례가 많았어요. 재현에 문제이죠.

또 팀 프로젝트를 하게될 때도 모델 비교가 쉽지 않았습니다. 개인이 각자 프로젝트를 진행하는 느낌이였죠.

이러한 필요성 때문에 wandb를 사용합니다. 공식 홈페이지에서 회원가입을 하면 쉽게 사용가능합니다.( https://wandb.ai/site )

간단한 사용법은 코드를 참고하시면 됩니다.

~~~python
# 설치
!pip install wandb -q
import wandb

# wandb 시작. 이 부분에서 홈페이지 내 개인 키 값 입력 필요
wandb.init(project="프로젝트명", entity='계정명')

# 하이퍼 파라미터 값을 넣어줍니다.
wandb.config = {
  "learning_rate": 0.001,
  "epochs": 100,
  "batch_size": 128
}

for e in range(1, EPOCHS+1):
    ...
    ...
    ...
    # wandb에 기록합니다.
    wandb.log({'accuracy': train_acc, 'loss': train_loss})
~~~

![wandb](https://user-images.githubusercontent.com/79916736/192943467-bb10927a-5db3-4dea-9223-fc449ddc0b0c.png)

실제 wandb 사용 사진입니다. 시각적으로 훌륭해 모델 프로젝트 관리가 용이합니다.

## ray

병렬처리 패키지이면서 하이퍼 파라미터 튜닝을 쉽게 도와주는 ray를 간단하게 소개합니다.

~~~python
# 패키지 설치, 불러오기
!pip install ray 
!pip install tensorboardX

from ray import tune
from ray.tune import CLIReporter
from ray.tune.schedulers import ASHAScheduler
from functools import partial

# ray 사용시 학습하는 과정이 하나의 함수로 이뤄져 있어야함.
def main(num_samples=10, max_num_epochs=10, gpus_per_trial=2):
    
    data_dir = os.path.abspath("./data")
    load_data(data_dir)
    # (1번)데이터를 tune.sample_from 등을 활용해 그리드/랜덤 서치 선언
    config = {
        "l1": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),
        "l2": tune.sample_from(lambda _: 2 ** np.random.randint(2, 9)),
        "lr": tune.loguniform(1e-4, 1e-1),
        "batch_size": tune.choice([2, 4, 8, 16])
    }

    # (2번)가망이 없을 것 같은 파라미터는 더 이상 학습하지 않고 짤라냄
    scheduler = ASHAScheduler(
        metric="loss",
        mode="min",
        max_t=max_num_epochs,
        grace_period=1,
        reduction_factor=2)
    
    # (3번)결과 출력 양식 정함
    reporter = CLIReporter(
        # parameter_columns=["l1", "l2", "lr", "batch_size"],
        metric_columns=["loss", "accuracy", "training_iteration"])
    
    # 병렬처리 과정 진행
    result = tune.run(
        # train_cifar 함수, data_dir 데이터를 사용해서 병렬처리.
        partial(train_cifar, data_dir=data_dir),
        resources_per_trial={"cpu": 2, "gpu": gpus_per_trial},
        config=config, # 1번
        num_samples=num_samples,
        scheduler=scheduler, # 2번
        progress_reporter=reporter) # 3번

    best_trial = result.get_best_trial("loss", "min", "last")
    print("Best trial config: {}".format(best_trial.config))
    print("Best trial final validation loss: {}".format(
        best_trial.last_result["loss"]))
    print("Best trial final validation accuracy: {}".format(
        best_trial.last_result["accuracy"]))

~~~


## OOM

딥러닝 모델을 사용하다 보면(제 기준에선 코렙!..) 메모리를 많이 사용해서 터지는 경우가 정말 허다합니다.

향후 더 큰 데이터를 다루게 되면 이러한 오류를 계속 겪을텐데 나름의 대처법을 정리했습니다.

배치 사이즈를 최대한 낮추면서 다른 옵션을 건드리는 방향으로 접근합니다. 배치사이즈만 조금 낮춰도 문제가 대부분 해결됩니다.

GPU 내 메모리를 얼마나 사용하는지 알기 위해 GPUUtil 모듈을 사용하는 것도 좋습니다. iter마다 메모리가 얼마나 늘어나는지 확인해보고 코드를 보안합니다.

또 torch.cuda.empty_cache()나 del을 이용해 사용하지 않는 GPU 내 캐쉬를 정리해 메모리를 확보하는 방식도 좋습니다.

다음으로 루프 안에 tensor로 축척되는 변수가 있는지를 확인합니다. 1차원 텐서는 파이썬 기본객체로 변환합니다.

그리고 역전파시 쌓이는 메모리에서 자유로워지기 위해 with torch.no_grad() 구문을 학습하지 않을 때 잊지 않고 사용합니다.

CNN의 경우 크기가 안맞아서 생기는 오류인지 확인해보고 LSTM같은 큰 모델은 사용을 피합니다.

마지막으로 float 변수를 16bit로 줄여서 전반적인 데이터 크기를 감소시키는 것도 고려해봅니다.


## 느낀점

오늘 정리한 내용이 꽤 많은 내용이고 실제 모델을 만들 때 사용되는 부분이여서 디테일한 코드 정리까지는 힘듭니다.

하지만 키워드와 간단한 사용예시 정도를 잘 정리해놓으면 향후 프로젝트 수행 시 다시 이 페이지를 확인한다면 많은 도움이 되야한다 생각하고 작성했습니다.

** 위 수식과 그림은은 부스트캠프 AI Tech 교육 자료를 참고하였습니다.
