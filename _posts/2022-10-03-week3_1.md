---
toc: true
layout: post
description: 부스트캠프 11일차 공부 정리.
image : images/221003.PNG
categories: [BoostCamp, Pytorch, DeepLearning, Optimizer]
title: "[BoostCamp]Day11 딥러닝 기초1"
---
# 11일차 공부 정리
## 딥러닝 Key Components

딥러닝 모델, 논문을 살펴볼 때 4가지 중요요소를 가지고 어떤 차별점이 있는지 확인하면 이해가 편합니다.

4가지 Key Components로

- Data(무슨 문제를 해결하고 싶은 데이터인지)
- Model(데이터를 어떻게 변환하는 모델인지)
- Loss(우리가 원하는 목적을 이루기 위해 어떤 손실 함수를 사용하는지)
- Optimizer Algorithm(모델 최적화를 위해 어떤 기법을 사용하는지)

가 존재합니다.

강의에서 인상깊게 들었던 부분은 손실함수가 줄어드는 것이 우리의 문제를 해결하는 방향과 완전히 일치하기는 쉽지 않다는 것 입니다.

MSE를 손실함수로 사용한다면 왜 하필 두 값의 차이에 제곱을 사용하는지, 실제로는 두 값의 차이에 제곱보다 덜 손실이 날 수 도 있는데 너무 과하게 대하는 것은 아닌지, 이렇게 되면 극단적인 값이 원하는 것 보다 모델에 더 영향력이 큰게 아닌지 등등을 생각할 수 있습니다.

분류문제에서도 마찬가지로 크로스엔트로피 함수를 사용한다면 찾아야하는 타겟 값이 다른 값보다 높기만 하면 되는 방향으로 학습이 진행되게 됩니다.

어떤 문제를 정확히 정의하고 손실함수는 내가 정의한 문제를 해결하는 방향과 잘 들어 맞는지 생각해야겠습니다.

## 딥러닝의 역사

딥러닝의 트렌드가 변한 사건을 집어보겠습니다.

### 2012년 AlexNet

이미지 분류 대회에서 전통적인 머신러닝 모델을 꺽고 처음으로 딥러닝 모델이 1등을 기록했습니다.

딥러닝이 세상에 자신의 가치를 들어낸 모델입니다.

### 2013년 DQN

강화학습 모델을 세상에 알렸습니다.

### 2014년 Encoder / Decoder, Adam Optimizer

인코더 디코더가 나왔습니다. 기계변역을 할 수 있는 시기가 왔습니다.

지금도 사용되는 옵티마이저의 표준격인 Adam이 나왔습니다. 자원이 부족한 일반인의 하이퍼파라미터 튜닝이 많이 간편해졌습니다.

### 2015년 GAN, ResNet

생성 모델이 나와 딥러닝이 할 수 있는 영역을 넓혔습니다.

ResNet은 네트워크를 길게 쌓았을 때 퍼포먼스가 잘 나올 수 있다는 것을 증명했습니다.

### 2017년 Transformer

Transformer은 RNN, LSTM을 넘어서 대부분의 시퀀스 데이터를 다루는 표준 모델로 자리잡았고, CNN까지 넘보고 있습니다.

### 2018년 BERT

BERT는 현재 표준적으로 사용되는 Pre-training 모델을 활용한 파인튜닝 방식을 대중화 시켰습니다.

### 2019 BIG Language Models

GPT-3 모델이 약 1750개 파라미터를 사용하였는데, 딥러닝 모델이 점점 거대해지는 것을 야기했습니다.

### 2020 Self Supervised Learning

비지도학습을 학습에 같이 활용합니다. 고도화된 도메인지식을 활용한다면 데이터를 오히려 만들 수도 있습니다.

연도별로 딥러닝에 전반적인 영향을 끼친 모델을 살펴봤는데요. 확확 트렌드가 바뀌는 만큼 논문을 읽는 역량과 계속 현황을 파악하는 노력이 필요한 것 같습니다.

## Neural Networks

딥러닝 내 Neural Networks은 뇌와 비슷하다고 하는데 비행기도 새를 본따서 만들었지만 지금 사용하는 비행기는 새와 거리가 있듯이 딥러닝 모델도 뇌를 본따서 만들었지만 뇌구조에 너무 갖혀서 생각할 필요는 없는 것 같습니다.

그리고 히든레이어가 1개 있는 뉴럴 네트워크를 정말 잘 학습시킨다면 어떤 데이터든 원하는 값에 근사가 가능합니다.

하지만 이 모델이 존재한다는 것과 존재하는 것을 찾는 것은 다른 문제입니다. 히든레이어가 1개 있는 뉴럴 네트워크 모델이 존재하긴 하나 찾기가 굉장히 어렵습니다.

그렇기 때문에 더 깊게 Neural Networks 층을 쌓는다고 이해하면 될 것 같습니다.

## Optimizer

### Gradient Descent

![Gradient Descent](https://user-images.githubusercontent.com/79916736/193718608-3d064530-29a5-4a6a-aaa1-0768aab58720.png)

가장 기본적인 옵티마이징 방식입니다. Gradient 값에 '-'을 붙이는 경사하강법 아이디어를 사용하며 Learning rate를 이용해 학습 정도를 조정합니다.

적절한 Learning rate를 찾기 어렵다는 단점이 있으며 이외에도 local minimum으로 수렴하는 등 뒷 방법 대비 단점이 많습니다.

### Momentum

![momentum](https://user-images.githubusercontent.com/79916736/193719011-1724df3d-76f4-4545-b839-2353f9179d3f.png)

배치 단위마다 학습이 불안정하게 진행되지 않도록 앞서 진행한 Gradient 값을 이용해 관성을 유지하여 학습을 진행하도록 하는 방식입니다. 

momentum 값으로 대체로 0.9를 사용하지만 하이퍼 파라미터가  하나가 더 늘어난다는 것은 단점일 수 있습니다.

### Nesterov Accelerated Gradient

![Nesterov Accelerated Gradient](https://user-images.githubusercontent.com/79916736/193719666-f7accad3-24b7-454e-ad82-e11e81b246bb.png)

![Nesterov Accelerated Gradient2](https://user-images.githubusercontent.com/79916736/193719840-37fcf533-084d-4c17-9ade-a77f469466be.png)

Momentum를 일부 개선시킨 옵티마이저 입니다. Gradient 값 계산을 원래 값에서 하는 것이 아니라 관성으로 이동한 값에서 계산하는 것이 차이점 입니다.

### Adagrad

![Adagrad](https://user-images.githubusercontent.com/79916736/193720019-07de5992-7848-4091-b4e6-f22270d25b92.png)

Momentum에서 사용한 관성을 이용하진 않고, 자주 업데이트 된 파라미터는 상대적으로 업데이트를 시키지 않는 방식입니다.

상대적으로 파라미터를 골고루 업데이트 시켜준다는 강점을 가집니다. 다만 복잡한 다차원함수는 업데이트 하기 쉽지 않습니다.

### Adadelta

![Adadelta](https://user-images.githubusercontent.com/79916736/193720378-41205c7a-296b-4f7b-a514-f27479c102bc.png)

Adadelta은 Adagrad를 조금 수정한 방식으로 전체 Gradient 기록을 보관하지 않고 일부 window 기록만을 이용해 파라미터가 자주 업데이트 되었는지 파악합니다.

learning rate를 사용하지 않는다는 특징이 있습니다.

### RMSprop

![RMSprop](https://user-images.githubusercontent.com/79916736/193720562-2bea1bba-a9a7-4deb-ac7e-fd7149ac4476.png)

Gradient를 단순히 누적 시키지 않고 지수이동평균 방법을 이용해 가장 최신의 파라미터 업데이트를 더 높은 가중치를 두어서 계산합니다.

### Adam

![Adam](https://user-images.githubusercontent.com/79916736/193721258-36899316-5d70-494f-8bb2-f91e84701029.png)

앞서 다룬 두 가지 포인트, 관성과 얼마나 파라미터 업데이트가 자주 일어났는지 여부, 모두 고려한 옵티마이저 방식입니다.

대중적으로 많이 쓰이는 방식입니다.

### Optimizer 총정리

![image](https://user-images.githubusercontent.com/79916736/193721534-c97e061c-8c9e-4678-a685-321054e92b2a.png)

## 느낀점

딥러닝을 본격적으로 다루기 전에 많은 것을 배웠습니다. 여기에 다루진 않았지만 기본2번째 실습에서 옵티마이저 별로 어떻게 학습이 진행되는지를 살펴보며 느낀 것이 많았습니다.

구체적으로 딥러닝 모델링을 개선시킬때 문제 정의를 잘 해야하고 정의된 문제를 바탕으로 내가 선택을 할 때 이런 기초 지식이 중요하겠구나 느꼈습니다.

그리고 연휴에도 고생한 나 자신을 칭찬합니다.