---
toc: true
layout: post
description: 부스트캠프 36일차 공부 정리.
image : images/221107.PNG
categories: [BoostCamp, MLOps, Model Serving]
title: "[BoostCamp]Day36 MLOps 이론"
search_exclude: False
---
# 36일차 공부 정리

## MLOps

머신러닝 기술을 사업자 입장에서 실제로 서빙하려면 어떤 것들을 고민해야 할까요?

제 입장을 기준으로 머신러닝 기술만을 알고 있을 뿐 산업에 어떻게 적용해야할지 많은 고민을 하진 않았습니다.

충분한 고려 없이 머신러닝 모델을 자신의 서버 인스턴스에서 실행하는 환경이 아닌 Real World에 적용 하면 다음과 같은 사건이 생겼을 때 제대로 대처하기 힘들 수 있습니다.

- 모델의 입력값이 이상할 때
- 모델의 결과값이 이상할 때(입력값이 이상하면 잘 벌어집니다.)
- 모델의 성능이 계속 변경될 때
- 새로 적용한 모델이 성능이 떨어짐을 인지해 기존 모델로 회귀하고 싶을 때

이러한 문제를 해결하고 반복적인 일을 자동화해 모델링에 집중할 환경을 만들기 위해 MLOps 개념을 사용합니다.

강의를 듣는 시간 기준(2020년? 이제는 나왔을 수도 있습니다.) MLOps 툴은 아직 Best라고 할만한 라이브러리가 존재하진 않습니다. 즉 하나의 툴을 꼼꼼히 배우기보단 공부하는 지금은 큰 시각으로 무슨 장점이 있어서 해당 툴을 사용하는지 위주로 공부하는 것이 좋다고 합니다.

Researcher가 될 것이 아니라면(개인적으로 대학원을 가야하며 미래에 티오가 크지 않을 것 같아요) 모델링만 잘하는 것 보다 ML 모델 서빙하는 과정을 잘 아는 것이 취업시장에서 강점이 될 것 같아요. 

강의에서도 예시를 들어 말씀하셨는데 나만의 언어로 예시를 들면 예전에 자주 본 골목식당에서 요리 정말 잘하시는 분도 비지니스적으로 바라보질 못해 망해가기 직전이였던 가게랑 비슷한 것 같아요. 요리를 집에서 잘하는 것과 인기있는 레스토랑을 만드는 것은 다르죠. ML 분야의 백종원이 되겠다는 목표가 생겼습니다.

그렇다면 MLOps의 구성 요소에는 어떤 것이 있는지 살펴봅시다.

- 인프라(서버, GPU) : 클라우드 AWS나 직접 서버를 설치.
- Serving : 상황에 따라 Batch, Online 방식이 존재.
- Experiment, Model Management : 모델 생성일, 성능, 메타 정보 등을 기록함. MLflow 사용.
- Feature Store : 피처의 대한 정보를 미리 연산하여 사용.
- Data Validation(Data Management) : 연구환경과 실제 서빙시 input이 유사한지 살펴봄.
- Continuous Training : 새로운 데이터가 생기거나 일정 주기로 모델 Retrain 함.
- Monitoring : 모델의 지표를 잘 기록해 추가로 아이디어를 얻을 수도 있음
- AutoML : 자동으로 모델링을 해주는 툴.

## Model Serving

Serving이란 Production(Real World) 환경에 모델을 사용할 수 있도록 배포하는 것 입니다.

서빙을 하는 방식으로 크게 Batch 서빙과 Online 서빙으로 나눕니다. input이 하나씩 들어오면 Online 서빙이 필요하고, 실시간으로 Output을 낼 필요성이 없어 일정 주기로 서빙하는 방식을 Batch 서빙이라고 합니다.

### Online Serving

우선 웹 서버를 먼저 정의합시다. 쉽게 요청(Request)을 받으면 요청한 내용을 보내주는(Response) 프로그램으로 생각할 수 있는데요. 크롬에서 네이버 주소창을 검색하면(HTTP을 통해 Request) 네이버 메인 창이 나오는(요청하는 HTML 문서를 Response 해줌) 것을 예시로 들 수 있겠네요.

세부 카테고리인 ML모델 서버는 무언가 요청(배민에서 음식 배달 시간이 얼마나 걸리는지)하면 머신러닝 모델 Output 값을 보내주는 것으로 웹 서버와 따로 둘 수도 있습니다.

다음으로 API란 운영체제나 프로그래밍 언어가 제공하는 기능을 제어할 수 있게 만든 인터페이스라고 합니다.

여기서 인터페이스란 리모컨이나 키오스크 같이 기계와 인간의 소통 창구를 예시로 들 수 있는데요. API는 외부에서 해당하는 기능을 사용하게 도와준다고 생각할 수 있습니다. 파이토치 패키지도 하나의 예시가 될 수 있겠네요.

![Online Serving](https://user-images.githubusercontent.com/79916736/200243375-04fd1daa-e6f7-4636-82d5-8d515793ad0c.png)


서버 내 API를 통해 input 데이터를 서버 내 ML 모델에 넣어 나온 값을 Output 데이터로 내보내는 역할입니다.

Request가 올 때마다 실시간으로 예측하고 반환해 주는 것이 잘 정의가 되는 것이 Online Serving입니다.

단일 데이터를 받아 실시간으로 예측하는 예제인 경우 조금 까다롭지만 Online Serving을 해야하는 상황입니다.

Online Serving을 구현하는 세 가지 방식과 장단점은 다음과 같습니다.

- 직접 API 웹 서버 개발(Flask, FastAPI 등) : Low Level.
- 클라우드 서비스 활용(AWS 등) : 비용 부담. 프로토타입으로 좋음.
- Serving 라이브러리 활용(Tensorflow Serving, MLFlows) : 잘 된 오픈소스로 쉬움.

Online Serving시 유의할 점으로 Output이 재현이 안되면 Risk가 크기 때문에 이를 위해 Python 버전, 패키지 버전을 잘 맞춰야 합니다.

또 실시간 예측을 하기 때문에 Latency(지연시간)을 최소화해야 합니다. 이를 위해선 Database 쿼리 수행시간과 모델이 얼마나 복잡한지를 잘 따져봐야 합니다.

### Batch Serving

![Batch Serving](https://user-images.githubusercontent.com/79916736/200244956-b1c1b6f5-f38d-4690-baa2-24176fb606a5.png)

Batch Serving은 Batch 단위로 특정 주기당 한번씩 함수 단위의 .py 파일을 수행하는 서빙 방식입니다.

Online Serving 대비 구현이 수월해 실시간이 필요 없는 대부분의 방식에서 사용됩니다.

데이터 엔지니어링에서 자주 활용되는 Airflow를 활용해 Workflow Scheduler를 제작하여 사용합니다.

## 머신러닝 프로젝트 Flow

실무에서는 문제 정의를 잘 하는 것이 가장 중요한 부분 중 하나라고 합니다. 아이슈타인의 말을 빌리면 1시간 중 55분은 문제 정의를 한다고 하는군요.

문제 정의를 명확하고 구체적으로 하는 것이 중요합니다. 미리 잘 생각해놔야지 문제 해결 과정에서 다시 돌아오는 일이 생기지 않습니다. 이 과정에서 최적화할 Metric도 잘 정의해야 합니다.

문제 정의를 잘 해놓으면 머신러닝 문제로 접근해야 하는 문제인지 파악하기 쉽습니다.

머신러닝 모델은 요소 간 다소 복잡한 패턴이 있을 때, 사람이 반복적으로 해야하는 경우(우범화물탐지나 변압기 컨트롤 등) 데이터 라벨링이 잘 되어 있을 때 사용하는 것이 좋습니다.

간단한 Rule base 값을 BaseLine으로 삼아 머신러닝 모델이 어느정도 효과가 있는지 탐색하는 것이 중요합니다.

머신러닝은 만능이 아니기 때문에 보다 간단한 방식으로 대체가 가능한지 항상 염두해야합니다.

줄이고 싶은 Loss가 2개가 있다면 모델을 분리하여 각각 최적화 한다면 모델 별 가중치 재 학습이 용이하고 유지보수도 각각 할 수 있어 편리합니다. 다만 두 Loss가 상충되는 부분이 크다면 유의해야겠죠.

## AI 현업자 특강1

업스테이지 CTO이신 이활석 강사님의 서바스 향 AI 모델 개발에 대한 특강을 들었습니다.

주로 해왔지만 스스로도 이런 역량으로 회사를 들어가도 될까라고 고민했던 부분인 수업이나 개인 공부에서 하는 AI 모델 개발과 실제 현업에서 사용하는 AI 모델 개발은 어떤 차이점이 있는지 강의해주셨는데요.

제가 궁금했던 부분인 현업에서 사용하는 AI 모델 개발을 명확하게 설명해주셔서 좋았습니다.

강의를 통해 전체 파이프라인을 보며 모델 성능을 0.1점 높이는 것 보다 서비스 요구사항을 주는 분과 원할한 소통이 중요하고 상황에 맞는 데이터 셋을 구축하는 것 자체가 일이며 예산도 중요한 피처라는 것을 느꼈습니다.

마지막에 모델 서빙하는 부분에 고려해야 하는 사항인 Latency, 서버, 장비사항, 서빙방식, qps(초당 몇개의 요청이 가능한지? 장비, 처리시간, 모델크기에 따라 달라짐)도 열심히 들었습니다.

또한 Offline 평가를 의존하면 안된다는 것을 1:1 게임 AI를 통해 잘 설명해 주셔서 계속 기억하고 있을 것 같아요.

마지막 조언으로 여러 역량을 익히고 개발 능력도 갖추는 것이 필요하다. 그리고 기술 트렌드에 민감해야한다는 말씀이 제 진로의 방향성을 구체화 시켜주어서 좋았습니다.

## 느낀점

대회 이후 오랜만에 강의를 들으니깐 여유로움이 조금 있는게 맞나 싶었습니다. 마치 훈련소에 있다가 자대 온 느낌이네요. 이 기분도 다음 주면 사라지겠지만요.

AI 서빙 부분 굉장히 걱정하면서도 내가 배울 것이 많기 때문에 열정과 긴장을 모두 갖고 들었는데요. 강의를 제 입장에서도 들을 수 있게 깔끔하게 해주셔서 잘 들었던 것 같습니다. 감사합니다.

아직 Streamlit이나 리눅스, 도커 등은 접근하지 않았는데요. 긴장과 기대가 동시에 됩니다.

유플러스 대회도 겸하려고 하는데 두 마리 토끼를 다 놓치지 않도록 열심히 노력해야겠습니다.

아직 이르지만 새로운 팀원들도 기대가 되고 지금 팀원들하고 저 혼자만인진 모르겠지만 정이 들었는데 약간 아쉽네요. 그래도 같이 부캠 하니깐 계속 연락 잘하면서 지냈으면 좋겠습니다.