---
toc: true
layout: post
description: 부스트캠프 25일차 공부 정리.
image : images/221021.PNG
categories: [BoostCamp, Recommender system, Pytorch templete, Git, NGCF]
title: "[BoostCamp]Day25 간단한 학습정리 및 회고"
search_exclude: False
---
# 25일차 공부 정리

## Pytorch templete을 이용한 깃 허브 협업 툴 연습

[Pytorch templete](https://github.com/victoresque/pytorch-template)을 예전에 배웠었는데 대회 기간 전 팀원들과 같이 사용법을 알아봤습니다.

팀원들이 어떻게 생각하는지 까진 모르겠는데 개인적으로 주피터 노트북이나 코랩과 다른 계층구조로 되어있는 .py파일을 돌려본 적이 처음이라 새로웠고 어색했습니다.

하지만 현업에서 꼭 필요한 능력이고 제가 많이 부족한 부분이기 때문에 남들보다 열심히 적응하려고 했습니다.

물론 어떻게 돌아가는지 알기 어렵고 남이 만들어 준 코드이지만 사용법은 조금은 알아간 것 같습니다.

실전에서 어떻게 쓰일진 모르겠지만 Pytorch templete를 활용해 movie 데이터를 간단한 딥러닝 모델로 학습한 경험과 깃헙을 사용해 협업한 경험이 저에게는 소중한 자산이 될 것 같습니다.

Pytorch templete 구조 얘기를 해보면 데이터 로더와 모델과 트레이너 그리고 손실 함수 등 다 분기가 되어 있습니다. 작업을 할 때 분기된 .py을 수정하면 되고 config를 통해 옵션을 조정해 주면 됩니다.

수 많은 오류를 극복하고 학습 진행되는 상황을 봤을 때 정말 뿌듯했습니다. 그리고 wandb와도 간단히 연동을 성공했습니다. wandb의 효능을 체감하진 못했지만 다양하게 경험해보려 합니다.

마지막으로 피어세션 때 깃허브 관련해서 의견을 나눴는데 어제 배운 내용을 실제로 실습하니 학습효과가 배가된 것 같습니다.


## Neural Graph Collaborative Filtering 수식 부분

Neural Graph Collaborative Filtering(이하 NGCF) 이론에 대해 이전에 학습하였습니다. 그래프 개념을 사용한 것이 흥미로웠습니다. ([논문](https://arxiv.org/pdf/1905.08108.pdf))

다만 그래프를 사용한다는 이론을 어떻게 수식으로 잘 녹여서 쓰는지 의문이였습니다.

심화과제2에서 설명을 하고 있는데 이해가 안되서 포기한 상태였는데 오늘 오피스아워시간에 많이 배웠습니다.

다른 부분은 재끼고 그래프를 어떻게 행렬로 사용했는지만 알아보겠습니다.

![NGCF1](https://user-images.githubusercontent.com/79916736/197173951-0819bca4-bc69-4f78-a43e-99ba7edb4d9d.png)

(그림은 조교님이 직접 쓰신 수식인 것 같습니다. 문제가 되면 삭제하겠습니다.)

그래프가 몇 개와 연결되었는지를 대각 원소에 넣고 두 요소가 연결 되었을 때 행렬에 -1 값을 넣습니다.

-1을 넣는 이유는 몇 개와 연결되었는지와 두 요소가 연결 되었다는 두 다른 의미를 구분하기 위해 -를 사용했다고 합니다.

이후 이 행렬에 $D^{-1/2}$를 곱한 이유는 많이 연결된 요소로 인해 값이 확 커지는 것을 방지하기 위해 정규화 했다고 생각하면 될 것 같습니다.

논문에서는 조금 다르게 L 행렬을 정의했는데 큰 맥락에서 윗 L과 동일합니다.

이렇게 요소들의 그래프 관계를 나타내는 L행렬을 정의했습니다.

![NGCF2](https://user-images.githubusercontent.com/79916736/197175318-ee68ff65-f8fa-4d16-a005-a68323f8b3b7.png)

![NGCF3](https://user-images.githubusercontent.com/79916736/197175406-6c9611a2-b497-4a81-a959-ffc4ba8a3459.png)

미리 결론부터 말하면 (5)와 (6)을 합치면 (7)이 됩니다. (7)의 L은 앞서 정의한 L행렬 입니다.

(5)는 하나의 유저 임베딩 벡터이고 (7)은 전체 유저와 아이템 임베딩 벡터의 $l$번째 값 입니다.

(6) 첫번째 식 앞 부분과 두번째 식을 결합한 것이 (7) 앞 부분 식이고 (6) 첫번째 식 뒷부분이 (7) 뒷부분 입니다.

항등행렬 $I$가 들어간 이유는 (6) 아랫 부분에 유저 메세지를 나타내는 부분을 의미하는데 자기 자신만을 그대로 유지시켜야 하기 때문이구요. 앞에 L행렬을 해석해보면 (5) 시그마 부분을 의미한다고 생각하면 됩니다. 나와 1차원적으로 연결이 있는 메세지만을 받아야하기 때문이죠. 이 때 L 행벡터를 살펴보면 요소가 다른 요소와 연결되어있는지 여부를 체크하게 됩니다. 연결되어있지 않으면 0이기 때문에 메세지가 전달이 안되죠. 이 부분 때문에 L행렬과 행렬곱 연산을 하게되면 (5) 시그마와 같은 효과를 보는 것을 알 수 있습니다.

## 느낀점

항상 금요일은 스페셜 피어세션 등 정해진 일정이 많기 때문에 많은 내용을 학습하진 못하는데요.

그럼에도 집중력을 잃지 않고 기대했던 것 보다 많은 것을 얻어가는 것 같습니다.

많은 분량이지만 저번주와 이번주 초반 미리 공부를 해서 하고싶은 공부를 잘 한것같아 기분이 좋습니다.

정리를 하기 전에는 귀찮다 생각하지만 정리하고보면 머리속까지 정리가 잘 된 느낌이네요. 복습 효과가 좋은 것 같습니다.

다음 주 대회형 프로젝트를 처음으로 진행되는데 개인적으로 기대가 많이 됩니다.

이전에 대회를 통해 많이 성장했다고 생각해서 그런지 대회 후 많이 성장할 자신의 모습이 기대됩니다.

이번 주 스스로 고생 많았다고 칭찬해주고 싶고 번아웃이 오지 않기 위해 주말에 부캠관련 모든 걸 잊고 월요일에 더 강하고 힘차게 돌아오겠습니다.

** 위 수식과 그림은 부스트캠프 AI Tech 교육 자료를 참고하였습니다.