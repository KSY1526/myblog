---
toc: true
layout: post
description: 부스트캠프 28일차 간단한 회고.
categories: [BoostCamp, Recommender system, PStage]
title: "[BoostCamp]Day28 PStage3"
search_exclude: False
---
# 28일차 간단한 회고

EDA 한 내용을 팀원들에게 전달도 잘 하고 공유도 하고 싶은 마음에 아침부터 정리를 하고 공유했습니다.

제가 데이터를 어떻게 바라봤는지 한번 더 정리된 것 같아 좋았던 것 같아요.

이후 데이터 전처리를 주피터가 아닌 py 파일 내에서 동작하도록 코딩했습니다. 다시 생각해보면 짧은 대회 기간에 중복되는 불필요한 일을 했던 것 같아요.

한창 작업하던 도중 한 팀원이 베이스라인을 한번씩 돌려보고 결과를 공유했습니다. 결과는 충격적이였는데요.

제 예상과 다르게 이미지를 이용하거나 텍스트를 이용한 추천 시스템이 성능이 가장 좋았던 것입니다.

특히 이미지 데이터는 쓸때없다고 지워버렸는데 서버 환경에서 다시 이미지 데이터 불러오는데 정말 많은 고생을 했습니다.

기존 FM 모델을 방치하고 성능이 가장 좋아보이는 텍스트 모델(DeepCoNN)을 살펴보기로 했습니다.

이후 피어세션 시간에는 대략 다음 얘기를 나눴습니다. 

- K-fold 관련 토론하기
- 베이스라인 모델 성능 비교하기
- DeepCoNN 모델 설명하기
- 각자의 역할 러프하게 부여하기

리더보드에 값을 넣어봤는데 결과가 처참합니다. 다만 기 죽어 있을 필요는 없을 것 같습니다.

왜냐하면 한 가지 신기한 사실을 발견했기 때문이죠.

![image](https://user-images.githubusercontent.com/79916736/198164493-d13d9af4-3e30-48d2-a394-39e10ed0a332.png)

무지성으로 평균값에 가까운 7을 train 데이터 모든 값에 넣고 rmse을 확인했더니 2.4가 나왔습니다.

지금 리더보드에 있는 score는 이보다 아주 조금 좋으며 제가 사용한 모델은 이보다도 훨씬 못합니다.

뭔가 모델이 핀트를 잘 못잡고 있는 것 같아요. 고민해야할 포인트가 많습니다.

사실 오늘 오후 DeepCoNN의 CNN 구조를 언어벡터에 맞는 RNN이나 트렌스포머를 사용하는게 목표였는데 그것 대신에 DeepCoNN 입력값에 age, state, years 등 아이템과 유저 정보를 받는 모델로 변환해보자는 목표가 생겼습니다.

잘 나올진 모르지만 도전 해보고 싶어서 늦게까지 조금 빡센 코딩을 진행했습니다.

valid 기준 기존 DeepCoNN보다 조금 좋았는데 리더보드에 제출하니 실망스러운 결과가 나왔습니다.

(valid rmse : 1.0, test rmse : 3.0)

다만 너무 갭이 커서 무언가 이상이 있을거다 짐작을 했지만 원인을 몰라 속상했는데요.

그 원인을 사실 다음날에 찾았는데 다음날 회고에 자세히 쓰겠습니다.

어제 예상했던 오늘 할 일과 실제 한 일이 완전히 다르네요. 오랜만에 실전 대회라 방향성을 조금 잃은 것 같습니다. ㅋㅋ. 

의미가 있을진 모르겠지만 내일 목표로는 다음과 같습니다.

- DeepCoNN를 발전시켜 좋은 성능을 내게 해보기
- cold start 문제 해결 방식 생각하기
- 부스팅 기반 머신러닝 모델 적용해보기

솔직히 점수가 안 나와 속상한 하루였습니다. 노력도 많이 했는데 결과가 안따라주네요.

다만 아직 하루밖에 안지났고 다른 팀들도 전부 7을 넣은 값과 성능이 비슷한 모델을 가지고 있어 데이터에 대한 이해가 깊어졌다고 생각하고 남은 기간 열심히 정진해야겠습니다.