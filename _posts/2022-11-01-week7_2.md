---
toc: true
layout: post
description: 부스트캠프 31, 32일차 간단한 회고.
categories: [BoostCamp, Recommender system, PStage]
title: "[BoostCamp]Day32 PStage6,7"
search_exclude: False
---
# 31, 32일차 간단한 회고

어제(PStage 6일차 월요일) 컨디션이 많이 안 좋아서 많은 실험을 진행하지 못했어서 오늘 회고와 같이 묶어 씁니다.

팀원들과 협의를 통해 이번주부터는 분야를 나눠서 작업을 진행하고 피어세션 시간에 공유를 하기로 했습니다.

CatBoost 모델 성능이 현재까지 우수하기 때문에 이와 유사하며 상위호환이 될 수 있는 TabNet 모델 탐구, CatBoost 모델에 잘 적용하기 위한 데이터 전처리 방식 찾기, 앙상블을 위해 CatBoost와 다른 부분의 학습이 가능한 좋은 딥러닝 모델을 찾아보기까지 세 파트로 나눠 수요일 피어세션 이전까지 학습하고 이후는 모델 고도화에 집중하기로 했습니다.

인상적인 소식으로는 나름 신경써서 EDA를 한 뒤 데이터 전처리를 마친 뒤 적용한 데이터보다 베이스라인 데이터가 CatBoost 모델에 잘 들어맞는다는 소식입니다.

특히 CatBoost 모델은 범주형 데이터에 대해서는 항목 개수가 많이 늘어나더라도 완벽에 가까운 처리를 잘 해주기 때문에 일반적으로 로버스트하게 처리해주는 전처리는 필요가 없다는 것을 다시 한번 느꼈습니다.

다음으로 Wandb 내 swap 기능을 사용해보았습니다. 팀원 한 분이 오류와 함께 고생을 해서 얻는 사용법을 이용했더니 너무 편했습니다. [링크](https://velog.io/@jjjjj/wandb-hyper-parameter-tuning)

CatBoost 변수 중요도를 살펴보면 사용자 id에 대해선 매우 높은 성능을 보였는데 책 id에 대해선 항목 대비 좋지 않은 성능을 보입니다. 사용자에 따라 평점이 바뀌는 정도가 책보다 크긴 하지만 조금 의야해서 이 부분을 개선할 수 있지 않을까 도전해보았습니다.

책을 단순 id로 사용하는 것이 아니라 책의 이미지나 요약본 등을 책의 특징을 나타내는 자료로 사용하는 것 입니다. 여기서 요약본은 NULL 값이 너무 많아 사용을 포기했습니다.

딥러닝 모델이 아니기 때문에 이미지 데이터를 임베딩을 하려면 오토인코더 방식을 사용해야합니다.

책 id 대신에 오토인코더 방식을 사용하여 이미지 정보 요약본을 사용했는데요. 조금은 효과가 있지 않을까 했는데 크게 유의미한 성능을 뽑진 못했습니다.

오토인코더 방식이 rating을 신경쓰지 않는 비지도 학습 방식이여서 이미지 자료 요약이 rating과 상관 없는 방식으로 된 점도 문제가 될 수 있고 성능이 좋은 오토인코더를 잘 구현하지 못했을 수도 있고 이미지 정보가 rating과 정말 연관이 없을 수도 있습니다. 시간이 부족해 여러가지 실험을 못해보는게 아쉽습니다.

다음으로 cold 유저에 대해 알아봤는데요. rmse score가 cold 유저에 경우 더 큰 현상은 이미 알고 있었죠.

물론 cold 유저가 1점을 주는 비율이 다소 높아 기본적으로 어떤 값을 주더라도 rmse score가 높게 나오긴 하지만 그 정도보다 모델이 cold 유저를 잘 못맞추는 현상이 나옵니다.

어떻게 보면 당연합니다. 정보가 부족한 cold 유저는 예측하기 쉽지 않으니깐요.

다만 cold 유저가 일반 유저 대비 극단적인 값(1 or 10점)을 많이 주는 등 성향이 다르다고 생각하고 모델이 이 점을 노쳤을 수도 있을거라는 생각속에 cold 유저에게 예측 rating에 다음 식을 적용해보았습니다.

- (pred_rating - colduser_rating_mean) * (1 + a) + colduser_rating_mean

일반 유저 대비 극단적인 값(1 or 10점)을 많이 갖는데요. rmse는 극단적인 값에 약하기 때문에 이를 보정한 것입니다.

하지만 이 식을 적용해보니 실제로 수치가 떨어집니다. 긴 결론은 CatBoost은 이 부분까지 이미 고려했다는 것입니다. 정말 범주형 변수에 대해 대단한 모델입니다.

그리고 딥러닝 모델을 적용했을 때 성능이 평균값을 그냥 넣었을 때와 비슷하다고 말씀드렸었는데 FM 모델 같은 경우 이전에 이와 비슷한 valid score가 나왔습니다.

CatBoost 모델에서 적은 수의 군집을 Others 취급 하는 것이 좋지 않았는데 딥러닝 모델(FM 등)은 오히려 Others 취급을 해줘야 오버피팅이 일어나지 않는다고 생각을 했는데 많은 실험을 하진 못햇지만 성능 향상을 확인했습니다. CatBoost와 딥러닝 모델 간 효과적인 전처리 방식이 다른 것을 깨닳았습니다.

FM이나 FFM 모델을 내일까지 만저보는 것이 목표입니다. 

마지막으로 5-fold를 진행한 뒤 각 fold마다에 모델에 optima을 사용해 최적의 파라미터를 찾고 여러 pred 값을 평균내었습니다. 과연 효과가 좋을지 두근두근했는데 2.12로 최고기록을 경신해서 기쁜 하루였습니다.

느낀 점으로 다소 부족하더라도 협업과 효과적인 진행을 위해서는 내가 했던 작업물을 중간중간 계속 정리하는게 중요하다는 것을 깨닳았습니다.

남들에게 보기 좋은 코드와 원칙 있는 코드 그리고 팀 내 일관된 변수명도 중요한 것 같아요.

컨디션이 어제 오늘 좋지 않은데 조금만 힘내서 꼭 1등 유지했으면 좋겠습니다. 화이팅!