---
toc: true
layout: post
description: 부스트캠프 7일차 공부 정리.
image : images/220928.PNG
categories: [BoostCamp, Python, Pytorch, AutoGrad, Optimizer, Dataset, DataLoader]
title: "[BoostCamp]Day7 파이토치 사용법1"
---
# 7일차 공부 정리
## Layer

딥러닝을 구성하는 Layer의 base 클래스로 torch.nn.Module 이 존재합니다.

torch.nn.Module 내에 입/출력값, Forward, Backward가 정의되고 학습의 대상이 되는 파라미터도 정의됩니다.

모듈 내 텐서가 학습이 되기 위해서는 required_grad를 True로 선언해주어야 합니다. 때문에 파라미터 변수는 Tensor객체를 상속한 nn.Parameter 객체를 사용합니다.

nn.Parameter 객체는 nn.Module 내 attribute가 될 때 required_grad가 True로 바뀌어 파라미터 변수는 이 객체를 사용해야합니다. 다만 low-level을 다루지 않는다면 직접 다루지 않습니다.

## Backward

~~~python
for epoch in range(epochs):
    ...
    ...
    ...
    # 1) 옵티마이저를 초기화함.
    optimizer.zero_grad()

    # 2) 모델에 입력값을 넣어 출력물을 저장함.
    outputs = model(inputs)

    # 3) 출력값과 실제 y값을 사용해 손실함수 값을 계산함.
    loss = criterion(outputs, labels)

    # 4) 손실함수를 사용해 backward(역전파)를 진행함. 
    loss.backward()

    # 5) 옵티마이저를 이용해 가중치 업데이트를 함.
    optimizer.step()
~~~

이렇게 총 5단계 스텝을 거처 학습이 진행됩니다. 자주 쓰는 코드이니 순서대로 잘 기억하면 좋겠습니다.

## Dataset, DataLoader

![model](https://user-images.githubusercontent.com/79916736/192254173-331f6e4c-548a-418b-8fc1-cd0db3930c7d.png)

다양한 종류에 데이터들을 표준화 시키는 곳이 Dataset, 배치를 생성하는 곳이 DataLoader 입니다.

### Dataset

~~~ python
import torch
from torch.utils.data import Dataset

class CustomDataset(Dataset): # Dataset을 상속받은 커스텀 데이터셋
    def __init__(self, text, labels): 
        # 생성자. 초기 데이터 생성 방법.
        # 데이터의 위치나 파일명과 같은 초기화 작업을 위해 동작
        self.labels = labels
        self.data = text

    def __len__(self): 
        # 데이터 전체 길이 반환 함수
        return len(self.labels)

    def __getitem__(self, idx): 
        # 데이터셋의 idx번째 데이터를 반환하는데 사용
        label = self.labels[idx]
        text = self.data[idx]
        sample = {'Text' : text, 'Class' : label}
        return sample

~~~

심플한 데이터 셋 코드 입니다. 이미지의 텐서변화와 같은 것을 꼭 데이터 생성시점에 처리할 필요는 없고 학습이 필요한 시점에 변환합니다.

### DataLoader

데이터로더는 앞서 정의한 데이터 셋을 사용해 미니배치형태로 제공하여 모델학습을 용이하게 합니다.

하이퍼 파라미터는 다음과 같습니다.

~~~Python
DataLoader(
    dataset, # Dataset 인스턴스가 들어감
    batch_size = 1 # 배치 사이즈 설정
    shuffle = False # 데이터를 섞는지 유무. 트레인 할때는 섞어야함
    sampler = None 
    batch_sampler = None # index를 컨트롤 하는 도구
    num_workers = 0 # 데이터 불러올때 사용하는 프로세스 개수
    collate_fn = None # 데이터 셋 크기가 일정하지 않을 때 배치 단위로 적용할 함수 입력
    drop_last = False # 마지막 배치 사용 여부
    timeout = 0 # 데이터를 불러오는데 제한 시간

)
~~~

## 느낀점

무심코 썼던 파이토치 라이브러리 내 다양한 클래스와 함수들이 설계하는 사람 입장에서 정말 체계적으로 제작했구나 알게 되었습니다.

제가 많이 부족해 파이토치 내 기능을 아직 많이 못쓰는구나 생각했고 많이 배웠습니다.

특히 공식문서 읽는법, Parameter 객체, collate_fn 적용 등 과제를 통해 많이 성장한 것 같습니다.

다만.. 많이 힘드네요. 아직 7일차지만 장기 레이스임을 인지하고 꾸준히 열심히 해야겠습니다.

** 위 수식과 그림은 부스트캠프 AI Tech 교육 자료를 참고하였습니다.

