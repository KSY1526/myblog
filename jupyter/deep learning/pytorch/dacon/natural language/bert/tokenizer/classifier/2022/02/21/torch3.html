<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>[DACON] 자연어 처리 문장 쌍 분류하기2 With Pytorch | 나의 빅데이터 공부 기록</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="[DACON] 자연어 처리 문장 쌍 분류하기2 With Pytorch" />
<meta name="author" content="Seong Yeon Kim" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="다양한 머신러닝/딥러닝 코드들이 기록되어 있습니다." />
<meta property="og:description" content="다양한 머신러닝/딥러닝 코드들이 기록되어 있습니다." />
<link rel="canonical" href="https://ksy1526.github.io/myblog/jupyter/deep%20learning/pytorch/dacon/natural%20language/bert/tokenizer/classifier/2022/02/21/torch3.html" />
<meta property="og:url" content="https://ksy1526.github.io/myblog/jupyter/deep%20learning/pytorch/dacon/natural%20language/bert/tokenizer/classifier/2022/02/21/torch3.html" />
<meta property="og:site_name" content="나의 빅데이터 공부 기록" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-02-21T00:00:00-06:00" />
<script type="application/ld+json">
{"datePublished":"2022-02-21T00:00:00-06:00","url":"https://ksy1526.github.io/myblog/jupyter/deep%20learning/pytorch/dacon/natural%20language/bert/tokenizer/classifier/2022/02/21/torch3.html","@type":"BlogPosting","headline":"[DACON] 자연어 처리 문장 쌍 분류하기2 With Pytorch","dateModified":"2022-02-21T00:00:00-06:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://ksy1526.github.io/myblog/jupyter/deep%20learning/pytorch/dacon/natural%20language/bert/tokenizer/classifier/2022/02/21/torch3.html"},"author":{"@type":"Person","name":"Seong Yeon Kim"},"description":"다양한 머신러닝/딥러닝 코드들이 기록되어 있습니다.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/myblog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://ksy1526.github.io/myblog/feed.xml" title="나의 빅데이터 공부 기록" /><link rel="shortcut icon" type="image/x-icon" href="/myblog/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/myblog/">나의 빅데이터 공부 기록</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/myblog/about/">About Me</a><a class="page-link" href="/myblog/search/">Search</a><a class="page-link" href="/myblog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">[DACON] 자연어 처리 문장 쌍 분류하기2 With Pytorch</h1><p class="post-meta post-meta-title"><time class="dt-published" datetime="2022-02-21T00:00:00-06:00" itemprop="datePublished">
        Feb 21, 2022
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Seong Yeon Kim</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      13 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/myblog/categories/#jupyter">jupyter</a>
        &nbsp;
      
        <a class="category-tags-link" href="/myblog/categories/#Deep Learning">Deep Learning</a>
        &nbsp;
      
        <a class="category-tags-link" href="/myblog/categories/#Pytorch">Pytorch</a>
        &nbsp;
      
        <a class="category-tags-link" href="/myblog/categories/#DACON">DACON</a>
        &nbsp;
      
        <a class="category-tags-link" href="/myblog/categories/#natural language">natural language</a>
        &nbsp;
      
        <a class="category-tags-link" href="/myblog/categories/#BERT">BERT</a>
        &nbsp;
      
        <a class="category-tags-link" href="/myblog/categories/#tokenizer">tokenizer</a>
        &nbsp;
      
        <a class="category-tags-link" href="/myblog/categories/#Classifier">Classifier</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          
          
          
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2022-02-21-torch3.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="https://colab.research.google.com/github/KSY1526/myblog/blob/master/_notebooks/2022-02-21-torch3.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="&#54056;&#53412;&#51648;-&#49444;&#52824;&#54616;&#44592;">&#54056;&#53412;&#51648; &#49444;&#52824;&#54616;&#44592;<a class="anchor-link" href="#&#54056;&#53412;&#51648;-&#49444;&#52824;&#54616;&#44592;"> </a></h1>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">google.colab</span> <span class="kn">import</span> <span class="n">drive</span>
<span class="n">drive</span><span class="o">.</span><span class="n">mount</span><span class="p">(</span><span class="s1">&#39;/content/drive&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Mounted at /content/drive
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>구글 드라이브와 연동합니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">mxnet</span><span class="o">-</span><span class="n">cu101</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">gluonnlp</span> <span class="n">pandas</span> <span class="n">tqdm</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">sentencepiece</span><span class="o">==</span><span class="mf">0.1</span><span class="o">.</span><span class="mi">85</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">transformers</span><span class="o">==</span><span class="mf">2.1</span><span class="o">.</span><span class="mi">1</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="n">git</span><span class="o">+</span><span class="n">https</span><span class="p">:</span><span class="o">//</span><span class="n">git</span><span class="nd">@github</span><span class="o">.</span><span class="n">com</span><span class="o">/</span><span class="n">SKTBrain</span><span class="o">/</span><span class="n">KoBERT</span><span class="o">.</span><span class="n">git</span><span class="nd">@master</span>

<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span><span class="p">,</span> <span class="n">tqdm_notebook</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span><span class="p">,</span> <span class="n">DataLoader</span>

<span class="kn">import</span> <span class="nn">gluonnlp</span> <span class="k">as</span> <span class="nn">nlp</span>

<span class="c1">#kobert</span>
<span class="kn">from</span> <span class="nn">kobert.utils</span> <span class="kn">import</span> <span class="n">get_tokenizer</span>
<span class="kn">from</span> <span class="nn">kobert.pytorch_kobert</span> <span class="kn">import</span> <span class="n">get_pytorch_kobert_model</span>

<span class="c1">#transformers</span>
<span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AdamW</span>
<span class="c1"># 스케줄러 조정 함수</span>
<span class="kn">from</span> <span class="nn">transformers.optimization</span> <span class="kn">import</span> <span class="n">get_cosine_schedule_with_warmup</span>


<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Collecting mxnet-cu101
  Downloading mxnet_cu101-1.9.0-py3-none-manylinux2014_x86_64.whl (358.1 MB)
     |████████████████████████████████| 358.1 MB 4.7 kB/s 
Requirement already satisfied: numpy&lt;2.0.0,&gt;1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet-cu101) (1.21.5)
Requirement already satisfied: requests&lt;3,&gt;=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet-cu101) (2.23.0)
Collecting graphviz&lt;0.9.0,&gt;=0.8.1
  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)
Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests&lt;3,&gt;=2.20.0-&gt;mxnet-cu101) (3.0.4)
Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests&lt;3,&gt;=2.20.0-&gt;mxnet-cu101) (2.10)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests&lt;3,&gt;=2.20.0-&gt;mxnet-cu101) (1.24.3)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests&lt;3,&gt;=2.20.0-&gt;mxnet-cu101) (2021.10.8)
Installing collected packages: graphviz, mxnet-cu101
  Attempting uninstall: graphviz
    Found existing installation: graphviz 0.10.1
    Uninstalling graphviz-0.10.1:
      Successfully uninstalled graphviz-0.10.1
Successfully installed graphviz-0.8.4 mxnet-cu101-1.9.0
Collecting gluonnlp
  Downloading gluonnlp-0.10.0.tar.gz (344 kB)
     |████████████████████████████████| 344 kB 11.0 MB/s 
Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)
Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.3)
Requirement already satisfied: numpy&gt;=1.16.0 in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (1.21.5)
Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (0.29.27)
Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (21.3)
Requirement already satisfied: python-dateutil&gt;=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)
Requirement already satisfied: pytz&gt;=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil&gt;=2.7.3-&gt;pandas) (1.15.0)
Requirement already satisfied: pyparsing!=3.0.5,&gt;=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging-&gt;gluonnlp) (3.0.7)
Building wheels for collected packages: gluonnlp
  Building wheel for gluonnlp (setup.py) ... done
  Created wheel for gluonnlp: filename=gluonnlp-0.10.0-cp37-cp37m-linux_x86_64.whl size=595727 sha256=21bfa5933185a4a625340e1bfaf8e75fd58e3e8d80269d47e30a5d2587306f84
  Stored in directory: /root/.cache/pip/wheels/be/b4/06/7f3fdfaf707e6b5e98b79c041e023acffbe395d78a527eae00
Successfully built gluonnlp
Installing collected packages: gluonnlp
Successfully installed gluonnlp-0.10.0
Collecting sentencepiece==0.1.85
  Downloading sentencepiece-0.1.85-cp37-cp37m-manylinux1_x86_64.whl (1.0 MB)
     |████████████████████████████████| 1.0 MB 11.2 MB/s 
Installing collected packages: sentencepiece
Successfully installed sentencepiece-0.1.85
Collecting transformers==2.1.1
  Downloading transformers-2.1.1-py3-none-any.whl (311 kB)
     |████████████████████████████████| 311 kB 11.2 MB/s 
Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==2.1.1) (0.1.85)
Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.1.1) (2.23.0)
Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from transformers==2.1.1) (2019.12.20)
Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from transformers==2.1.1) (4.62.3)
Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.1.1) (1.21.5)
Collecting boto3
  Downloading boto3-1.21.3-py3-none-any.whl (132 kB)
     |████████████████████████████████| 132 kB 51.3 MB/s 
Collecting sacremoses
  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)
     |████████████████████████████████| 895 kB 51.4 MB/s 
Collecting jmespath&lt;1.0.0,&gt;=0.7.1
  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)
Collecting botocore&lt;1.25.0,&gt;=1.24.3
  Downloading botocore-1.24.3-py3-none-any.whl (8.5 MB)
     |████████████████████████████████| 8.5 MB 7.0 MB/s 
Collecting s3transfer&lt;0.6.0,&gt;=0.5.0
  Downloading s3transfer-0.5.1-py3-none-any.whl (79 kB)
     |████████████████████████████████| 79 kB 8.5 MB/s 
Collecting urllib3&lt;1.27,&gt;=1.25.4
  Downloading urllib3-1.26.8-py2.py3-none-any.whl (138 kB)
     |████████████████████████████████| 138 kB 53.8 MB/s 
Requirement already satisfied: python-dateutil&lt;3.0.0,&gt;=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore&lt;1.25.0,&gt;=1.24.3-&gt;boto3-&gt;transformers==2.1.1) (2.8.2)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil&lt;3.0.0,&gt;=2.1-&gt;botocore&lt;1.25.0,&gt;=1.24.3-&gt;boto3-&gt;transformers==2.1.1) (1.15.0)
Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;transformers==2.1.1) (3.0.4)
  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)
     |████████████████████████████████| 127 kB 49.3 MB/s 
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;transformers==2.1.1) (2021.10.8)
Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests-&gt;transformers==2.1.1) (2.10)
Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses-&gt;transformers==2.1.1) (1.1.0)
Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses-&gt;transformers==2.1.1) (7.1.2)
Installing collected packages: urllib3, jmespath, botocore, s3transfer, sacremoses, boto3, transformers
  Attempting uninstall: urllib3
    Found existing installation: urllib3 1.24.3
    Uninstalling urllib3-1.24.3:
      Successfully uninstalled urllib3-1.24.3
<span class="ansi-red-fg">ERROR: pip&#39;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.</span>
Successfully installed boto3-1.21.3 botocore-1.24.3 jmespath-0.10.0 s3transfer-0.5.1 sacremoses-0.0.47 transformers-2.1.1 urllib3-1.25.11
Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master
  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /tmp/pip-req-build-3u3t0irc
  Running command git clone -q &#39;https://****@github.com/SKTBrain/KoBERT.git&#39; /tmp/pip-req-build-3u3t0irc
Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (1.21.3)
Requirement already satisfied: gluonnlp&gt;=0.6.0 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (0.10.0)
Collecting mxnet&gt;=1.4.0
  Downloading mxnet-1.9.0-py3-none-manylinux2014_x86_64.whl (47.3 MB)
     |████████████████████████████████| 47.3 MB 37.5 MB/s 
Collecting onnxruntime==1.8.0
  Downloading onnxruntime-1.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)
     |████████████████████████████████| 4.5 MB 39.4 MB/s 
Requirement already satisfied: sentencepiece&gt;=0.1.6 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (0.1.85)
Requirement already satisfied: torch&gt;=1.7.0 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (1.10.0+cu111)
Collecting transformers&gt;=4.8.1
  Downloading transformers-4.16.2-py3-none-any.whl (3.5 MB)
     |████████████████████████████████| 3.5 MB 40.1 MB/s 
Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime==1.8.0-&gt;kobert==0.2.3) (2.0)
Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnxruntime==1.8.0-&gt;kobert==0.2.3) (3.17.3)
Requirement already satisfied: numpy&gt;=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnxruntime==1.8.0-&gt;kobert==0.2.3) (1.21.5)
Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp&gt;=0.6.0-&gt;kobert==0.2.3) (21.3)
Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp&gt;=0.6.0-&gt;kobert==0.2.3) (0.29.27)
Requirement already satisfied: requests&lt;3,&gt;=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet&gt;=1.4.0-&gt;kobert==0.2.3) (2.23.0)
Requirement already satisfied: graphviz&lt;0.9.0,&gt;=0.8.1 in /usr/local/lib/python3.7/dist-packages (from mxnet&gt;=1.4.0-&gt;kobert==0.2.3) (0.8.4)
Requirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests&lt;3,&gt;=2.20.0-&gt;mxnet&gt;=1.4.0-&gt;kobert==0.2.3) (2021.10.8)
Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests&lt;3,&gt;=2.20.0-&gt;mxnet&gt;=1.4.0-&gt;kobert==0.2.3) (3.0.4)
Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests&lt;3,&gt;=2.20.0-&gt;mxnet&gt;=1.4.0-&gt;kobert==0.2.3) (1.25.11)
Requirement already satisfied: idna&lt;3,&gt;=2.5 in /usr/local/lib/python3.7/dist-packages (from requests&lt;3,&gt;=2.20.0-&gt;mxnet&gt;=1.4.0-&gt;kobert==0.2.3) (2.10)
Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch&gt;=1.7.0-&gt;kobert==0.2.3) (3.10.0.2)
Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers&gt;=4.8.1-&gt;kobert==0.2.3) (3.4.2)
Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers&gt;=4.8.1-&gt;kobert==0.2.3) (4.11.0)
Collecting huggingface-hub&lt;1.0,&gt;=0.1.0
  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)
     |████████████████████████████████| 67 kB 6.6 MB/s 
Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers&gt;=4.8.1-&gt;kobert==0.2.3) (2019.12.20)
Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers&gt;=4.8.1-&gt;kobert==0.2.3) (0.0.47)
Collecting pyyaml&gt;=5.1
  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)
     |████████████████████████████████| 596 kB 44.1 MB/s 
Requirement already satisfied: tqdm&gt;=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers&gt;=4.8.1-&gt;kobert==0.2.3) (4.62.3)
Collecting tokenizers!=0.11.3,&gt;=0.10.1
  Downloading tokenizers-0.11.5-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.8 MB)
     |████████████████████████████████| 6.8 MB 49.8 MB/s 
Requirement already satisfied: pyparsing!=3.0.5,&gt;=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging-&gt;gluonnlp&gt;=0.6.0-&gt;kobert==0.2.3) (3.0.7)
Requirement already satisfied: s3transfer&lt;0.6.0,&gt;=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3-&gt;kobert==0.2.3) (0.5.1)
Requirement already satisfied: jmespath&lt;1.0.0,&gt;=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3-&gt;kobert==0.2.3) (0.10.0)
Requirement already satisfied: botocore&lt;1.25.0,&gt;=1.24.3 in /usr/local/lib/python3.7/dist-packages (from boto3-&gt;kobert==0.2.3) (1.24.3)
Requirement already satisfied: python-dateutil&lt;3.0.0,&gt;=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore&lt;1.25.0,&gt;=1.24.3-&gt;boto3-&gt;kobert==0.2.3) (2.8.2)
Requirement already satisfied: six&gt;=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil&lt;3.0.0,&gt;=2.1-&gt;botocore&lt;1.25.0,&gt;=1.24.3-&gt;boto3-&gt;kobert==0.2.3) (1.15.0)
Requirement already satisfied: zipp&gt;=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata-&gt;transformers&gt;=4.8.1-&gt;kobert==0.2.3) (3.7.0)
Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses-&gt;transformers&gt;=4.8.1-&gt;kobert==0.2.3) (7.1.2)
Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses-&gt;transformers&gt;=4.8.1-&gt;kobert==0.2.3) (1.1.0)
Building wheels for collected packages: kobert
  Building wheel for kobert (setup.py) ... done
  Created wheel for kobert: filename=kobert-0.2.3-py3-none-any.whl size=15449 sha256=5ca56065402e4d6b5d7a3099cd3639179f1e840149ba1a0fbe8273c500f816f1
  Stored in directory: /tmp/pip-ephem-wheel-cache-kat_1l4g/wheels/d3/68/ca/334747dfb038313b49cf71f84832a33372f3470d9ddfd051c0
Successfully built kobert
Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers, onnxruntime, mxnet, kobert
  Attempting uninstall: pyyaml
    Found existing installation: PyYAML 3.13
    Uninstalling PyYAML-3.13:
      Successfully uninstalled PyYAML-3.13
  Attempting uninstall: transformers
    Found existing installation: transformers 2.1.1
    Uninstalling transformers-2.1.1:
      Successfully uninstalled transformers-2.1.1
Successfully installed huggingface-hub-0.4.0 kobert-0.2.3 mxnet-1.9.0 onnxruntime-1.8.0 pyyaml-6.0 tokenizers-0.11.5 transformers-4.16.2
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>필요한 패키지를 설치하고 임포트 합니다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="&#45936;&#51060;&#53552;-&#48520;&#47084;&#50724;&#44592;">&#45936;&#51060;&#53552; &#48520;&#47084;&#50724;&#44592;<a class="anchor-link" href="#&#45936;&#51060;&#53552;-&#48520;&#47084;&#50724;&#44592;"> </a></h1>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">path</span> <span class="o">=</span> <span class="s1">&#39;/content/drive/MyDrive/sentence/&#39;</span>

<span class="n">train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">path</span> <span class="o">+</span> <span class="s1">&#39;train_data.csv&#39;</span><span class="p">)</span>
<span class="n">test</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">path</span> <span class="o">+</span> <span class="s1">&#39;test_data.csv&#39;</span><span class="p">)</span>
<span class="n">sample_submission</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">path</span> <span class="o">+</span> <span class="s1">&#39;sample_submission.csv&#39;</span><span class="p">)</span>

<span class="n">train</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">

  <div id="df-0ddf36dd-2b03-4813-b0be-4faf598af020">
    <div class="colab-df-container">
      <div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>index</th>
      <th>premise</th>
      <th>hypothesis</th>
      <th>label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>씨름은 상고시대로부터 전해져 내려오는 남자들의 대표적인 놀이로서, 소년이나 장정들이...</td>
      <td>씨름의 여자들의 놀이이다.</td>
      <td>contradiction</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>삼성은 자작극을 벌인 2명에게 형사 고소 등의 법적 대응을 검토 중이라고 하였으나,...</td>
      <td>자작극을 벌인 이는 3명이다.</td>
      <td>contradiction</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2</td>
      <td>이를 위해 예측적 범죄예방 시스템을 구축하고 고도화한다.</td>
      <td>예측적 범죄예방 시스템 구축하고 고도화하는 것은 목적이 있기 때문이다.</td>
      <td>entailment</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3</td>
      <td>광주광역시가 재개발 정비사업 원주민들에 대한 종합대책을 마련하는 등 원주민 보호에 ...</td>
      <td>원주민들은 종합대책에 만족했다.</td>
      <td>neutral</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4</td>
      <td>진정 소비자와 직원들에게 사랑 받는 기업으로 오래 지속되고 싶으면, 이런 상황에서는...</td>
      <td>이런 상황에서 책임 있는 모습을 보여주는 기업은 아주 드물다.</td>
      <td>neutral</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-0ddf36dd-2b03-4813-b0be-4faf598af020')" title="Convert this dataframe to an interactive table." style="display:none;">
        
  &lt;svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px"&gt;
    <path d="M0 0h24v24H0V0z" fill="none" />
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z" /><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z" />
  &lt;/svg&gt;
      </button>
      
  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-0ddf36dd-2b03-4813-b0be-4faf598af020 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-0ddf36dd-2b03-4813-b0be-4faf598af020');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
  
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>데이터를 불러옵니다. 데이터에 대한 설명은 이전에 했으니 생략합니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">label_dict</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;entailment&#39;</span> <span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;contradiction&#39;</span> <span class="p">:</span> <span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;neutral&#39;</span> <span class="p">:</span> <span class="mi">2</span><span class="p">}</span>

<span class="n">train_content</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">test_content</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">index</span><span class="p">):</span>
    <span class="n">train_content</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">list</span><span class="p">([[</span><span class="n">train</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="s1">&#39;premise&#39;</span><span class="p">],</span> <span class="n">train</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="s1">&#39;hypothesis&#39;</span><span class="p">]],</span>
                               <span class="n">label_dict</span><span class="p">[</span><span class="n">train</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="s1">&#39;label&#39;</span><span class="p">]]]))</span>

<span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">test</span><span class="o">.</span><span class="n">index</span><span class="p">):</span>
    <span class="n">test_content</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">list</span><span class="p">([[</span><span class="n">test</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="s1">&#39;premise&#39;</span><span class="p">],</span> <span class="n">test</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">idx</span><span class="p">,</span> <span class="s1">&#39;hypothesis&#39;</span><span class="p">]]]))</span>


<span class="n">dataset_train</span> <span class="o">=</span> <span class="n">train_content</span><span class="p">[:</span><span class="mi">20000</span><span class="p">]</span>
<span class="n">dataset_valid</span> <span class="o">=</span> <span class="n">train_content</span><span class="p">[</span><span class="mi">20000</span><span class="p">:]</span>
<span class="n">dataset_test</span> <span class="o">=</span> <span class="n">test_content</span>

<span class="n">dataset_train</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|██████████| 24998/24998 [00:01&lt;00:00, 23116.36it/s]
100%|██████████| 1666/1666 [00:00&lt;00:00, 39118.13it/s]
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[[[&#39;씨름은 상고시대로부터 전해져 내려오는 남자들의 대표적인 놀이로서, 소년이나 장정들이 넓고 평평한 백사장이나 마당에서 모여 서로 힘과 슬기를 겨루는 것이다.&#39;,
   &#39;씨름의 여자들의 놀이이다.&#39;],
  1],
 [[&#39;삼성은 자작극을 벌인 2명에게 형사 고소 등의 법적 대응을 검토 중이라고 하였으나, 중국 내에서의 여론은 자작극이라는 증거가 충분함에도 불구하고 좋지 않다.&#39;,
   &#39;자작극을 벌인 이는 3명이다.&#39;],
  1],
 [[&#39;이를 위해 예측적 범죄예방 시스템을 구축하고 고도화한다.&#39;,
   &#39;예측적 범죄예방 시스템 구축하고 고도화하는 것은 목적이 있기 때문이다.&#39;],
  0],
 [[&#39;광주광역시가 재개발 정비사업 원주민들에 대한 종합대책을 마련하는 등 원주민 보호에 적극 나섰다.&#39;,
   &#39;원주민들은 종합대책에 만족했다.&#39;],
  2],
 [[&#39;진정 소비자와 직원들에게 사랑 받는 기업으로 오래 지속되고 싶으면, 이런 상황에서는 책임 있는 모습을 보여주는 것이 필요하다.&#39;,
   &#39;이런 상황에서 책임 있는 모습을 보여주는 기업은 아주 드물다.&#39;],
  2]]</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>입력된 데이터를 리스트 형태로 다시 구성합니다. 이때 [[전제, 가설], 라벨] 구성으로 데이터 한 세트를 만듭니다.</p>
<p>2만개를 트레인 세트, 나머지 약 5천개를 valid 세트로 구성합니다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="&#45936;&#51060;&#53552;-&#47196;&#45908;-&#44396;&#52629;&#54616;&#44592;">&#45936;&#51060;&#53552; &#47196;&#45908; &#44396;&#52629;&#54616;&#44592;<a class="anchor-link" href="#&#45936;&#51060;&#53552;-&#47196;&#45908;-&#44396;&#52629;&#54616;&#44592;"> </a></h1>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">max_len</span> <span class="o">=</span> <span class="mi">70</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">64</span>
<span class="n">warmup_ratio</span> <span class="o">=</span> <span class="mf">0.1</span>
<span class="n">num_epochs</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">max_grad_norm</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">log_interval</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">5e-5</span>

<span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda:0&#39;</span><span class="p">)</span>

<span class="k">else</span><span class="p">:</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>

<span class="c1"># kobert 패키지 내 BERT 모델과 어휘 집합을 입력받습니다. </span>
<span class="n">bertmodel</span><span class="p">,</span> <span class="n">vocab</span> <span class="o">=</span> <span class="n">get_pytorch_kobert_model</span><span class="p">(</span><span class="n">cachedir</span> <span class="o">=</span> <span class="s1">&#39;.cache&#39;</span><span class="p">)</span>

<span class="c1"># kobert 패키지 내 토크나이저를 입력받습니다.</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">get_tokenizer</span><span class="p">()</span>

<span class="c1"># 입력받은 토크나이저를 입력받은 어휘 집합을 이용해 학습합니다.</span>
<span class="n">tok</span> <span class="o">=</span> <span class="n">nlp</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">BERTSPTokenizer</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">lower</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>/content/.cache/kobert_v1.zip[██████████████████████████████████████████████████]
/content/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece[██████████████████████████████████████████████████]
using cached model. /content/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>기본적인 하이퍼 파라미터 설정을 미리 합니다. 문장 최대 길이, 에포크, 러닝레이트 등등을 미리 지정합니다.</p>
<p>또 kobert 패키지 내 BERT 모델, 토크나이저, 어휘 집합을 입력받습니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">BERTDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dataset</span><span class="p">,</span> <span class="n">sen_idx</span><span class="p">,</span> <span class="n">label_idx</span><span class="p">,</span> <span class="n">bert_tokenizer</span><span class="p">,</span> <span class="n">max_len</span><span class="p">,</span>
                 <span class="n">pad</span><span class="p">,</span> <span class="n">pair</span><span class="p">,</span> <span class="n">mode</span> <span class="o">=</span> <span class="s1">&#39;train&#39;</span><span class="p">):</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">=</span> <span class="n">mode</span>
        <span class="n">transform</span> <span class="o">=</span> <span class="n">nlp</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">BERTSentenceTransform</span><span class="p">(</span><span class="n">bert_tokenizer</span><span class="p">,</span> <span class="n">max_seq_length</span> <span class="o">=</span> <span class="n">max_len</span><span class="p">,</span>
                                                   <span class="n">pad</span> <span class="o">=</span> <span class="n">pad</span><span class="p">,</span> <span class="n">pair</span> <span class="o">=</span> <span class="n">pair</span><span class="p">)</span>
        <span class="c1"># 문장 쌍(pair = True)을 학습하는 트렌스포머를 만듭니다.</span>
        
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;train&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sentence</span> <span class="o">=</span> <span class="p">[</span><span class="n">transform</span><span class="p">(</span><span class="n">i</span><span class="p">[</span><span class="n">sen_idx</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">(</span><span class="n">i</span><span class="p">[</span><span class="n">label_idx</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">]</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sentence</span> <span class="o">=</span> <span class="p">[</span><span class="n">transform</span><span class="p">(</span><span class="n">i</span><span class="p">[</span><span class="n">sen_idx</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">dataset</span><span class="p">]</span>


    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">mode</span> <span class="o">==</span> <span class="s1">&#39;train&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sentence</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">],))</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">sentence</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sentence</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>파이토치 내 Dataset 클래스를 상속받아서 데이터 셋을 클래스로 만듭니다.</p>
<p>Dataset 클래스를 상속했기 때문에 향후 DataLoader 내에 실을 수 있겠죠.</p>
<p>리스트 형태인 데이터 내 문장을 트랜스포머를 이용해서 변환 한 뒤 sentence 내 리스트 형태로 저장합니다.</p>
<p>라벨 값 또한 labels 내 리스트 형태로 저장합니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">data_train</span> <span class="o">=</span> <span class="n">BERTDataset</span><span class="p">(</span><span class="n">dataset_train</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">tok</span><span class="p">,</span> <span class="n">max_len</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="n">mode</span> <span class="o">=</span> <span class="s1">&#39;train&#39;</span><span class="p">)</span>
<span class="n">data_valid</span> <span class="o">=</span> <span class="n">BERTDataset</span><span class="p">(</span><span class="n">dataset_valid</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">tok</span><span class="p">,</span> <span class="n">max_len</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="n">mode</span> <span class="o">=</span> <span class="s1">&#39;train&#39;</span><span class="p">)</span>
<span class="n">data_test</span> <span class="o">=</span> <span class="n">BERTDataset</span><span class="p">(</span><span class="n">dataset_test</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">tok</span><span class="p">,</span> <span class="n">max_len</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="n">mode</span> <span class="o">=</span> <span class="s1">&#39;test&#39;</span><span class="p">)</span>

<span class="n">train_dataloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">data_train</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_workers</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">valid_dataloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">data_valid</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_workers</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">test_dataloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">data_test</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_workers</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>앞서 정의한 BERTDataset 클래스를 이용해 문장을 트랜스포머로 변형하고, 로더에 실겠습니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">data_train</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>(array([   2, 3088, 6117, 7086, 2658, 5439, 6708, 6080, 4059, 7245, 1442,
        6965, 1423, 5939, 1678, 1504, 7096, 6081,  517,   46, 2822, 5712,
        7098, 3954, 7227, 5940, 1459, 5439, 4841, 7724, 7828, 2298, 6493,
        7178, 7098, 1907, 5804, 6903, 2064, 2720, 5211, 5468, 2948, 5573,
         517, 5411, 6095, 5760,  913,  517,   54,    3, 3088, 6117, 7095,
        3318, 5939, 1504, 7096, 7100,  517,   54,    3,    1,    1,    1,
           1,    1,    1,    1], dtype=int32),
 array(63, dtype=int32),
 array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
        0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,
        0, 0, 0, 0], dtype=int32),
 1)</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>이 데이터 셋은 문장을 트랜스포머를 통해 숫자로 바꾼 값, 전체 문장이 끝나는 위치, 두번째 문장을 1로 표기한 리스트, 라벨값으로 구성됩니다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="&#47784;&#45944;-&#44396;&#52629;&#54616;&#44592;">&#47784;&#45944; &#44396;&#52629;&#54616;&#44592;<a class="anchor-link" href="#&#47784;&#45944;-&#44396;&#52629;&#54616;&#44592;"> </a></h1>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">BERTClassifier</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">bert</span><span class="p">,</span> <span class="n">hidden_size</span> <span class="o">=</span> <span class="mi">768</span><span class="p">,</span> <span class="n">num_classes</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span> <span class="n">dr_rate</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">params</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">BERTClassifier</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bert</span> <span class="o">=</span> <span class="n">bert</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dr_rate</span> <span class="o">=</span> <span class="n">dr_rate</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">dr_rate</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span> <span class="o">=</span> <span class="n">dr_rate</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">gen_attention_mask</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token_ids</span><span class="p">,</span> <span class="n">valid_length</span><span class="p">):</span>
        <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">token_ids</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">valid_length</span><span class="p">):</span>
            <span class="n">attention_mask</span><span class="p">[</span><span class="n">i</span><span class="p">][:</span><span class="n">v</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">return</span> <span class="n">attention_mask</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>


    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">token_ids</span><span class="p">,</span> <span class="n">valid_length</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">):</span>
        <span class="n">attention_mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">gen_attention_mask</span><span class="p">(</span><span class="n">token_ids</span><span class="p">,</span> <span class="n">valid_length</span><span class="p">)</span>

        <span class="n">_</span><span class="p">,</span> <span class="n">pooler</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bert</span><span class="p">(</span><span class="n">input_ids</span> <span class="o">=</span> <span class="n">token_ids</span><span class="p">,</span> <span class="n">token_type_ids</span> <span class="o">=</span> <span class="n">segment_ids</span><span class="o">.</span><span class="n">long</span><span class="p">(),</span>
                              <span class="n">attention_mask</span> <span class="o">=</span> <span class="n">attention_mask</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">token_ids</span><span class="o">.</span><span class="n">device</span><span class="p">))</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dr_rate</span><span class="p">:</span>
            <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">pooler</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>파이토치 내 nn.Module 클래스를 상속받아 모델을 클래스로 구현했습니다. init 함수로 정의를 하고 forward 함수에서 실행을 합니다.</p>
<p>특이한 점은 bert 모델에 입력값으로 input_ids(숫자로 변환된 문장), token_type_ids(두번째 문장을 1로 표기한 리스트), attention_mask(문장부분을 1로, 문장 아닌부분을 0으로 표기한 리스트) 세가지를 받습니다.</p>
<p>현재 데이터 로더는 input_ids, token_type_ids는 bert 입력값과 같은형태이나, attention_mask가 아닌 문장이 끝나는 부분을 숫자로 알려줍니다.</p>
<p>문장이 끝나는 부분 값을 attention_mask 형식으로 바꾸기 위해 gen_attention_mask 함수를 사용했습니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">BERTClassifier</span><span class="p">(</span><span class="n">bertmodel</span><span class="p">,</span> <span class="n">dr_rate</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="c1"># 가중치 감퇴를 위한 부분 (오버피팅 방지를 위해)</span>
<span class="n">no_decay</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;bias&#39;</span><span class="p">,</span> <span class="s1">&#39;LayerNorm.weight&#39;</span><span class="p">]</span> <span class="c1"># 이 부분은 가중치 감퇴 x</span>
<span class="n">optimizer_group_parameters</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">()</span> <span class="k">if</span> <span class="ow">not</span> <span class="nb">any</span><span class="p">(</span><span class="n">nd</span> <span class="ow">in</span> <span class="n">n</span> <span class="k">for</span> <span class="n">nd</span> <span class="ow">in</span> <span class="n">no_decay</span><span class="p">)],</span>
     <span class="s1">&#39;weight_decay&#39;</span> <span class="p">:</span> <span class="mf">0.01</span><span class="p">},</span>
    <span class="p">{</span><span class="s1">&#39;params&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">()</span> <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="n">nd</span> <span class="ow">in</span> <span class="n">n</span> <span class="k">for</span> <span class="n">nd</span> <span class="ow">in</span> <span class="n">no_decay</span><span class="p">)],</span>
     <span class="s1">&#39;weight_decay&#39;</span> <span class="p">:</span> <span class="mf">0.0</span><span class="p">}</span>
<span class="p">]</span>

<span class="n">optimizer</span> <span class="o">=</span> <span class="n">AdamW</span><span class="p">(</span><span class="n">optimizer_group_parameters</span><span class="p">,</span> <span class="n">lr</span> <span class="o">=</span> <span class="n">learning_rate</span><span class="p">)</span>
<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

<span class="c1"># warnup 값을 설정해줍니다.</span>
<span class="n">t_total</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">)</span> <span class="o">*</span> <span class="n">num_epochs</span>
<span class="n">warmup_step</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">t_total</span> <span class="o">*</span> <span class="n">warmup_ratio</span><span class="p">)</span>

<span class="c1"># warnup 값보다 스텝이 작을경우 러닝레이트를 선형증가, 클경우 러닝레이트 임의에 방법으로 업데이트 합니다.</span>
<span class="n">scheduler</span> <span class="o">=</span> <span class="n">get_cosine_schedule_with_warmup</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">num_warmup_steps</span> <span class="o">=</span> <span class="n">warmup_step</span><span class="p">,</span>
                                            <span class="n">num_training_steps</span> <span class="o">=</span> <span class="n">t_total</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>모델을 정의하고, 자연어 분류문제에 자주 사용되는 AdamW 옵티마이저와 크로스엔트로피 손실함수를 정의합니다.</p>
<p>오버피팅 방지를 위해 가중치를 규제하는 부분도 정의했으며, 러닝레이트 또한 스케줄러를 통해 유동적으로 조정해줍니다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="&#47784;&#45944;-&#54617;&#49845;&#54616;&#44592;">&#47784;&#45944; &#54617;&#49845;&#54616;&#44592;<a class="anchor-link" href="#&#47784;&#45944;-&#54617;&#49845;&#54616;&#44592;"> </a></h1>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">calc_accuracy</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">y</span><span class="p">):</span>
    <span class="n">max_vals</span><span class="p">,</span> <span class="n">max_indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">train_acc</span> <span class="o">=</span> <span class="p">(</span><span class="n">max_indices</span> <span class="o">==</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="o">/</span> <span class="n">max_indices</span><span class="o">.</span><span class="n">size</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">train_acc</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>모델 성능 확인을 위해 정확도를 계산해주는 함수를 만들었습니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">enum</span>
<span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
    <span class="n">train_acc</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">valid_acc</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">batch_id</span><span class="p">,</span> <span class="p">(</span><span class="n">token_ids</span><span class="p">,</span> <span class="n">valid_length</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">),</span> <span class="n">total</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_dataloader</span><span class="p">)):</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span> <span class="c1"># 옵티마이저 파라미터 배치단위로 초기화</span>
        <span class="n">token_ids</span> <span class="o">=</span> <span class="n">token_ids</span><span class="o">.</span><span class="n">long</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span> 
        <span class="n">segment_ids</span> <span class="o">=</span> <span class="n">segment_ids</span><span class="o">.</span><span class="n">long</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">valid_length</span> <span class="o">=</span> <span class="n">valid_length</span>
        <span class="n">label</span> <span class="o">=</span> <span class="n">label</span><span class="o">.</span><span class="n">long</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">token_ids</span><span class="p">,</span> <span class="n">valid_length</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

        <span class="c1"># Gradient Vanishing 또는 Exploding 방지</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">max_grad_norm</span><span class="p">)</span>

        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span> <span class="c1"># 러닝 레이트 업데이트</span>
        <span class="n">train_acc</span> <span class="o">+=</span> <span class="n">calc_accuracy</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;epoch </span><span class="si">{}</span><span class="s2"> train acc </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">e</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">train_acc</span> <span class="o">/</span> <span class="p">(</span><span class="n">batch_id</span><span class="o">+</span><span class="mi">1</span><span class="p">)))</span>
    
    <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">batch_id</span><span class="p">,</span> <span class="p">(</span><span class="n">token_ids</span><span class="p">,</span> <span class="n">valid_length</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">valid_dataloader</span><span class="p">),</span> <span class="n">total</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">valid_dataloader</span><span class="p">)):</span>
        <span class="n">token_ids</span> <span class="o">=</span> <span class="n">token_ids</span><span class="o">.</span><span class="n">long</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">segment_ids</span> <span class="o">=</span> <span class="n">segment_ids</span><span class="o">.</span><span class="n">long</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">valid_length</span> <span class="o">=</span> <span class="n">valid_length</span>
        <span class="n">label</span> <span class="o">=</span> <span class="n">label</span><span class="o">.</span><span class="n">long</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">token_ids</span><span class="p">,</span> <span class="n">valid_length</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">)</span>
        <span class="n">valid_acc</span> <span class="o">+=</span> <span class="n">calc_accuracy</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">label</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;epoch </span><span class="si">{}</span><span class="s2"> valid acc </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">e</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span> <span class="n">valid_acc</span> <span class="o">/</span> <span class="p">(</span><span class="n">batch_id</span><span class="o">+</span><span class="mi">1</span><span class="p">)))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|██████████| 313/313 [07:05&lt;00:00,  1.36s/it]
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>epoch 1 train acc 0.7162040734824281
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|██████████| 79/79 [00:39&lt;00:00,  2.01it/s]
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>epoch 1 valid acc 0.7140690928270043
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|██████████| 313/313 [07:06&lt;00:00,  1.36s/it]
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>epoch 2 train acc 0.8008186900958466
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|██████████| 79/79 [00:39&lt;00:00,  2.01it/s]
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>epoch 2 valid acc 0.7144646624472574
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|██████████| 313/313 [07:06&lt;00:00,  1.36s/it]
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>epoch 3 train acc 0.8582268370607029
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|██████████| 79/79 [00:38&lt;00:00,  2.05it/s]
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>epoch 3 valid acc 0.7225738396624473
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|██████████| 313/313 [06:59&lt;00:00,  1.34s/it]
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>epoch 4 train acc 0.8917731629392971
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|██████████| 79/79 [00:38&lt;00:00,  2.04it/s]
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>epoch 4 valid acc 0.7298918776371308
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|██████████| 313/313 [07:01&lt;00:00,  1.35s/it]
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>epoch 5 train acc 0.9011581469648562
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|██████████| 79/79 [00:38&lt;00:00,  2.04it/s]</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>epoch 5 valid acc 0.7172336497890296
</pre>
</div>
</div>

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>데이터 로더에서 배치단위로 값을 꺼내서 모델에 적용하고, 가중치를 업데이트 시켜줬습니다.</p>
<p>한 에포크가 끝날때마다 정확도를 지속적으로 확인하는 모습입니다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="&#47784;&#45944;-&#51060;&#50857;&#54616;&#44592;">&#47784;&#45944; &#51060;&#50857;&#54616;&#44592;<a class="anchor-link" href="#&#47784;&#45944;-&#51060;&#50857;&#54616;&#44592;"> </a></h1>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">result</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">batch_id</span><span class="p">,</span> <span class="p">(</span><span class="n">token_ids</span><span class="p">,</span> <span class="n">valid_length</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">)</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">enumerate</span><span class="p">(</span><span class="n">test_dataloader</span><span class="p">),</span> <span class="n">total</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">test_dataloader</span><span class="p">)):</span>
        <span class="n">token_ids</span> <span class="o">=</span> <span class="n">token_ids</span><span class="o">.</span><span class="n">long</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">segment_ids</span> <span class="o">=</span> <span class="n">segment_ids</span><span class="o">.</span><span class="n">long</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
        <span class="n">valid_length</span> <span class="o">=</span> <span class="n">valid_length</span>
        <span class="n">result</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">token_ids</span><span class="p">,</span> <span class="n">valid_length</span><span class="p">,</span> <span class="n">segment_ids</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>100%|██████████| 27/27 [00:12&lt;00:00,  2.11it/s]
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>모델을 평가모드로 변환하고 테스트 데이터를 모델에 넣어 3개 라벨의 예측 확률을 출력한 것을 result 안에 넣습니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">result_</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">result</span><span class="p">:</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">i</span><span class="p">:</span>
        <span class="n">result_</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">j</span><span class="p">)))</span>

<span class="n">out</span> <span class="o">=</span> <span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="n">label_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">())[</span><span class="n">_</span><span class="p">]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">result_</span><span class="p">]</span>

<span class="n">sample_submission</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">out</span>

<span class="n">sample_submission</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s1">&#39;sentence_4.csv&#39;</span><span class="p">,</span><span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>우리가 최종적으로 필요한 것은 라벨 이름입니다. 지금 result에 있는 값은 3개 라벨의 각각의 확률값이죠.</p>
<p>argmax 함수를 사용해 가장 확률이 높은 값을 추출하고, 앞서 정의한 딕셔너리를 이용해 라벨로 변환하여 파일로 저장합니다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="&#45712;&#45184;&#51216;">&#45712;&#45184;&#51216;<a class="anchor-link" href="#&#45712;&#45184;&#51216;"> </a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>파이토치 사용법을 익히기 위해 이해하기 쉽고 좋은 코드들을 직접 하나하나 따라치는 중입니다.</p>
<p>이번 코드는 딥러닝에 한 분야인 자연어 처리쪽으로, 제가 가장 관심있는 분야인데요. 이전 코드보단 확실히 난이도가 있는 것 같습니다.</p>
<p>가중치에 오버피팅, 폭주, 소실을 막기 위해 더 다양한 기술들을 사용하는데 시간이 날때 보다 자세히 관찰하려합니다.</p>
<p>GPU에 성능 체감을 처음 하는데 이것때문에 현질을 한 사람의 마음이 바로 이해가 되네요.</p>
<p>max_grad_norm 값을 실수로 -1로 했을 뿐인데 모델 성능이 극악으로 안좋아졌습니다. 이것때문에 고생 많이 했는데, 긍정적으로 보면 max_grad_norm 값이 매우 중요하다는 걸 피부로 느꼈네요.</p>
<p>다음엔 이미지 분류 문제를 공부할 것 같습니다.</p>

</div>
</div>
</div>
</div>



  </div><script src="https://utteranc.es/client.js"
        repo="KSY1526/myblog"
        issue-term="pathname"
        theme="github-dark"
        crossorigin="anonymous"
        async>
</script>
  <a class="u-url" href="/myblog/jupyter/deep%20learning/pytorch/dacon/natural%20language/bert/tokenizer/classifier/2022/02/21/torch3.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/myblog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/myblog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/myblog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>다양한 머신러닝/딥러닝 코드들이 기록되어 있습니다.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/https%3A%2F%2Fgithub.com%2FKSY1526" target="_blank" title="https://github.com/KSY1526"><svg class="svg-icon grey"><use xlink:href="/myblog/assets/minima-social-icons.svg#github"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
