<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>[처음 시작하는 딥러닝] 2. 밑바닥부터 만들어보는 딥러닝 | 나의 빅데이터 공부 기록</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="[처음 시작하는 딥러닝] 2. 밑바닥부터 만들어보는 딥러닝" />
<meta name="author" content="Seong Yeon Kim" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="다양한 머신러닝/딥러닝 코드들이 기록되어 있습니다." />
<meta property="og:description" content="다양한 머신러닝/딥러닝 코드들이 기록되어 있습니다." />
<link rel="canonical" href="https://ksy1526.github.io/myblog/book/jupyter/deep%20learning/matrix/math/class/2021/12/29/FirstDeep2.html" />
<meta property="og:url" content="https://ksy1526.github.io/myblog/book/jupyter/deep%20learning/matrix/math/class/2021/12/29/FirstDeep2.html" />
<meta property="og:site_name" content="나의 빅데이터 공부 기록" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-12-29T00:00:00-06:00" />
<script type="application/ld+json">
{"datePublished":"2021-12-29T00:00:00-06:00","url":"https://ksy1526.github.io/myblog/book/jupyter/deep%20learning/matrix/math/class/2021/12/29/FirstDeep2.html","@type":"BlogPosting","headline":"[처음 시작하는 딥러닝] 2. 밑바닥부터 만들어보는 딥러닝","dateModified":"2021-12-29T00:00:00-06:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://ksy1526.github.io/myblog/book/jupyter/deep%20learning/matrix/math/class/2021/12/29/FirstDeep2.html"},"author":{"@type":"Person","name":"Seong Yeon Kim"},"description":"다양한 머신러닝/딥러닝 코드들이 기록되어 있습니다.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/myblog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://ksy1526.github.io/myblog/feed.xml" title="나의 빅데이터 공부 기록" /><link rel="shortcut icon" type="image/x-icon" href="/myblog/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/myblog/">나의 빅데이터 공부 기록</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/myblog/about/">About Me</a><a class="page-link" href="/myblog/search/">Search</a><a class="page-link" href="/myblog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">[처음 시작하는 딥러닝] 2. 밑바닥부터 만들어보는 딥러닝</h1><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-12-29T00:00:00-06:00" itemprop="datePublished">
        Dec 29, 2021
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Seong Yeon Kim</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      9 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/myblog/categories/#book">book</a>
        &nbsp;
      
        <a class="category-tags-link" href="/myblog/categories/#jupyter">jupyter</a>
        &nbsp;
      
        <a class="category-tags-link" href="/myblog/categories/#Deep Learning">Deep Learning</a>
        &nbsp;
      
        <a class="category-tags-link" href="/myblog/categories/#matrix">matrix</a>
        &nbsp;
      
        <a class="category-tags-link" href="/myblog/categories/#math">math</a>
        &nbsp;
      
        <a class="category-tags-link" href="/myblog/categories/#class">class</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          
          
          
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2021-12-29-FirstDeep2.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="https://colab.research.google.com/github/KSY1526/myblog/blob/master/_notebooks/2021-12-29-FirstDeep2.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="&#49888;&#44221;&#47581;&#51032;-&#44396;&#49457;&#50836;&#49548;:-&#50672;&#49328;">&#49888;&#44221;&#47581;&#51032; &#44396;&#49457;&#50836;&#49548;: &#50672;&#49328;<a class="anchor-link" href="#&#49888;&#44221;&#47581;&#51032;-&#44396;&#49457;&#50836;&#49548;:-&#50672;&#49328;"> </a></h1>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">assert_same_shape</span><span class="p">(</span><span class="n">array</span><span class="p">,</span> <span class="n">array_grad</span><span class="p">):</span>
    <span class="k">assert</span> <span class="n">array</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">array_grad</span><span class="o">.</span><span class="n">shape</span>
    <span class="k">return</span> <span class="kc">None</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">Operation</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_</span><span class="p">):</span> <span class="c1"># input_은 ndarray</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_</span> <span class="o">=</span> <span class="n">input_</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_output</span><span class="p">()</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">output</span>

    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_grad</span><span class="p">):</span> <span class="c1"># output_grad은 ndarray</span>
        <span class="n">assert_same_shape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="p">,</span> <span class="n">output_grad</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">input_grad</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_grad</span><span class="p">(</span><span class="n">output_grad</span><span class="p">)</span>

        <span class="n">assert_same_shape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_grad</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_grad</span>

    <span class="c1"># 서브 클래스에서 오버라이딩 하기 위해 있는 부분</span>
    <span class="c1"># 이 클래스에서는 추상 메소드만 선언함</span>
    <span class="k">def</span> <span class="nf">_output</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_input_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_grad</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>상속을 해주기 위한 간단한 연산 클래스를 만들었습니다.</p>
<p>forward 부분은 input_을 받고 아웃풋을 내는 함수를 호출합니다.</p>
<p>backward 부분은 output_grad를 받고 _input_grad 함수를 호출합니다.</p>
<p>여기서 assert_same_shape은 입력값이 정상인지 확인하는 역할을 합니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">ParamOperation</span><span class="p">(</span><span class="n">Operation</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">param</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span> <span class="c1"># 상속 받은 클레스의 생성자를 실행해줘야함</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">param</span> <span class="o">=</span> <span class="n">param</span> <span class="c1"># 파라미터도 입력받음.</span>

    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_grad</span><span class="p">):</span>
        
        <span class="n">assert_same_shape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="p">,</span> <span class="n">output_grad</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_grad</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_grad</span><span class="p">(</span><span class="n">output_grad</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">param_grad</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_param_grad</span><span class="p">(</span><span class="n">output_grad</span><span class="p">)</span>
        
        <span class="n">assert_same_shape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_grad</span><span class="p">)</span>
        <span class="n">assert_same_shape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">param</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">param_grad</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_grad</span>

    <span class="k">def</span> <span class="nf">_param_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_grad</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>파라미터가 있는 연산를 정의하기 위해 제일 기본적인 연산 클래스를 상속받아 만들었습니다.</p>
<p>backward 함수는 _input_grad, _param_grad(출력물에 대한 입력값/파라미터 기울기) 함수를 호출해 값을 구합니다.</p>
<p>이전 backward와 달라진점은 _param_grad 부분이 추가했다는 것입니다.</p>
<p>이 클래스를 상속하는 클래스는 _output, _input_grad, _pram_grad 함수를 정의해야합니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># 신경망의 가중치 행렬 곱 연산, 순방향/역방향 모두 제공.</span>
<span class="k">class</span> <span class="nc">WeightMultiply</span><span class="p">(</span><span class="n">ParamOperation</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">W</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">W</span><span class="p">)</span>

    <span class="c1"># Operation 클래스 내 forward 함수에서 내부 호출 당하는 함수, 순방향 출력</span>
    <span class="k">def</span> <span class="nf">_output</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>        
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">param</span><span class="p">)</span> <span class="c1"># forward 함수 내 self.input_은 정해줌.</span>

    <span class="c1"># Operation 클래스 내 backward 함수에서 내부 호출 당하는 함수, 역방향 출력</span>
    <span class="c1"># 입력의 대한 기울기, 파라미터에 대한 기울기를 두 함수로 만듬.</span>
    <span class="k">def</span> <span class="nf">_input_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_grad</span><span class="p">):</span> <span class="c1"># 입력에 대한 기울기 출력.</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">output_grad</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">param</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">)))</span>

    <span class="k">def</span> <span class="nf">_param_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_grad</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_</span><span class="p">,</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">)),</span> <span class="n">output_grad</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>ParamOperation를 상속해 신경망의 가중치 행렬 곱 연산을 하는 WeightMultiply를 만들었습니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">BiasAdd</span><span class="p">(</span><span class="n">ParamOperation</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">B</span><span class="p">):</span>
        <span class="k">assert</span> <span class="n">B</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span>
        <span class="c1"># 상속받은 클래스(ParamOperation)의 생성자(param) 값에 B를 넣어줌.</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">B</span><span class="p">)</span>

    <span class="c1"># forward 호출하는 내부함수.</span>
    <span class="k">def</span> <span class="nf">_output</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">param</span>

    <span class="c1"># backward에서 호출하는 내부함수(output_grad 이미 입력받음), 입력에 대한 기울기</span>
    <span class="k">def</span> <span class="nf">_input_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_grad</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_</span><span class="p">)</span> <span class="o">*</span> <span class="n">output_grad</span>

    <span class="c1"># 파라미터에 대한 기울기</span>
    <span class="k">def</span> <span class="nf">_param_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_grad</span><span class="p">):</span>
        <span class="n">param_grad</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">param</span><span class="p">)</span> <span class="o">*</span> <span class="n">output_grad</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">param_grad</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">param_grad</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>편향을 더하는 연산도 마찬가지로 ParamOperation를 상속하여 만들었습니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">Sigmoid</span><span class="p">(</span><span class="n">Operation</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_output</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="mf">1.0</span><span class="o">/</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mf">1.0</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_</span><span class="p">))</span>

    <span class="c1"># 입력에 대한 기울기 계산</span>
    <span class="k">def</span> <span class="nf">_input_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_grad</span><span class="p">):</span>
        <span class="n">sigmoid_backward</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output</span> <span class="o">*</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="p">)</span>
        <span class="n">input_grad</span> <span class="o">=</span> <span class="n">sigmoid_backward</span> <span class="o">*</span> <span class="n">output_grad</span>
        <span class="k">return</span> <span class="n">input_grad</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>시그모이드 연산은 파라미터가 없기 때문에 Operation 클래스를 상속했습니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">Linear</span><span class="p">(</span><span class="n">Operation</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>     
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_output</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_</span>

    <span class="k">def</span> <span class="nf">_input_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_grad</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">output_grad</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>입력을 받은 대로 출력해주는 Linear 클래스 입니다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="&#49888;&#44221;&#47581;&#51032;-&#44396;&#49457;&#50836;&#49548;:-&#52789;">&#49888;&#44221;&#47581;&#51032; &#44396;&#49457;&#50836;&#49548;: &#52789;<a class="anchor-link" href="#&#49888;&#44221;&#47581;&#51032;-&#44396;&#49457;&#50836;&#49548;:-&#52789;"> </a></h1>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">Layer</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="c1"># 뉴런의 개수는 층의 너비에 해당</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">neurons</span><span class="p">):</span> <span class="c1"># neurons : 층의 너비</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">neurons</span> <span class="o">=</span> <span class="n">neurons</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">first</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">param_grads</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">operations</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># 층을 구현하는 메서드</span>
    <span class="k">def</span> <span class="nf">_setup_layer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_in</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>

    <span class="c1"># 입력값을 연산에 순서대로 통과시켜 순방향 계산을 함.</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">first</span><span class="p">:</span> <span class="c1"># 처음 층을 만드는 것이면, _setup_layer 함수 실행.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_setup_layer</span><span class="p">(</span><span class="n">input_</span><span class="p">)</span> 
            <span class="bp">self</span><span class="o">.</span><span class="n">first</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">input_</span> <span class="o">=</span> <span class="n">input_</span>
        
        <span class="k">for</span> <span class="n">operation</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">operations</span><span class="p">:</span> <span class="c1"># 여러개의 operations 들의 합</span>
            <span class="n">input_</span> <span class="o">=</span> <span class="n">operation</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">input_</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="n">input_</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">output</span>

    <span class="c1"># output_grad를 각 연산에 역순으로 통과시켜 역방향 계산을 함</span>
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">output_grad</span><span class="p">):</span>
        <span class="n">assert_same_shape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output</span><span class="p">,</span> <span class="n">output_grad</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">operation</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">operations</span><span class="p">):</span>
            <span class="n">output_grad</span> <span class="o">=</span> <span class="n">operation</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">output_grad</span><span class="p">)</span>

        <span class="n">input_grad</span> <span class="o">=</span> <span class="n">output_grad</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_param_grads</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">input_grad</span>

    <span class="c1"># 각 operation 객체에서 _param_grad 값을 꺼냄</span>
    <span class="k">def</span> <span class="nf">_param_grads</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">param_grads</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">operation</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">operations</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">issubclass</span><span class="p">(</span><span class="n">operation</span><span class="o">.</span><span class="vm">__class__</span><span class="p">,</span> <span class="n">ParamOperation</span><span class="p">):</span> <span class="c1"># 서브클래스에 속하는가?</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">param_grads</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">operation</span><span class="o">.</span><span class="n">param_grad</span><span class="p">)</span>

    <span class="c1"># 각 operationn 객체에서 _params 값을 꺼냄</span>
    <span class="k">def</span> <span class="nf">_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="k">for</span> <span class="n">operation</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">operations</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">issubclass</span><span class="p">(</span><span class="n">operation</span><span class="o">.</span><span class="vm">__class__</span><span class="p">,</span> <span class="n">ParamOperation</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">operation</span><span class="o">.</span><span class="n">param</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>층을 정의합니다. 이때 Operation 객체의 리스트를 operations 속성에 담고 있습니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">Dence</span><span class="p">(</span><span class="n">Layer</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">neurons</span><span class="p">,</span> <span class="n">activation</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">neurons</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">activation</span>

    <span class="c1"># 밀집층의 연산 정의</span>
    <span class="k">def</span> <span class="nf">_setup_layer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">:</span>
            <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># 가중치</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">input_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">neurons</span><span class="p">))</span>

        <span class="c1">#편향</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">neurons</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">operations</span> <span class="o">=</span> <span class="p">[</span><span class="n">WeightMultiply</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="c1"># 신경망의 가중치 행렬곱 연산</span>
                           <span class="n">BiasAdd</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">]</span>

        <span class="k">return</span> <span class="kc">None</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>layer 클래스에 _setup_layer 함수를 추가로 구현하기 위해 Dence(밀집층) 클래스를 생성했습니다.</p>
<p>랜덤 시드를 받아서 파라미터 초기값에 랜덤값을 넣어줍니다.</p>
<p>여기서 operatings을 정의하는데 층을 하나 만들기 위해서 여러 연산 클래스를 사용합니다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="&#49888;&#44221;&#47581;&#51032;-&#44396;&#49457;&#50836;&#49548;:-&#49552;&#49892;&#54632;&#49688;">&#49888;&#44221;&#47581;&#51032; &#44396;&#49457;&#50836;&#49548;: &#49552;&#49892;&#54632;&#49688;<a class="anchor-link" href="#&#49888;&#44221;&#47581;&#51032;-&#44396;&#49457;&#50836;&#49548;:-&#49552;&#49892;&#54632;&#49688;"> </a></h1>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">Loss</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="c1"># 실제 손실값을 계산하는 함수</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prediction</span><span class="p">,</span> <span class="n">target</span><span class="p">):</span>
        <span class="n">assert_same_shape</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">prediction</span> <span class="o">=</span> <span class="n">prediction</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="n">target</span>

        <span class="n">loss_value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_output</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">loss_value</span>
    
    <span class="c1"># 손실함수의 입력값에 대해 손실의 기울기를 계산.</span>
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_grad</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_grad</span><span class="p">()</span>

        <span class="n">assert_same_shape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prediction</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_grad</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_grad</span>

    <span class="k">def</span> <span class="nf">_output</span><span class="p">(</span><span class="n">slef</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_input_grad</span><span class="p">(</span><span class="n">slef</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>손실함수를 구성하는 Loss 클래스 입니다. 타겟값과 예측값을 가지고 _output 함수를 돌려 loss를 구합니다.</p>
<p>backward 함수는 입력 값에 따른 손실의 기울기를 계산해줍니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">MeanSquaredError</span><span class="p">(</span><span class="n">Loss</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
    
    <span class="c1"># 평균 제곱오차 손실함수</span>
    <span class="k">def</span> <span class="nf">_output</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prediction</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">prediction</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">loss</span>

    <span class="c1"># 예측값에 대한 평균제곱오차 손실의 기울기를 계산</span>
    <span class="k">def</span> <span class="nf">_input_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="mf">2.0</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prediction</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">prediction</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Loss 클래스를 상속받아 MeanSquaredError 클래스를 만들었는데요. _output, _input_grad 두 함수의 수식을 구체적으로 구현했습니다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="&#46373;&#47084;&#45789;&#51032;-&#44396;&#49457;&#50836;&#49548;:-&#45684;&#47088;">&#46373;&#47084;&#45789;&#51032; &#44396;&#49457;&#50836;&#49548;: &#45684;&#47088;<a class="anchor-link" href="#&#46373;&#47084;&#45789;&#51032;-&#44396;&#49457;&#50836;&#49548;:-&#45684;&#47088;"> </a></h1>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">NeuralNetwork</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layers</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">seed</span> <span class="o">=</span> <span class="mi">1</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">layers</span> <span class="c1"># 신경망의 층 정의, layers 클래스를 받음.(리스트로 받을수도)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span> <span class="c1"># loss 클래스를 받음.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span>
        <span class="k">if</span> <span class="n">seed</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
                <span class="nb">setattr</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="s1">&#39;seed&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span> <span class="c1"># layer.seed = self.seed와 동일</span>
    
    <span class="c1"># 데이터를 각 층에 순서대로 통과시킴</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_batch</span><span class="p">):</span> <span class="c1"># x_batch는 ndarray.</span>
        <span class="n">x_out</span> <span class="o">=</span> <span class="n">x_batch</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="n">x_out</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x_out</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x_out</span>

    <span class="c1"># 데이터를 각 층에 역순으로 통과시킴</span>
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loss_grad</span><span class="p">):</span>
        <span class="n">grad</span> <span class="o">=</span> <span class="n">loss_grad</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">):</span>
            <span class="n">grad</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">grad</span><span class="p">)</span>
        <span class="k">return</span> <span class="kc">None</span>

    <span class="k">def</span> <span class="nf">train_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_batch</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">):</span>
        <span class="c1"># 순방향 계산 수행.</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x_batch</span><span class="p">)</span>
        <span class="c1"># 손실값 계산</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">)</span>
        <span class="c1"># 역방향 계산 수행</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">loss</span>

    <span class="c1"># 신경망의 파라미터 값을 받음</span>
    <span class="k">def</span> <span class="nf">params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="k">yield from</span> <span class="n">layer</span><span class="o">.</span><span class="n">params</span> <span class="c1"># 리스트에 있는 요소를 한개씩 밖으로 전달.</span>

    <span class="c1"># 신경망의 각 파라미터에 대한 손실값의 기울기를 받음.</span>
    <span class="k">def</span> <span class="nf">param_grads</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="k">yield from</span> <span class="n">layer</span><span class="o">.</span><span class="n">param_grads</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">neural_network</span> <span class="o">=</span> <span class="n">NeuralNetwork</span><span class="p">(</span>
    <span class="n">layers</span> <span class="o">=</span> <span class="p">[</span><span class="n">Dence</span><span class="p">(</span><span class="n">neurons</span> <span class="o">=</span> <span class="mi">13</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="n">Sigmoid</span><span class="p">()),</span>
              <span class="n">Dence</span><span class="p">(</span><span class="n">neurons</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">activation</span> <span class="o">=</span> <span class="n">Linear</span><span class="p">())],</span>
    <span class="n">loss</span> <span class="o">=</span> <span class="n">MeanSquaredError</span><span class="p">(),</span>
    <span class="c1">#learning_rata = 0.01</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>딥러닝 구현을 위해 NeuralNetwork 클래스를 구현했습니다. 앞서 구현한 층, 손실함수를 이용했습니다.</p>
<p>우선 layers로 층 클래스를 리스트로 받습니다. 층 클래스는 또 뉴런 개수와 활성화함수인 연산 클래스를 입력해야합니다.</p>
<p>또 loss에는 손실함수 클래스를 넣어주면 됩니다.</p>
<p>forward 부분에서는 입력된 x값을 여러 층에 차레대로 넣습니다. 층에서는 또 차레대로 연산을 해서 prediction을 출력합니다.</p>
<p>그 후 loss 클래스를 이용해서 손실값을 계산합니다. 다음으로 손실의 기울기를 backward 함수에 넣습니다.</p>
<p>backward 함수에서는 손실의 기울기를 여러 층에 앞선 차레와 반대 순서로 넣습니다.</p>
<p>이렇게 나온 backward 함수의 최종 값은 input의 기울기 입니다. 이 값을 통해 loss를 줄여가는게 학습에 방향이겠죠.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="&#46373;&#47084;&#45789;&#51032;-&#44396;&#49457;&#50836;&#49548;:-&#50741;&#54000;&#47560;&#51060;&#51200;">&#46373;&#47084;&#45789;&#51032; &#44396;&#49457;&#50836;&#49548;: &#50741;&#54000;&#47560;&#51060;&#51200;<a class="anchor-link" href="#&#46373;&#47084;&#45789;&#51032;-&#44396;&#49457;&#50836;&#49548;:-&#50741;&#54000;&#47560;&#51060;&#51200;"> </a></h1>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">Optimizer</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lr</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">=</span> <span class="n">lr</span>

    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>옵티마이저의 간단한 추상클래스입니다. lr은 학습률을 의미합니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">SGD</span><span class="p">(</span><span class="n">Optimizer</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lr</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">lr</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">param</span><span class="p">,</span> <span class="n">param_grad</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">params</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">param_grads</span><span class="p">()):</span>
            <span class="c1"># 뉴런에 있는 파라미터들을 꺼내오는 함수를 씀.</span>
            <span class="n">param</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">*</span> <span class="n">param_grad</span>
            <span class="c1"># 이게 과연 층이나 연산 클래스 내 param까지 영향을 끼칠까??</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>옵티마이저에서 step 부분을 SGD(확률적 경사 하강법)을 이용해서 구성한 모습입니다.</p>
<p>구체적으로 학습률 * (loss값에 영향을 주는 param_grad값)으로 param 값을 업데이트 해나가는 방식입니다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="&#46373;&#47084;&#45789;&#51032;-&#44396;&#49457;&#50836;&#49548;:-Trainer">&#46373;&#47084;&#45789;&#51032; &#44396;&#49457;&#50836;&#49548;: Trainer<a class="anchor-link" href="#&#46373;&#47084;&#45789;&#51032;-&#44396;&#49457;&#50836;&#49548;:-Trainer"> </a></h1>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">permute_data</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">perm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="c1"># 크기만큼 데이터를 셔플해줌</span>
    <span class="k">return</span> <span class="n">X</span><span class="p">[</span><span class="n">perm</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">perm</span><span class="p">]</span>

<span class="k">class</span> <span class="nc">Trainer</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">net</span><span class="p">,</span> <span class="n">optim</span><span class="p">):</span> <span class="c1"># net은 NeuralNetwork, optim은 Optimizer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">net</span> <span class="o">=</span> <span class="n">net</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optim</span> <span class="o">=</span> <span class="n">optim</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optim</span><span class="p">,</span> <span class="s1">&#39;net&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">generate_batches</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">size</span> <span class="o">=</span> <span class="mi">32</span><span class="p">):</span> <span class="c1"># 배치 사이즈로 데이터를 쪼개는 함수.</span>
        <span class="k">assert</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">N</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">ii</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">N</span><span class="p">,</span> <span class="n">size</span><span class="p">):</span>
            <span class="n">X_batch</span><span class="p">,</span> <span class="n">y_batch</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">ii</span><span class="p">:</span><span class="n">ii</span><span class="o">+</span><span class="n">size</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">ii</span><span class="p">:</span><span class="n">ii</span><span class="o">+</span><span class="n">size</span><span class="p">]</span> <span class="c1"># 배치만큼 잘라서</span>
            <span class="k">yield</span> <span class="n">X_batch</span><span class="p">,</span> <span class="n">y_batch</span> <span class="c1"># 지속적으로 내보냄</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
            <span class="n">eval_every</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span> <span class="n">seed</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">restart</span> <span class="o">=</span> <span class="kc">True</span><span class="p">):</span>
        <span class="c1"># eval_every 주기로 테스트 데이터를 사용해 예측성능 추정</span>

        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">restart</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span> <span class="c1"># 뉴런 내 모든 층은</span>
                <span class="n">layer</span><span class="o">.</span><span class="n">first</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1"># 층을 초기화하라.</span>
        
        <span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
            <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="n">permute_data</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span> <span class="c1"># 데이터 셔플</span>

            <span class="c1"># 데이터가 배치 크기만큼 쪼개짐.</span>
            <span class="n">batch_generator</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">generate_batches</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">ii</span><span class="p">,</span> <span class="p">(</span><span class="n">X_batch</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">batch_generator</span><span class="p">):</span>
                <span class="c1"># enumerate는 인덱스를 함께 출력해줌.</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">train_batch</span><span class="p">(</span><span class="n">X_batch</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">)</span> <span class="c1"># 학습.</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">step</span><span class="p">()</span> <span class="c1"># 학습 후 나온 파라미터를 업데이트 해줌.</span>

            <span class="k">if</span> <span class="p">(</span><span class="n">e</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">eval_every</span> <span class="o">==</span><span class="mi">0</span><span class="p">:</span>
                <span class="n">test_preds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">net</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">test_preds</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
                
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">e</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s1">에폭에서 검증 데이터에 대한 손실값: </span><span class="si">{</span><span class="n">loss</span><span class="si">:</span><span class="s1">.3f</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>뉴런과 옵티마이저 클래스를 사용하는 트레이너 클래스입니다.</p>
<p>fit 함수로 데이터를 입력받아 데이터를 배치 단위로 쪼갠뒤 배치 데이터를 적용시켜 loss와 파라미터 기울기를 구합니다.</p>
<p>그 후 옵티마이저 내 step 함수를 사용해 파라미터를 파라미터 기울기를 사용해서 업데이트 해줍니다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="&#50696;&#51228;-&#51088;&#47308;-&#50629;&#47196;&#46300;">&#50696;&#51228; &#51088;&#47308; &#50629;&#47196;&#46300;<a class="anchor-link" href="#&#50696;&#51228;-&#51088;&#47308;-&#50629;&#47196;&#46300;"> </a></h1>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_boston</span>

<span class="n">boston</span> <span class="o">=</span> <span class="n">load_boston</span><span class="p">()</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">boston</span><span class="o">.</span><span class="n">data</span>
<span class="n">target</span> <span class="o">=</span> <span class="n">boston</span><span class="o">.</span><span class="n">target</span>
<span class="n">features</span> <span class="o">=</span> <span class="n">boston</span><span class="o">.</span><span class="n">feature_names</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.

    The Boston housing prices dataset has an ethical problem. You can refer to
    the documentation of this function for further details.

    The scikit-learn maintainers therefore strongly discourage the use of this
    dataset unless the purpose of the code is to study and educate about
    ethical issues in data science and machine learning.

    In this special case, you can fetch the dataset from the original
    source::

        import pandas as pd
        import numpy as np


        data_url = &#34;http://lib.stat.cmu.edu/datasets/boston&#34;
        raw_df = pd.read_csv(data_url, sep=&#34;\s+&#34;, skiprows=22, header=None)
        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])
        target = raw_df.values[1::2, 2]

    Alternative datasets include the California housing dataset (i.e.
    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing
    dataset. You can load the datasets as follows::

        from sklearn.datasets import fetch_california_housing
        housing = fetch_california_housing()

    for the California housing dataset and::

        from sklearn.datasets import fetch_openml
        housing = fetch_openml(name=&#34;house_prices&#34;, as_frame=True)

    for the Ames housing dataset.
    
  warnings.warn(msg, category=FutureWarning)
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="n">s</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">def</span> <span class="nf">to_2d_np</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="nb">type</span> <span class="o">=</span> <span class="s1">&#39;col&#39;</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    1차원 텐서를 2차원으로 변환</span>
<span class="sd">    &#39;&#39;&#39;</span>

    <span class="k">assert</span> <span class="n">a</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> \
    <span class="s2">&quot;입력된 텐서는 1차원이어야 함&quot;</span>
    
    <span class="k">if</span> <span class="nb">type</span> <span class="o">==</span> <span class="s2">&quot;col&quot;</span><span class="p">:</span>        
        <span class="k">return</span> <span class="n">a</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">type</span> <span class="o">==</span> <span class="s2">&quot;row&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">a</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">80718</span><span class="p">)</span>

<span class="c1"># 목푯값을 2차원 배열로 변환</span>
<span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">to_2d_np</span><span class="p">(</span><span class="n">y_train</span><span class="p">),</span> <span class="n">to_2d_np</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="&#50696;&#49884;">&#50696;&#49884;<a class="anchor-link" href="#&#50696;&#49884;"> </a></h1>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">(</span><span class="n">lr</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">neural_network</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">)</span>

<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">=</span> <span class="mi">50</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>10에폭에서 검증 데이터에 대한 손실값: 32.121
20에폭에서 검증 데이터에 대한 손실값: 26.972
30에폭에서 검증 데이터에 대한 손실값: 20.426
40에폭에서 검증 데이터에 대한 손실값: 18.131
50에폭에서 검증 데이터에 대한 손실값: 16.930
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="&#45712;&#45184;&#51216;">&#45712;&#45184;&#51216;<a class="anchor-link" href="#&#45712;&#45184;&#51216;"> </a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>딥러닝 관련해서 저번에 신경망을 간단하게 구현을 했었습니다.</p>
<p>오늘은 은닉층이 더 복잡해지기 때문에 일반화에 용이한 클래스로 딥러닝을 구현했습니다.</p>
<p>자바로 객체지향프로그래밍을 조금 안 상태에서 학습을 해도 파이썬 문법하고 다른 측면이 있어서 학습이 다소 힘들긴 했습니다.</p>
<p>처음 연산/층 클래스를 구현할 때는 이게 무슨 코드인지 이해가 안되고 재미도 없었는데 뉴런 부분을 구현할 때 전반적으로 책에서 정리를 해줘서 그 때 전반적인 감을 잡았던 것 같아요.</p>
<p>코드도 일부 누락되어 있어 깃허브 찾아보면서 매꾸는 등 어려운 과정이 참 많았지만 하길 잘 한것 같습니다.</p>
<p>딥러닝이란 무엇인가 정말 피부로 체감을 할 수 있었습니다. 그만큼 하나하나 천천히 이해하는데 시간이 오래걸리긴 했지만요.</p>
<p>맨날 나오는 신경망, 뉴런, 옵티마이저, 트레이너 등등 단어의 의미를 이전보다 훨씬 직관적으로 이해를 잘 할 수 있었던 시간인것 같습니다.</p>
<p>과정이 다소 복잡하기 때문에 주기적으로 복습을 하며 더 딥러닝과 가까워질 생각입니다.</p>

</div>
</div>
</div>
</div>



  </div><script src="https://utteranc.es/client.js"
        repo="KSY1526/myblog"
        issue-term="pathname"
        theme="github-dark"
        crossorigin="anonymous"
        async>
</script>
  <a class="u-url" href="/myblog/book/jupyter/deep%20learning/matrix/math/class/2021/12/29/FirstDeep2.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/myblog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/myblog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/myblog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>다양한 머신러닝/딥러닝 코드들이 기록되어 있습니다.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/KSY1526" target="_blank" title="KSY1526"><svg class="svg-icon grey"><use xlink:href="/myblog/assets/minima-social-icons.svg#github"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
