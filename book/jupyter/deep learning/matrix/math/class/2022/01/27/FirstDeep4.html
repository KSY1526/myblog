<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>[처음 시작하는 딥러닝] 4. 밑바닥부터 만들어보는 RNN | 나의 빅데이터 공부 기록</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="[처음 시작하는 딥러닝] 4. 밑바닥부터 만들어보는 RNN" />
<meta name="author" content="Seong Yeon Kim" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="다양한 머신러닝/딥러닝 코드들이 기록되어 있습니다." />
<meta property="og:description" content="다양한 머신러닝/딥러닝 코드들이 기록되어 있습니다." />
<link rel="canonical" href="https://ksy1526.github.io/myblog/book/jupyter/deep%20learning/matrix/math/class/2022/01/27/FirstDeep4.html" />
<meta property="og:url" content="https://ksy1526.github.io/myblog/book/jupyter/deep%20learning/matrix/math/class/2022/01/27/FirstDeep4.html" />
<meta property="og:site_name" content="나의 빅데이터 공부 기록" />
<meta property="og:image" content="https://ksy1526.github.io/myblog/images/220127.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-01-27T00:00:00-06:00" />
<script type="application/ld+json">
{"datePublished":"2022-01-27T00:00:00-06:00","url":"https://ksy1526.github.io/myblog/book/jupyter/deep%20learning/matrix/math/class/2022/01/27/FirstDeep4.html","@type":"BlogPosting","image":"https://ksy1526.github.io/myblog/images/220127.png","headline":"[처음 시작하는 딥러닝] 4. 밑바닥부터 만들어보는 RNN","dateModified":"2022-01-27T00:00:00-06:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://ksy1526.github.io/myblog/book/jupyter/deep%20learning/matrix/math/class/2022/01/27/FirstDeep4.html"},"author":{"@type":"Person","name":"Seong Yeon Kim"},"description":"다양한 머신러닝/딥러닝 코드들이 기록되어 있습니다.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/myblog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://ksy1526.github.io/myblog/feed.xml" title="나의 빅데이터 공부 기록" /><link rel="shortcut icon" type="image/x-icon" href="/myblog/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/myblog/">나의 빅데이터 공부 기록</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/myblog/about/">About Me</a><a class="page-link" href="/myblog/search/">Search</a><a class="page-link" href="/myblog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">[처음 시작하는 딥러닝] 4. 밑바닥부터 만들어보는 RNN</h1><p class="post-meta post-meta-title"><time class="dt-published" datetime="2022-01-27T00:00:00-06:00" itemprop="datePublished">
        Jan 27, 2022
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Seong Yeon Kim</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      13 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/myblog/categories/#book">book</a>
        &nbsp;
      
        <a class="category-tags-link" href="/myblog/categories/#jupyter">jupyter</a>
        &nbsp;
      
        <a class="category-tags-link" href="/myblog/categories/#Deep Learning">Deep Learning</a>
        &nbsp;
      
        <a class="category-tags-link" href="/myblog/categories/#matrix">matrix</a>
        &nbsp;
      
        <a class="category-tags-link" href="/myblog/categories/#math">math</a>
        &nbsp;
      
        <a class="category-tags-link" href="/myblog/categories/#class">class</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          
          
          
        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2022-01-27-FirstDeep4.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><a href="https://colab.research.google.com/github/KSY1526/myblog/blob/master/_notebooks/2022-01-27-FirstDeep4.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab" /></a></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="&#51088;&#46041;&#48120;&#48516;">&#51088;&#46041;&#48120;&#48516;<a class="anchor-link" href="#&#51088;&#46041;&#48120;&#48516;"> </a></h1>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>

<span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;__add__ 함수 사용:&#39;</span><span class="p">,</span> <span class="n">a</span><span class="o">.</span><span class="fm">__add__</span><span class="p">(</span><span class="mi">4</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;+ 연산자 사용:&#39;</span><span class="p">,</span> <span class="n">a</span> <span class="o">+</span> <span class="mi">4</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[2 3 1 0]
__add__ 함수 사용: [6 7 5 4]
+ 연산자 사용: [6 7 5 4]
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>파이썬에서는 + 연산자를 사용할 때 내부에서  <em> </em> add<em> </em>  함수가 호출되는 방식입니다.</p>
<p>다른 연산자도 마찬가지로 연결된 함수를 불러오는 방식으로 실행됩니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Union</span><span class="p">,</span> <span class="n">List</span>

<span class="n">Numberable</span> <span class="o">=</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">int</span><span class="p">]</span> 
<span class="c1"># 정수, 소수 둘다 함께하는 자료형 생성, 파이토치에서는 tensor가 비슷한 역할을 함.</span>

<span class="k">def</span> <span class="nf">ensure_number</span><span class="p">(</span><span class="n">num</span><span class="p">:</span> <span class="n">Numberable</span><span class="p">):</span> <span class="c1"># -&gt; NumberWithGrad, 자료형으로 출력해줌.</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">num</span><span class="p">,</span> <span class="n">NumberWithGrad</span><span class="p">):</span> <span class="c1"># 자료형 확인함수</span>
        <span class="k">return</span> <span class="n">num</span>
    
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">NumberWithGrad</span><span class="p">(</span><span class="n">num</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">NumberWithGrad</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num</span><span class="p">:</span> <span class="n">Numberable</span><span class="p">,</span>
                 <span class="n">depends_on</span> <span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Numberable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
                 <span class="n">creation_op</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num</span> <span class="o">=</span> <span class="n">num</span> <span class="c1"># 원래 값(숫자) 자체를 저장.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">depends_on</span> <span class="o">=</span> <span class="n">depends_on</span> <span class="ow">or</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">creation_op</span> <span class="o">=</span> <span class="n">creation_op</span>

    <span class="k">def</span> <span class="fm">__add__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="n">Numberable</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span> <span class="c1"># NumberWithGrad 출력</span>
        <span class="k">return</span> <span class="n">NumberWithGrad</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num</span> <span class="o">+</span> <span class="n">ensure_number</span><span class="p">(</span><span class="n">other</span><span class="p">)</span><span class="o">.</span><span class="n">num</span><span class="p">,</span>
                              <span class="c1"># 입력된 값 NumberWithGrad 자료형으로 변환 후 더하기.</span>
                              <span class="n">depends_on</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="p">,</span> <span class="n">ensure_number</span><span class="p">(</span><span class="n">other</span><span class="p">)],</span>
                              <span class="c1"># 3 + 4이면 [3, 4]로 저장(NumberWithGrad 자료형으로)</span>
                              <span class="n">creation_op</span> <span class="o">=</span> <span class="s1">&#39;add&#39;</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="fm">__mul__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">other</span><span class="p">:</span> <span class="n">Numberable</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span> <span class="c1"># NumberWithGrad 출력</span>
        <span class="k">return</span> <span class="n">NumberWithGrad</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num</span> <span class="o">*</span> <span class="n">ensure_number</span><span class="p">(</span><span class="n">other</span><span class="p">)</span><span class="o">.</span><span class="n">num</span><span class="p">,</span>
                              <span class="n">depends_on</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="p">,</span> <span class="n">ensure_number</span><span class="p">(</span><span class="n">other</span><span class="p">)],</span>
                              <span class="n">creation_op</span> <span class="o">=</span> <span class="s1">&#39;mul&#39;</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">backward_grad</span><span class="p">:</span> <span class="n">Numberable</span> <span class="o">=</span> <span class="kc">None</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">backward_grad</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="c1"># 이 함수가 처음 호출될때</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="mi">1</span>

        <span class="c1"># 이부분에서 기울기가 누적.</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">grad</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span> <span class="c1"># 기울기 정보가 아직 없다면</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">grad</span> <span class="o">=</span> <span class="n">backward_grad</span> <span class="c1"># backward_grad로 설정</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">grad</span> <span class="o">+=</span> <span class="n">backward_grad</span> <span class="c1"># 있다면 기존 기울기에 backward_grad를 더함.</span>


        <span class="c1"># self.grad를 역방향으로 전달.</span>
        <span class="c1"># 둘 중 어느 요소를 증가시켜도 출력이 같은 값만큼 증가함.</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">creation_op</span> <span class="o">==</span> <span class="s1">&#39;add&#39;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">depends_on</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">depends_on</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>


        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">creation_op</span> <span class="o">==</span> <span class="s1">&#39;mul&#39;</span><span class="p">:</span>
            <span class="c1"># 첫번째 요소에 대한 미분 계산</span>
            <span class="n">new</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">depends_on</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">grad</span>
            <span class="c1"># 미분을 역방향으로 전달</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">depends_on</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">new</span><span class="o">.</span><span class="n">num</span><span class="p">)</span>

            <span class="c1"># 두번째 요소에 대한 미분 계산</span>
            <span class="n">new</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">depends_on</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">grad</span>
            <span class="c1">#미분을 역방향으로 전달.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">depends_on</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">new</span><span class="o">.</span><span class="n">num</span><span class="p">)</span>

<span class="n">a</span> <span class="o">=</span> <span class="n">NumberWithGrad</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>

<span class="n">b</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="mi">4</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">b</span> <span class="o">+</span> <span class="mi">5</span>

<span class="n">c</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>4
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>자동 미분을 간단하게 구현한 함수입니다. 저도 이해하는데 꽤 걸렸는데 단기간에 이해하기 쉽진 않습니다.</p>
<p>우선 Numberable 자료형을 생성합니다. int, float 자료형을 통합했다고 보면 될 것 같아요. 또 ensure_number 함수는 입력되는 모든 값을 뒤에 나오는 NumberWithGrad 자료형으로 변환해준다고 생각하면 됩니다.</p>
<p>NumberWithGrad 클레스도 간단하게 하나의 자료형으로 이해하시는게 좋습니다. a = NumberWithGrad(3)은 3이라는 값을 NumberWithGrad 자료형으로 선언했다고 생각하면 됩니다.</p>
<p>이후 a * 4 코드가 진행되면 파이썬에서는 a. <strong> mul </strong>(4) 함수를 써서 곱하기를 진행하는데, NumberWithGrad 자료형 내부에 <strong> mul </strong> 함수가 오버라이딩 되어있습니다.</p>
<p>오버라이딩 된 NumberWithGrad 내부 함수는 값 부분에 정상적인 곱하기 연산을 수행하고, depends_on 부분에 연산에 사용된 숫자를 NumberWithGrad 자료형으로 기록, creation_op 부분에 곱하기 연산이 수행됬다는 것을 기록합니다.</p>
<p>즉 b = a * 4 연산을 통해 b는 NumberWithGrad 자료형으로 바뀌고 연산에 사용된 숫자와 연산기호가 NumberWithGrad 자료형 내부에 저장됩니다.</p>
<p>c = b + 5 부분에서 c도 마찬가지로 NumberWithGrad 자료형으로 저장되며 b와 5가 depends_on 부분에 저장되는데 b 같은 경우 이전 NumberWithGrad 자료형 그대로 저장되는 것을 주목합시다.</p>
<p>그리고 c.backward() 함수를 실행하면 backward_grad 입력값에 아무것도 안 넣었기 때문에 첫번째 if문에 걸립니다. c의 grad 값은 1로 선언됩니다.</p>
<p>그 뒤 c를 만들기 위해 사용했던 연산기호가 + 이기 때문에 세번째 if문에 걸리게 되고 c를 만들어준 두 연산자가 기록되어 있는 depends_on을 이용해 다시 backward 함수를 실행시킵니다.</p>
<p>backward 함수를 실행시킬때 함수 입력값에 c.grad을 넣고 함수를 실행합니다. 상세히 말하면 c.depends_on[0] = b이기 때문에 b.backward(c.grad)를 실행합니다.</p>
<p>함수 입력값에 c.grad가 있기 때문에 두번째 if문에 걸리게 되고 b.grad 값에 1을 넣게 됩니다. 그 후 아까 c에서 벌어졌던 연산을 다시 반복합니다.</p>
<p>이후 내용을 한번 더 상세하게 설명하면 b를 만들기 위해 사용했던 연산기호가 * 이므로 네번째 if문에 걸리게 되고 여기서는 b.grad에 서로 반대되는 값을 곱해준 것을 backward 함수에 전달합니다.</p>
<p>과정이 조금 복잡해서 저도 되집어본다고 생각하고 클레스 구조를 간단히 서술했는데 관심있는 분들은 스스로 코드를 해석해보시면서 제 설명을 참고하시면 보다 쉽게 익힐 수 있을거 같아요. 이해 안되는 부분은 댓글달아주시면 아는 선에서 설명드리겠습니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">a</span> <span class="o">=</span> <span class="n">NumberWithGrad</span><span class="p">(</span><span class="mi">3</span><span class="p">)</span>

<span class="n">b</span> <span class="o">=</span> <span class="n">a</span> <span class="o">*</span> <span class="mi">4</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">b</span> <span class="o">+</span> <span class="mi">3</span>
<span class="n">d</span> <span class="o">=</span> <span class="p">(</span><span class="n">a</span> <span class="o">+</span> <span class="mi">2</span><span class="p">)</span> <span class="c1"># a 다시 사용.</span>
<span class="n">e</span> <span class="o">=</span> <span class="n">c</span> <span class="o">*</span> <span class="n">d</span>
<span class="n">e</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="n">a</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>35
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>아까보다 한단계 복잡한 자동미분 예시입니다. 실제 도함수를 통해 계산한 결과와 일치하는 것을 볼 수 있어요.</p>
<p>예제는 d = (4<em>a + 3) </em> (a + 2) 입니다.</p>
<p>자동 미분이 필요한 이유가 순방향 계산 과정의 중간 결과를 재사용 할 수 있습니다. 윗 예제도 a를 두번 써도 정상적으로 실행됩니다.</p>
<p>이전에 했던 합성함수 미분법을 활용했을때는 윗 예제와 같은 식을 설명할 수 없기 때문에 자동 미분 방법이 중요합니다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="&#54596;&#50836;&#54620;-&#46972;&#51060;&#48652;&#47084;&#47532;-&#51076;&#54252;&#53944;,-&#54876;&#49457;&#54868;-&#54632;&#49688;-&#49440;&#50616;">&#54596;&#50836;&#54620; &#46972;&#51060;&#48652;&#47084;&#47532; &#51076;&#54252;&#53944;, &#54876;&#49457;&#54868; &#54632;&#49688; &#49440;&#50616;<a class="anchor-link" href="#&#54596;&#50836;&#54620;-&#46972;&#51060;&#48652;&#47084;&#47532;-&#51076;&#54252;&#53944;,-&#54876;&#49457;&#54868;-&#54632;&#49688;-&#49440;&#50616;"> </a></h1>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">ndarray</span>

<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Tuple</span>

<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">IPython</span> <span class="kn">import</span> <span class="n">display</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;seaborn-white&#39;</span><span class="p">)</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>

<span class="kn">from</span> <span class="nn">copy</span> <span class="kn">import</span> <span class="n">deepcopy</span>
<span class="kn">from</span> <span class="nn">collections</span> <span class="kn">import</span> <span class="n">deque</span>

<span class="kn">from</span> <span class="nn">scipy.special</span> <span class="kn">import</span> <span class="n">logsumexp</span>



<span class="k">def</span> <span class="nf">assert_same_shape</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="n">output_grad</span><span class="p">):</span>
    <span class="k">assert</span> <span class="n">output</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="n">output_grad</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> \
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    두 ndarray의 모양이 같아야 하는데,</span>
<span class="sd">    첫 번째 ndarray의 모양은 {0}이고</span>
<span class="sd">    두 번째 ndarray의 모양은 {1}이다.</span>
<span class="sd">    &#39;&#39;&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">output_grad</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
    <span class="k">return</span> <span class="kc">None</span>

<span class="k">def</span> <span class="nf">assert_dim</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">dim</span><span class="p">):</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">==</span> <span class="n">dim</span><span class="p">,</span> \
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    이 텐서는 {0}차원이어야 하는데, {1}차원이다.</span>
<span class="sd">    &#39;&#39;&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">t</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
    <span class="k">return</span> <span class="kc">None</span>


    

<span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">ndarray</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">dsigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">ndarray</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">tanh</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">ndarray</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">dtanh</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">ndarray</span><span class="p">):</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">logsumexp</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">batch_softmax</span><span class="p">(</span><span class="n">input_array</span><span class="p">:</span> <span class="n">ndarray</span><span class="p">):</span>
    <span class="n">out</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">input_array</span><span class="p">:</span>
        <span class="n">out</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">softmax</span><span class="p">(</span><span class="n">row</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>필요한 라이브러리와 활성화 함수를 선언했습니다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="&#50741;&#54000;&#47560;&#51060;&#51200;,-&#49552;&#49892;&#54632;&#49688;">&#50741;&#54000;&#47560;&#51060;&#51200;, &#49552;&#49892;&#54632;&#49688;<a class="anchor-link" href="#&#50741;&#54000;&#47560;&#51060;&#51200;,-&#49552;&#49892;&#54632;&#49688;"> </a></h1>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">RNNOptimizer</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lr</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">,</span>
                 <span class="n">gradient_clipping</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lr</span> <span class="o">=</span> <span class="n">lr</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">gradient_clipping</span> <span class="o">=</span> <span class="n">gradient_clipping</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">first</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>

        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">layer</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>

                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">gradient_clipping</span><span class="p">:</span>
                    <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="s1">&#39;deriv&#39;</span><span class="p">],</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="s1">&#39;deriv&#39;</span><span class="p">])</span>

                <span class="bp">self</span><span class="o">.</span><span class="n">_update_rule</span><span class="p">(</span><span class="n">param</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="s1">&#39;value&#39;</span><span class="p">],</span>
                                  <span class="n">grad</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="s1">&#39;deriv&#39;</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">_update_rule</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>RNNOptimizer 클레스를 통해 RNN에서 사용할 수 있는 옵티마이저의 기본 골격을 만들었습니다.</p>
<p>코드 내 상세 내용은 저도 정확히 모르겠습니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">SGD</span><span class="p">(</span><span class="n">RNNOptimizer</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">lr</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">,</span>
                 <span class="n">gradient_clipping</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">lr</span><span class="p">,</span> <span class="n">gradient_clipping</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_update_rule</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>

        <span class="n">update</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lr</span><span class="o">*</span><span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;grad&#39;</span><span class="p">]</span>
        <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;param&#39;</span><span class="p">]</span> <span class="o">-=</span> <span class="n">update</span>


<span class="k">class</span> <span class="nc">AdaGrad</span><span class="p">(</span><span class="n">RNNOptimizer</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                 <span class="n">lr</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.01</span><span class="p">,</span>
                <span class="n">gradient_clipping</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">lr</span><span class="p">,</span> <span class="n">gradient_clipping</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="o">=</span> <span class="mf">1e-7</span>

    <span class="k">def</span> <span class="nf">step</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">first</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sum_squares</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">sum_squares</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
                <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">layer</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">sum_squares</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="s1">&#39;value&#39;</span><span class="p">])</span>
            
            <span class="bp">self</span><span class="o">.</span><span class="n">first</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">layers</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">layer</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
                
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">gradient_clipping</span><span class="p">:</span>
                    <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="s1">&#39;deriv&#39;</span><span class="p">],</span> <span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">layer</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="s1">&#39;deriv&#39;</span><span class="p">])</span>
                
                <span class="bp">self</span><span class="o">.</span><span class="n">_update_rule</span><span class="p">(</span><span class="n">param</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="s1">&#39;value&#39;</span><span class="p">],</span>
                                  <span class="n">grad</span><span class="o">=</span><span class="n">layer</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="s1">&#39;deriv&#39;</span><span class="p">],</span>
                                  <span class="n">sum_square</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sum_squares</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">key</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">_update_rule</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>

            <span class="c1"># 이전 기울기의 제곱의 합을 계산</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;sum_square&#39;</span><span class="p">]</span> <span class="o">+=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="o">+</span>
                                     <span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;grad&#39;</span><span class="p">],</span> <span class="mi">2</span><span class="p">))</span>

            <span class="c1"># 이전 5개 기울기의 제곱의 합으로 학습률을 수정</span>
            <span class="n">lr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lr</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;sum_square&#39;</span><span class="p">]))</span>

            <span class="c1"># 수정된 학습률을 적용</span>
            <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;param&#39;</span><span class="p">]</span> <span class="o">-=</span> <span class="n">lr</span> <span class="o">*</span> <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;grad&#39;</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>앞서 만든 RNNOptimizer를 상속받아 SGD와 AdaGrad 옵티마이저 클레스를 만들었습니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">Loss</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span>
                <span class="n">prediction</span><span class="p">:</span> <span class="n">ndarray</span><span class="p">,</span>
                <span class="n">target</span><span class="p">:</span> <span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>

        <span class="n">assert_same_shape</span><span class="p">(</span><span class="n">prediction</span><span class="p">,</span> <span class="n">target</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">prediction</span> <span class="o">=</span> <span class="n">prediction</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">target</span> <span class="o">=</span> <span class="n">target</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_output</span><span class="p">()</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">output</span>
    
    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ndarray</span><span class="p">:</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">input_grad</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_input_grad</span><span class="p">()</span>

        <span class="n">assert_same_shape</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">prediction</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_grad</span><span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_grad</span>

    <span class="k">def</span> <span class="nf">_output</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">_input_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ndarray</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>

        
<span class="k">class</span> <span class="nc">SoftmaxCrossEntropy</span><span class="p">(</span><span class="n">Loss</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">eps</span><span class="p">:</span> <span class="nb">float</span><span class="o">=</span><span class="mf">1e-9</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="o">=</span> <span class="n">eps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">single_class</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">_output</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>

        <span class="n">out</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">prediction</span><span class="p">:</span>
            <span class="n">out</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">softmax</span><span class="p">(</span><span class="n">row</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">softmax_preds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">out</span><span class="p">)</span>

        <span class="c1"># 안정적인 계산을 위해 소프트맥스의 출력을 제한</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">softmax_preds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">softmax_preds</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">,</span> <span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="p">)</span>

        <span class="c1"># 손실을 실제로 계산</span>
        <span class="n">softmax_cross_entropy_loss</span> <span class="o">=</span> <span class="o">-</span><span class="mf">1.0</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">target</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">softmax_preds</span><span class="p">)</span> <span class="o">-</span> \
            <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">target</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax_preds</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">softmax_cross_entropy_loss</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_input_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">softmax_preds</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">target</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>이 부분도 가벼운 마음으로 정리했습니다. 주가 아닌 부분이기 때문에 자세한 설명은 생략할께요.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="&#49692;&#54872;-&#49888;&#44221;&#47581;-&#44396;&#54788;">&#49692;&#54872; &#49888;&#44221;&#47581; &#44396;&#54788;<a class="anchor-link" href="#&#49692;&#54872;-&#49888;&#44221;&#47581;-&#44396;&#54788;"> </a></h1>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">RNNLayer</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">,</span> <span class="n">weight_scale</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span> <span class="c1"># 은닉 뉴런수</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span> <span class="o">=</span> <span class="n">output_size</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">weight_scale</span> <span class="o">=</span> <span class="n">weight_scale</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">start_H</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">))</span> <span class="c1"># 이 층에 내부상태 저장</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">first</span> <span class="o">=</span> <span class="kc">True</span> <span class="c1"># 처음임을 선언</span>


    <span class="k">def</span> <span class="nf">_init_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_</span><span class="p">:</span> <span class="n">ndarray</span><span class="p">):</span> <span class="c1"># input_ = x_seq_in</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">input_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="c1"># 사용되는 글자의 가짓수</span>
        
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_scale</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">weight_scale</span> <span class="o">=</span> <span class="mi">2</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span><span class="p">)</span>
        
        <span class="c1"># 밑에 나오는 것은 파라미터를 저장하기 위한 형식입니다.</span>
        <span class="c1"># 키 value부분은 실제 파라미터, 키 deriv는 그에대한 기울깃값입니다.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;W_f&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;B_f&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;W_v&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;B_v&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{}</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;W_f&#39;</span><span class="p">][</span><span class="s1">&#39;value&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
                                                      <span class="n">scale</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">weight_scale</span><span class="p">,</span>
                                                      <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;B_f&#39;</span><span class="p">][</span><span class="s1">&#39;value&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
                                                      <span class="n">scale</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">weight_scale</span><span class="p">,</span>
                                                      <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;W_v&#39;</span><span class="p">][</span><span class="s1">&#39;value&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                                                      <span class="n">scale</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">weight_scale</span><span class="p">,</span>
                                                      <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;B_v&#39;</span><span class="p">][</span><span class="s1">&#39;value&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span>
                                                      <span class="n">scale</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">weight_scale</span><span class="p">,</span>
                                                      <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span><span class="p">))</span>    
        
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;W_f&#39;</span><span class="p">][</span><span class="s1">&#39;deriv&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;W_f&#39;</span><span class="p">][</span><span class="s1">&#39;value&#39;</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;B_f&#39;</span><span class="p">][</span><span class="s1">&#39;deriv&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;B_f&#39;</span><span class="p">][</span><span class="s1">&#39;value&#39;</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;W_v&#39;</span><span class="p">][</span><span class="s1">&#39;deriv&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;W_v&#39;</span><span class="p">][</span><span class="s1">&#39;value&#39;</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;B_v&#39;</span><span class="p">][</span><span class="s1">&#39;deriv&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="s1">&#39;B_v&#39;</span><span class="p">][</span><span class="s1">&#39;value&#39;</span><span class="p">])</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">cells</span> <span class="o">=</span> <span class="p">[</span><span class="n">RNNNode</span><span class="p">()</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">input_</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span> <span class="c1"># input_shape[1] : 시간순서</span>
        <span class="c1"># 시간 순서만큼 RNN 노드를 리스트형태로 만들어 cells에 저장.</span>

    
    <span class="k">def</span> <span class="nf">_clear_gradients</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="s1">&#39;deriv&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">[</span><span class="n">key</span><span class="p">][</span><span class="s1">&#39;deriv&#39;</span><span class="p">])</span>

    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_seq_in</span><span class="p">:</span> <span class="n">ndarray</span><span class="p">):</span> <span class="c1"># 입력값은 배치, 순서(시간), 변수 크기</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">first</span><span class="p">:</span> <span class="c1"># 처음이면</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_init_params</span><span class="p">(</span><span class="n">x_seq_in</span><span class="p">)</span> <span class="c1"># 윗 함수 실행할 것.</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">first</span> <span class="o">=</span> <span class="kc">False</span> <span class="c1"># 처음 아닌 상태 표시</span>

        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">x_seq_in</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="c1"># 배치 크기 입력</span>

        <span class="n">H_in</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">start_H</span><span class="p">)</span> <span class="c1"># 은닉층 내부 상태 저장. (1, 은닉층)</span>
        <span class="n">H_in</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">H_in</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span> <span class="c1"># 은닉층 배치크기만큼 확대. (배치크기, 은닉층)</span>

        <span class="n">sequence_length</span> <span class="o">=</span> <span class="n">x_seq_in</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="c1"># 순서형 자료 개수 입력</span>

        <span class="n">x_seq_out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span><span class="p">))</span>

        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">sequence_length</span><span class="p">):</span> <span class="c1"># 순서형 자료 개수만큼</span>
            <span class="n">x_in</span> <span class="o">=</span> <span class="n">x_seq_in</span><span class="p">[:,</span> <span class="n">t</span><span class="p">,</span> <span class="p">:]</span> <span class="c1"># 특정 시점에 입력값들.</span>

            <span class="c1"># RNN 노드 내 forward함수 실행. H_in 값이 지속적으로 업데이트 됩니다.</span>
            <span class="n">y_out</span><span class="p">,</span> <span class="n">H_in</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cells</span><span class="p">[</span><span class="n">t</span><span class="p">]</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x_in</span><span class="p">,</span> <span class="n">H_in</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
            <span class="n">x_seq_out</span><span class="p">[:,</span> <span class="n">t</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">y_out</span> <span class="c1"># 출력층에 값을 넣어줍니다.</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">start_H</span> <span class="o">=</span> <span class="n">H_in</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">keepdims</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> 
        <span class="c1"># 마지막 은닉층 값을 기억합니다.</span>

        <span class="k">return</span> <span class="n">x_seq_out</span>


    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_seq_out_grad</span><span class="p">:</span> <span class="n">ndarray</span><span class="p">):</span>
        
        <span class="n">batch_size</span> <span class="o">=</span> <span class="n">x_seq_out_grad</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

        <span class="n">h_in_grad</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span><span class="p">))</span>

        <span class="n">sequence_length</span> <span class="o">=</span> <span class="n">x_seq_out_grad</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        
        <span class="n">x_seq_in_grad</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">))</span>


        <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">sequence_length</span><span class="p">)):</span>
            <span class="n">x_out_grad</span> <span class="o">=</span> <span class="n">x_seq_out_grad</span><span class="p">[:,</span> <span class="n">t</span><span class="p">,</span> <span class="p">:]</span>

            <span class="n">grad_out</span><span class="p">,</span> <span class="n">h_in_grad</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cells</span><span class="p">[</span><span class="n">t</span><span class="p">]</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">x_out_grad</span><span class="p">,</span> <span class="n">h_in_grad</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>

            <span class="n">x_seq_in_grad</span><span class="p">[:,</span> <span class="n">t</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">grad_out</span>

        <span class="k">return</span> <span class="n">x_seq_in_grad</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>RNN 층을 직접 구현했습니다. 내용이 상당히 방대해 이해하기 쉽진 않습니다.</p>
<p>쉽게 정리하면 입력되는 형태는 (배치크기, 순서, 특성 크기) 인 3차원 입니다.</p>
<p>그 후 층 내부에서는 처음에 배치단위별로 한 순서씩 모든 특성크기가 입력 됩니다.</p>
<p>층 내부 구조는 입력층, 히든층, 출력층으로 되어있으며 입력층은 입력된 특성크기 + 히든층 크기 로 구성되어있습니다.</p>
<p>히든층은 사용자가 정의하며, 출력층은 원하는 결과물에 따라 개수를 정해주면 됩니다.</p>
<p>이때 히든층은 지속적으로 업데이트되어 출력됩니다. 더 자세한 설명은 RNN 노드 부분에서 하겠습니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">RNNNode</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_in</span><span class="p">:</span> <span class="n">ndarray</span><span class="p">,</span> <span class="n">H_in</span><span class="p">:</span> <span class="n">ndarray</span><span class="p">,</span>
                <span class="n">params_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ndarray</span><span class="p">]])</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">ndarray</span><span class="p">]:</span>
                <span class="c1"># params_dic 예시로 [B_f][value, ndarray] 로 생각하면 됩니다.</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">X_in</span> <span class="o">=</span> <span class="n">x_in</span> <span class="c1"># (배치크기, 변수 크기)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">H_in</span> <span class="o">=</span> <span class="n">H_in</span> <span class="c1"># (배치크기, 은닉층 크기)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">Z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">((</span><span class="n">x_in</span><span class="p">,</span> <span class="n">H_in</span><span class="p">))</span>
        <span class="c1"># column_stack 함수는 두 넘파이 배열을 입력받아 열을 기준(여기선 배치마다)으로 병합합니다.</span>
        <span class="c1"># 즉 Z는 (배치크기, 변수 + 은닉층 크기) 입니다. </span>
        <span class="c1"># 이 말은 입력값은 입력된 변수 + 이전 은닉층 값이라는 거죠. 이 부분이 핵심입니다.</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">H_int</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Z</span><span class="p">,</span> <span class="n">params_dict</span><span class="p">[</span><span class="s1">&#39;W_f&#39;</span><span class="p">][</span><span class="s1">&#39;value&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">params_dict</span><span class="p">[</span><span class="s1">&#39;B_f&#39;</span><span class="p">][</span><span class="s1">&#39;value&#39;</span><span class="p">])</span>
        <span class="c1"># W_f는 (은닉층 + 변수, 은닉층), B_f는 (1, 은닉층), 두 개 합 또한 넘파이 재활용 규칙으로 (은닉층 + 변수, 은닉층).</span>
        <span class="c1"># 출력값은 (배치, 은닉층) 이 됩니다.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">H_out</span> <span class="o">=</span> <span class="n">tanh</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">H_int</span><span class="p">)</span> <span class="c1"># 은닉층 값에 활성화 함수를 거칩니다.</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">X_out</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">H_out</span><span class="p">,</span> <span class="n">params_dict</span><span class="p">[</span><span class="s1">&#39;W_v&#39;</span><span class="p">][</span><span class="s1">&#39;value&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">params_dict</span><span class="p">[</span><span class="s1">&#39;B_v&#39;</span><span class="p">][</span><span class="s1">&#39;value&#39;</span><span class="p">])</span>
        <span class="c1"># W_v는 (은닉층, 출력층), B_f는 (1, 출력층) 합은 재활용 규칙으로 (은닉층, 출력층)</span>
        <span class="c1"># 출력값은 (배치, 출력층)이 됩니다.</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_out</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">H_out</span> <span class="c1"># 출력층 값, 은닉층 값 돌려줍니다.</span>


    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_out_grad</span><span class="p">:</span> <span class="n">ndarray</span><span class="p">,</span> <span class="n">H_out_grad</span><span class="p">:</span> <span class="n">ndarray</span><span class="p">,</span>
                 <span class="n">params_dict</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">ndarray</span><span class="p">]])</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">ndarray</span><span class="p">]:</span>

        <span class="n">assert_same_shape</span><span class="p">(</span><span class="n">X_out_grad</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_out</span><span class="p">)</span>
        <span class="n">assert_same_shape</span><span class="p">(</span><span class="n">H_out_grad</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">H_out</span><span class="p">)</span>
        
        <span class="n">params_dict</span><span class="p">[</span><span class="s1">&#39;B_v&#39;</span><span class="p">][</span><span class="s1">&#39;deriv&#39;</span><span class="p">]</span> <span class="o">+=</span> <span class="n">X_out_grad</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">params_dict</span><span class="p">[</span><span class="s1">&#39;W_v&#39;</span><span class="p">][</span><span class="s1">&#39;deriv&#39;</span><span class="p">]</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">H_out</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">X_out_grad</span><span class="p">)</span>

        <span class="n">dh</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X_out_grad</span><span class="p">,</span> <span class="n">params_dict</span><span class="p">[</span><span class="s1">&#39;W_v&#39;</span><span class="p">][</span><span class="s1">&#39;value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        <span class="n">dh</span> <span class="o">+=</span> <span class="n">H_out_grad</span>

        <span class="n">dH_int</span> <span class="o">=</span> <span class="n">dh</span> <span class="o">*</span> <span class="n">dtanh</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">H_int</span><span class="p">)</span>

        <span class="n">params_dict</span><span class="p">[</span><span class="s1">&#39;B_f&#39;</span><span class="p">][</span><span class="s1">&#39;deriv&#39;</span><span class="p">]</span> <span class="o">+=</span> <span class="n">dH_int</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">params_dict</span><span class="p">[</span><span class="s1">&#39;W_f&#39;</span><span class="p">][</span><span class="s1">&#39;deriv&#39;</span><span class="p">]</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">Z</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">dH_int</span><span class="p">)</span>

        <span class="n">dz</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">dH_int</span><span class="p">,</span> <span class="n">params_dict</span><span class="p">[</span><span class="s1">&#39;W_f&#39;</span><span class="p">][</span><span class="s1">&#39;value&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>

        <span class="n">X_in_grad</span> <span class="o">=</span> <span class="n">dz</span><span class="p">[:,</span> <span class="p">:</span><span class="bp">self</span><span class="o">.</span><span class="n">X_in</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span>
        <span class="n">H_in_grad</span> <span class="o">=</span> <span class="n">dz</span><span class="p">[:,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_in</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:]</span>

        <span class="n">assert_same_shape</span><span class="p">(</span><span class="n">X_out_grad</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">X_out</span><span class="p">)</span>
        <span class="n">assert_same_shape</span><span class="p">(</span><span class="n">H_out_grad</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">H_out</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">X_in_grad</span><span class="p">,</span> <span class="n">H_in_grad</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>우선 역전파는 수리적으로 다소 어렵고 모델 구조 이해와 큰 연관이 없기 때문에 순전파 위주로 학습하겠습니다.</p>
<p>여기서 주목할 건 학습할 때 입력값만 쓰는 것이 아니라 이전 은닉층 값도 사용한다는 것입니다.</p>
<p>이전 은닉층 값은 이전 입력값과 연관이 있기 때문에 순서가 있는 데이터에서 상당히 유용합니다.</p>
<p>나머지 부분은 코드 내 주석을 잘 읽어보시고, 이해가 안되시면 댓글 써주시면 아는 선에서 답변 드리겠습니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">RNNModel</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">layers</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">RNNLayer</span><span class="p">],</span> 
                 <span class="n">sequence_length</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">loss</span><span class="p">:</span> <span class="n">Loss</span><span class="p">):</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">layers</span> <span class="o">=</span> <span class="n">layers</span> <span class="c1"># 층을 리스트 단위로 입력</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">vocab_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sequence_length</span> <span class="o">=</span> <span class="n">sequence_length</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span>

        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="c1"># 층마다 sequence_length 값 지정</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="s1">&#39;sequence_length&#39;</span><span class="p">,</span> <span class="n">sequence_length</span><span class="p">)</span>


    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_batch</span><span class="p">:</span> <span class="n">ndarray</span><span class="p">):</span>

        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="c1"># x_batch : (배치, 순서값, 특성값)</span>
            <span class="n">x_batch</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x_batch</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">x_batch</span>

    <span class="k">def</span> <span class="nf">backward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loss_grad</span><span class="p">:</span> <span class="n">ndarray</span><span class="p">):</span>

        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">):</span>
            <span class="n">loss_grad</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss_grad</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">loss_grad</span>

    <span class="k">def</span> <span class="nf">single_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x_batch</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">):</span>

        <span class="c1"># 순방향 계산</span>
        <span class="n">x_batch_out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x_batch</span><span class="p">)</span>
        
        <span class="c1"># 손실 및 손실의 기울기 계산</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">x_batch_out</span><span class="p">,</span> <span class="n">y_batch</span><span class="p">)</span>
        <span class="n">loss_grad</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">layers</span><span class="p">:</span>
            <span class="n">layer</span><span class="o">.</span><span class="n">_clear_gradients</span><span class="p">()</span>

        <span class="c1"># 역방향 계산</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">loss_grad</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>이 클래스는 입력과 목푯값으로 신경망을 실제로 학습해 손실을 계산합니다.</p>
<p>층들을 리스트로 입력받으며 single_step 함수를 사용해 실제 연산을 진행합니다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="&#51088;&#50672;&#50612;-&#44288;&#47144;-&#49892;&#49845;">&#51088;&#50672;&#50612; &#44288;&#47144; &#49892;&#49845;<a class="anchor-link" href="#&#51088;&#50672;&#50612;-&#44288;&#47144;-&#49892;&#49845;"> </a></h1>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="k">class</span> <span class="nc">RNNTrainer</span><span class="p">:</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">text_file</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">RNNModel</span><span class="p">,</span>
                 <span class="n">optim</span><span class="p">:</span> <span class="n">RNNOptimizer</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">32</span><span class="p">):</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="n">text_file</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">chars</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">chars</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">char_to_idx</span> <span class="o">=</span> <span class="p">{</span><span class="n">ch</span><span class="p">:</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">chars</span><span class="p">)}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">idx_to_char</span> <span class="o">=</span> <span class="p">{</span><span class="n">i</span><span class="p">:</span><span class="n">ch</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">ch</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">chars</span><span class="p">)}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sequence_length</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">sequence_length</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optim</span> <span class="o">=</span> <span class="n">optim</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">optim</span><span class="p">,</span> <span class="s1">&#39;model&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_generate_inputs_targets</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">start_pos</span><span class="p">):</span>
        
        <span class="n">inputs_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">sequence_length</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
        <span class="n">targets_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">sequence_length</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
        
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">):</span>
            
            <span class="n">inputs_indices</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">char_to_idx</span><span class="p">[</span><span class="n">ch</span><span class="p">]</span> 
                            <span class="k">for</span> <span class="n">ch</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">start_pos</span> <span class="o">+</span> <span class="n">i</span><span class="p">:</span> <span class="n">start_pos</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">sequence_length</span>  <span class="o">+</span> <span class="n">i</span><span class="p">]])</span>
            <span class="n">targets_indices</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">char_to_idx</span><span class="p">[</span><span class="n">ch</span><span class="p">]</span> 
                         <span class="k">for</span> <span class="n">ch</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">start_pos</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">i</span><span class="p">:</span> <span class="n">start_pos</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">sequence_length</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">i</span><span class="p">]])</span>

        <span class="k">return</span> <span class="n">inputs_indices</span><span class="p">,</span> <span class="n">targets_indices</span>


    <span class="k">def</span> <span class="nf">_generate_one_hot_array</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">:</span> <span class="n">ndarray</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        param indices: 모양이 (batch_size, sequence_length)인 넘파이 배열</span>
<span class="sd">        return batch - 모양이 (batch_size, sequence_length, vocab_size)인 넘파이 배열</span>
<span class="sd">        &#39;&#39;&#39;</span> 
        <span class="n">batch</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">seq</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">:</span>
            
            <span class="n">one_hot_sequence</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">sequence_length</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">))</span>
            
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">sequence_length</span><span class="p">):</span>
                <span class="n">one_hot_sequence</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">seq</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="mf">1.0</span>

            <span class="n">batch</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">one_hot_sequence</span><span class="p">)</span> 

        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>


    <span class="k">def</span> <span class="nf">sample_output</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_char</span><span class="p">,</span> <span class="n">sample_length</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        현재 학습된 모델로 한 글자씩 출력을 생성한다.</span>
<span class="sd">        param input_char: int - 연속열을 시작하는 글자의 인덱스에 해당하는 정수</span>
<span class="sd">        param sample_length: int - 생성할 연속열의 길이</span>
<span class="sd">        return txt: string - 길이가 sample_length이며 모델을 통해 생성한 문자열</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">indices</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="n">sample_model</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">)</span>
        
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">sample_length</span><span class="p">):</span>
            <span class="n">input_char_batch</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">))</span>
            
            <span class="n">input_char_batch</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">input_char</span><span class="p">]</span> <span class="o">=</span> <span class="mf">1.0</span>
            
            <span class="n">x_batch_out</span> <span class="o">=</span> <span class="n">sample_model</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">input_char_batch</span><span class="p">)</span>
            
            <span class="n">x_softmax</span> <span class="o">=</span> <span class="n">batch_softmax</span><span class="p">(</span><span class="n">x_batch_out</span><span class="p">)</span>
            
            <span class="n">input_char</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">),</span> <span class="n">p</span><span class="o">=</span><span class="n">x_softmax</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>
            
            <span class="n">indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">input_char</span><span class="p">)</span>
            
        <span class="n">txt</span> <span class="o">=</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">idx_to_char</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="k">for</span> <span class="n">idx</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">txt</span>

    <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_iterations</span><span class="p">,</span> <span class="n">sample_every</span> <span class="o">=</span> <span class="mi">100</span><span class="p">):</span>
        <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">        &quot;글자 생성기&quot;를 학습</span>
<span class="sd">        각 반복마다 신경망에 크기가 1인 배치가 입력된다</span>
<span class="sd">        num_iterations회 반복한다. 매 반복마다 현재 학습된 모델로 생성한 텍스트가 출력된다.</span>
<span class="sd">        &#39;&#39;&#39;</span>
        <span class="n">plot_iter</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">0</span><span class="p">))</span>
        <span class="n">plot_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">0</span><span class="p">))</span>
        
        <span class="n">num_iter</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">start_pos</span> <span class="o">=</span> <span class="mi">0</span>
        
        <span class="n">moving_average</span> <span class="o">=</span> <span class="n">deque</span><span class="p">(</span><span class="n">maxlen</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
        <span class="k">while</span> <span class="n">num_iter</span> <span class="o">&lt;</span> <span class="n">num_iterations</span><span class="p">:</span>
            
            <span class="k">if</span> <span class="n">start_pos</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">sequence_length</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">&gt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">):</span>
                <span class="n">start_pos</span> <span class="o">=</span> <span class="mi">0</span>
            
            <span class="c1">## 모델 수정</span>
            <span class="n">inputs_indices</span><span class="p">,</span> <span class="n">targets_indices</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_inputs_targets</span><span class="p">(</span><span class="n">start_pos</span><span class="p">)</span>

            <span class="n">inputs_batch</span><span class="p">,</span> <span class="n">targets_batch</span> <span class="o">=</span> \
                <span class="bp">self</span><span class="o">.</span><span class="n">_generate_one_hot_array</span><span class="p">(</span><span class="n">inputs_indices</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_one_hot_array</span><span class="p">(</span><span class="n">targets_indices</span><span class="p">)</span>
            
            <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">single_step</span><span class="p">(</span><span class="n">inputs_batch</span><span class="p">,</span> <span class="n">targets_batch</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
            
            <span class="n">moving_average</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">loss</span><span class="p">)</span>
            <span class="n">ma_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">moving_average</span><span class="p">)</span>
            
            <span class="n">start_pos</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span>
            
            <span class="n">plot_iter</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">plot_iter</span><span class="p">,</span> <span class="p">[</span><span class="n">num_iter</span><span class="p">])</span>
            <span class="n">plot_loss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">plot_loss</span><span class="p">,</span> <span class="p">[</span><span class="n">ma_loss</span><span class="p">])</span>
            
            <span class="k">if</span> <span class="n">num_iter</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">plot_iter</span><span class="p">,</span> <span class="n">plot_loss</span><span class="p">)</span>
                <span class="n">display</span><span class="o">.</span><span class="n">clear_output</span><span class="p">(</span><span class="n">wait</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
                <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
                
                <span class="n">sample_text</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sample_output</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">char_to_idx</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="n">start_pos</span><span class="p">]],</span> 
                                                 <span class="mi">200</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">sample_text</span><span class="p">)</span>

            <span class="n">num_iter</span> <span class="o">+=</span> <span class="mi">1</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>텍스트 파일과 모델을 전달받아 이어지는 글자를 예측하는 트레이너 입니다.</p>
<p>자연어 관련 실습을 하기 위해 가져온 트레이너이기 때문에 자세한 설명은 생략하겠습니다.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-python"><pre><span></span><span class="n">layers</span> <span class="o">=</span> <span class="p">[</span><span class="n">RNNLayer</span><span class="p">(</span><span class="n">hidden_size</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="mi">62</span><span class="p">)]</span>
<span class="n">mod</span> <span class="o">=</span> <span class="n">RNNModel</span><span class="p">(</span><span class="n">layers</span><span class="o">=</span><span class="n">layers</span><span class="p">,</span>
               <span class="n">vocab_size</span><span class="o">=</span><span class="mi">62</span><span class="p">,</span> <span class="n">sequence_length</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
               <span class="n">loss</span><span class="o">=</span><span class="n">SoftmaxCrossEntropy</span><span class="p">())</span>
<span class="n">optim</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">(</span><span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">gradient_clipping</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">trainer</span> <span class="o">=</span> <span class="n">RNNTrainer</span><span class="p">(</span><span class="s1">&#39;input.txt&#39;</span><span class="p">,</span> <span class="n">mod</span><span class="p">,</span> <span class="n">optim</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="mi">1000</span><span class="p">,</span> <span class="n">sample_every</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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
" />
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>haglaw ahd Fh wo:&#39;ZiNJyFB yPsiEIiw :O woreyVVklEer y chimulmwofeoyTid?Phee
IQSFZUinl;QhJvkP ikQw;KtUe
;khoahort fhaonZgb!ugor.;;wlZA oa;eyDbiT
 NlhbmoeLe Pneeh&#39;by,ne ajburPtUs zY xar ary
jIsuor.wZwTDH
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>간단한 실습을 해봤습니다. 사실 자세한 내용은 잘 이해가 안되는데 직접 구현한 코드로도 실제 실습이 된다는 점을 중요하게 생각하겠습니다.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="&#45712;&#45184;&#51216;">&#45712;&#45184;&#51216;<a class="anchor-link" href="#&#45712;&#45184;&#51216;"> </a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>코드는 엄청 길지 않은데 진짜 이해하는데 한참걸렸던 것 같습니다.</p>
<p>RNN, 순환 신경망. 재사용한다는 것 까진 알겠는데 뭐가 어떻게 재사용이 되서 시계열, 자연어 처리에 쓰이는데? 하는 의문을 가졌는데요.</p>
<p>100% 해결했다라고 자신있기 말하진 못하겠지만 어느정도 느낌은 받았던 것 같습니다. RNN 구조에 대해 직관적으로 머리 속에 들어온 것 같아요.</p>
<p>특히 RNN 층 관련 내용 학습할 때, 긴 시간 씨름하다 이해가 됬을때 정말 기뻤습니다. 또 자동미분부분도 재밌게 했던 것 같아요.</p>

</div>
</div>
</div>
</div>



  </div><script src="https://utteranc.es/client.js"
        repo="KSY1526/myblog"
        issue-term="pathname"
        theme="github-dark"
        crossorigin="anonymous"
        async>
</script>
  <a class="u-url" href="/myblog/book/jupyter/deep%20learning/matrix/math/class/2022/01/27/FirstDeep4.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/myblog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/myblog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/myblog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>다양한 머신러닝/딥러닝 코드들이 기록되어 있습니다.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li>
  <a rel="me" href="https://github.com/KSY1526" target="_blank" title="github">
    <svg class="svg-icon grey">
      <use xlink:href="/myblog/assets/minima-social-icons.svg#github"></use>
    </svg>
  </a>
</li>
</ul>
</div>

  </div>

</footer>
</body>

</html>
